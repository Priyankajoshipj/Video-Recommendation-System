#id,type,language,parent_id,rec_date,pub_date,name,description,slide_titles
4622,'lecture','en',4620,'2005-09-08','2009-11-04','Lecture 1: The Origins of the Space Shuttle',NULL,'The Shuttle Origin;;Space shuttle (1);;Space shuttle (2);;Pre Lunar Landing Planning;;Initial Public Awareness;;Meanwhile, the Budget Crash;;NASA Strategy - 1970;;The Concept for a Shuttle;;The Technology Development 1950 - 1970;;Burnelli Lifting Body;;Evolution of the Shuttle 1969 - 1970;;Meanwhile, the Mission Model;;Evolution of Requirements (mostly from Military Requirements);;Space Shuttle;;Evolution II;;The Mathematical Study;;Resulting Program (1);;Resulting Program (2);;Design Issues;;Design Issues cont\'d;;Operation Costs (1);;Operation Costs (2);;Shuttle Performance;;Spacecraft are not like Airplanes;;So, for the next program;;The End;;The Shuttle Origin or\nThe Making of a new Program\n by Dale Myers;;Pre Lunar Landing Planning\n2/61-10/68 Jim Webb didn’t want future\n plans—wanted to keep options open\n  3/69-9/70 Tom Paine never saw a future plan he didn’t like  1/64-10/68-Lots of lifting body work\n  10/68-early 70 NASA dreamed of ever increasing budgets, and planned accordingly;;Initial Public Awareness\nAgnew Study- with Bob Seamans, Tom Paine, Lee Dubridge Supported by NASA’s ideas\n30 ft Diameter, 12 man Space Station\n2 in earth orbit, one in Lunar orbit Lunar Base 100-150 flights per year\nTwo stage fully recoverable Shuttle\nSkyLab with 5 visits by Command Modules\nContinue Saturn 1b and Saturn V production\nSpace tug for higher orbits than LEO Nuclear stage for Moon and Mars Mars program by 1983;;Meanwhile, the Budget Crash\nEuphoria of 1968 followed by severe cuts\n  Vietnam, Great Society budget deficits were causes, Nixon not a big supporter  1966 MSF budget=$3.8B, 1972=$1.7B\n  Was there going to be a human space program at all?  Mueller leaves in late 1969  Paine leaves in late 70 (Low acting Admin.)\n  Myers (1/70) and Fletcher (4/71);;NASA Strategy-1970\nShuttle is first priority, because low cost to space will encourage all the Agnew Report items later Start 2 stage Shuttle Phase B, and\nCancel Apollo 18 and 19 and Saturn 1b and V Cancel 2nd Skylab and CSM’s Cancel 30 ft. Space Stations Don’t start Space Tug Don’t start Nuclear Stage Cancel Mars program\nIndustry down from 400,000 to 150,000;;The Concept for a Shuttle\nReusability equals low cost\n“you wouldn’t fly to New York and throw away the airplane”\nSince R & D is higher, need many flights to beat ballistic systems  The lower the R & D the less flights needed to beat ballistic systems  If flights are many (because cost/flight is so low) a two stage, fully reusable system is right;;The Technology Development\nBurnelli lifting body\n X-20 Dynasoar delta wing HL-10 Lifting body X-24A-Lifting body X-15-Winged, internal fuel X-15-Winged, internal and external fuel\n Navaho M=3 parallel tank separation;;Burnelli Lifting Body;;Evolution of the Shuttle\nFully reusable two stage Straight wing, like an X-15\nInternal fuel  Metal shingles (or unobtainium or some ablative)  20000 lb. payload, due east  Payload bay 12X40?  400 miles crossrange  100 to 150 flights/year  $5 Million/flight in 1970 dollars;;Meanwhile, the Mission Model\nWhen the Space Station, lunar base, etc. disappeared, we needed more payloads (50+/year)\nMilitary agreed to put all payloads on Shuttle if we increased payload and designed for 1500 miles of crossrange, and met our cost/flight estimates.  Commercial agreed to carry all payloads on Shuttle (assumed we would develop a low cost upper stage and meet cost/flight estimates).  Science bought space servicing (i.e. Hubble) and a low cost reusable platform;;Evolution of Requirements (mostly from Military Requirements)\nPayload increased to 40,000 lbs Polar Crossrange increased to 1500 miles Payload bay increased to 15 by 60 Non ablative reusable thermal protection Two fully recoverable piloted stages Automatic checkout and 30 day turnaround;;Evolution II\nPhase B showed Development of two stage fully recoverable Shuttle costs $14B for R&D Nixon says “Build any shuttle you want as long as it doesn’t cost more than $5B” OMB says “make it cost effective” NASA looked for alternatives with new Phase A\nSingle Stage to orbit Trimese X24B surrounded with tanks External Orbiter tanks Parallel or series booster;;The Mathematica Study\nTo convince OMB, Nixon and Congress\nWe hired Mathematica to do cost effectiveness study Delta wing for crossrange Weight increase for military payloads 15 x 60 payload bay (15 for Space Station, 60 for military) 40,000 lb. payload, polar Parallel External throwaway monocoque tank 2 Recoverable, abortable solids Liftoff thrust augmentation with engines in Orbiter\nResults showed today’s configuration best;;Resulting Program\n Nixon Start on Jan. 5, 1972 5 Orbiters\nReusable Orbiter and engines, reusable solid cases, expendable fuel tank  40 to 50 flights per year  $10M-$15M per flight in 1970$  $5.2B+20% reserve for R & D in 1970$*\n*As soon as Nixon left office, OMB forgot the 20% reserve NASA Comptroller (pressed by OMB) didn’t agree to 1970 base;;Design Issues\nStraight vs Delta wing\nDelta wing required for crossrange\nExternal much lighter. Fuel transfer difficult Ceramic tiles, carbon-carbon and blankets Solids looked more reliable and cheaper R&D Start on ground safer, better performance Staged combustion better performance\nExternal vs internal tank(s)\nThermal Insulation\nSolids or liquid booster\nEngine location and type\nRetractable turbojets\nNo--Depend on low L/D landings Series heavy, less performance\nSeries vs parallel boosters;;Design Issues cont’d\n2 Solids vs. 1 or 2 Liquid strapons\nTwo solids could be shipped by rail Solids had a better reliability record Solids could be recovered (industry studied pressure fed) Designers thought they could turn off solids.\nLater found they could not\nCeramic tiles, carbon carbon, and external insulation blankets (all new)\nHigh pressure staged combustion engine (new) Crew escape. (Only with complete structure) Operations Costs;;Operations Costs\nEnormous confidence from the Apollo program Studies by American Airlines, IDA and the Aerospace Corporation nearly confirmed NASA operations costs NASA thought they had enough reliable, space based hardware in the industry to support quick turnaround, easy to maintain hardware NASA did not properly account for costs associated with:\nPost flight maintenance\nAssuring safety of flight in a hostile environment Difficult cutting edge technology (Engine and Thermal) FO/FO/FS Cost tradeoffs between R & D and Operations;;Operations Cost\nIn 1970, $10M/flight price was based on same accounting system used for Apollo-hands on only, with a separate account for overhead. With $400M/year overhead, and inflation according to the consumers price index, cost per flight would be: 1981 $23M $45M $135M 2005 $50M $101M $302M\n1970 40 flts/year, no overhead $10M 40 flts/year, include ovhd. $20M 8 flts/yr, include overhead $60M;;Shuttle Performance\nThe Shuttle has done everything it was designed to do. It has delivered Military, commercial, and scientific payloads to LEO and GEO, retrieved and replaced satellites, repaired spacecraft, and launched elements of the Space Station In the 80’s, shuttle had 4% of launches, 41% of mass launched Shuttle R&D was within what Nixon and Fletcher agreed. ($5.2B +20% reserve in 1970$) Missed two key design issues (cold O rings and foam shedding) Missed operations costs. A two stage reusable system would have missed worse. Spacecraft are not “like an airplane”.;;Spacecraft are not like Airplanes\nEvery flight is a “structural dive demo.”\n  No reusable space system gets millions of hours of stressed operation  No reusable space system develops decades of evolutionary model improvement  Every reusable system is exposed to\n enormous environmental variations\nThermal, vibration, pressure, Mach Number;;So, for the next program\nKeep it simple. Don’t stretch the technology Use good margins of safety Keep it as small as possible  Carry as few passengers as possible  Carry people or cargo, not both  Keep requirements to a minimum Use as many past components and systems as have been proven reliable Design for operations  Easy access, one man can replace boxes, etc.  Keep a program design reserve to reduce Ops. costs'
4623,'lecture','en',4620,'2005-09-13','2009-11-04','Lecture 2: Space Shuttle History',NULL,'Shuttle History;;Top Level Requirements;;Shuttle Studies (1);;Shuttle Studies (2);;Shuttle Studies (3);;Shuttle Studies (4);;Results of Studies;;Major Shuttle Configuration Decisions;;Orbiter Decisions (1);;Orbiter Decisions (2);;Hardware Sub-Systems;;Orbiter Sub-Systems;;Analytical Studies;;SHUTTLE HISTORY\n• 1952 FULLY REUSABLE LAUNCH VEHICLE CONCEPT DISCUSSED • 1962 FULLY REUSABLE VEHICLE SERIOUSLY CONSIDERED • AIR FORCE STUDIED PROJECT DYNASOAR, WHICH WAS CANCELLED IN 1969 • 1969 NASA ADOPTED THE IDEA OF A FULLY REUSABLE SPACE SHIP;;TOP LEVEL REQUIREMENTS\n• • • • FULLY REUSABLE 14 DAY TURN AROUND TO NEXT FLIGHT\n DEPLOY AND RETRIEVE PAYLOADS DESIGN, DEVELOPMENT, & TEST PHASE ESTIMATED TO BE 5.1B IN 1971 DOLLARS • ORIGINAL COST PER FLIGHT FOR 65,000 POUNDS WAS 10.5M PER FLIGHT IN 1971 $ FOR A FLIGHT RATE OF 60 PER YEAR;;SHUTTLE STUDIES\n• PHASE “A” STUDIES WERE CONDUCTED TO DETERMINE BASIC REQUIREMENTS AND THEIR EFFECT ON DESIGN IN 1969 • PRINCIPAL ISSUES:\n– SIZE AND WEIGHT OF PAYLOAD – CROSS RANGE OF THE ORBITER – HEAT-RESISTANT STRUCTURE OR REUSABLE INSULATING MATERIAL;;• PRINCIPAL ISSUES:\n– HYPERGOLIC REACTION CONTROL SYSTEM OR LIQUID OXYGEN/HYDROGEN – FLY- BY-WIRE FLIGHT CONTROL SYSTEM\n – WIND TUNNEL TESTS TO DETERMINE WING SIZE AND CONFIGURATION – AIR BREATHING ENGINES WERE CONSIDERED FOR FLY BACK; LATER WERE DETERMINED TO BE TOO HEAVY;;– ENTRY TECHNIQUES – LANDING SPEED – APPROACH PATTERN;;• PHASE “B” STUDIES WERE PERFORMED IN MID 1970’S TO DETERMINE A PRELIMINARY DESIGN • RESULTS:\n– FULLY RECOVERABLE ORBITER – DISPOSABLE FUEL TANK – PARACHUTE-RECOVERABLE SOLID ROCKET BOOSTERS – HIGH PERFORMANCE HYDROGEN-OXYGEN ENGINES PLACED IN THE ORBITER TO BE RECOVERED;;RESULTS OF STUDIES\n• FULLY REUSABLE WITH FLY-BACK BOOSTER WAS GREATER THAN 5.1B. • MANY CONFIGURATIONS WERE STUDIED (EXAMPLES) • TURN AROUND TIME REQUIRED LANDING A WINGED VEHICLE ON A RUNWAY • PAYLOAD DEPLOYMENT AND RETRIEVAL REQUIREMENT DETERMINED LOCATION OF ORBITER ON LAUNCH CONFIGURATION;;MAJOR SHUTTLE\n CONFIGURATION DECISIONS\n• HYDROGEN/OXYGEN MAIN ENGINES\n • THIS SIZED THE LIQUID OXYGEN/HYDROGEN TANK, WHICH IS NOT REUSABLE • SOLID ROCKET BOOSTERS PROVIDED THE ADDITIONAL PROPULSION REQUIRED TO GET THE ORBITER INTO EARTH ORBIT • SOLID ROCKET BOOSTERS DESIGNED TO BE RECOVERED AND RE-USED;;ORBITER DECISIONS\n• ORBITER ENTRY CROSS RANGE REQUIRED DELTA WINGS • DELETION OF AIR BREATHING ENGINES\n FOR MOVING ORBITER REQUIRED THE\n BOEING 747 TO CARRY THE ORBITER\n • FO/FS GUIDANCE, NAVIGATION, AND CONTROL SYSTEM • FLY- BY- WIRE WITH A DIGITAL AUTO PILOT;;• SIZE OF PAYLOAD BAY 60 FEET LONG BY 15 FEET DIAMETER • SIZE OF CREW CABIN DEFINED TO BE OVER 2600 CUBIC FEET • PAYLOAD 65,000 POUNDS AT LIFT OFF AND 35,OOO POUNDS AT LANDING • THE ORBITER IS A LAUNCH VEHICLE,\n A SPACE CRAFT, AND AN AIRCRAFT;;HARDWARE SUB-SYSTEMS\n• • • • • • • • • THERMAL PROTECTION SYSTEM\n STRUCTURES SPACE SHUTTLE MAIN ENGINES\n HYDRAULIC, AUX POWER, FUEL CELLS. OMS, & RCS SYSTEMS GUIDANCE, NAVIGATION, AND CONTROL\n ENVIRONMENTAL CONTROL & LIFE SUPPORT IN CREW CABIN LANDING & MECHANICAL SYSTEMS\n COMMUNICATIONS ELECTRICAL POWER;;ORBITER SUB-SYSTEMS\n• MAJOR ISSUES\n– FUNCTIONS THAT ARE REQUIRED TO BE PERFORMED (FUNCTIONAL REQUIREMENTS) – PERFORMANCE THAT IS REQUIRED\n (PERFORMANCE REQUIREMENTS)\n – WEIGHT – INTERFACES – AVAILABLE TECHNOLOGY\n – SCHEDULE – COST;;ANALYTICAL STUDIES\n• AERODYNAMICS • AEROTHERMODYNAMICS'
4624,'lecture','en',4620,'2005-09-15','2009-11-04','Lecture 3: Orbiter Sub-System Design',NULL,'Orbiter Sub-System Design;;Auxiliary Power Unit Subsystem Schematic;;Hydraulic Actuator Systems;;ase05_cohen_ossd_Page_04;;Guidance, Navigation and Control Subsystem Hardware Configuration;;ase05_cohen_ossd_Page_06;;ase05_cohen_ossd_Page_07;;Hydraulic Systems;;Orbiter structure;;Final Design Refinement - 1972-1973;;ase05_cohen_ossd_Page_11;;Lift off;;Space Shuttel Nominal Mission Profile;;Space Shuttle System;;ase05_cohen_ossd_Page_15;;Thermal Protection System;;Orbiter Sub-System Design\nProf. Aaron Cohen MIT 16.885J'
4625,'lecture','en',4620,'2005-09-20','2009-11-04','Lecture 4: The Decision to Build the Shuttle',NULL,'ase05_logsdon_dbs_Page_01;;ase05_logsdon_dbs_Page_02;;ase05_logsdon_dbs_Page_03;;ase05_logsdon_dbs_Page_04;;ase05_logsdon_dbs_Page_05;;ase05_logsdon_dbs_Page_06;;ase05_logsdon_dbs_Page_07;;ase05_logsdon_dbs_Page_08;;ase05_logsdon_dbs_Page_09;;ase05_logsdon_dbs_Page_10;;ase05_logsdon_dbs_Page_11;;ase05_logsdon_dbs_Page_12;;ase05_logsdon_dbs_Page_13;;ase05_logsdon_dbs_Page_14;;ase05_logsdon_dbs_Page_15;;ase05_logsdon_dbs_Page_16;;ase05_logsdon_dbs_Page_17;;ase05_logsdon_dbs_Page_18;;ase05_logsdon_dbs_Page_19;;ase05_logsdon_dbs_Page_20;;ase05_logsdon_dbs_Page_21;;ase05_logsdon_dbs_Page_22;;ase05_logsdon_dbs_Page_23;;ase05_logsdon_dbs_Page_24;;ase05_logsdon_dbs_Page_25;;ase05_logsdon_dbs_Page_26;;ase05_logsdon_dbs_Page_27;;ase05_logsdon_dbs_Page_28;;ase05_logsdon_dbs_Page_29;;ase05_logsdon_dbs_Page_30;;ase05_logsdon_dbs_Page_31;;ase05_logsdon_dbs_Page_32;;ase05_logsdon_dbs_Page_33;;ase05_logsdon_dbs_Page_34;;ase05_logsdon_dbs_Page_35;;ase05_logsdon_dbs_Page_36;;ase05_logsdon_dbs_Page_37;;ase05_logsdon_dbs_Page_38;;ase05_logsdon_dbs_Page_39'
4626,'lecture','en',4620,'2005-09-22','2009-11-04','Lecture 5: Orbiter Structure + Thermal Protection System',NULL,'Orbiter Structure and Thermal Protection Systems (TPS);;Credits and Recognition;;The Systems Engineering (SE) Process;;The Systems Engineering Process (con\'t);;Orbiter Structure;;Concept Studies (1968-1972);;Study Variables;;Shuttle Study Parameters Significant to Structural and Thermal Engineering;;Early Shuttle Configurations;;Selected MCS Configurations;;Final Concept;;Concept Definition;;Space Shuttle Configuration;;Beginning Design, Development, Test and Evaluation (DDT&E);;Challenges for the Definition Phase;;Orbiter Structural Design Criteria;;Combined Stress Criteria;;ase05_moser_ost_Page_18;;Airframe Material;;Structure and TPS Weights and Costs;;Crew Module (Cabin) Design;;Crew Module Concept;;Accounting for Thermal Stress;;Accounting for Thermal Stress (con\'t);;Accounting for Thermal Stress (con\'t);;Compartment Venting;;Major Structural Concept Trades;;Structure Configuration;;Design Loads;;Nominal Shuttle Mission;;Lift-Off Loads (1);;Lift-Off Loads (2);;Ascent;;Ascent Loads;;Ascent Loads Envelope (Squatchaloids);;Benefits of the Squatchaloid Approach;;Descent Loads;;Descent Loads Criterion;;Detailed Design;;Challenges for Detaild Design;;Weight Reduction;;Structural Materials;;Structural Certification;;Ultimate Strenght Integrity;;Static Test Article - Challenger;;Fatigue Life Integrity;;Acoustic Fatigue Tests;;Thermal Protection System;;Concept Definition;;Requirements;;TPS Options;;Structure and TPS Weight and Cost;;Acreage TPS Materials;;33,000 TPS Articles;;Leading Edge TPS;;Tile Design;;Detailed Design;;Challenges;;Combined Designed Loads;;Structural Deformation and Pressure Induced Stress;;Tiles Stress Allowables;;Analitical Tile Factors of Safety;;Verification of Flight Tiles;;Tile System Acceptance Logic;;Operations;;Flight Experience/Ops Modification;;MIT System Engineering Challenges;;Chalenges for the MIT Systems Engineering Study;;Review of the \n Design and Development \nOrbiter\n Structure and Thermal Protection \n System (TPS) \nTom Moser September 22, 2005\nMIT Lecture 1;;Credits and Recognition\nThe successful design of the Structure and TPS is in large part because of • The leadership, support, and commitment of – John F. Yardley – NASA Associate Administrator for Spaceflight – Chris C. Kraft, Jr. – Director of NASA Johnson Space Center – Max Faget – Director of Engineering, NASA JSC – Robert F. Thompson – Manager, Space Shuttle Program – Aaron Cohen – Manager, Orbiter Project The many dedicated engineers and authors of the technical papers (provided) – “Orbiter Structural Design and Verification”, P.C. Glynn and T.L. Moser – “Strength Integrity of the Space Shuttle Orbiter Tiles”, T.L. Moser and W.C. Schneider – “Reliability Engineering of the Space Shuttle: Lessons Learned”, T.L. Moser – “Structural Load Challenges During Space Shuttle Development”, A.C. Mackey and R.E. Gatto – “Shuttle Structural Dynamics Characteristics”, C.T. Modlin and G.A. Zupp;;The Systems Engineering (SE) Process\n• A thorough and in-depth Systems Engineering effort is critical to the success of any complex development program, especially where technology advancement is required. • The Space Shuttle Program is an excellent case study\n • In the SE process, structural engineering is an important element, and is the SE element for which this lecture focuses.;;The Systems Engineering Process (con’t)\n• Structural engineering parameters assessed during each phase of the Shuttle design and operations process\n– Concept Studies – weight, cost, producibility – Concept Definition – weight, cost, producibility – Preliminary Design – detail design trades- configuration, weight, cost, – – – – \nproducibility and operations Critical Design – same as PD but emphasis on weight, cost, and flight certification plans. Production – weight management, anomaly resolution consistent with design requirements Certification – design and/or operations modifications Operations – determining operations flexibility within the capabilities of the structure\nMIT Lecture;;Orbiter Structure;;Concept Studies\n (Conceiving and characterizing\n (qualitatively and quantitatively) the\n concepts that would serve as a\n Space Transportation System);;Study Variables\n• • • • • • • • Earth-to-Orbit Transportation System Multi-year budgets Development and ops costs Payload mass and size (delivery and return)\n Operational orbits Fully or partially reusable flight systems Turn-around time Entry cross-range\nMIT Lecture 7;;Shuttle Study Parameters Significant to Structural and\n Thermal Engineering\n• Initial Performance requirements that were structural and TPS drivers: – Reusable Space Flight System – Payload size for delivery and return – Cross-range for landing – Low development and recurring costs, and peak annual costs\nStructural evaluation parameters\n– – – – – – – – – – Load path efficiency Weight Payload size Aerodynamic surface loading Peak temperatures Heat rate and load Technology readiness Producibility and operability Reliability Cost;;Early Shuttle Configurations\nNASA JSC (formerly MSC) conceptually designed\n 53 Orbiters in a “skunk works” from ’70 to ’72\n• • • • • Payloads: 15K to 40K lbs.; 8’ to 15’ dia.; 30’ to 75’ long Orbiter wings: Straight to 60 deg. Delta; Double Delta Landing weights: 70K to 215K lbs. Boosters: Fully reusable; Partially reusable: Expendable Propulsion System: LH2 and LOX; Air Breathers; Pump fed and Pressure fed; • Propulsion Tanks: Internal to Orbiter, External to Orbiter, Expendable\nFor each configuration, the Structural Parameters on the previous page were quantified for assessment.;;Selected MSC Configurations;;Final Concept\n• Two and one half stage launch vehicle • Reusable Orbiter\n– – – – – – Delta wing 100 mission life Ascent - 3g max acceleration and max. q = 650psf Atmospheric flight – +2.5g/1.0g Crew of four for one week Payload\n• • • • 65,000 lbs. delivery, 40,000 lbs. return 15’Dia x 60’ Length Up to 5 Payloads /mission Deployable\n– 1265 mile cross range during entry – TPS material not defined;;Concept Definition\n(Ready to proceed to Preliminary Design\n July 1972)\nMIT Lecture;;Space Shuttle Configuration;;Beginning Design, Development, Test and\n Evaluation (DDT&E)\n• Four years of NASA in-house and contracted studies resulted in the configuration and top level requirements that were structure drivers, e.g.\n– – – – – – – Orbiter Life - 100 missions Payload – 65K lbs., 15’dia.x 60’lg, 1 to 10 1265 mile cross range (entry to landing) Max. aero dynamic pressure, q=650 psf Max. ascent acceleration, 3 g’s Re-entry maneuvers, 2.5 g/-1.0g limit Rationale loss of one SSME during ascent\n• The challenge was to not over specify the structural requirements in order to enable flexibility and authority for the contracted DDT&E\nMIT Lecture 14;;Challenges for the Definition Phase\n• Detailed Design criteria • Airframe material • Structural design\n– Integral or floating cabin – Accounting for Thermal Stress\n – Compartment venting – Major Structural Concepts Trades\n• Design Loads;;Orbiter Structural Design Criteria\n• Ultimate Factor of Safety = 1.4 for limit load (maximum expected loads) • Yield F.S. – not specified (no detrimental deformation allowed for limit loads) • Thermal and mechanical stresses to be additive except when thermal stress is relieving • Life -100 missions with a scatter factor or 4, all parts considered for fracture mechanics • Ultimate F.S.=1.25 at the end of life • Material allowables\n– 95 percentile and 95 percent confidence for single load paths – 90 percentile and 95 percent confidence for redundant load paths;;Combined Stress Criteria\n• An unprecedented criterion was established for combining stresses to\n– Assure determining a realistic maximum \n expected stress \n – Avoid reducing stress because of thermal gradients – Incorporate classical tank pressure induced stress\nMIT Lecture;;MIT Lecture ;;Airframe Material\n• Systems studies showed that the weight of structure plus TPS was approximately the same (p.20)\n– Based on allowable max. temp., heat sink, and unit weights\n• Aluminum was selected based\n– Producibility and material properties data base – SR-71 (Titanium – “Black Bird”) experience\n – Beryllium manufacturing difficulty.\nMIT Lecture;;Structure and TPS Weights and Costs\nMIT Lecture ;;Crew Module (Cabin) Design\n• Pressure integrity of the Cabin was critical for crew safety and had to be verified prior to each flight. • A “floating” design (p.22) isolated the Cabin from the fuselage loads, simplified the design and increased reliability. • The Cabin design weight was 30K lbs. based on Apollo densities and growth.;;Crew Module Concept\n•Pressure vessel design •Four discrete attachment points with the forward fuselage •Minimum heat transfer to Crew Module •Fracture mechanics – leak before rupture\nMIT Lecture;;Accounting for Thermal Stress\nIssue:\n • Desensitizing the structural design for thermal stress was not practical (based on SR-71 and Concorde experience). • Areas effected by thermal gradients\n– – – – – – between skin-stringer panels and frames or ribs between upper and lower wing covers circumferentially around frames between lower surface and side skin panels between the wing and fuselage and tail and fuselage Within skin-stringer panels\n• Not possible to represent the entire structure with a 3-D finite element model for temperature and loads\nMIT Lecture 23;;Accounting for Thermal Stress (con’t)\nApproach:\n • Determined the temperatures on the vehicle for eight initial conditions for entry and at several times during entry • Analyzed 100+ models for various regions of the vehicle and extrapolated to the entire structural model (p.25) • The operational planners had to ensure that the\n operational envelope stayed within the budget.;;Compartment Venting\n• Previous spacecraft design would have connected the entire volume and vented it through base vent areas. • The Orbiter design precluded this approach because of contamination and cleanliness of the payload bay and the potential hazards of hydrogen concentration. • Extensive analyses were required because of the pressure coefficients at the vents, pressure differential across bulkheads, and to define critical combinations of venting parameters.;;Major Structural Concept Trades\n• SSME Thrust Structure: Space frame vs. plate girder\nsaved 1730 lbs. of weight\n• Aft Wing Spar carry-through: Integrating with the aft\n(1307) bulkhead vs. a floating carry through saved 450 lbs. of weight\n• Payload bay doors: Designed for torsion and\npressure loads only (not body bending) to enable doors to be flexible and “zipped” closed prior to re-entry, or maximum reliability for opening and closing in space.\n• Payload attachments: Designed to be statically\ndeterminate so as to preclude load sharing based on the relative stiffness of Orbiter and payload(s).;;Structure Configuration\nMIT Lecture;;Design Loads;;Nominal Shuttle Mission;;Lift-Off Loads\n• Determined by a statistical combination of:\n– Rocket engines\n• Start Sequence • Thrust vector misalignment • Ignition overpressure\nGround winds and gusts Vortex shedding Proximity to nearby structures Pressurization Shrinkage of structure because of cryo temps.\nMIT Lecture 31;;MIT Lecture;;Ascent;;Ascent Loads\n• Surveying the entire flight envelope to determine critical conditions for hardware design was cumbersome and not practical • Innovative approach:\n– Developed synthetic wind profiles using recorded data and guidelines – Determined angle of attack and sideslip by analytically flying the vehicle (with control system) through the synthetic winds profiles – Added system dispersions (3 sigma) such as SRB thrust mismatch, aerodynamics, thrust variations, flight control system variations – Generated an envelope of side slip and angle of attack was generated (similar to an aircraft V-n diagram) – Generated design loads at any point around the “squatcheloid” envelope (p. 35).\nMIT Lecture 34;;Ascent Loads Envelope (Squatchaloids)\nMIT Lecture;;Benefits of the Squatcheloid Approach\n• Load indicators were established for hundreds of conditions within the envelope that could be used for trajectory analyses • SSME thrust structure were designed for realistic conditions rather than a worst case • Allowed the performance, flight control, and\n structures disciplines to work in parallel.\nMIT Lecture 36;;Descent Loads\n• Entry simulations using ballistic trajectories did not require any significant maneuvers and therefore no meaningful “design to” envelopes. • Structural design was based on Mach number dependent V-n diagrams (p.38) • Max. speed, equivalent to 375 psf, was derived from upsetting the nominal trajectory and recovering within the entry control limits. • The criterion came under serious challenge because the deterministic flight conditions could not justify the many descent cases. • The criterion was found to be logical and set a precedent\n for deviating from deterministic ballistic load definition.;;Descent Loads Criterion;;Detailed Design\n(Completing the design and\n establishing flight certification\n plans)\nMIT Lecture;;Challenges for Detailed Design\n• Weight reduction • Ground Certification for first flight;;Weight Reduction\n• As with any aircraft or spacecraft, weight control/management is a major effort and requires a weight reduction effort – no different for the Orbiter. • Weight reductions:\n– Payload bay doors – 900 lbs. - Changing from Aluminum to Graphite/Epoxy (limited knowledge) – Thrust Structure – 1200 lbs.(?) – Titanium stiffened with Boron/Epoxy for increased compression modulus – Other use of composite materials (p.41)\nMIT Lecture 41;;Structure Materials\nMIT Lecture;;Structural Certification\n(Deviating from the “norm”\n and Innovation);;Ultimate Strength Integrity\n• Consistent with classical airframe certification, the Orbiter Project planned for a dedicated Static Test Article. • Situation:\n– Most of the primary structure had significant thermal stress components. Attempts to factor mechanical loads to induce equivalent thermal stress resulted in inconsistent stress distribution. – Combining mechanical loads and thermal environment (ala Concorde testing) was not practical – The Project had a $100 million funding short-fall\n• Solution:\n– Apply 110% of limit mechanical loads to an airframe – Predict the strain response to verify the structural analyses – Extrapolate to 140% of mechanical load and add thermal stress to demonstrate ultimate load capability – Refurbish the airframe as a flight vehicle (Challenger) to save $100 M. – The approach passed an independent review of “wide body aircraft” experts.\nMIT Lecture 44;;Static Test Article- Challenger\nMIT Lecture;;Fatigue Life Integrity\n• Consistent with classical airframe certification, the Orbiter Project planned for a dedicated Fatigue Test Article. • Situation\n– A short life of 100 missions did not indicate low- cycle, high-stress being critical for integrity – High acoustic levels (p. 47) did indicate that high-cycle, low-stress was critical for integrity – How to certify a large, complex, multi-material, multi-configuration structure with multi-combinations of mechanical and thermal loads at high acoustic levels.\n• Solution\n– Test representative structure (p.47) acoustically to failure to determine the acoustic fatigue damage allowable – Size the test articles so only one third of the specimen was the test region – two thirds was compromised for boundary conditions. – Adjust the determined allowable for the effect of flight loads and elevated temperature.\nMIT Lecture 46;;Acoustic Fatigue Tests\nMIT Lecture;;Thermal Protection System;;Concept Definition\n(Ready to proceed to Preliminary Design\n July 1972);;Requirements\n• Protect the structure from maximum temperatures of 2800 deg. F • Reusable for 100 missions\n • Light weight • Cost effective;;TPS Options\n• The US had re-entry vehicle experience with\n– ablative TPS (Mercury, Gemini, and Apollo) – not reusable – “hot structure” designs (up to 800 deg. F) – complex design – metallic TPS (up to 2800 deg. F) – oxidation\n• NASA and contractor Lockheed developed a fibrous silica material with 2500 deg. F capability – fragile and low strength\nMIT Lecture 51;;Structure and TPS Weights and Costs;;Acreage TPS Materials;;30,000 TPS Articles\nMIT Lecture;;Leading Edge TPS;;Tile Design\nMIT Lecture ;;Detailed Design\n(Completing the design and\n establishing flight certification\n plans)\nMIT Lecture;;Challenges\n• Tile material (silica) deformation at high temperature\n– Solution: Control purity of material\n• Assuring strength integrity of 25,000 (low strength) Tiles for complex combined loads • Inadequate bond line strength of LI-900 Tiles\n • Certification Tests • Assuring the integrity of installed tiles.;;Combined Designed Loads\nNote the absence of debris impact;;Structural Deformation and Pressure\n Induced Stress\nStructural Deformation Pressure Distribution;;Tile Stress Allowables\nSIP Local Stiffness reduced effective Tile strength By 50% Allowable Stress vs. Structural Deformation\nMIT Lecture ;;Analytical Tile Factors of Safety\nMIT Lecture;;Verification of Flight Tiles\nIssues:\n • A large number of densified and undensified tiles installed, both critical and non-critical tiles (loss of one catastrophic), and some fail-safe. • Needed to quickly demonstrate the required\n strength integrity. Solution: • Proof load test each tile to 125% of flight load, or\n • Demonstrate by other methods that adequate strength existed\nMIT Lecture 63;;Tile System Acceptance Logic\nMIT Lecture;;Operations;;Flight Experience/Ops Modifications\n• Rigorous and innovative engineering and testing enabled the Orbiter Structure and TPS to perform successfully for design-to flight environments (not including debris). • Surprises on STS-1\n– Overpressure on the vehicle because hydrogen gas accumulation – Center of pressure on the wing was further outboard and aft than predicted (because of SRB plume effect on pressure distribution) – Tile damage from debris\n• Operations Changes\n– Hydrogen accumulation was contained and burned prior to SSME ignition – Ascent profiles were tailored to stay within the wing structural allowables modifying ascent trajectories and SSME thrust. Later day-of-launch winds were used to predict wing loads and increase the probability of launch.\n• Design Changes\n– The ET foam insulation process was modified;;MIT System Engineering\n Challenges;;Challenges for the MIT Systems\n Engineering Study\n• What different evaluation parameters, criteria, and analytical tools would you use during each phase of development and operations? • What are the analytical tools are available today that were not available then, and what is the significance? Especially consider a combine thermal and structural model. Thermal stress is important. • Are there thermal protection systems that could withstand the same environment as the Shuttle but that would be more damage tolerant? • Would you design a separate crew escape system? Would this be the most reliable system for crew safety, or would it better to make the entire system more reliable? • How would you “fix” the ET Insulation debris/Orbiter TPS problem? • How important is “political systems engineering” and should it be a consideration for an entire program or even for a crew escape system?'
4627,'lecture','en',4620,'2005-09-27','2009-11-04','Lecture 6: Propulsion - Space Shuttle Main Engines',NULL,NULL
4628,'lecture','en',4620,'2005-09-29','2009-11-04','Lecture 7: Aerodynamics - (From Sub - to Hypersonic and Back)',NULL,NULL
4629,'lecture','en',4620,'2005-10-04','2009-11-04','Lecture 8: Landing and Mechanical Systems ',NULL,'Shuttle Orbiter Remote Manipulator System, Mechanical Systems;;Exploratory Development;;Exploratory Development - Concept Definiton;;Concept Development ;;Master - Slave Concept;;Determination of Concept Requirements;;Small Facility - Building 13 High Bay;;Larger Facility - Building 9A;;Payload Simulations - Inflatables;;Orbiter - Trunion Latches;;Orbiter Payloads - V Guide & Scuff Plate;;Hand Controllers - Manipulator;;Orbiter Remote Manipulator;;Orbiter RMS - Dimension & Joint Limits;;Manipulator System Retention System;;Orbiter Remote Manipulator System Avionics;;Orbiter Payload Bay;;Orbiter Flight Deck Work Station;;Orbiter Hand Controllers;;Payload Grapple Fixture - End Effector;;Backup - Failure Modes;;Concluding Remarks - Remote Manipulator system;;Shuttle Orbiter\n Remote Manipulator System\n Mechanical Systems;;Exploratory Development\n0 Shuttle Orbiter was designed with a capability to transport large Payloads 0 In general the concept was to bring varied payloads to various orbital altitudes and inclinations 0 Initial Orbiter configuration had a large payload bay with a significant payload capability – 65,000lbs, 15ft diameter, 60ft long. 0 Initial design did not define a concept for handling payloads 0 NASA resources were used to assure Shuttle Transportation System’s flight worthiness as prime objective 0 Manipulator Concepts were initiated in the early 1970’s – competed for resources with other programs: - Skylab - Apollo Soyez Test Project - Prime objective of Shuttle Transportation System;;Exploratory Development – Concept Definition\n0 NASA Centers explored many concepts – all had shortcomings 0 Most payload handling systems were designed to perform either deployment or retrieval tasks. None were proficient at both tasks. 0 Manipulators were contenders once requirements became more refined. 0 JSC - Spacecraft Design Division began to assign resources to understand the functions, design and operations of manipulators 0 Initial studies included use of available Atomic Energy Commission manipulators that were designed for remote handling of radio active items 0 Analyses indicated that exploratory hardware development was necessary 0 Objectives were to determine the mix of handling and design requirements;;Concept Development\n0 Initial test with master slave systems indicated that several design requirements were not compatible with ergonomics or available resources of the Orbiter Flight Deck - Large sweep volume was required - Ratcheting of master to change movement ratio 0 The tactile feedback was very desirable for dexterous operations 0 Available master-slave units were of small size; though dexterous, amplification to a large cargo handing system was marginal 0 During several tests, operators arm became tired 0 Master-slave concept was maintained for future testing – other control schemes analysis were initiated;;Master – Slave Concept\nYaw Joint Pitch Joint\nYaw Joint\nPitch Joint\nEnd Effector\nHand Controller Pitch Joint\nNotes: - Motion by the Master will replicated by the Slave - Movement by the Master will be amplified by the Salve - Joints and joining structures are proportional between the Master and Slave\nPitch Joint Yaw Joint\nPitch Joint\nMaster\nPitch Joint Yaw Joint\nRoll Out joint was needed To place Manipulator in operational Attitude\nSlave;;Determination of Concept Requirements\n0 Initial operations indicated that a larger system was needed to determine needed requirements 0 An industrial Manipulator was purchased to continue concept development - A G.E. hydraulic manipulator was located - It was formerly used by Pittsburgh Plate Glass Co. - 25 feet long used for moving plate glass - Master-Slave control system - Vacuum end effector 0 Several concept elements to be analyzed - Master-Slave/alternate concept - Feedback vs fixed hand controller - Viewing – line sight/TV - End effector configuration - Power source - Size, joint speed, tip speed - Payload/cargo handling - Satellite Capture and Retrieval;;Small Facility – Building 13 High Bay \n0 The larger manipulator required a much larger floor space to accommodate the initial development and anticipated growth-manipulator approx 30ft 0 Analysis indicated that an air bearing floor was needed 0 The Initial floor was about 25 ft by 30 ft in size; the floor was sufficiently smooth to accommodate: - Heavy weight payloads- air bearings - Stationary payloads - Free flying satellites- air bearings 0 Initial findings determined several requirements - Master-slave system was used but not optimum - Feedback was not a facilitator - Line of sight and TV would be required - No suitable end effector configuration was defined - End effector tip speed was defined - Moving satellites could be captured and retrieved - Analyses defined that an orbital hydraulic system was not optimum;;Larger Facility – Building 9A\n0 Larger facilities were required to develop and confirm requirements 0 As requirement developed, full scale Orbiter mockups were needed to prove scale integrity 0 In addition to the full scale Orbiter Trainers/Mockups, an entire building was fabricated to confirm manipulator proof of concept 0 A new smoother floor was fabricated – approximately 60ft x 40ft 0 Manipulator sized increased to simulate concept for Orbiter and installed in a full scale mockup – 50ft length with hydraulic to simulate electrical system 0 Large scale payloads were also needed 0 A complete retention system was also devised to hold the payloads 0 Analysis and design began to develop a fixed hand controller concept;;Payload Simulations - Inflatables\nLegend: Grapple Fixture\n15 ft\nTrunion Keel Fitting\n30 ft\n60 ft\nNote: - Inflatables were helium filled - Low weight/good inertia;;Orbiter – Trunion Latches\nTrunion Latch – Four Places\nActive Payload Retention System (V-Guides Not Shown);;Orbiter Payload - V Guide & Scuff Plate;;Hand Controllers - Manipulator\nRoll Joint Yaw Joint Pitch Joint\nEnd Effector\nYaw, Pitch, Roll Hand Controller Pitch,\nNotes: - Motion by the Master will replicated by the Slave - Movement by the Master will be amplified by the Salve - Joints and joining structures are proportional between the Master and Slave\nPitch Joint\nPitch Joint Yaw Joint\nRoll Out joint was needed To place Manipulator in operational Attitude\nSlave;;Orbiter Remote Manipulator\nRMS Jettison Subsystem\nMPM - Manipulator Positioning Mechanism MRL - Manipulator Retention Latch Note: RMS jettison interface is at base of MPM on longeron;;Orbiter RMS – Dimensions & Joint Limits;; nipulator System Retention System Ma;;Orbiter Remote Manipulator System Avionics;;Orbiter Payload Bay;;Orbiter Flight Deck Work Station;;Orbiter Hand Controllers\nTranslation Hand Controller (THC)\nRotational Hand Controller (RHC);;Payload Grapple Fixture – End Effector\nGrapple Fixture\nEnd Effector;;Backup – Failure Modes\n0 Backup Mode - Joint or electrical failure was most likely necessity for a backup mode - Single Joint mode - As implied, commands a single joint - This mode is computer supported - Direct joint mode - Commands single joint - Commands transmitted by hard wire 0 Jettison - Failure that would prohibit RMS operation - Would jeopardize safety - Non propulsive jettison is performed - Expedited Jettison is also available;;Concluding Remarks – Remote Manipulator System\n0 Though initial requirements were not well defined, the use of development concepts and hardware did enhance a workable system 0 Use of available technology and equipment expedited the derivation of the the flight design 0 Integration of the Crewman into the system did require adjustments in the the control system 0 Initial inflatable testing was crucial in determining feasibility and viability of the design 0 International cooperation was not a hindrance in Remote Manipulator development 0 The initial design though upgraded with improvements is still flying'
4630,'lecture','en',4620,'2005-10-06','2009-11-04','Lecture 9: OMS, RCS, Fuel Cells, Auxiliary Power Unit and Hydraulic Systems',NULL,'OMS/RCS/APU/HYDRAULICS;;OMC/RCS;;Requirements;;Development Program;;Differences between OMS and RCS;;APU/Hydraulics (1);;APU/Hydraulics (2);;MIT Lecture\nOMS/RCS\n APU/HYDRAULICS;;• • • • • Break into 2 sessions\n– OMS RCS first session / APU Hydraulics second\nTalk for about 30 minutes with 30 minutes for questions. Ask questions anytime. No lecture– I will throw a few things out and we will talk about them. Cover APU/ Hydraulics the same way. Cover the start of the Space Shuttle Program\n– – – – `Max Appointed Jim Chamberlain To head Study Group. I sent the best Engineer I had. He balked Quickly run through Many configurations\nUnderstand the impact of requirements very clearly\n Fail OP fail safe good buzz word but can make a system less safe.  I can make a case that a 2 engine aircraft is safer then a 4 engine aircraft because of the way requirements are written.;; Original requirements  Low cost of operations\n Oxygen/Hydrogen  Oxygen/ Methane  Oxygen/Alcohol\n Requirements changed to Low development costs\n OMS went to Bipropellant\n MMH?N204\n Lot of experience-Apollo Agena\n Performance—Long steady state burns\n RCS went to Monopropellant hydrazine\n Too Heavy—Weight in Back\n Changed to Bi Propellant MMH/N2O4;;• Development Program\n– Remember\n• It is not natural for Earth bound humans to think in terms of no gravity • It is not natural for earth bound humans to think in terms of the absence of pressure.\n– There is no substitute for a good test program\n• No vibration test\n– Had good structural programs » Helium bottle fell out during Vibration test.;;• Differences between OMS and RCS\n– OMS has few starts\n• Performance is critical\n– RCS thousands of starts\n• Very short (millisecond burns) to steady state burns of 500 or more seconds • Must operate over a wide range of mixture ratios and inlet pressures. • Dribble volume—effect of refrigeration—Helium saturation. • Effects of no gravity on Expulsion.\n• Questions:;;APU/Hydraulics\n• Will cover both Subsystems together because they are so closely related. • Like OMS/RCS went through many iterations\n– Fail op-fail op-fail safe VS fail safe – Big mistake to call APU Auxiliary Power unit\n• Should have been called PPU—Primary power unit.\n– Low Operational costs VS low development costs. – Power Requirements\n• Aero and Control people Want instant response.\n– Weight carried in someone else\'s budget.\n– Dual Tandem actuators – 4 VS 3 Systems – Hydraulics VS Electromechanical;;Power Source\n– – – – – – – Electric VS Turbine Hydrogen/Oxygen MMH/N2O4 Hydrazine Pressure modulated VS Pulse Modulated Absent of gravity on Gearbox development\n• • • Used gears to pump oil to sump Heat soaked to valve in vacuum. Added water spray for several flights\nTurbine Development\nAbsent of air and gravity on gas Generator development.\nHydraulics\n– Hydraulics mostly off the shelf.\n• • Added bellows and pressure source to Hydraulic reservoir Added Water boiler to cool Hydraulic fluid.\n– First concept was to run the hydraulic fluid through a bucket of water.\nImportance of good test program and to think in terms of no gravity and no pressure. Questions.'
4631,'lecture','en',4620,'2005-10-13','2009-11-04','Lecture 10: The DoD and the Space Shuttle',NULL,NULL
4632,'lecture','en',4620,'2005-10-18','2009-11-04','Lecture 11: Use of Subsystems as a Function of Flight Phase',NULL,NULL
4633,'lecture','en',4620,'2005-10-20','2009-11-04','Lecture 12: Aerothermodynamics',NULL,'Entry Flight Regimes: Apollo and Orbiter;;Design and Flight Test Environments;;Design Heating Methodology;;Logic for Predicting Boundary Layer Transition on the Orbiter;;Surface Catalysis Flight Prediction Process;;Orbiter Flow Field Results;;Comparison of STS-3 Flight Data with Preflight Test Predictions: Forward Windward Centerline;;Comparison of STS-3 Flight Data with Preflight Test Predictions: Midbody Windward Centerline;;Comparison of STS-3 Flight Data with Preflight Test Predictions: Aft Windward Centerline;;STS-3, Orbiter Inferred and Predicted Heat Flux;;Leeward Surface Flight Data vs. Reynolds Number;;SA 201;;Entry Bondline Thermal Response, Midbody Windward;;Matrix of Understanding'
4634,'lecture','en',4620,'2005-10-25','2009-11-04','Lecture 13: Environmental Control Systems',NULL,'Shuttel Environmental/Thermal Control & Life Support System;;Outline;;Subsystem Elements - Cabin Atmospheric Revitalization;;Space Shuttle Atmosphere Revitalization Subsystem;;Atmospheric Revitalization Subsystem;;Atmospheric Revitalization Subsystem Test Facility;;Atmospheric Revitalization Subsystem Test Installation;;Cabin Atmospheric Revitalization (1);;Carbon Dioxide Absorber Test Results;;Cabin Atmospheric Revitalization (2);;Cabin Atmospheric Revitalization (3);;Cabin Atmospheric Revitalization (4);;Orbiter Air Distribution System;;Subsystem Elements - Cabin Atmospheric Pressure and Composition Control ;;Space shuttle Atmospheric Pressure and Composition Control Subsystem;;Atmospheric Pressure and Composition Control Subsystem;;Cabin Atmospheric Pressure & Composition Control (1);;Cabin Atmospheric Pressure & Composition Control (2);;Orbiter Cabin Test Facility;;Shuttle Cabin Test Facility;;Orbiter Cabin Test Facility Interior;;Typical Operation of Atmospheric Pressure and Composition Control Subsystem;;Cabin Atmospheric Pressure & Composition Control (3);;Typical Cabin Pressure Profile for 8 PSI Emergency Return;;Cabin Atmospheric Pressure & Composition Control (4);;Cabin Atmospheric Pressure & Composition Control (5);;Orbiter Cabin Pressure Profile for 9 PSI Operation;;Cabin PPO2 Profile for 9 PSIA to 14.7 PSIA Pressure;;Cabin and Closed Volumes PPO2 Profile for 9 PSIA to 14,7 PSIA Pressure ;;Avionics Test Bed Installation;;Cabin PPO2 Profile for 9 PSIA to 14,7 PSIA Pressure ;;Subsystem Elements - Water & Waste Management;;Water & Waste Management;;Space Shuttle Water and Waste Management Subsystem;;Portable Water;;Water and Waste Management;;Waste Management ;;Commode and Urinal;;Subsystem Elements - Cabin Thermal Control;;Space Shuttle Cabin Thermal Control Subsystem;;Cabin Thermal Control Subsystem;;Cabin Thermal Control System (1);;Cabin Thermal Control System (2);;Subsystem Elements - Spacecraft Active Thermal Control;;Active Thermal Control System;;ATCS (Simplified Flow Schematic);;Spacecraft Active Thermal Control Subsystem (1);;Spacecraft Active Thermal Control Subsystem (2);;Spacecraft Active Thermal Control Subsystem (3);;Spacecraft Active Thermal Control Subsystem (4);;Spacecraft Active Thermal Control Subsystem (5);;Rotating Equipment Life Test;;Orbiter Rotating Equipment Life Test Laboratory;;Functional Requirements;;Orbiter Cabin Test Facility with Airlock;;Airlock Test Facility with EVA;;Shuttle Environmental/Thermal Control & Life Support System\nW. Guy;;Shuttle Orbiter Environmental/Thermal Control & Life Support System • Cabin Atmospheric Revitalization Subsystem • Cabin Atmospheric Pressure and Composition Control Subsystem • Water and Waste Management Subsystem • Cabin Thermal Control Subsystem • Spacecraft Active Thermal Control Subsystem • EVA Airlock Support Subsystem;;Shuttle Orbiter Environmental/Thermal Control & Life Support System\nSubsystem Elements: • CABIN ATMOSPHERIC REVITALIZATION • CO2 and trace gas removal • Humidity control • Environmental cooling • Atmospheric circulation/ventilation;;Cabin Atmospheric Revitalization _______________________________ CO2 and Trace Gas Removal:\n< • CO2 Acceptable level = 7.6 mmHg • CO2 Absorption (from humidified cabin gas) • Absorbent: Lithium Hydroxide (LiOH) • LiOH + CO2 LiCO3 + H2O + heat\n• Single use (expendable);;Cabin Atmospheric Revitalization CO2 and Trace Gas Removal:\n• CO2 Absorption (from humidified cabin gas) • Absorbent: solid amine (polymerized ethyleneimine: RNH) • Absorb • Desorb\nRNH + H2O OH- + CO2 RNH+2 + OHHCO-3 + heat RNH + H2O + CO2\nRNH+2 + HCO-3+ heat + vacuum\n• Multi-use (regenerative);;• Trace gas removal • Activated charcoal • Single use (expendable)\nEnvironmental Cooling and Humidity Control:\n• Cabin atmospheric heat-exchanger • Condensing heat-exchanger • Centrifugal water/gas separator;;Cabin Atmospheric Revitalization Atmospheric Circulation/Ventilation:\n• Redundant cabin fans • Flight-deck and mid-deck duct system;;Shuttle Orbiter Environmental/Thermal Control & Life Support System\nSubsystem Elements: • CABIN ATMOSPHERIC PRESSURE & COMPOSITION CONTROL • 14.7 psia total pressure control (normal) • 8 psia total pressure control (emergency de-orbit) • O2/N2 partial pressure control • Crew O2 breathing masks • Positive and negative cabin pressure relief (anomaly) • Gaseous O2/N2 storage • Pressurization N2 for Water & Waste Management;;Cabin Atmospheric Pressure & Composition Control\nNormal Operations:\n• Total pressure control (gaseous N2) • 14.7 psia (“automatic” pressure regulator) • O2 partial pressure control (cryogenic O2) • 3.2 psia (“on-off” solenoid valve);;Cabin Atmospheric Pressure & Composition Control Cabin Pressure Relief:\n• Over pressure protection – 16.2 psid - 3 relief values (only two needed) • Negative pressure protection – 8 psid - 3 relief values (only two needed);;Cabin Atmospheric Pressure & Composition Control Crew Emergency Breathing Equipment:\n• Plug-in face masks • Purge-type breathing masks • For use with a contaminated cabin atmosphere • For use with a low concentration of O2 in cabin;;Cabin Atmospheric Pressure & Composition Control 9 psia Cabin Pressure Control for Pre EVA\n• Shuttle spacesuits operate on 100% O2 • Normally, ~four hours of 100% O2 pre-breath @ 14.7 psia > required to prevent “bends” • However, subsequent to 12 hours acclimatization at 9 psia, only a short pre-breath required • The short pre-breath (~ 30 minutes) is accommodated by suit-up and EVA preparation procedures • But cabin atmospheric pressure and composition control not designed for automatically maintaining 9 psia • Thus, a manual operational procedure for the crew was required;;Cabin Atmospheric Pressure & Composition Control _____________________________________________ Issues with 9 psia Cabin Pressure Operation • Flow-rate acceptability of fans at 9 psia • Thermal acceptability of fans at 9 psia • CO2 absorption performance of LiOH at 9 psia • Cabin ventilation adequacy for O2/N2 mixing with press/depress operation;;Shuttle Orbiter Environmental/Thermal Control & Life Support System\nSubsystem Elements: • WATER & WASTE MANAGEMENT • Potable/waste water inventory management • Potable water storage for drinking and food preparation • Waste water storage for dumping to space • Commode and urinal for human waste collection • Supply water for flash evaporators;;Water & Waste Management Water Sources:\nPotable Water • Fuel cell byproduct H2O • Launch storage of H2O • Drinking water sterilization Waste Water • Condensate from cabin humidity control • Urine • Urine pre-treat for NH3;;Water and Waste Management Solid Waste:\n• On-orbit trash storage (overboard dump for odor control) • Human solid waste collection and storage (vacuum dried/stabilized);;Shuttle Orbiter Environmental/Thermal Control & Life Support System\nSubsystem Elements: • CABIN THERMAL CONTROL • • • • • • • Cabin circulating liquid cooling system Atmospheric heat sink Cabin heat rejection to spacecraft cooling system Avionics cold-plate heat rejection Air-cooled avionics-bay heat rejection EVA crew cooling in airlock Crew potable water chiller;;Cabin Thermal Control System\nCabin Thermal Control Subsystem Functions:\n• • • • • • • • Cool cabin atmospheric Cool atmosphere in avionics bays Remove heat from cold-plated electronics Cool IMU Thermal control of windows & hatch Provide water chiller for crew Cool space-suited crew in airlock Reject cabin thermal energy to vehicle heat rejection system;;Cabin Circulating Liquid Cooling Loop:\n• • • • • H20 as coolant Redundant pumps Liquid/gas heat-exchangers for atmospheric cooling Cold-plates for electronics cooling Window-mount/hatch-mount thermal control\nAvionics Circulating Gas Cooling Loop:\n• • • Cabin atmospheric used as coolant Redundant fans in avionics bays Double redundant fans for IMU cooling;;Shuttle Orbiter Environmental/Thermal Control & Life Support System\nSubsystem Elements: • SPACECRAFT ACTIVE THERMAL CONTROL • • • • • • • • • On-orbit radiative heat sink On-orbit evaporative heat sink Ascent/entry evaporative heat sinks Vehicle circulating liquid cooling system Cabin heat sink Fuel cell heat sink Hydraulics heat sink Cold-plate electronics heat sink Payload heat sink;;Spacecraft Active Thermal Control Subsystem ________________________________________\nActive Thermal Control Subsystem Functions:\n• Collect waste thermal energy from orbiter subsystems • Reject waste-heat radiatively to space (on-orbit) • Augment space radiators with evaporative heat sink at high-load/hot-environments • Throttle radiators to restrict heat rejection and utilize evaporative heat sink to consume excess fuel cell H2O • Reject waste-heat evaporatively during assent (H2O) • Reject waste-heat evaporatively during entry (NH3);;Spacecraft Active Thermal Control Subsystem\nHeat Rejection - Radiator:\n• 2 mirror-image radiator systems • _ of the radiators located in separate cooling loops • “Bypass-type” thermal control concept utilized • Dual Set points - 40oF & 56oF • 4 single-sided, fixed space radiators • 4 two-sided, deployable space radiators • Honeycomb structure with embedded tubes for coolant • Silver-Teflon, thermal surface coating;;Heat Rejection - Flash Evaporators:\n• • • • Heat sink is phase-change of H2O Dual flash chambers – “high-load” and “topper” Non-propulsive over-board steam duct for “topper” Second over-board steam duct for “high-load”\nHeat Rejection – Ammonia Boiler:\n• • • • Heat sink is phase-change of NH3 Redundant boilers Utilized during entry at < 100,000 feet altitude Utilized on runway until ground cooling available;;Circulating Liquid Cooling Loop:\n• Freon 21 as coolant • Redundant pumps • Liquid/liquid heat exchangers • Cold-plates;;Shuttle Orbiter Environmental/Thermal Control and Life Support System\nROTATING EQUIPMENT LIFE TEST • Equipment • Cabin fan • Water/gas separator • Avionics bay fan • Cabin coolant pump • Vehicle coolant pump • Life Requirement • 100 missions • 20,000 hours;;Shuttle Orbiter Environmental/Thermal Control & Life Support System\nFunctional Requirements: EVA AIRLOCK SUPPORT • Maintain cabin pressure & O2/N2 composition during airlock depress/repress • Interface with EMU service and cooling umbilical • Provide heat rejection for spacesuit cooling garment • Supply backpack O2 recharge (900 psia) • Supply backpack H2O recharge for sublimator • Drain humidity condensate from backpack post-EVA'
4635,'lecture','en',4620,'2005-10-27','2009-11-04','Lecture 14: Ground Operations - Launching the Shuttle',NULL,'ase05_sieck_gol_Page_01;;ase05_sieck_gol_Page_02;;ase05_sieck_gol_Page_03;;ase05_sieck_gol_Page_04;;ase05_sieck_gol_Page_05;;ase05_sieck_gol_Page_06;;ase05_sieck_gol_Page_07;;ase05_sieck_gol_Page_08;;ase05_sieck_gol_Page_09;;ase05_sieck_gol_Page_10;;ase05_sieck_gol_Page_11;;ase05_sieck_gol_Page_12;;ase05_sieck_gol_Page_13;;ase05_sieck_gol_Page_14;;ase05_sieck_gol_Page_15;;ase05_sieck_gol_Page_16;;ase05_sieck_gol_Page_17;;ase05_sieck_gol_Page_18;;ase05_sieck_gol_Page_19;;ase05_sieck_gol_Page_20;;ase05_sieck_gol_Page_21;;Launching the Space Shuttle\nBob Sieck October 2005;;Agenda\n Background  Engineering  Operations  Human\nFactors;;KSC Shuttle Infrastructure\nEquivalent to a Small City\nFacilities Kennedy Space Center  Vehicle Assembly Building  525’ Tall Three Orbiter Processing Facilities Launch Pads A&B  Landing Facility Support Building\n140,000 Acres 8 Acre Footprint, 30,000 SF Each Fuel/Oxidizer Tank Capacity of 1.8 M Gal 15,000’ Runway, 300’ Wide 200,000 SF Office\n Shuttle\n Operations\nSpace\nSupport 300 Generators, 60 UPS Units, 156 Substations 30,000 Tons of Air Conditioning Over 52 Cranes, 217 Hoists, and 55 Elevators 100 miles of Water Distribution Lines 441 Pieces of Heavy Equipment 270 Miles of Fiber Optic Cable Over 900 Fiber Optic Transmitters and 900 Fiber Optic Receivers\n LC-39 TV System Includes 166 Cameras, 9 Video \n Recorders, and Over 7770 Monitors \n 142,000 Line Items in Inventory \n 10,000 Issues Per Month;;Standard Work Flow;;Shuttle Processing Team  Space Flight Operations Contractor – United Space Alliance  Responsible for processing Orbiter, External Tank (ET), Solid Rocket Boosters (SRB) and Re-usable Solid Rocket Motors (RSRM)  Responsible for facility and Ground Support Equipment (GSE) maintenance  Additional support provided by development and institutional contractors\n NASA Shuttle Processing Director is the designated Technical  Management of NASA shuttle support at KSC  Disposition of technical issues for KSC equipment  Validating contractor processes meet NASA requirements  NASA Launch Director is responsible for:  Management of launch count, landing and\nManager for:\nrecovery operations;;NASA Shuttle Processing Responsibilities\nEngineering  Approve  Non conformance to Program Requirements  New/Changed Requirements  Implementation Procedures  NASA Managed Activities  Analyze Test Data  Observe Critical Procedures / Tasks  Audit Requirements Implementation  Assess Contractor Metrics\nOperations Integration  Lead NASA Managed Activities / Approve Procedures  Lead Vehicle Flow Planning  Approve Requirements  Observe Critical Integrated Procedures / Tasks  Observe Day-to-Day Operations  Assess Contractor Metrics  Manifest (Flight Schedule) Development;;Orbiter Processing Facility (OPF) Operations;;Orbiter Processing Facility (OPF)\n Operations  Initial access and safing  Post-flight hardware problem resolution  Thermal Protection System maintenance, replacement and repair  Space Shuttle Main Engine (SSME) removal and installation  Payload bay operations  Down mission payload removal  Mission kit reconfiguration  Up mission horizontal payload configuration and installation  Orbiter modifications  Orbiter sub-system design requirement re-verification  Orbiter preparation for roll over to VAB (Vertical Operations);;Vehicle Assembly Building (VAB) Operations;;Vehicle Assembly Building (VAB)\n Operations  Perform\nExternal Tank (ET) checkout  Solid Rocket Booster stacking requires approximately three weeks  ET mate and closeout requires approximately two weeks  Orbiter mate requires approximately one week  Test interfaces between Shuttle elements  Perform structural closeout;;Launch Pad;;Launch Pads 39A and 39B\n Operations  Pad\nprocessing takes approximately 4 weeks  Payload transfer from payload canister to Payload Change-out Room (PCR) to Orbiter  Shuttle/Pad system validation  Simulated launch count with astronauts  Final preparations to vehicle for launch countdown;;Launch Processing System (LPS) / Control Room;; Description  Automated\nand computer controlled Shuttle launch and checkout\nsystem  Customized hardware for Shuttle  Custom language used for application software  Linked to orbiter, External Tank, and Solid Rocket Booster, and Ground Support Equipment at all processing locations  Operations Support  Automated checkout of Shuttle and associated Ground Support Equipment during preparation for launch  Problem resolution and data reduction;;Engineering Approach\n Engineering\nRequirements – Demonstrate the “as built ready to launch shuttle” is the same “as designed and certified”\nDevelopment / design organizations establish requirements implemented at KSC  Requirements dictate hardware / software performance and limitations in ground tests and inspections  Verified by review of documents used to assemble, inspect and test  Periodic management reviews certify readiness\n Launch\nCount Requirements\nRequirements documented in engineering drawings, NASA Program documents and Launch Commit Criteria  Acceptable limits for the system performance and the configuration of the hardware and software\n System\nEngineers develop procedures and software to implement \n requirements\nApproximately 500 requirements with approximately 2000 associated\n measurements\n  Launch count procedures: Approximately 20 documents totaling 5000 pages  Approximately 500 software programs;;Launch Team Structure\nMission Management Team\nLaunch Director\nEngineering Support\nRange\nPayload\nSafety\nNASA & Contractor Project Managers\nNASA Test Director\nNASA & Contractor Senior Engineers\nContractor Test Conductors\nNASA JSC Flight\nNASA and Contractor System Engineers\nNASA KSC Integration Engineering;;Shuttle Launch Operations Summary\nActivate and test flight and ground systems (16 hrs) No work hold (4 hrs) Load fuel cell cryogenics (8 hrs) No work hold (4 hrs) Activate and test remaining shuttle systems (12 hrs) Time critical stowage and service structure disconnects (12 hrs) ET propellant load preps (5 hrs) No work hold (2 hrs) ET Load (3 hrs) No work hold (3 hrs) Terminal count (4 hrs) 72 hrs Operations Sequenced to: Provide orderly closeout of vehicle and launch accessories Activate and verify systems meet requirements Minimize hazards to personnel and equipment Scheduled hold time to allow work to catch up;;Shuttle Launch – Terminal Count Phase\nT-3 hrs\nCrew ingress Communications tests Crew cabin closeout and integrity test Guidance systems initialization 10 minute hold Orbiter computers sequencing initialized 45 minute hold Final poll of management, operations, engineering, weather, range safety and flight teams Retract crew access arm Automated test of orbiter flight controls Pressurize ET oxygen tank Pressurize ET hydrogen tank Activate SRB systems Initiate Orbiter sequencer Final automated “Go” to orbiter computers Verification of critical ground system activation\nT-20 min T-9 min T-7 min T-4 min T-2:55 T-1:57 T-0:31 T-0:10;;Launch Count - Controls\n The\nGround Launch Sequencer (GLS) is the software supervisor of \n critical command sequencing and measurement verification for \n terminal launch countdown \nIssues or delegates all ground initiated commands to the Shuttle and Ground Support Equipment (GSE) from T-9 min  Initiates critical activities performed by software at other firing room system consoles  Monitors all measurements whose violation require immediate reaction  Monitors all measurements associated with GLS issued commands  Performs critical safing  Controls ground and onboard clocks – sets liftoff time;;Human Factors\n Automation\nvs. Manual Control  Responsibility  Teamwork Dynamics\nDecision making process Communication “Launch Fever”'
4636,'lecture','en',4620,'2005-11-02','2009-11-04','Lecture 15: Space Shuttle Accidents',NULL,NULL
4637,'lecture','en',4620,'2005-11-03','2009-11-04','Lecture 16: Guidance, Navigation and Control',NULL,NULL
4638,'lecture','en',4620,'2005-11-08','2009-11-04','Lecture 17: Mission Control 1',NULL,'ase05_kraft_mc1_Page_1;;ase05_kraft_mc1_Page_2;;ase05_kraft_mc1_Page_3;;ase05_kraft_mc1_Page_4;;ase05_kraft_mc1_Page_5;;ase05_kraft_mc1_Page_6;;MIT Lecture—Systems Engineering-Flight Control 1 By Christopher Kraft ( NACA/NASA-1945 to 1982 ) Major Topics to be covered: Project Mercury Objectives of the program etc. Development Of World-Wide Network Basic Requirements Based on how often data required—set the location of number of stations ( Diplomatic issues) --use of available missile ranges—S and C band radar, telemetry, voice communications, ground communications, data retrieval and transmission, display. Mission Plan Evolution Of flight control concepts Concepts based on previous airplane flight test experience Orbit Determination Astronaut and systems health Consumables analysis Retrofire and landing point control Contingency planning Recovery planning-Very big operation involving all departments of the DOD Evolution Of Mission Control Centralized decision making really the determining factor—real time decisions Data and information flow and display requirements Computer complex—launch trajectory, orbit determination, retrofire and impact prediction Communications requirements—air to ground—ground to ground Recovery Control Center—Interplay with flight control Mission Rules Evolution a. Real time driven—need for careful thought pre event—time for unknown unknowns\n b. Process had systems instrumentation and design effects;;c. Allowed top management review preflight d. Brought about support from design and development departments Training—Simulation Systems Development Astronaut training requirements Flight control training as well as network training and integration Integrated astronaut and flight control training. Initial rudimentary approach Development of sophisticated approach Dawn Of Systems Engineering a. Definition of b. Development of the concept in flight control 1. Systems diagrams 2. Mission Rules and Malfunction Procedures. 3. Brought about appreciation of interaction between systems and importance of knowledge of other systems. Further Evolution of Flight Control Concepts Results Of Project Mercury And Lunar Challenge Brought Gemini And Apollo Programs. Gemini Objectives Based On Apollo Mission Requirements: A. Orbit Maneuvers-rendezvous and docking concepts and operational experience B. Long Duration Flight-up to 14 days because of lunar flight requirements C. Systems Development- Electrical Power, Caution and Warning, OMSrocket development, Heat Protection-ablative materials D. Extra Vehicular Activities-Suit development-Back pack for EVA E. Entry Guidance- Maneuvering concept--On Board Computerhardwaresoftware requirements Advanced Mission Control Center A. Computer and Communications Complex-Rendezvous, entry etc. B. Computer driven display system C. Advanced Simulation Requirements- Network simulation etc D. Remote sight modification-eventual satellite communication-data and voice, NASA satellite addition to network communications--full;;time information. E . Location-where to locate geographically--multi-mission (CSM and LM)- Agena target vehicle--rendezvous and docking. Greatly Expanded Mission Rules And Malfunction Procedure Requirements Apollo Flight Control Requirements A. MCC design requirements-Besides Gemini and its requirements to operate one manned and one unmanned vehicle together-Apollo required support to two manned vehicles. Also the need to support two separate missions simultaneously --Gemini and unmanned Apollo tests--Two control rooms and associated communication and computer requirements.(Fortuitous flight control support to Gemini-76) B. Computer analysis and support to entirely new set of orbital mechanics problems--Launch aborts, EO and TLI and possible earth return-free return trajectories and quick return to earth--LOI and its associated abort trajectories. C. Lunar orbit determination--accuracy problems--Lunar gravitational anomalies found from Lunar Orbiter D. Optimal lunar descent trajectories and abort from them--Landing point selection , accuracy and prediction-1. Maximum performance vs. pilot view of landing site and choice of landing point. E. Lunar launch trajectory and rendezvous requirements--rendezvous with CSM--LEM disposal and impact prediction-F. EOI and attendant abort problems-G. Translunar corrections to meet earth entry requirements, entry corridors and skip trajectory control 1. Landing point control and prediction including possibilities of weather avoidance. H. Deep Space Network interfaces. Real time world wide communications--Tracking, telemetry, voice transmissions--phasing and use of numerous capabilities throughout US and the world--Spain and Australia. I. Requirements of stated needs brought total revampment of MCC computer and communications complex.;;Flight Control Support To Unmanned Apollo Development Tests A. Launch abort tests, TPS and CSM launch and reentry tests--use of Saturn V--Saturn V anomalies and program effects. All of above allowed for qualification of flight control concepts and flight controller training and qualification Apollo 1 Disaster A. Cause and effect . Formulation Of Apollo Test Program A. Unmanned development tests, manned tests to prove CSM and LEM hardware in EO, lunar operations pre landing attempt, lunar landing B. Formulation of step by step test program, each phase building on the results of previous missions 1.Each category a set of objectives--number of flights required in each category thought possibly more then one depending on results. Conception Of Manned Lunar Orbit Mission-Apollo 8 A. LEM Problems--CSM ready as planned B. Expedite flight objectives to reach moon C. Lunar fly by vs. lunar orbit D. Contingent on success of Apollo 7 EO flight and flight control readiness. E. Probably Apollo\'s most significant flight Apollo 11 Apollo 13 A. Flight control\'s finest hour. Shuttle Challenges To Flight Control A. Use of aerodynamic capabilities--on board computer redundancy-systems redundancy;;B. Abort possibilities--use of aerodynamics and on board propulsion a. Separation and recontact problems with ET C. TPS limitations-entry from launch abort and from orbit D. Weather avoidance for RTLS and normal entry a. TPS damage--visual flight rules E. Flight control aides a. Navigation and air data inputs b. Intersection of HAC-energy control-glide slope-landing flaregear deploy-GCA Decision To Fly Manned Or Unmanned On First Flight A. Risk analysis--design philosophy and systems reliability B. Low g flight made pilot less liable to health problems C. Training and simulation capability--fixed base, movable base, G-2 simulator--all added confidence for pilot capability. D. High risk factors--Launch abort-RTLS-entry aerodynamics and autopilot reliability-TPS-landing proficiency E. Pilot presence made system reliability significantly higher in all cases F. Discussed at highest levels of the agency--recommended by all management levels. G. Thoughts in retrospect--what unmanned capability would provide Approach and Landing Tests A. Orbiter transport--747 purchase and reconfiguration B. 747 offered landing test opportunity C. Need for proof of dead stick landing--pilot confidence and training D. Aid to development of landing techniques--flare and gear deploy E. Nay sayers doubted ability to “fly” orbiter off back of 747 F. Test results--additional knowledge and experience always helpful a. Control rates--airplane response to elevon control Determining When To Fly First Shuttle A. Admittedly difficult decision particularly because of manned first flight--first time a rocket system flown manned on first flight B. Critical design reviews--programmatic C. Design factors--structure at least FS-1.4 and quad redundancy in all orbiter critical systems--extensive engine tests to prove engine qualification--solid rocket tests and reliability (design flaw determined after flight tests) D. TPS concerns--structural integrity--SIP--Bond to aluminum skin, method of attachment, proof testing, TPS test articles--combined loads, lost tile concerns, critical tile criteria (surface density discovery), transition point, steps and gaps-established criteria, interference problems at doors and;;aero controls and aero leak problems, instrumentation for post flight analysis E. Entry control--aerodynamic properties, instability (gain changing), Monte Carlo analysis, landing point control, energy preservation and concepts (Use of G-2 provided pilot and program confidence) F. Outside Expert Reviews--pros and cons G. Final dissenters--thought TPS tiles would fail in the SIP or at the bond line due to vibration and or aerodynamic loads--NASA engineers disagreed on basis of tests and analysis H. How decide when ready to fly? Simply--did not know what else to do so it was time to suck it up and GO. I. Unknowns and “unknown” unknowns Opinion--Today’s Travesty--Not Using STS and ISS.'
4639,'lecture','en',4620,'2005-11-10','2009-11-04','Lecture 18: Mission Control 2',NULL,NULL
4640,'lecture','en',4620,'2005-11-17','2009-11-04','Lecture 19: Design Process as it Relates to the Shuttle',NULL,NULL
4641,'lecture','en',4620,'2005-11-22','2009-11-04','Lecture 20: EVA and Robotics on the Shuttle',NULL,NULL
4642,'lecture','en',4620,'2005-11-29','2009-11-04','Lecture 21: Systems Engineering for Space Shuttle Payloads',NULL,'ase05_lavoie_ses_Page_01;;ase05_lavoie_ses_Page_02;;ase05_lavoie_ses_Page_03;;ase05_lavoie_ses_Page_04;;ase05_lavoie_ses_Page_05;;ase05_lavoie_ses_Page_06;;ase05_lavoie_ses_Page_07;;ase05_lavoie_ses_Page_08;;ase05_lavoie_ses_Page_09;;ase05_lavoie_ses_Page_10;;ase05_lavoie_ses_Page_11;;ase05_lavoie_ses_Page_12;;ase05_lavoie_ses_Page_13;;ase05_lavoie_ses_Page_14;;ase05_lavoie_ses_Page_15;;ase05_lavoie_ses_Page_16;;ase05_lavoie_ses_Page_17;;ase05_lavoie_ses_Page_18;;ase05_lavoie_ses_Page_19;;ase05_lavoie_ses_Page_20;;ase05_lavoie_ses_Page_21;;ase05_lavoie_ses_Page_22;;ase05_lavoie_ses_Page_23;;ase05_lavoie_ses_Page_24;;ase05_lavoie_ses_Page_25;;ase05_lavoie_ses_Page_26;;ase05_lavoie_ses_Page_27;;ase05_lavoie_ses_Page_28;;ase05_lavoie_ses_Page_29;;ase05_lavoie_ses_Page_30;;ase05_lavoie_ses_Page_31;;ase05_lavoie_ses_Page_32;;ase05_lavoie_ses_Page_33;;ase05_lavoie_ses_Page_34;;ase05_lavoie_ses_Page_35;;ase05_lavoie_ses_Page_36;;ase05_lavoie_ses_Page_37;;ase05_lavoie_ses_Page_38;;ase05_lavoie_ses_Page_39;;ase05_lavoie_ses_Page_40;;ase05_lavoie_ses_Page_41;;ase05_lavoie_ses_Page_42;;ase05_lavoie_ses_Page_43;;ase05_lavoie_ses_Page_44;;ase05_lavoie_ses_Page_45;;ase05_lavoie_ses_Page_46;;ase05_lavoie_ses_Page_47;;ase05_lavoie_ses_Page_48;;ase05_lavoie_ses_Page_49;;ase05_lavoie_ses_Page_50;;ase05_lavoie_ses_Page_51;;ase05_lavoie_ses_Page_52;;ase05_lavoie_ses_Page_53;;ase05_lavoie_ses_Page_54;;ase05_lavoie_ses_Page_55;;ase05_lavoie_ses_Page_56;;ase05_lavoie_ses_Page_57;;ase05_lavoie_ses_Page_58;;ase05_lavoie_ses_Page_59;;ase05_lavoie_ses_Page_60;;ase05_lavoie_ses_Page_61;;ase05_lavoie_ses_Page_62;;ase05_lavoie_ses_Page_63;;M82 Galaxy\nCassiopeia A\nCrab Nebula\nEta Carinae;;o CXO Overview o Chandra History o Challenges 1. Mirrors 2. Restructuring 3. Science Instruments 4. Integrated Testing 5. Management\n6. HRMA Alignment 7. Cleanliness 8. SIM Mechanisms 9. X-ray Calibration Facility 10. On-orbit Proton Radiation;;Chandra X-ray Observatory: Overview\no ONE OF THE 4 “GREAT OBSERVATORIES” o PROGRAM OBJECTIVE: The objective of the Chandra Program is to Make Fundamental Scientific Discoveries and Contribute to our Understanding of the Universe Through Rigorous Analysis and Distribution of Unique Scientific Data. This responds to the the NASA Strategic Plan in the Space Science Enterprise by responding to the mission, “To advance and communicate scientific knowledge and understanding of Earth, the Solar System, and the Universe.” o SCIENCE OBJECTIVES: a. Determine the nature of celestial objects from stars to quasars b. Understand the nature of physical processes which take place in and between astronomical objects c. Understand the history and evolution of the universe o PRINCIPAL CUSTOMERS: Astronomical Science Community NASA Headquarters, Office of Space Science (OSS) Congress and the General Public;;o KEY SCIENCE PERFORMANCE REQUIREMENTS:\n- Percent Encircled Energy (How sharp is the image?) \n - Registration (Where is the target in the sky?) \n - Effective area (How many photons can you collect?) \no KEY DERIVED REQUIREMENTS FROM PERFORMANCE REQUIREMENTS:\nMirror size and design \n Focal length \n Pointing\n Thermal stability \n Instrument sensitivity \n Fiducial Transfer System \no NEXT, FILL IN THE REST OF THE REQUIREMENTS o ONCE REQUIREMENTS ARE SET, CONCEPTS CAN BE DEFINED AND THE DESIGN CAN BE DEVELOPED;;A PRELIMINARY DESIGN!;;NOTE THE FINAL DESIGN!;;o o o o o o o o o o o AXAF Mission Definition Study  HQ approval for new start:  Authority to Proceed (ATP) for Prime contract: ATP for Science Instruments:  Mirror validation test (VETA-1):  Program Restructure:  System Requirements Review:  Preliminary Design Review:  Critical Design Review:  Mirror delivery to Calibration Facility: Shipped to KSC:  1978 1988 January 1989 June 1990 June 1991 1992 December 1992 November 1994 February 1996 November 1996 February 1999 July 23, 1999 10,000 km x 140,000 km at 28.5o inclination August 7, 1999 August 12, 1999 August 17, 1999 September 19, 1999 October 12, 1999\no Launched:  o Orbit:  o Final Orbit Achieved:  o Sunshade Door Opened:  o First Safemode (ground error):  o End of Orbital Checkout:  o End of First Eclipse Season:;;Science Instruments Advanced CCD Imaging Spectrometer (ACIS)\nPrinciple Investigator Gordon P. Garmire Penn State\nInstrument Description Array of 10 CCD devices with Sub-arcsecond angular resolution Micro-channel plate imager with better than 0.5 arcsecond angular resolution Spectral BW from 0.4 to 8.0 keV; Resolution = 800 at 1.0 keV; ACIS images spectral dispersion of gratings Spectral BW from 0.1 - 3.0 keV; Resolution = 750 at low energies; HRC images spectral dispersion of grating\nHigh Resolution Camera (HRC) Steven S. Murray SAO\nHigh Energy Transmission Grating (HETG) (includes both high and medium energy gratings Low Energy Transmission Grating (LETG)\nClaude R. Canizares MIT\nAlbert Brinkman SRU, Utrecht, Netherlands;;Chandra Ground System Architecture\nChandra\nTelemetry Commands\nTelemetry Commands DSN Scheduling State Vector\nDeep Space Network\nOff-Line System\nS/C Support & Eng Analysis Attitude Det. & Sensor Cal Mission Planning & Scheduling Command Management\nOCC/ESC\nOn-Line System\nData Capture Telemetry Processing Observation Request Mission Schedules Telemetry CXC Proposed Observation Science Data IPIs,General Observers\nOps Simulator Operations Database\nCommand Processing Communication\nFlight S/W Maint Fac\nS/W Changes;;Chandra X-ray Observatory: History\no AXAF MISSION DEFINITION STUDY BEGAN IN 1978. - Based upon successful HEAO series \n - Extrapolated results and new technology improvements to derive top level performance. \n - Maintained a “study” level of effort for several years. \n - In order to “sell” concept, elected early on to involve independent (non-profit) party, SAO,\n to review all telescope studies and work - Also brought on-board a senior telescope scientist and various interdisciplinary scientists in 1985. o TRW WAS SELECTED AS PRIME CONTRACTOR IN 1988 o AXAF WAS GIVEN A NEW START IN 1989. - Full new start authority was contingent upon successful completion of mirror technology test - Test mandated by congress in 1991 and completed successfully and on-time. - NASA HQ approved for a new start with metrics along the way;;o TO REDUCE LIFE CYCLE COST, PROGRAM RESTRUCTURED IN 1992 - Imaging mission o Reduced mirror pairs from 6 to 4 o Dropped 2 focal plane instruments (now only 2, plus 2 gratings) o Dropped servicing requirement o Changed lifetime from 15 years to 5 years o Placed into higher orbit to increase observing time and preserve science objectives \n - Spectroscopy mission \n o Took one of the instruments and built a mission around it o To save cost, this was to be built totally in-house at MSFC o NATIONAL ACAEDMY OF SCIENCES ENDORSED PROGRAM o AXAF-SPECTROSCOPY MISSION WAS CANCELLED BY SENATE IN 1994 - Program was on track and within cost (?!) \n - Smaller version of the instrument slated for the Japanese mission ASTRO-E \n - ASTRO-E mission was lost during ascent earlier this year. ;;Chandra X-ray Observatory: Challenges\nWhy is imaging so important? Imaging allows scientists to pinpoint where in space the x-rays are coming from. The more precision the telescope has, the better the resolution to identify the X-rays. This allows even further detail and scientific discovery in understanding more about the object and how it came to be.\nRosat Image\nChandra Image;;1. Mirrors (TECHNICAL) o BIGGESST CHALLENGE WAS MIRROR DEVELOPMENT - Mirrors had never been figured to this precision for this size - Program needed to develop innovative approach to mirror fabrication and testing o SUBSCALE STRATEGY - Develop single mirror pair comparable to smallest Chandra (AXAF) mirror pair - Demonstrate technology to build mirrors - Develop in-process metrology, feed metrology data into computer modeling, predict resulting mirror performance, and validate with newly-developed optical test methods - Program developed Technology Mirror Assembly (TMA) - Program selected/developed 3 types of metrology measurements - All measurements were fed into analytical software programs to predict performance. - Predicted performance was compared to actual performance of mirrors. o The initial performance did not quite match predictions. o A small gap was found between the 3 types of metrology metrics that left some part of mirror surface undefined. o Metrology was enhanced; mirror flaw was found; mirror was re-polished.;;High Resolution Mirror Assembly (HRMA);;What makes Chandra Unique? Chandra has outstanding imaging precision; its mirrors are the largest, the most perfectly aligned, and smoothest ever built. The images Chandra makes are 25 times sharper than the best previous x-ray telescope.\nPolishing a CXO Mirror Shell\nCXO hrma assembly;;1. Mirrors (TECHNICAL) o IN-PROCESS METROLOGY MEASUREMENTS AND CROSS-CHECKS - 4 independent metrology measurements on mirrors - Each has overlapping frequencies so that cross-checks with one or more of the other metrology devices is performed. - Each metrology measurement device was improved over the TMA devices. - The testing of the metrology devices was extensive. - During the mirror assembly, a co-located team of Government and contractor personnel reviewed all of the metrology data as it was taken. o EARLY TESTING OF LARGEST MIRROR PAIR MANDATED BY CONGRESS - H1/P1 tested in a VETA-1 (Verification Test Article) configuration at MSFC’s XRCF - Testing was performed on-time and showed performance better than mandated spec value. - A second development test, VETA-2, took outer mirror pair and assembled them into a flight High Resolution Mirror Assembly (HRMA) using nominal procedures and Ground Support Equipment (GSE) o This HRMA (with mass simulators for remaining shells) was shaken as a structural test article to verify alignment stability;;1. Mirrors (TECHNICAL) o END-TO-END X-RAY TESTING OF FINAL HRMA ARTICLE - Performed at XRCF under direction of MSFC \n - Used flight science instruments and HRMA \n - Demonstrated quality mirrors and compared well with predictions\n o KEY TO SUCCESS IS GOOD SYSTEMS ENGINEERING - Necessary because of multiple separate parties, academia, non-profits, and foreign groups - LESSON LEARNED: Perform multiple cross-checks wherever possible - LESSON LEARNED: Let more than one group perform review - LESSON LEARNED: No substitute for direct test or measurement - LESSON LEARNED: Keep science informed and part of the decision-making process - LESSON LEARNED: Establish error budgets and allocate error terms early on, and continually review them;;1. Mirrors (TECHNICAL) PAYOFF!;;2. Descope (PROGRAMMATIC) o NEXT BIGGEST CHALLENGE WAS COST – NASA HQ & CONGRESS DID NOT WANT TO PAY THE INITIAL PRICE - Total recurring cost was problem \n - Solution: Remove servicing and reduce life from 15 yrs to 5 yrs. \n - 2 instruments were dropped as well \n - Also, Systems Engineering was cut!\n o MITIGATION - Finally settled on moving Chandra to a higher orbit to minimize earth eclipse but it needed to be high enough to avoid disturbance from Van Allen radiation belts. - To go higher in orbit, Chandra had to lose weight so that an upper stage could achieve the higher orbit. - Also studied new launch vehicles to achieve the best efficiency for the available funds. - Keep the Shuttle launch vehicle. - Weight needed to drop more than a factor of 2!;;Challenges\n2. Descope (PROGRAMMATIC) o WEIGHT REDUCTION - Use new technology lightweight composites for telescope. \n - MSFC had never used this percentage of composites for a large space structure \n - Since the mirrors were a significant weight contributor, 2 mirror pairs were dropped. \n - SIM was changed to all composite structure.\n o WEIGHT REDUCTION IMPACTS - Developed new methods of analyzing total structure - Since composites crack, adopted a new handling paradigm to prevent damage - Developed new methods of structurally testing composite integrity - Since SI’s were cantilevered out in Shuttle cargo bay, weight problem remained acute for SI’s and SIM until late in program - SIM and SI’s weight containment policy resulted in constant attention and change and ate most of program slack - Universities had different structural analysis tools than contractors, so communication and common understanding was difficult at times.;;2. Descope (PROGRAMMATIC) o MANAGEMENT TECHNICAL, ENGINEERING, AND PROGRAMMATIC OVERSIGHT - Set element weight allocations. \n - Define frequent reporting scheme; address frequently. \n - Understand and penetrate the tradeoffs of weight loss \n - Balance need for adherence to schedule versus time to fix/complete mandatory events \n - Revise allocations as needed to get the job done. \n - Keep all elements informed of progress. \n - Keep communication flowing! \n - Be sensitive to the impact of changes to all areas not just the ones directly affected by a\n change. o COMPENSATE FOR CONTRACTOR LOSS OF SYSTEMS ENGINEERING EFFORT - Established Technical Oversight Panels \n - Controlled the external ICD’s and led the ICD working groups \n - Perform all top-level (Level II) systems engineering activities \n - Establish technical presence at locations where the action is. ;;2. Descope (PROGRAMMATIC) o LESSONS LEARNED: - Set resource allocations early and continue to monitor, tradeoff, and refine them through to delivery - Maintain strong Systems Engineering group throughout program - Maintain controlled schedule and carefully evaluate any changes to schedule. - Set up routine to have periodic meetings will all elements, the more hectic the phase the more critical the need. - At least during critical times, plan and schedule on-site representation;;Hard work pays off!;;3. Science Instruments (TECHNICAL) o ACIS NEW TECHNOLOGY ITEMS - ACIS used 1024 x 1024 pixel CCD’s, larger than anything made like it. - ACIS also cooled the CCD’s to -120C for the first time - A new type of X-ray CCD was developed for 2 of the 10 CCD’s - Very low noise signal chain - Unique application of paraffin actuators for door mechanism o NEW TECHNOLOGY PROBLEMS - Radiation susceptibility - Thermal extremes for flexible multilayer circuit cards - Low yields for the new type of CCD’s - ESD sensitivity - Extensive software development - Complicated and sensitive procedures - ACIS sunshade temperature extremes;;HRC Detector\nACIS Detector;;Chandra X-ray Observatory: Challenges\n3. Science Instruments (TECHNICAL) o HRC NEW TECHNOLOGY ITEMS - Low noise signal chain (different concept than ACIS) \n - 3 Microchannel plates linked together \n - Accurate event timing \n o NEW TECHNOLOGY PROBLEMS - Spacecraft charging protection \n - Spurious noise susceptibility \n o BOTH GRATINGS DEVELOPED NEW METHODS OF DEPOSITING FINE MESH STRUCTURES ON THIN FILMS - Unknown is vibration sensitivity \n - Much work done early on to verify adequacy ;;3. Science Instruments (TECHNICAL) o GOOD SYSTEMS ENGINEERING AND SOUND COMMUNICATIONS - Ensure participation in working groups - Keep each party informed when internal as well as interface changes occur - Encourage teamwork - Balance need for adherence to schedule versus time to fix/improve - Keep science involved. - Bring in discipline experts when needed (don’t be afraid to go outside of the program) o LESSONS LEARNED: - Maintain awareness of SI’s at the same level as other flight hardware. \n - Establish standing Interface Working Groups with mandatory SI participation \n - Keep science involved in engineering activities. \n - When problems occur, go outside of MSFC to get help when value-added. \n - Encourage teamwork. Many times, programs suffer culture clash between SI’s and\n prime contractors.;;3. Science Instruments (TECHNICAL) o PAYOFF: ;;4. Integrated Testing (ENGINEERING) o INTEGRATION IS ALWAYS A CHALLENGE - Each group has a different test paradigm - Communication inherently tougher from group to group - Each group brings its own GSE, which is more often than not incompatible with the other groups’ hardware and software. - Logistics of who does what when must be carefully choreographed - Schedules and expectations are always optimistic and success-oriented o CHALLENGE MET! - Created a working group to address integration both at Ball for the ISIM and later at TRW - Documented the integration and test planning in an ad hoc document - Good working relationship focused on teamwork and getting the job done - ISIM integration and testing went OK, but did have surprises that took some time to fix.;;4. Integrated Testing (ENGINEERING) o EVEN THE BEST LAID PLANS…… - During Observatory integration, TRW couldn’t hold schedule - Problem caused by antiquated EGSE and software - Exacerbated by unique test-only database - Funds to monitor activity and help out via systems engineering were cut during restructuring - Government did not pay enough attention and did not have a full-time Integration and Test lead. - Contractor chose a complicated software test script test methodology o RECOVERY - Program Office initiated daily focus on schedule - Around-the-clock operations at the test site - New I&T Lead at TRW - More involvement of the MSFC technical Teams - MSFC technical presence to help out (not just critique) at the test site;;4. Integrated Testing (ENGINEERING) o WARNING: WHEN PRESSED FOR TIME, DON’T CUT CORNERS! - Reviewed all testing and did not delete any testing that was considered mandatory - Added systems testing to verify total system performance - Added some science end-to-end testing in Thermal Vacuum Test - Added much more end-to-end testing between the vehicle and the control center o LESSONS LEARNED: - Try to keep one integrated database for testing and operations - Define Test/Integration lead early on, before that phase begins - Review I&T approach including test GSE early - Prior to launch, perform end-to-end testing on the flight hardware from the operations center using the final version of databases and flight software - Encourage end-to-end testing participation of the operations group early and often. - If running a system level TV test, spend time to run it remotely from the operations center. - Give adequate time for box level testing and data system integrated testing. Don’t shortcut box testing if at all possible.;;5. Management (PROGRAMMATIC) o CHALLENGES APLENTY - Develop, build, and fly complete spacecraft - Multiple contracts - Companies, universities, foreign interests, external reviewers, other NASA centers, other government agencies \n - External budget constraints \n - Complicated new technology\n o UNKNOWN UNKNOWNS - Program restructure \n - Integration delay \n - Myriad of technical challenges \n - Changing government oversight paradigm \n - External reviews ;;5. Management (PROGRAMMATIC) o APPROACH TO SUCCESS: - Experience from Hubble - Top management had technical background - Worked closely with Science community - Fostered teamwork, enhanced communication - Set up proper contracts and contract monitoring - Held enough reserves (until the integration activity) - Set MSFC technical personnel accountable - Good contractors with good managers - Solicited and received outside help when needed - High priority for MSFC - Set schedule early and balanced need for schedule adherence with need to slow down and catch our breath.;;5. Management (PROGRAMMATIC) o LESSONS LEARNED: - Define good requirements early; get wide buy-in, hold the line against requirements creep. \n - Plan early program involvement of operations community \n - Communicate regularly with the whole team; set periodic telecons and brief issues and\n status. - Maintain strong engineering involvement early - Foster teamwork and assign ownership of the effort by contractors as well as CS. - Set up proper contracts and contract monitoring - Held enough reserves (at least 25%) for the amount of new technology development - Set MSFC technical personnel accountable to having the project elements work (not accountable to verify the contractor made it work). - Develop strong end-to-end systems engineering, not just the pieces - Solicit outside help when needed - If program is required to have an Independent Assessment group, get them in early and keep them in for all major reviews and resolution of all critical issues - Set schedule early and balanced need for schedule adherence with need to slow down and “catch our breath”.;;Chandra X-ray Observatory: Challenges \nFY92 CY92\nAXAF Mission Schedule FY93 FY94 FY95 FY96\nCY93 CY94\nUpdate of: April\nCY95\nCY96\nCDR\nFOT at\nACIS-2C OCC\nFY97 CY97\n2 Start S/C A&T HRC ACIS 3 5 10\nFY98 CY98\n3 5 6 8 10 Launch D ORR Del OV C 4 5 to Complete R KS G3 F3 C\n1Q 2Q 3Q 4Q 1Q 2Q 3Q 4Q 1Q 2Q 3Q 4Q 1Q 2Q 3Q 4Q 1Q 2Q 3Q 4Q 1Q 2Q 3Q 4Q 1Q 2Q 3Q 4Q\nPDR\nHRMA to XRCF\nMajor Milestones\nSRR\n5 F 0/1 12 12 12 9\n8 G 0/1 12\nStar t OBS SI Del XRCF SI Del XRCF I&T 11 2 3 F2 G2\nReqmts Dev/Alloc Prel/Detail Design Integral Propulsion System Structural Fab Structural Test Art Fab Static Test/Modal Survey S/C Assy and Test OBS Integ and Test Launch Prep Optical Bench Telescope Assy and Test Mirror Fab Mirror Coating HRMA XRCF * SI Dev SIM Surrogate SIM Fab/SIM A&V/ISIM I&T\nElec & Str PDA\nElec & Str CDA\nPDA\nCDA 6\nEarly Start P-6 FAB\nEarly Completion\nCDA\nPDA\nCDA\nHRMA/LETG/HETG 2 11/30 HRC 3/17\nACIS 5/24\nRR\nPDA\nCDR\nLETG\nHETG\nISIM HRC/ACIS\n4 GSR1 4\n7/1 9/23 ETE #1 11 /12\n8/27 MBV MBV 77 33 1/23 5/27\nETE #4 PAD 7/31 ETE #2 2/25\nOC1\nMBV\nETE #3 (CITE) 7/8 POP Test 7/3\nOCC/ESC DEVELOPMENT\n= Slack in days *= Slack Critical Path * XRCF includes 30 day contingency test period\nOC2 OC3 OC4\n= Safety Review, F=Flight, G=Ground\ni:\\trw_work\\pmr\\AXAF703D.ppt;;Chandra X-ray Observatory: Challenges\n6. HRMA Alignment and Stability (TECHNICAL) o MIRRORS MUST WORK AS A UNIT - Align each mirror very accurately - No shell-to-shell variations - No bulk variations - No changes after XRCF calibration - No major changes to measured alignment of telescope after integration o MIRRORS DROVE THE DESIGN - Stiff, rigid structures \n - Isothermal environment \n - Critical thermal coatings \n - Thermal control very granular \n - Accurate sensors \n - Integration and test implications (how to verify) ;;Chandra X-ray Observatory: Overview;;Chandra X-ray Observatory: Challenges\n6. HRMA Alignment and Stability (TECHNICAL) o UNANTICIPATED PROBLEMS OCCUR! EXAMPLE: SPACECRAFT CHARGING - Very tight thermal requirements for HRMA and telescope led to choice of silverized Teflon thermal blankets - Teflon outer surface is dielectric; it builds up charge - In Chandra orbit, high degree of background plasma flux charges blankets - Blankets eventually discharge, which can disrupt signals either radiatively or conductively - Major effort on Chandra to first avoid and later mitigate problem - SI’s (being potential victims) wanted materials changed; Observatory contractor required surface for thermal reasons. - Thermal design won out, coupled with extensive testing and shielding of sensitive signals - Spark test developed to test radiative susceptibility - Other innovations made to reduce susceptibility, including evaluation of major Chandralevel plasma test (ultimately rejected).;;6. HRMA Alignment and Stability (TECHNICAL) o USE PATHFINDER - Developed special alignment tower - VETA-2 was used as pathfinder for process - Kodak developed very elaborate alignment tower - LESSON LEARNED: Put effort into error budgets, allocations, and analysis - LESSON LEARNED: Get independent reviewers involved in data review - Final crosscheck performed at XRCF on HRMA and each shell wrt to the whole o PAY ATTENTION TO HRMA STABILITY - Error budget allocations and accountability - Tested thermal stability - Kept Science involved - LESSON LEARNED: Multiple independent development tests and analyses prior to assembly - Independent review of data - LESSON LEARNED: Multiple cross-checks implemented after final assembly. - Developed method to check focus after Chandra environmental testing - Used method to check after shipment to KSC.;;6. HRMA Alignment and Stability (TECHNICAL) o EXPECT UNKNOWN UNKNOWNS - During mirror assembly, noted focus alignment error after the bond dried on first mirror pair - Problem traced to temp difference of mirror with lights on versus lights off! - Mirrors were set with lights on - Lights resulted in mirror shape change - Post-bond measurement made with lights off! - Fortunately, there was enough margin in total error allocation to press without redo - LESSON LEARNED: For sensitive activities, ensure consistent environment;;7. Cleanliness (ENGINEERING) o MIRROR PERFORMANCE EXTREMELY SENSITIVE TO PARTICULATE AND MOLECULAR (FILM) CONTAMINATION - Much more sensitive than Hubble \n - No equivalent large-scale cleanliness capability existed at MSFC\n o NEW METHODS REQUIRED - Better ways to measure contamination - Improved ways of cleaning hardware - Expanded database of allowable materials - New paradigm had to be followed to keep everything in the optical cavity or touching it at any time clean. o FOCUS AREA – CONTAMINATION CONTROL - Science community helped push need - Contamination budgets set early and religiously followed - LESSON LEARNED: Contamination guru identified on program whose sole job was contamination - Everything baked out to boil off contaminants;;7. Cleanliness (ENGINEERING) o AS A RULE, BAKE OUT – EXCEPTION: OPTICAL BENCH - Very controversial and emotional, but bottom line was that the benefit did not outweigh schedule and cost impact - Tested with wipe samples and monitored outgasing constituents during TV Test - Cleaned very thoroughly at Kodak and witnessed by outside parties o IN SPACE, CONTAMINATES COLLECT AT LOWEST TEMPERATURE – RISK: ACIS - As long as mirrors stayed hotter than surrounding, little contamination would accumulate. - As a backup measure for ACIS, the capability to bakeout the instrument on-orbit was provided. - LESSON LEARNED: Develop backups o MIRROR PERFORMANCE WOULD CHANGE (DEGRADE) IF CONTAMINATES ON SURFACE - To compensate, radioactive sources were mounted in door to directly measure contamination on-orbit - Radioactive sources also mounted on SIM to check ACIS periodically.;;8. Science Instrument Module (SIM) Mechanisms (TECHNICAL) o SIM WAS A CHALLENGE - One axis translation and focus both required. - Very different thermal constraints from the telescope and SI’s, with ACIS in particular - Needed to be very light-weight, since its mass was at the cantilevered end of Chandra - Needed to be ultra-clean o REQUIRED INNOVATION - Composite table structures \n - Innovative thermal coatings and adhesions \n - Active thermal control of composite flexures \n - New ways of structurally studying the composite flexures\n o INNOVATIONS BRING PROBLEMS - Bonding and adhesion problems \n - Thermal material cracking \n - Moisture desorption alignment problems \n - Choice of acceptable lubrication ;;Top Hat and Lean-to Optical Bench Cutaway of Contamination Cover, “Cake pan” area +X\nPSMC RCTU BTU\n+Z Focus Structure C\n+Y\nA\nHRC TSC ACIS FLCA Flexure B\nTranslation Table\nACIS Radiator Shade\nACIS Sun Shade;;8. SIM Mechanisms (TECHNICAL) o RESULT: SIM WAS DELAYED - Weight problem caused late readiness \n - Composite structural integrity testing harder than planned \n - Debonding occurred in first Thermal Vacuum test \n - Themal surfaces cracked during integration \n - Risk of mitigating each was weighed against option of schedule slip\n o RECOVERY - LESSON LEARNED: Define error budgets early and follow them - LESSON LEARNED: Develop early ICD and iterate/communicate with all parties - Developed life test article to demonstrate compliance - Kept focus on both schedule awareness and meeting requirements - Use competent engineers, especially for alignment - LESSON LEARNED: Send engineer to plant for critical periods to help move things along;;9. X-ray Calibration Facility (XRCF) (ENGINEERING) o CHALLENGE: XRCF READINESS - Needed early in the program and used periodically with increasing importance - Needed to become world-class clean vacuum facility - Required facility modifications - GSE for facility needed to be absolutely calibrated and ready to work before testing o More accurate than the flight systems o Clean as flight but earlier \n - Procedures needed to be developed and certified prior to testing\n o LESSON LEARNED: ASSIGN A SEPARATE ORGANIZATION FOR SPECIAL FOCUS - Could concentrate solely on XRCF as a multi-program facility - Selected very competent technical leader with Chandra technical experience - Trained them to be sensitive to contamination in everything they did;;9. X-ray Calibration Facility (XRCF) (ENGINEERING) o RESPONSE: - Established frequent tagups to address schedule and worked pro-actively with contractors developing and bringing GSE to the XRCF - When HRMA finally arrived, became around-the-clock operation - Science had major role; to ensure smooth handoff, had daily shift meetings - Shifted into more of a test and integration mindset than hardware development mindset - LESSON LEARNED: Concentrate on teamwork and communication - Work performed equally between XRCF operators, civil servants, contractors, scientists, and instrument personnel. \n - Since time was critical, everyone had an input into the schedule\n o RESULT: - Ultimately, XRCF performed extremely well - It is a world-class facility - It is preparing for future calibration work for JWST and Constellation X;;10. On-Orbit Proton Radiation (OPERATIONS) o ACIS SUSCEPTIBILITY - Prior to launch, it was not expected that ACIS was susceptible to low energy protons and ions - Shielding in the HRMA and pre-collimator blocked radiation belts - Problem was, HRMA partially reflected ion proton and ion? radiation - Protons strike ACIS CCD’s and charge loss occurs when electrons are clocked off of the CCD - Prior to launch, electron reflections off the HRMA were expected and baffles and magnets were used to sweep electrons from focal path o SOURCES - Radiation belts (below 60,000 km) \n - Solar flare \n - Galactic (generally all the time)\n o MITIGATION - Move SIM to keep ACIS out of beam during threat \n - Develop acceptable error budget for gradual degradation (galactic) \n - Develop early warning system to note environment and react if it is threatening ;;Chandra X-ray Observatory\nBackup;;Chandra X-ray Observatory: Overview\no Launch System:  o Mirror Configuration:  o Focal Length:  o X-ray Energy Range:  o Encircled Energy @ 1 Arcsec:\nShuttle (STS-93) with IUS 4 Nested Grazing Incidence Mirror Pairs 10 meters Approx 0.1 keV to Approx 10 keV 60% at 0.93 keV at 19% at 8.04 keV (spec; actuals at higher energies are much better) Advanced CCD Imaging Spectrometer (ACIS), High Resolution Camera (HRC), and 2 movable gratings, one each for low and high energies\no Science Instruments:;;X-Ray-Bright Highest-Z Quasars\nBrandt et al. 2002;;The Re-Emitted Line Radiation in Seyfert 2s\nKinkhabwala et al. (2002) ;;Chandra X-ray Observatory\nIllustration of CCD\nCXC'
4643,'lecture','en',4620,'2005-12-01','2009-11-04','Lecture 22: Test Flying the Space Shuttle',NULL,NULL
5022,'introduction','en',5005,'2008-05-15','2009-10-22','Welcome and introduction to WS DEBATE',NULL,NULL
5023,'introduction','en',5005,'2008-05-15','2009-10-22','Welcome and introduction to WS DEBATE',NULL,NULL
5024,'lecture','en',5005,'2008-05-15','2009-10-22','Introduction to the conference programme',NULL,NULL
5025,'lecture','en',5005,'2008-05-15','2009-10-22','Science on VideoLectures',NULL,NULL
5026,'lecture','en',5005,'2008-05-15','2009-10-22','Where did they all go?',NULL,'Where Did They All Go?;;The Problem;;The Facts;;The Differences;;Stereotypes Concerning Women and ICT - 1;;Stereotypes Concerning Women and ICT - 2;;Gender Strategy;;Intervention;;Professional Life Style - 1;;Professional Life Style - 2;;Best Practices - 1;;Best Practices - 2;;Best Practices - 3;;Best Practices - 4;;What Is Shadowing;;Why Shadowing;;You Can Help;;Interested?;;Where did they all go?\nNancy Pascall Dir G: Components and Systems WiP School Ljubljana, 15-16 May 2008\nNancy Pascall Directorate G – Components and Systems- 1;;The Problem\n• Not enough girls (or boys) choosing careers in ICT • Even when they go into these careers they drop out along the way • Lack of engineers – approximately 300,000 by 2010 in Europe and 500,000 in India The problem is twofold:\nGetting in and Staying in\nNancy Pascall Directorate G – Components and Systems;;The Facts\n% 8 6 4 2 0 1998 1999 2000 2001 2002 Males Females 2003 2004\nPercentage of computer science male/female graduates from total of graduates Percentage of engineering male/female graduates from total graduates\n2000 Male s\n2001 2002 Fe male s\nA general increase in the number of highly educated females; However, in specific sectors, such as computing and engineering and engineering trades female graduates are significantly outnumbered by male graduates;;The differences\nGender differences exist in the frequency with which they use the computer, the context in which they learn to do so, the types of activity carried out and their self-assessment of their own abilities. (PISA 2003);;Stereotypes concerning women and ICT\nStereotypes that women have of the ICT sector: Poor quality working conditions No holidays, no spare time Very male dominated Being a mother and having a career in ICT is not compatible;;Stereotypes that the ICT sector has about women: Technical incompetence Lack of commitment and motivation to take up a challenging career No managerial capacities in top positions Being a mother and having a career is not compatible;;Gender Strategy\nA gender strategy is needed based on the following principles: Encouragement and promotion rather than criticism Compensation (awards, recognition) Pushing rather than striking Being part of a larger network Promotion of female professional excellence and competence – Quality rather than quantity;;Intervention\n• Professional Life style\n– – – – Education (fight technophobia) Recruitment (transparent) Best Practices (leaky pipeline) Management (glass ceiling)\n• Stereotypes\n– Shadowing – Awareness raising;;Professional Life Style\n• Education – choosing relevant careers Mentoring at school and university, shadowing, role models • Recruitment – ICT jobs unattractive image Attractive employer image, transparent recruitment policies and women networks • Career Development – difficult to retain Coaching, career planning, selfassessment, cross mentoring;;Professional Life Style • Management – discriminatory promotion and progression procedures, working conditions Best practices • Uptakes after leaves – loosing skills and competences Mentoring, training • Maturity Self-employment;;Best Practices\n• Linked to socio-economic context of the country • Vocation and profile of organisation BUT They can be transferred and effectively adapted to other contexts.;;Company Culture • Women and men are fundamentally considered equal • Maternity/paternity leaves considered normal • Commitment and actions from gender equality also come from men and not only from women;;Legislation • Proper application of existing legislation with regards to Equal Opportunities Measures to encourage staying in • Job sharing, training in particular managerial training, teleworking, parental leave, mentoring, coaching, awarding, transparency of procedures;;Infrastructures • Child care facilities • Internal training and information programmes • Fora and networking • As before mentoring schemes • Adoption and propagation of best practices Information Gender training and sensitization, visibility;;What is shadowing\n• Attract girls to choose careers in ICT • Invite young girls (14-16) to follow a woman engineer in her daily duties • Show many facets of ICT and in particular its human face • Break stereotypes, show it is fun;;Why shadowing\nWork towards the staff you’ll need in the future Corporate Responsibility/good management Help your nation reach its employment goals Publicity Participation certificate – European Commission It’s Fun!;;You can help\nYou are the ones who made it!\n• Chose a career in the sector • Stayed • Progressed\nYou can be the ambassadors and the role models for young girls and women!;;INTERESTED?\nContact: itgirls@ec.europa.eu http://www.europa.eu/itgirls Nancy Pascall - +322 29 63 483 nancy.pascall@ec.europa.eu'
5027,'lecture','en',5005,'2008-05-15','2009-10-22','Research on position of women in science',NULL,'Women in science and cultural environment;;Sexism and (male-biased) science;;Women\'s entering universities;;Cultural legacy and misogyny;;Reproduction;;20th, 21st century: Parcial decomposition of androcentrism;;Picture of mother with children;;Women in science: Contemporary situation - 1;;Women in science: Contemporary situation - 2;;Women in science: Contemporary situation - 3;;Caricature by Božo Kos;;Gender discrimination – Worldwide problem;;Slovenia: Women in science - 1;;Slovenia: Women in science - 2;;Women in S&R - 1;;Women in S&R - 2;;Women in S&R - 3;;Obstacles for women\'s career (investigation in 1996);;What to do for the gender equality in science? - 1;;What to do for the gender equality in science? - 2;;What to do for the gender equality in science? - 3;;Thank you!;;Maca Jogan\nWomen in science and cultural environment Ljubljana, May 15.-16.,2008;;1 Sexism and (male-biased) science:;;Women\'s entering universities;;2 Cultural legacy and misogyny\n2.1 Androcentric social order: • gender division of labour and of personal identities • reason/emotion split: public/private • hierarchic connection of male/female activities • unexchangeability and constraint of gender roles;;Scheme no.1 Reproduction;;2.2 20th, 21st century: parcial decomposition of androc.:\n• prevalence of woman\'s proper role= »natural« • addition principle for women (»natural« + public role) • →discrimination: »glass-ceilings/walls«, »chilly climate« • women\'s activity= helper-activity →undervaluated.;;Picture of mother with children;;3 Women in science: contemporary situation\n• mass W entering the HE and science (»male fortress«) • horizontal segregation (»female«/ »male« dsciplines) • vertical segregation (w – »academic proletariat«) • social isolation, marginalization • »chilly climate« of organization (Harding, 1996);;• covert discrimination (latent androcentric order) → rejection of matherhood → postponing of matherhood → acceptance of matherhood & career break → acceptance of m. & continuous career;;• family overburdened women scientists: • special measures for women→ reproduction of traditional order • special measures for parents (=women and men) • →decomposition of androc. order and reconstruction of the organization of society;;Caricature by Božo Kos;;4 Gender discrimination – worldwide problem\n• • • • • UNO - Decade of Women (1976-1985) UNESCO – European Conference (Bled 1998) “Women in Science: Quality and Equality” Council of Europe – gender equality in science EU – programme for implementation of GEO policy: • Women and Science – Mobilisation of Women…1999, • Helsinki Group for Women and Science (1999), • ENWISE Expert Group (2002);;5 Slovenia: Women in science\n5.1 After WW II –socialist system (SFRJ till 1991): • gender equality = objective + basis for practice • harmonization between work and family, legal acts: • 1974: Constitution - women are free to decide • on giving birth; • 1974: prolongation of mat. leave (135days - 6 months); • 1976: possibility of sharing of mat./parental leave • (mother + father); • 1986: the mater./parental leave - prolonged to 1 year;;;the 1970s + 1980s: a lot of kindergartens, elderly homes, health centers have been built (“socially responsible parenthood”). Since 1990 till now: multiparty democracy: transition + »modernization« = repatriarchalization; • prevalent: rejection of one-bread-winnner ideology; • value priority at wom. and men : family+employment;;5.2 Women in S&R:\n• increase of women undergraduate students • (1950/51–32,3% ; 1980/81–53,9%, 2000/01– 57,2); • portion of women postgraduates increased • master\'s degree 1975–18,2%, 1990–35,6%, 2003–52,7; • PhD 1975–17,7%, 1990–26,4%, 2003–41,4%); • increase of women researchers 1992–28,3%, 2003–34%. • portion of women FT university teachers • 1980–15%; 1990–17,5%, 2004–31,4%.;;• prevalent is continuous career • since the middle of the 1970s: the extension of the time taken up by maternity/parental leave at re/elections for women and men. • gradual inclusion of gender perspective into academic teaching (since the 1970s) by prevalent integration model;;;1985 till now - programme »Young Researchers«: contributed to the increase of women young researchers; young researchers are employed for a specified period; along with the post-graduate studies, they work on basic and applied projects; within the period of training and education at home, they can also study abroad (from 1 month to 12 months);;;5.3 Obstacles for women\'s career (investigation in 1996):\n• • • • • at beginning - majority had no troubles hidden discrimination + stricter control of women lack of support in organization - »chilly« climate negative prejudices load of pedagogic and unpleasant work imposed upon women, worse conditions for their research • majority of women equally efficient (on behalf of “Spartan style of life”) • overburdening of women by family work • low women\'s awareness of possible changes;;5.4 What to do for the gender equality in science?\n• • • • • Nothing to do = status quo. Necessary activities on key levels: a) social environment b) work environment c) individual value orientation (consciousness-raising);;• National Committee for Gender Equality in Science (2001): • gender mainstreaming in strategic policy documents • informing researchers and academic leading staff • stimulating of the networking of researchers dealing in various fields with gender research • ongoing detection of cases of discrimination • cooperation with Helsinki Group • CEC-WYS (2006) – segmented recommendations;;•Thank you!'
5028,'lecture','en',5005,'2008-05-15','2009-10-22','Women in technical sciences research',NULL,'Women in technical sciences research;;Engineering;;Serbia - 1;;Serbia - 2;;USA - 1;;USA - 2;;Italy;;Thank you!;;Women in technical sciences research\nTatjana Bolic Venice International University;;Engineering\n• Civil and environmental\n• Electrical engineering and a computer science • Mechanical engineering • Bioengineering • Chemical engineering\n– Transportation;;Serbia\n• Faculty of Transport and Traffic Engineering\n– ~60 years – Almost none – 50-50%\n• Other engineering;;• Policy;;USA\n• Numbers differ by field\n• Academia vs. industry;;• Policy\n– Affirmative action – Family vs. work;;Italy\n• Policy or culture?;;• Thank you!'
5029,'lecture','en',5005,'2008-05-15','2009-10-22','Women in university education',NULL,NULL
5030,'lecture','en',5005,'2008-05-15','2009-10-22','The Forgotten Half',NULL,'The Forgotten Half: Portraits of Women in 19th and 20th Century in Slovenia;;The Forgotten Half - 1;;The Forgotten Half - 2;;The Forgotten Half: Two Women/Cases;;Adela Žgur;;129 Women and Creativity;;“Prešeren Awards”;;The Slovenian Academy of Sciences and Arts;;The Forgotten Half\nPortraits of Women in 19th and 20th Century in Slovenia (A.Šelih at al., eds);;The Forfotten Half:\n• 129 portraits of women, born between 18181920 Written by 60 authors Backgound: Slovenska ţena (1926, ed. Minka Govekar), portraits published by Janez Kajzer (Jana, 1970s), Splošno ţensko društvo (2003, eds.N. Budna Kodrič, A.Serše) Basis for future research;;The Forgotten Half\n• Fields of activity/creativity: literature, music,\ndance, fine arts, theatre and film, education, social sciences, politics, law, natural sciences, humanities, nunhood, health care, medicine, sports, turism, supporters/Maecenas; Common features: they all faught to make themselves value; great majority faced prejudices, discrimination and neglect; as a rule care of their children/families by themselves, often by themselves alone;;The Forgotten Half. Two women/cases\n• Felicita Kalinšek(1865-1937):a nun, author of\nthe most widespread/popular cookbook in Slovenia, more than 20 reprints, almost no personal data to be found. Is cooking a creative activity? Adela Ţgur (1909-1992): germanist,professor, translator, of modest origins, active anti-fascist, imprisoned, frail health, contributed significantly to modern education of German and English at the Faculty of Arts, author of Deutsche Grammatik and other grammar and text books, excellent translator;;Adela Ţgur:\ndid she do anything wrong as far as the public recognition of her work and personality is concerned?\n-as an excellent translator she charged very little institutions of education and culture she mostly worked for (resentment!) -didn’t care about scientific titles and statuses (“work makes me happy, that’s enough”) -extremely generous (seen as an eccentricity, she offered almost all she had to people in need in general and to Bosnian refugees in particular: “I need so little”) -when retired she liked her solitude, used to listen to classical music and knitted marvelous sweaters with most complicated designs. They went unnoticed.;;129 Women and Creativity\n• Were they creative? • If so, how can the lack of creative women\nin the history of Slovenia and Slovenians be explained? (selective mechanisms?, patriarchal context?, type of creativity?) • The power to define, select, interprete and forget creativity;;“Prešeren Awards”\n• Since 1947, outstanding achievements in\nculture • Gender structure 1947-2004: • 756 awards, 103 women (13,6%) and 653 men (86,4%) • Administration boards: 275 members, 28 women (10,18%) and 255 men (89,82%);;The Slovenian Academy of Sciences and Arts\n• Elected members for their outstanding\nachievements in sciences and arts; six sections. • Gender structure of members, present data: • Full members: 76, women 2 (2,6%) • Associate members: 27, woman 1 (3,7%) • Corresponding members: 79, women 0'
5031,'lecture','en',5005,'2008-05-15','2009-10-22','Managing research institute',NULL,'Managing Research Institute;;Research Institute;;Carreer Development;;The Director;;Major Qualities;;Department of Genetic Toxicology and Cancer Biology;;Perceptions of Being a Woman;;Family and Science – Slovenian Way;;Content;;Broader Societal Environment - 1;;Broader Societal Environment - 2;;Broader Societal Environment - 3;;In Conclusion;;Proportion of Female Researchers in 2003;;Content;;Figures - 1;;Share of Female Researchers - 1;;Figures - 2;;Share of Female Researchers - 2;;Proportions of Men and Women in a Typical Academic Career;;Zois Award: National Award for Science;;Share of Women in Advising Bodies and Evaluation Panels;;Gender Pay-Gap Covering Whole Economy;;Gender Pay-Gap in Research;;Legal Acts;;Women Among Researchers and R&D Expenditure;;Perspectives;;Content;;Recommendations;;Conclusions;;Thank You for Your Attention!;;WS DEBATE Conference, Ljubljana, May -15, 2008\nManaging Research Institute\nTamara Lah Turnšek\nNational Committee on Enhancement of the Role of Women in Science at the Ministry of Higher Education, Science and Technology\n- and remaining a scientist?;;Carreer development….\nfrom research assistant – lab work..\nData mining…and papers publishing\nGrant –writing, PIs and group leaders, Decision making - meetings and\nADMINISTRATION!\nDirector!;;THE DIRECTOR is: a PERSON with special: knowledge, talents, skills or training?\nScientist\nFittnes\nNetwork thinking\nManager\nPsychologist:emotional intelligence\nNobody has all the knowledge in all these fields - one can have some knowledge in some of the fields, but…;;Major qualities:\nFlexibility – not to think in the frames of disciplines – problem oriented approach Curiosity – novel pathways Networking- communication skills\nAmbition: for constant learning\nBe good listener – ready to compromise\nFast – but thorough and clear - decisions !!!;;Department of Genetic Toxicology and Cancer Biology ..since 1996\nNational Institute of Biology at Biological Centre\nsince1995;;… perceptions of being a WOMAN\nIn Society\nAt work\nAt home…;;Family and Science – Slovenian Way\nCREST –Meeting –BRDO-February 2008 Tamara Lah Turnšek\nNational Committee on Enhancement of the Role of Women in Science (Chair), Ministry of Higher Education, Science and Technology\nAnuška Ferligoj Danica Fink Maca Jogan Polona Novak Zofija Klemen Krek Jana Kolar Andreja Umek Venturini;;Content\n1: Broader societal environment 2: Figures 3: Recommendations;;Broader societal environment\nBefore 1990\n- 1945: Constitution grants man and women equal rights\nPolytical framework: self management Legal acts contributing to work-family harmonisation\n- 1974: Constitution grants women the decision on giving birth - 1974: The maternity leave is prolonged from 135 days to 6 months - 1976: The legal possibility of sharing of maternity (parental) leave - 1986: The paid maternity leave prolonged to 1 year.;;POST WW II:\nPeriod …\nPost 1991 period ..;;Broader societal environment Since 1990\n- Maternity leave is excluded for elections and evaluation system - Young Researchers project – “side effect”: more women in science!\nPolitical framework – towards parliamentary democracy\nScience and technology towards application Advanced evaluation system\nBUT\nScience is still considered “expenditure” and not an investment The change of the system did not improve social position of women Parental leave of absence is still mainly used by women Part time job/part time maternity leave is not possible Child/elderly care not satisfactory Work from home is (usually) not possible Limited mobility;;In conclusion…\nin Slovenia, as in many other former communist and socialist countries, the policies of early integration of women in the work force market and higher education, lead initially to relatively better situation of women in science compared to other, more industrialised countries, where women as yet have not achieved full integration in scientific and higher educational institutions. Due to specific political environment, Slovenia positioned itself and still remains in the middle – between Western and Eastern EU countries.;;Proportion of female researchers, 2003\nSlovenia\nSource: She Figures 2006\nEU25;;Content\n1: Broader societal environment 2: Figures\n3: Recommendations;;Figures\nAnalysis of present situation:\n- Similar situation as observed in most EU countries, except higher proportion of graduate students – Slovenian model.;;Share of female researchers\nIntroduction of Young Researchers Programme\nGraduates MsC 50 40 30 20 1950 1960 1970 1980 1990 2000 Full Professors (Institutes) Full professors (Academia) 2010 PhD\nSource: Statistical Office of the Republic of Slovenia, Slovenian Research Agency\nShare of women (%);;Figures\nAnalysis of present situation:\n- Similar situation as observed in most EU countries, except higher\nproportion of graduate students – Slovenian model. - Increased number of women applicants and beneficiaries of projects as well as increased success rate in natural sciences.\nBUT\n- Top positions - National science awards and - Slovenian Academy of Sciences and Arts members - Advising bodies and research councils are all men dominated and men-like behaviour expected\n- Vertical segregation: less pronounced at research institutes;;Share of female researchers\nIntroduction of Young Researchers Programme\nGraduates MsC 50 40 30 20 1950 1960 1970 1980 1990 2000 Full Professors (Institutes) Full professors (Academia) 2010 PhD\nSource: Statistical Office of the Republic of Slovenia, Slovenian Research Agency\nShare of women (%);;Proportions of men and women in a typical academic career\nproportion of men and women (%)\ngraduates\nMSc\nPhD\nFull professors\ndata for 2004;;Zois award: National award for science\nFor life achievements (13%)\nFor research excellence (12%)\nAcknowledgement (17%)\nDecreasing importance\nSource: Ministry of Higher Education, Science and Technology (www.mvzt.gov.si 2008);;Share of women in advising bodies and evaluation panels\nGovernment of the Republic of Slovenia\nPrime Minister\nScience & Technology Council\nMinistry of Higher Education, Science and Technology\nNational Committe ERWS\nSlovenian Research Agency\nSlovenian Technology Agency\nScientific Council\nExpert bodies\nEvaluation panels\nSources: Government of RS, Slovenian Research Agency (www.arrs.si 2008);;Gender pay-gap covering whole economy\nSource: She Figures 2006;;Gender pay-gap in research\nWomens’ Earnings Relative to Mens’ (%)\nAssist. (PhD) Assist. (Msc) Assist. Prof. Assoc. Prof. Assistant Full Prof.\nIncentive Function Suppl. 100% Total Gross Earning\nPublic Research Institutes by the Academic Grade - 2003/2004 Source: Ministry of Higher Education, Science and Technology, Slovenian Research Agency;;Legal acts\nNational Programme for Higher Education National Research and Development Programme (NRRP) National Programme for Equal Opportunities of Women and Men at the Section of Science and Research,\nrecognise obstacles to unequal position of women and men\nBUT - no quotas - no specific resources for gender mainstreaming. Although many legal acts demand for relative adequate presentation of women in all bodies, this is not always reflected at the lower acts and in practice.;;Women among researchers and R&D expenditure\nSl ov\nR&D expenditure per capita researcher (Euros)\nEU 15\nRe p\nen\nia\nH\nun\nSl ov\nLa tv ia\nCz\nE Ro sto m nia an i Bu a Li lg th ar ua ia ni a\nry\nla n\nec\nga\nPo\nak\nh\nRe pu b\nd\nub\nlic\nlic\nShare of women among researchers (%)\nSources: Eurostat, S&T statistics, EC 2003; ENWISE report, EC 2003;;Perspectives\nRecent statistical EU analysis are showing that in the technologically and scientifically less developed EU countries more women are in high position in science and academics. These inverse relationship between high-tech development and the employment of women in R&D, means that well paid, powerful, and prestigious positions are dominated by men! Moreover, this means, that in perspective, the technological development in the EU newcomers would lead to worsen the positions of women in science…\nIf not an immediate and strict measures are undertaken now in all EU countries!;;Content\n1: Broader societal environment 2: Figures 3: Recommendations;;Recommendations\n1. Clear target 2. Committment and Funds 3. Enhanced monitoring – EU impact 4. Building of awareness (general public, within the scientific community, particularly at the universities, within enterprises, media and networking ) 5. Positive measures are needed 6. Family friendly legislation (policy mix) to enhance demand side for women scientists and enable their transfer to economic sector;;Conclusions\nThe pool of highly sophisticated work force are undoubtedly highly educated women, women in science and academia. From the above, it is clear that the major goal of present activities is to improve the research and development potential by promoting more women into higher positions in research and development, particularly to recruit them in the economic sector. This is already recognised and practised by some companies in our country – economic benefit!\nThank you for your attention!;;Thank you for your attention! leaving NIB behind….'
5033,'lecture','en',5005,'2008-05-16','2009-10-22','Slovenian Equal Opportunity Office',NULL,'Women in Science and Decission-Making;;Women in Science and Research;;National Programme for Equal Opportunities for Women and Men;;Measures;;Implementation of NP - 1;;Implementation of NP - 2;;Women in Decission-Making;;Women in National Assembly;;Leadership Positionsin the Government;;Women in National Council;;Women Participation at Local Level;;Women in Local Councils;;Female Majors;;Members of the European Parliament;;Leadership Positionsin Administrative Structures;;Women in Judiciary in 2004;;Women in Prosecutor Offices;;Participation of Women in Economic Domain;;Legally Binding Provisions;;Science and Decission-Making\nWomen in\nSonja Robnik Ljubljana, May 16, 2008;;Women in Science and Research;;National Programme for Equal Opportunities for Women and Men, 2005 – 2013:\nReducing inequalities of women and men in science and research\nHolders of activities:\n• Ministry of Higher Education, Science and Technology • Office for Equal Opportunities;;Measures:  Implementation and support to programmes and projects promoting the participation of women in science and research\nPromotion and support to research and cooperation in the field of gender studies and implementation of gender mainstreaming in the programmes, policies and organizations of science and research Establishing and monitoring EU indicators on providing equal opportunities for women and men in the field of science and research\nAnalysing and eliminating the obstacles hindering work and promotion of female scientists;;Implementation of NP (2006-2007)\nPreparation and implementation of promotional programme for encouragement of women for profession scientists (in deficitary fields, in particular) and awareness raising activities on the importance of higher engagement of women in science for the development • Ministry of Higher Education, Science and Technology Tender for thematic research projects in the field of gender studies • Ministry of Higher Education, Science and Technology • Slovenian Research Agency;;Preparation of guidelines and implementation of the principle of obligatory preference of less represented sex among equal candidates in all relevant institutions • Ministry of Higher Education, Science and Technology • Slovenian Research Agency • other ministries • Commission Analysis on the situation of women in science and research in Slovenia according to indicators • Commission;;Women in Decission -Making;;Women in National Assembly\nSince the first multiparty elections the share of women in the parliament never exceeded 13 %.\nFemale MPs\nShare;;Leadership positions in the Government\nThe share of women ministers ranged from their absolute absence to 20 %.;;Women in National Council\nFemale Councillors Share 1;;Women participation at local level\nAfter elections in 2006, for which “women’s quotas”applied, percentage of women increased from 13 % to 21.5 %.;;Women in Local Councils\nFemale Councillors (%);;Female Majors\n1994 Local Communities Female Majors Share 147 2 1.4 % 1998 191 8 4.2 % 2002 193 12 6.2 % 2006 210 7 3.3 %;;Members of the European Parliament\nSlovenia:\n43% (among 7 members of the European Parliament 3 are women)\nEU average:;;Leadership positions in administrative structures (2004)\n52 % of women among senior administrative officials in government authorities and public administration 39 % of government offices are headed by women Women represent 36 % of members of the government bodies;;Women in judiciary in 2004\n44 % of judges of the Constitutional Court are women. 34 % of judges of the Supreme Court are women. 83 % of judges of labour courts are women. 77 % of judges of local courts are women. 50 % of presidential posts of local, district and labour courts are held by women.;;Women in prosecutor offices\n45 % of senior staff of the Supreme State Prosecutor General Office are women. 58 % of senior staff at district state prosecutor’s offices are women.\nState Prosecutor General is a woman.;;Participation of women in Economic domain\n49 % of government representatives in public enterprises are women 21 % of presidents and members of the highest decision-making body in the Top 50 companies are women (EU average is 11 %)\n7 % of members of daily executive body of the Top 50 companies are women (EU average is 4 %);;Legally binding provisions to promote gender balanced participation in elected assemblies\nconstitutional positive obligation for legislator to introduce special measures into electoral laws parity threshold (40 %) with ranking rule for female and male candidates introduced into the law on elections to the European Parliament parity threshold (40 %) with ranking rule for female and male candidates introduced in the law on local elections minimum of 35 % candidates of both sex with ranking rule for female and male candidates introduced in the law on parliamentary elections'
5034,'lecture','en',5005,'2008-05-16','2009-10-22','Experience of women in politics in socialism and transition period',NULL,'Experience of women in politics in socialism and transition period;;Position of women in a society is a reflection of the state of its democracy - 1;;Position of women in a society is a reflection of the state of its democracy - 2;;Black and white image of democracy before 1990;;The situation of women in Slovenia before 1990;;1970th on;;Societal environment - social care;;At work;;In political life - 1;;In political life - 2;;In political life - 3;;International activity;;Situation in 1989 in Slovenia;;After the first elections in 1990;;Societal environment;;At work place;;Political and public shere;;Anything in common?;;Experience of women in politics in socialism and transition period\nZofija Klemen-Krek;;Position of women in a society is a reflection of the state of its democracy (Nairobi Forward looking strategies);;• There is a glass ceilling, you can see the sun and a bright day, but clouds could come and cover it, the day is not any more bright. Making your day bright you have to watch for stormy clouds all the time.;;Black and white image of democracy before 1990: -Communist and socialist regimes as non-democratic,sometimes the Yugoslav’s was recognized as a different to others - All western countries as democratic regimes;;The situation of women in Slovenia before 1990\n• 1960th considerable change of economic and political situation (new Constitution 1963) • - growth of GDP and development, opened boarders • - rapid growth of employment of female population • - Enlargement of female enrolment in universities;;1970th on:\n• • • • 1974 new constitution followed by several codes Recognizing classical equal rights and: Special rpotection of women and mothers at work Family planning and free decision on childbearing (abortion) • paid maternity leave and parental leave introduced recognition of rape in family as criminal act • 1978 Resolution on Promoting the Status and Roel of women (as follow-up of Cuidad Mexico UN World Conference on Women -1975);;Societal environment- social care\n• construction of crashes and kindergartens • introduction of meals at work and in schools mandatory • paid parental leave for a sick child • broad introduction of family planning (free contraception) • Network of services as a help to the families;;At work\n• Equal payment for equal work • Forbidden any discrimination in advertising for a free working post except for health reasons when a work post was dangereous for fertility/pregnancy • Paid programs for continuation of education • Equal opportunities in competition for a job • special concern and care for women and mothers;;In political life\n• Communist Party introduced the role role of women in its program in 1940 and from then on it was in all its programs • Role of women incorporated in all relevant political documents and followed by a wide legal protection and promotion • Strong organization of councils for social political activities of women at all levels • Promotion and general understanding to tackle gender issues by constructing solidarity between women and men;;• Political promotion of involvement of women in political decision making at all levels (local community, community, republic and federal) • In decision-making in selfmanagement system in factories • League of Ccommunists, Socialist Alliance of Working People, Trade Unions, NGOs;;• No quotas, but it was ‘normal’ to include women into the list of candidates as a general obligation for all political and other organizations • Regular reports on situation of gender equality issues in the society and at work for political organizations;;International activity\n• Yugoslav system of self management was broadly followed and many progressive political parties used its ideas for their programs • Yugoslav delegations (mainly under strong influence of Slovene members) participated in all UN conferences on family planning and women, and substantially contributed to resolutions and final documents • Together with India and Irak Yugoslavia contributed to the 14 chapter of the Action plan of non-aligned countries and suggested an establishment of regular cooperation;;Situation in 1989 in Slovenia\n• Unemployment rate 2,5% • almost 48% out of labor force were women • 17,8 % members of Republic Assembly, 17% of Federal Assembly • 20% members of Community Councils • 28% members of councils of local communities • 37 % members of Trade Unions bodies • 33% members of worker’s councils in factories • In 1987 introduction of network on equality of men and women in all republic ministries, Board of Cocoordinators was presided by Vice President of the Republic Ggovernment as the follow-up of UN Nairobi Conference (1985);;After the first elections in 1990\n• • • • • • employment still high - 47% of women 4% of Parliament Members About 5 % of local communities councils Less than 10% in Trade Unions bodies Network of coordinators disappeared Political parties did not present equality of men and women in their political programs • No political action in favor of gender issues • Women disappeared from all decision-making positions • No female member of the Government;;Societal environment\n• equal rights were under severe pressure of conservative groups and in particular religious groups (mainly Catholic Church) – back to three K system • attack on free childbearing and family planning, strong oposition to abortion (the very first political demonstration against these pressures in December 1991) • Introduction of Office for equal opportunities – not active enough;;At work place\n• extreme growth of unemployment rate effected women most from mid 90th on • pressure on women against getting pregnant and use of parental leave for a sick child • rumors on signing a blank sheet of paper by young women, when getting a job • worsening of relations at work, worker’s rigts at stake • growth of prices of kindergartens and crashes, no new constructions • diminishing of equal payment for equal work;;Political and public shere\n• March 8 • Legal and political action • General presence of gender issues in media • Negation of all positive legal and political actions of the previous regime • Huge lack of knowledge among political decision-makers and their advisors;;Anything in common?\n• Legal and political will is not enough • Hidden discrimination is very dangereous in all systems • Every new commer in politics has to be informed anew • Being en garde all the time • Media are rather reluctant to discuss important issues on genders'
5035,'lecture','en',5005,'2008-05-16','2009-10-22','European Politics',NULL,NULL
5036,'lecture','en',5005,'2008-05-16','2009-10-22','Women in public institutions',NULL,'Analysing Female Visibility in Political Institutions;;Studies on Woman Participation in the Three Branches of Power;;Representation of Women in Jurisdiction;;Representation of Women in the Government - 1;;Representation ofWomen in the Government - 2;;Representation of Women in the Parliament - 1;;Representation of Women in the Parliament - 2;;Representation of Women in the Parliament - 3;;Parliamentary Deputies in the Media;;Parliamentary Deputies in the Media – An Example 1;;Parliamentary Deputies in the Media – An Example 2;;Parliamentary Deputies in the Media – An Example 3;;Parliamentary Deputies in the Media – An Example 4;;An Example from Textbook;;Analysing Female Visibility in Political Institutions Slovenia\nDr. Eva D. Bahovec University of Ljubljana;;Studies on woman participation in the three branches of power\n Most studies on woman participation in\npolitics focused mainly on the Government and Parliament.\n In the framework of EU research project on\nWomen and Governance the situation in jurisdiction has also been investigated.;;Representation of women in jurisdiction\n Representation of women in jurisdiction is far\nhigher than in the other two branches of power. This is also typical for other new EU members.\n Still, their presence declines with the\nimportance of the court.;;Representation of women in the Government\nSlovene Government\nThere used to be only one woman minster in the present government, in 2008 there are three of them.;;Ministrers by gender\n100% 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 1992 1996 2000* 2000 2004 men w omen\n The number of women ministers was highest\nin the period 2000-2004 (18,8%).;;Representation of women in the Parliament\n The number of woman deputies has varied\nbetween 7,8 and 13,3.\nDeputies by gender 100% 80% 60% 40% 20% 0% 1992 1996 2000 2004 men w omen;; Except for the one period they have been quite\nwell represented among the presidents of the Parliamentary Commissions...\nPresidents of Com m issions by gender 100% 80% 60% 40% 20% 0% 1992 1996 2000 2004 men w omen;;Heads of Deputies\' Clubs by gender\n ... but the same does\n100% 80% 60% 40% 20% 0% 1992 1996 2000 2004 men w omen\nnot hold true for the Deputies’ Clubs and Parliamentary Committees.\nPresidents of Com m ittees by gender 100% 80% 60% 40% 20% 0% 1992 1996 2000 2004 men w omen;;Parliamentary deputies in the media\n The Slovene Democratic Party seems to\nhave introduced a new way of presenting women in politics.;;Parliamentary deputies in the media – an example\nYellow press  Parliamentary deputies did not attract yellow press before the last elections when ex-TV speaker was elected.  Examples of questions: Do you wear the highest heels in the Parliament? Do your colleagues comment on your cleavage? Do you wear tanga slip?;;Maria Pozsonec\nHungarian minority Deputy since 1990\nMajda Potrata\nleft wing (Soc. Democrats) president of the Commission for Petitions, Equal Opportunities etc.\nEva Irgl\nright wing (SDS) theology student ex-tv speaker;;Photos from the media'
5037,'lecture','en',5005,'2008-05-16','2009-10-22','Women in international business',NULL,'Creative Women in Science & Public Life;;Women in International Business;;What can I contribute to this debate?;;Domain of work/services;;Types of investments;;Business impact – what is meant by this?;;Be patient with me – nearly there!;;So to your questions;;Current status of the gender policy in international businesses?;;Current activities to improve the women’s status and equality in international businesses;;Major problems and deviations;;Proposed solutions to improve the women’s equality status in an organisation/society;;Thank you for listening and happy to take questions!;;Creative women in Science & Public Life WS Debate Conference\n16 May 2008 Ljubljana;;Session 111 Women in International Business;;What can I contribute to this debate? Background Run a small niche (rapidly growing!) business in Cambridge, UK delivering services to (mainly) large firms/MNEs Business owner since 1993\nEvaluator of FP projects and other ‘expert’ contracts since 1994: mainly DG INFSO but also RESEARCH, Educ & Culture and Employment\nSome of these had specific gender/science dimension; more recently, E&D is ‘addressed’ in all FP projects;;Domain of work/services\nFocus is convergence of ‘Human Capital’ and ‘Knowledge Society’\nIntegration of technology into working and learning\nWorkplace/workforce changes Value of human capital and specifically, measurement of investment in human capital initiatives in workplaces Measurement of IMPACT and VALUE of investment in HC initiatives IMPACT – on the business / organisation’s goals\nVALUE – measuring costs versus benefits - was it worth spending the money?;;Types of investments\nLearning and Development (L&D) Knowledge Management (KM) Performance improvement Change management Workforce re-structuring\nNew business projects\nWould Equality and Diversity and Corporate Social Responsibility REMEMEBR ALL THESE INVESTMENTS COST THE BUSINESS – TIME, EXPENSES, 3RD PARTY EXPERTS ETC – ALL COSTS TO THE BUSINESS The business will always ask – what benefit will investing in these deliver to the business?;;Business impact – what is meant by this? Hard and soft measures\nHard measures include cost, time, output, quality\nSoft measures include innovation, external relationships, internal behaviours and attitudes\nIn order to measure: need a specific unit of measure ‘metric’ e.g. 1 hour of time, one kilo of item, one item which costs €X, one new patent, % change in customer satisfaction etc\nSome metrics can be converted into money easily (hard measures); others are very difficult (soft measures – intangibles);;Be patient with me – nearly there! Investment in human capital initiatives are usually accounted not as a cost of sale/cost of good or service but as an operating cost This is called ‘below the line’ Because they are not considered essential in selling the good/service, they tend to be treated with less importance Below the line costs tend to be subject to changing patterns of investment – usually linked to the financial performance of the organisation/economic environment: e.g. Learning and Development, R&D and other ‘desirable’ (but not essential) investments;;So to your questions Current status of the gender policy in an organisations/society Current activities to improve the women’s status and equality in an organisation/society\nMajor problems and deviations\nProposed solutions to improve the women’s equality status in an organisation/society;;Current status of the gender policy in international businesses? Most businesses have a policy but it almost always (in my experience) based on avoiding risk in relation to regulation (anti-discrimination) This means the business will usually have a policy which is NOT built from the expectation of a business benefit but the avoidance of a potential cost to the business Most businesses therefore develop a policy largely around the regulatory requirements and minimise the cost (of building and maintaining the policy) to the business as much as possible Result is that there is minimum investment and/because no business benefit demonstrated;;Current activities to improve the women’s status and equality in international businesses Most concerned with regulatory requirements Some focus on recruitment (if evidence of possible business benefit) Occasionally requiring balance on project teams (e.g. for customer engagement programmes) – if some potential business benefit – usually rather obvious May be very specific (e.g. contract may require certain conditions) Occasionally special ‘mobility’/women into senior management/executive initiatives Investment will be viewed from two perspectives – what business impact will it have and is it worth it? All of these investments are always going to be influenced by firm performance and economic climate AND amount of investment required;;Major problems and deviations\nBecause most organisations experience E&D primarily in terms of regulation, they view any E&D initiatives as an imposed cost which has no evident benefit to the business Because it is perceived to the a cost without evidence of benefit, organisations usually minimise the cost - often resulting in poor quality initiatives that deliver little or no result of any kind Most businesses are concerned with short term goals shareholders/investors ask few questions about long term investments and generally don’t care Businesses need to make a profit to grow and sustain/improve their competitive position; below the line investment will always be vulnerable Most people leading E&D initiatives in organisations make too little effort to build links to business metrics and measure the impact and value: the case is made in social and not economic terms;;Proposed solutions to improve the women’s equality status in an organisation/society\nNeed better and more organisation specific business impact studies – using standard business impact analytics and ROI measurement methodologies (not ‘one off’ research approaches based on variety of methodologies) – for reasons of cost and credibility\nPublic sector could do a great deal more as a customer/contractor\nPublic sector should also be showing business benefit and leading the way The champions need to accept that economic justification is required: otherwise business won’t listen!;;Thank you for listening and happy to take questions!'
5038,'lecture','en',5005,'2008-05-16','2009-10-22','Industry research centres',NULL,NULL
5039,'lecture','en',5005,'2008-05-16','2009-10-22','Women entrepreneurs',NULL,'“I am life”;;I feel like a woman;;I love creating;;I believe in an open smile;;Upbringing;;Inner drive;;External influence;;Mayor challenges;;What could be done;;Thank you;;“I am life”\nVioleta Bulc www.vibacom.si www.violeta.si\nEcontent Summit: scenarij za odućnost\nLjubljana, May 2008;;I feel like a woman, I act like a woman, I think like a woman, I dream like a woman, I am a woman. Yet deep inside I fell like a person brought to this world to fulfill the mission that inspires my path.;;I love creating I love uncovering new spaces and expending the existing ones I love to inspire others I love the beauty of life;;I believe in an open smile I believe in a strong handshake I believe in networks I believe in holistic solutions I believe in space;;Upbringing…. (Žiga’s story);;Inner drive …. (Violeta’s story);;External influence … (my cousin’s story a Slavic woman);;Mayor challenges: - fear - lack of opportunities to experience diversity - lack of respect and trust - lack of cooperation and communication - strength of historical principles - education materials - media - role models;;What could be done: - increase the realm of vision (diversity, possibilities,\nequality)\n- be persuasive and argumentative in a dialog with all interest groups - create models and networks (of diversity) and ensure their continuous evolution (based on\nsoftness and strengths of nurturing, support, care)\n- seek and achieve leadership - use quotas to speed up the process - learn how to lead and participate in a dialog - learn to believe in yourself;;Thank you\nVioleta\nwww.violeta.si www.vibacom.si'
5040,'debate','en',5005,'2008-05-16','2009-10-22','Round table discussion',NULL,NULL
6345,'invited talk','en',6300,'2006-03-06','2010-07-13','Visualizing density in photography',NULL,NULL
7160,'lecture','en',6319,'2005-02-02','2009-12-04','Lecture 1: Introduction - Sampling Theorem and Orthonormal PAM/QAM - Capacity of AWGN Channels',NULL,NULL
7161,'lecture','en',6319,'2005-02-07','2009-12-04','Lecture 2: Performance of Small Signal Constellations',NULL,NULL
7162,'lecture','en',6319,'2005-02-09','2009-12-04','Lecture 3 and 4: Hard-decision and Soft-decision Decoding',NULL,NULL
7163,'lecture','en',6319,'2005-02-16','2009-12-04','Lecture 5 and 6: Introduction to Binary Block Codes',NULL,NULL
7164,'lecture','en',6319,'2005-02-23','2009-12-04','Lecture 7, 8 and 9: Introduction to Finite Fields',NULL,NULL
7165,'lecture','en',6319,'2005-03-07','2009-12-04','Lecture 10, 11 and 12: Reed-Solomon Codes',NULL,NULL
7166,'lecture','en',6319,'2005-02-23','2009-12-04','Lecture 13 and 14: Introduction to Convolutional Codes',NULL,NULL
7167,'lecture','en',6319,'2005-04-06','2009-12-04','Lecture 15 and 16: Trellis Representations of Binary Linear Block Codes',NULL,NULL
7168,'lecture','en',6319,'2005-04-13','2009-12-04','Lecture 17 and 18: Codes on Graphs',NULL,NULL
7169,'lecture','en',6319,'2005-04-25','2009-12-04','Lecture 19: The Sum-Product Algorithm',NULL,NULL
7170,'lecture','en',6319,'2005-05-02','2009-12-04','Lecture 20 and 21: Turbo, LDPC, and RA Codes',NULL,NULL
7171,'lecture','en',6319,'2005-05-09','2009-12-04','Lecture 22 and 23: Lattice and Trellis Codes',NULL,NULL
7172,'lecture','en',6321,'2006-01-12','2010-05-13','Lecture 1: Introduction; Basics of Legal Research; Legal Citations',NULL,NULL
7173,'lecture','en',6321,'2006-01-19','2010-05-13','Lecture 2: LexisNexis®; 1976 Copyright Act','Here\'s a LexisNexis® handout you may find helpful. (PDF)\n\nPlease read these cases to discuss in class:\n\n- [[http://caselaw.lp.findlaw.com/scripts/getcase.pl?court=us&vol=499&invol=340|Feist Publications, Inc. v. Rural Telephone Service Co.]], 499 U.S. 340 (1991). ([[http://ocw.mit.edu/NR/rdonlyres/Electrical-Engineering-and-Computer-Science/6-912January--IAP--2006/A7D69482-B8C0-4A1D-952E-A58ADAC98216/0/feist.pdf|PDF]])\n\n- [[http://caselaw.lp.findlaw.com/scripts/getcase.pl?court=us&vol=000&invol=U10426|Campbell v. Acuff-Rose Music, Inc.]], 510 U.S. 569 (1994). ([[http://ocw.mit.edu/NR/rdonlyres/Electrical-Engineering-and-Computer-Science/6-912January--IAP--2006/1B8A67E3-1DC4-4E7C-8B56-E8C48E4056B3/0/campbell.pdf|PDF]])\n\n- On Command Video Corp. v. Columbia Pictures Industries, 777 F. Supp. 787 (N.D. Cal. 1991). (PDF)\n\n- [[http://caselaw.lp.findlaw.com/scripts/getcase.pl?court=us&vol=464&invol=417|ony Corp. of America v. Universal City Studios, Inc.]], 464 U.S. 417 (1984). ([[http://ocw.mit.edu/NR/rdonlyres/Electrical-Engineering-and-Computer-Science/6-912January--IAP--2006/E631BDFB-DF7D-4DA7-B6A7-1861AEF62A60/0/sony.pdf|PDF]])\n\n(Remember, just type the middle part of the citation (e.g., \"499 U.S. 340\") into the \"Get a Case\" citation field in Lexis-Nexis to call up the opinion.)',NULL
7174,'lecture','en',6321,'2006-01-26','2010-05-13','Lecture 3: Copyright applied to Music, Computers; Napster®; Peer-to-Peer File Sharing','Go to LexisNexis®, \"Legal Research,\" then \"Federal Code,\" and finally \"Guided Search.\" (That will take you to this form.)\n\nSearch for \"17 uscs\" in \"Cite.\" This will pull up the entire [[http://www.copyright.gov/title17/|Copyright Act]]. Alternately, you can use the [[http://www.copyright.gov/|U. S. Copyright Office]]\'s file: [[http://ocw.mit.edu/NR/rdonlyres/Electrical-Engineering-and-Computer-Science/6-912January--IAP--2006/AEADEBD6-84C3-4568-8131-467C351748A1/0/copyright_law.pdf|(PDF - 3 MB]]).\n\nRead the following sections of the statute. (If the section seems to go on and on, just read the first few subsections. You may find it helpful to look back at the definitions in section 101.)\n\n* 106 (Core Rights)\n* 106A (Limited Moral Rights)\n* 107 (Fair Use)\n* 109 (First Sale)\n* 110 (Exempt Performances)\n* 115 Only Read Subsections (a) and (b) (Musical \"Covers\")\n* 117 (Computer Programs)\n* 302 (Duration of Copyright)\n* 401 (Copyright Notice)\n* 411 (Registration)\n* 504 (Damages for Infringement)\n* 506 (Criminal Violations, including LaMacchia Law)',NULL
7175,'lecture','en',6321,'2006-02-02','2010-05-13','Lecture 4: Software Licensing; DVDs and Encryption','Read [[http://www4.law.cornell.edu/uscode/html/uscode17/usc_sec_17_00000512----000-.html|17 U.S.C. § 512.]] (Remember: Use \"17 uscs sec 512\".)\n\nRead [[http://www.law.cornell.edu/copyright/cases/180_F3d_1072.htm|Recording Industry Ass\'n of America v. Diamond Multimedia Systems, Inc.]], 180 F.3d 1072 (9th Cir. 1999).\n\nRead [[http://caselaw.lp.findlaw.com/scripts/getcase.pl?navby=case&court=2nd&no=00-9185|Universal City Studios, Inc. v. Corley]], 273 F.3d 429 (2d Cir. 2001). [[http://ocw.mit.edu/NR/rdonlyres/Electrical-Engineering-and-Computer-Science/6-912January--IAP--2006/10BD93D5-3B98-47E4-B1CB-20658542E0DC/0/corley.pdf|(PDF)]]\n\nRead [[http://caselaw.lp.findlaw.com/scripts/getcase.pl?navby=case&court=fed&no=04-1118|Chamberlain Group, Inc. v. Skylink Technologies, Inc.]], 381 F.3d 1178 (Fed. Cir. 2004). [[http://ocw.mit.edu/NR/rdonlyres/Electrical-Engineering-and-Computer-Science/6-912January--IAP--2006/8732161B-AF8C-44F2-B86D-8D32087A244C/0/chamberlain.pdf|(PDF)]]\n\nRead Jonathan Zittrain\'s essay, \"The Copyright Cage,\" in [[http://www.legalaffairs.org/issues/July-August-2003/feature_zittrain_julaug03.msp|legalaffairs magazine]].',NULL
7304,'lecture','en',6378,'2006-09-01','2010-06-28','Lecture 1: Derivatives, slope, velocity, rate of change',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.01 Single Variable Calculus\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;Lecture 1\nUnit 1: Derivatives\nA. What is a derivative?\n• Geometric interpretation • Physical interpretation • Important for any measurement (economics, political science, ﬁnance, physics, etc.)\nB. How to diﬀerentiate any function you know.\nd � x arctan x � • For example: e . We will discuss what a derivative is today. Figuring out how to dx diﬀerentiate any function is the subject of the ﬁrst two weeks of this course.\nLecture 1: Derivatives, Slope, Velocity, and Rate of Change\nGeometric Viewpoint on Derivatives\ny\nQ Secant line P f(x) x0 x0+∆x Tangent line\nFigure 1: A function with secant and tangent lines The derivative is the slope of the line tangent to the graph of f (x). But what is a tangent line, exactly? 1;;• It is NOT just a line that meets the graph at one point. • It is the limit of the secant line (a line drawn between two points on the graph) as the distance between the two points goes to zero.\nGeometric deﬁnition of the derivative:\nLimit of slopes of secant lines P Q as Q → P (P ﬁxed). The slope of P Q:\n(x0+∆x, f(x0+∆x))\nQ\nSecant Line\n∆f\n(x0, f(x0))\nP\n∆x\nFigure 2: Geometric deﬁnition of the derivative\nΔx→0\nlim\nΔf Δx\n= lim\nΔx→0\n“diﬀerence quotient”\nf (x0 + Δx) − f (x0 ) Δx � �� �\nf � (x0 ) � �� � “derivative of f at x0 ”\nExample 1. f (x) =\n1 x\nOne thing to keep in mind when working with derivatives: it may be tempting to plug in Δx = 0 Δf 0 right away. If you do this, however, you will always end up with = . You will always need to Δx 0 do some cancellation to get at the answer. Δf = Δx\n1 x0 +Δx\n1 x0\nΔx\n� � � � −1 1 x0 − (x0 + Δx) 1 −Δx = = = Δx (x0 + Δx)x0 Δx (x0 + Δx)x0 (x0 + Δx)x0 −1 −1 = 2 (x0 + Δx)x0 x0\nTaking the limit as Δx → 0,\nΔx→0\nlim;;y\nFigure 3: Graph of Hence,\n f � (x0 ) =\nNotice that f � (x0 ) is negative — as is the slope of the tangent line on the graph above. Finding the tangent line. Write the equation for the tangent line at the point (x0 , y0 ) using the equation for a line, which you all learned in high school algebra: y − y0 = f � (x0 )(x − x0 ) Plug in y0 = f (x0 ) = 1 −1 and f � (x0 ) = 2 to get: x0 x0 y− −1 1 = 2 (x − x0 ) x0 x0;;Figure 4: Graph of\nJust for fun, let’s compute the area of the triangle that the tangent line forms with the x- and y-axes (see the shaded region in Fig. 4). First calculate the x-intercept of this tangent line. The x-intercept is where y = 0. Plug y = 0 into the equation for this tangent line to get: 0 − 1 = x0 −1 = x0 1 x = x2 0 x = −1 (x − x0 ) x2 0 −1 1 x+ x2 x0 0 2 x0 2 x2 ( ) = 2x0 0 x0\nSo, the x-intercept of this tangent line is at x = 2x0 . 1 1 and x = are identical equations, x y the graph is symmetric when x and y are exchanged. By symmetry, then, the y-intercept is at y = 2y0 . If you don’t trust reasoning with symmetry, you may follow the same chain of algebraic reasoning that we used in ﬁnding the x-intercept. (Remember, the y-intercept is where x = 0.) Next we claim that the y-intercept is at y = 2y0 . Since y = Finally,\n Area = 1 1\n (2y0 )(2x0 ) = 2x0 y0 = 2x0 ( ) = 2 (see Fig. 5) 2 x0\nCuriously, the area of the triangle is always 2, no matter where on the graph we draw the tangent line.;;y x-1\n2y0 y0\nNotations\nCalculus, rather like English or any other language, was developed by several people. As a result, just as there are many ways to express the same thing, there are many notations for the derivative. Since y = f (x), it’s natural to write Δy = Δf = f (x) − f (x0 ) = f (x0 + Δx) − f (x0 ) We say “Delta y” or “Delta f ” or the “change in y”. If we divide both sides by Δx = x − x0 , we get two expressions for the diﬀerence quotient: Δy Δf = Δx Δx Taking the limit as Δx → 0, we get Δy Δx Δf Δx → → dy (Leibniz’ notation) dx f � (x0 ) (Newton’s notation)\nWhen you use Leibniz’ notation, you have to remember where you’re evaluating the derivative — in the example above, at x = x0 . Other, equally valid notations for the derivative of a function f include df � , f , and Df dx;;Example 2. f (x) = xn where n = 1, 2, 3...\nWhat is d n x ? dx\n To ﬁnd it, plug y = f (x) into the deﬁnition of the diﬀerence quotient.\n Δy (x0 + Δx)n − xn (x + Δx)n − xn 0 = = Δx Δx Δx (From here on, we replace x0 with x, so as to have less writing to do.) Since (x + Δx)n = (x + Δx)(x + Δx)...(x + Δx) We can rewrite this as � � xn + n(Δx)xn−1 + O (Δx)2 O(Δx)2 is shorthand for “all of the terms with (Δx)2 , (Δx)3 , and so on up to (Δx)n .” (This is part of what is known as the binomial theorem; see your textbook for details.) Δy (x + Δx)n − xn xn + n(Δx)(xn−1 ) + O(Δx)2 − xn = = = nxn−1 + O(Δx) Δx Δx Δx Take the limit:\nΔx→0\nn times\nlim\nΔy = nxn−1 Δx\nTherefore,\nd n x = nxn−1 dx This result extends to polynomials. For example, d 2 (x + 3x10 ) = 2x + 30x9 dx\nPhysical Interpretation of Derivatives\nYou can think of the derivative as representing a rate of change (speed is one example of this). On Halloween, MIT students have a tradition of dropping pumpkins from the roof of this building, which is about 400 feet high. The equation of motion for objects near the earth’s surface (which we will just accept for now) implies that the height above the ground y of the pumpkin is: y = 400 − 16t2 The average speed of the pumpkin (diﬀerence quotient) = When the pumpkin hits the ground, y = 0, 400 − 16t2 = 0 6 Δy distance travelled = Δt time elapsed;;Solve to ﬁnd t = 5. Thus it takes 5 seconds for the pumpkin to reach the ground. Average speed = 400 ft = 80 ft/s 5 sec\nA spectator is probably more interested in how fast the pumpkin is going when it slams into the ground. To ﬁnd the instantaneous velocity at t = 5, let’s evaluate y � : y � = −32t = (−32)(5) = −160 ft/s (about 110 mph)\ny � is negative because the pumpkin’s y-coordinate is decreasing: it is moving downward.'
7305,'lecture','en',6378,'2006-09-01','2010-06-28','Lecture 2: Limits, continuity - Trigonometric limits',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.01 Single Variable Calculus\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;Lecture 2\nLecture 2: Limits, Continuity, and Trigonometric\n Limits\nMore about the “rate of change” interpretation of the derivative\ny\ny = f(x)\n∆y\n∆x\nx\nFigure 1: Graph of a generic function, with Δx and Δy marked on the graph\nΔy Δx Average rate of change\ndy as Δx → 0 dx Instantaneous rate of change\nExamples\n1. q = charge 2. s = distance 3. T = temperature dq = electrical current dt ds = speed dt dT = temperature gradient dx;;4. Sensitivity of measurements: An example is carried out on Problem Set 1. In GPS, radio signals give us h up to a certain measurement error (See Fig. 2 and Fig. 3). The question is ΔL how accurately can we measure L. To decide, we ﬁnd . In other words, these variables are Δh related to each other. We want to ﬁnd how a change in one variable aﬀects the other variable.\nsatellite\ns\nh\nL\nyou\nFigure 2: The Global Positioning System Problem (GPS)\ns L\nh\nFigure 3: On problem set 1, you will look at this simpliﬁed “ﬂat earth” model;;Limits and Continuity\nEasy Limits\nx2 + x 32 + 3 12 = = =3 x→3 x + 1 3+1 4 With an easy limit, you can get a meaningful answer just by plugging in the limiting value. lim Remember,\nx→x0\nlim\nΔf f (x0 + Δx) − f (x0 ) = lim Δx x→x0 Δx\nis never an easy limit, because the denominator Δx = 0 is not allowed. (The limit x → x0 is computed under the implicit assumption that x = x0 .) �\nContinuity\nWe say f (x) is continuous at x0 when\nx→x0\nlim f (x) = f (x0 )\nPictures\ny\nx\nFigure 4: Graph of the discontinuous function listed below\n� f (x) =\nx+1 −x\nx>0 x≥0;;This discontinuous function is seen in Fig. 4. For x > 0,\nx→ 0\nlim f (x) = 1\nbut f (0) = 0. (One can also say, f is continuous from the left at 0, not the right.) 1.\nRemovable Discontinuity\nFigure 5: A removable discontinuity: function is continuous everywhere, except for one point\nDeﬁnition of removable discontinuity\n Right-hand limit: lim+ f (x) means lim f (x) for x > x0 .\nx→x0 x→x0\nLeft-hand limit:\nlim f (x) means lim f (x) for x < x0 .\nIf lim+ f (x) = lim− f (x) but this is not f (x0 ), or if f (x0 ) is undeﬁned, we say the disconti­\nnuity is removable. For example, sin(x) is deﬁned for x = 0. We will see later how to evaluate the limit as x → 0. � x;;Jump Discontinuity\nFigure 6: An example of a jump discontinuity\nlim for (x < x0 ) exists, and lim− for (x > x0 ) also exists, but they are NOT equal.\nInﬁnite Discontinuity\ny\nx\nFigure 7: An example of an inﬁnite discontinuity: Right-hand limit: lim 1 = ∞; x Left-hand limit: lim\n1 x\n1 = −∞ x;;Other (ugly) discontinuities\nFigure 8: An example of an ugly discontinuity: a function that oscillates a lot as it approaches the origin This function doesn’t even go to ±∞ — it doesn’t make sense to say it goes to anything. For something like this, we say the limit does not exist.;;Picturing the derivative\ny x\ny’\nx\nFigure 9: Top: graph of f (x) =\n and Bottom: graph of f � (x) = − 2\n x x\nNotice that the graph of f (x) does NOT look like the graph of f � (x)! (You might also notice that f (x) is an odd function, while f � (x) is an even function. The derivative of an odd function is always even, and vice versa.);;Pumpkin Drop, Part II\n This time, someone throws a pumpkin over the tallest building on campus.\nFigure 10: y = 400 − 16t2 , −5 ≤ t ≤ 5\nFigure 11: Top: graph of y(t) = 400 − 16t2 . Bottom: the derivative, y� (t);;Two Trig Limits\nNote: In the expressions below, θ is in radians— NOT degrees! sin θ = 1; θ 1 − cos θ =0 θ\nθ →0\nlim\nθ →0\nlim\nHere is a geometric proof for the ﬁrst limit:\n1 θ\nsinθ\narc length =θ\nFigure 12: A circle of radius 1 with an arc of angle θ\n1 θ\nsin θ\narc length =θ\nFigure 13: The sector in Fig. 12 as θ becomes very small Imagine what happens to the picture as θ gets very small (see Fig. 13). As θ → 0, we see that sin θ → 1. θ 9;;What about the second limit involving cosine?\nθ cos θ\n1 - cos θ\nFigure 14: Same picture as Fig. 12 except that the horizontal distance between the edge of the triangle and the\nperimeter of the circle is marked\nFrom Fig. 15 we can see that as θ → 0, the length 1 − cos θ of the short segment gets much 1 − cos θ smaller than the vertical distance θ along the arc. Hence, → 0. θ\nθ cos θ\n1 - cos θ\nFigure 15: The sector in Fig. 14 as θ becomes very small;;We end this lecture with a theorem that will help us to compute more derivatives next time. Theorem: Diﬀerentiable Implies Continuous. If f is diﬀerentiable at x0 , then f is continuous at x0 . � Proof: lim (f (x) − f (x0 )) = lim\nx→x0 x→x0\n� f (x) − f (x0 ) (x − x0 ) = f � (x0 ) · 0 = 0. x − x0 x − x0 . It looks as x − x0\nRemember: you can never divide by zero! The ﬁrst step was to multiply by\n0 if this is illegal because when x = x0 , we are multiplying by . But when computing the limit as 0 x → x0 we always assume x �= x0 . In other words x − x0 �= 0. So the proof is valid.'
7306,'lecture','en',6378,'2006-09-01','2010-06-28','Lecture 3: Derivatives of products, quotients, sine, cosine',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.01 Single Variable Calculus\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;Lecture 3\nLecture 3 (presented by Kobi Kremnizer): \n Derivatives of Products, Quotients, Sine, and \n Cosine \nDerivative Formulas\nThere are two kinds of derivative formulas: d 1. Specific Examples: -x\" or dx\n2. General Examples: (u\n+ v)\' = u1+ v1 and (cu) = cul (where c is a constant)\nA notational convention we will use today is:\nProof of (u v) = u v. (General) \' \'\n$@rt by using the definition af &hederivative.\n(U\n+ v)\'(x)\n(U U)(X a x ) - (U v)(x) ax U(X a x ) V(X AX) - U(X) V(X) lirn Ax-0 ax u(x Ax) - u(x) v (x Ax) - v(x) lim AX-O Ax Ax\nAx-0\nlirn\nFollow the same procedure to prove that (cu)\' = cu\'.\nDerivatives of sin x and cos x. (Specific)\nLast time, we computed\nx-0\nlim\nsin x x\nAX-o\nd -(sinx) I Z E o = dx d -(co~x)I~=~ = dx\nlirn\nsin(0\nCOS(O\nAX-0\nlim\n+ Ax) sin(0) = lim -= 1 sin(Ax) ax AX-o ax +a x ) C O S ( ~- i X) = lim =0\nCOS(O)\nax\nAZ-O\nax\nd d So, we know the value of - sin x and of - cos x at x = 0. Let us find these for arbitrary x. dx dx d sin(x Ax) - sin(x) -sin x = lirn dx AX-0 ax;;Recall:\nAx sin x(cos Ax - 1) lim AX-o Ax cos Ax - 1 AX-o s i n s ( lim Ax\nsin x cos Ax\n+ cos x sin Ax - sin(%)\ncos x sin Ax Ax\na s t oC\nO S X ( ~ )\nsin Ax\nSince\ncos Ax - 1 sin Ax + 0 and that - 1, the equation above simplifies to -+ Ax \n Ax d\n -sinx dx\n= cosx\nA similar calculation gives\nd cosx = dx\nProduct formula (General)\n(uv)\' Proof: (uv)\' = lim Now obviously, so adding that to the numerator won\'t change anything. (uv)\' = lirn\n= ulv\n+ uvl\nu(x\n(uv)(X\nh x t ~\n+ AX)- (UV) = (x)\nAx\nAxto\n+ Ax)v(x + Ax) - u(x)v(x)\nAX\nu(x\n+ Ax)v(x) - u(x)v(x) + U(X + AX)V(X Ax) - u(x + Ax)v(x) +\nAX\nWe can re-arrange that expression to get (uv)\'\n) V(X)+\n (uv)\'\n= ul(x)v(x)\nU(X\nRemember, the limit of a sum is the sum of the limits. u(x\n+ Ax) - u(x) \n+ u(x)vl(x)\nI>\nNote: we also used the fact that\nlirn u(x\n+ Ax) = u(x)\n(true because u is continuous)\nThis proof of the product rule assumes that u and v have derivatives, which implies both functions are continuous.;;Figure 1: A graphical \"proof\" of the product rule\nAn intuitive justification:\nWe want to find the difference in area between the large rectangle and the smaller, inner rectangle. The inner (orange) rectangle has area uv. Define Au, the change in u , by\n+Ax) - U ( X ) We also abbreviate u = u ( x ) ,so that u ( x + Ax) = u + Au, and, similarly, v ( x + A x ) = v + Av. Therefore the area of the largest rectangle is (u + Au) (v + Av).\nAu = u(x\nIf you let v increase and keep u constant, you add the area shaded in red. If you let u increase and keep v constant, you add the area shaded in yellow. The sum of areas of the red and yellow rectangles is: [u(v Av) - uv] [v(u Au) - uv] uAv vAu =\nIf Au and Av are small, then ( A u ) ( A v ) FZ 0, that is, the area of the white rectangle is very small. Therefore the difference in area between the laxgest rectangle and the orange rectangle is approximately the same as the sum of areas of the red and yellow rectangles. Thus we have:\n[(u Au) ( v + Av) - uv] w uAv + vAu\n(Divide by A x and let Ax + 0 to finish the argument.);;Quotient formula (General)\nTo calculate the derivative of ulv, we use the notations Au and Av above. Thus, u(x Ax) U(X Ax)\nu(x)\nV(X)\nu+Au v+Av (\"\nu v\n- u(v (common denominator) (v Av)v ( A u ) - u(Av) ~ (cancel uv - uv) (v Av)v\nHence,\nTherefore. u u\'v\nuv\'\nu2'
7307,'lecture','en',6378,'2006-09-01','2010-06-28','Lecture 4: Chain rule - Higher derivatives',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.01 Single Variable Calculus\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;Lecture 4\nSept. 14, 2006\nLecture 4 Chain Rule, and Higher Derivatives\nChain Rule\nWe’ve got general procedures for diﬀerentiating expressions with addition, subtraction, and multi­ \n plication. What about composition?\n Example 1. y = f (x) = sin x, x = g(t) = t2 .\n dy , write\n So, y = f (g(t)) = sin(t2 ). To ﬁnd dt t0 = t0 x0 = g(t0 ) y0 = f (x0 ) t = t0 + Δt x = x0 + Δx y = y0 + Δy\nΔy Δy Δx = · Δt Δx Δt As Δt → 0, Δx → 0 too, because of continuity. So we get: dy dy dx ← The Chain Rule! = dt dx dt In the example, dx dy = 2t and = cos x. dt dx\nSo,\n� d � sin(t2 ) dt\ndy dx )( ) dx dt (cos x)(2t) � � (2t) cos(t2 ) (\nAnother notation for the chain rule\nd f (g(t)) = f � (g(t))g � (t) dt Example 1. (continued) � or d f (g(x)) = f � (g(x))g � (x) dx �\nComposition of functions f (x) = sin x and g(x) = x2 = = �= f (g(x)) g(f (x)) g ◦ f. = = sin(x2 ) sin2 (x)\n(f ◦ g)(x) (g ◦ f )(x) Note: f ◦g\nNot Commutative!;;x\ng\ng(x)\nf\nf(g(x))\nFigure 1: Composition of functions: f ◦ g(x) = f (g(x)) d cos dx � � 1 =? x\nExample 2. Let u = 1 x\ndy dx dy du dy dx Example 3. d � −n � x =? dx\ndy du du dx − sin(u); du 1 = − 2 dx x\n� � 1 � � sin sin(u) −1 x = (− sin u) = x2 x2 x2\nThere are two ways to proceed. x−n =\n� �n 1 1 , or x−n = n x x\n� �n � �n−1 � � 1 1 −1 = n = −nx−(n−1) x−2 = −nx−n−1 x x x2 � � � � d � −n � d 1 −1 2. x = = nxn−1 = −nx−n−1 (Think of xn as u) dx dx xn x2n d � −n � d 1. x = dx dx;;Higher Derivatives\nHigher derivatives are derivatives of derivatives. For instance, if g = f � , then h = g � is the second derivative of f . We write h = (f � )� = f �� .\nNotations\nf � (x) f �� (x) f ��� (x) f (n) (x) Df D2 f D3 f Dn f df dx d2 f dx2 d3 f dx3 dn f dxn\nHigher derivatives are pretty straightforward —- just keep taking the derivative! Example. Dn xn = ?\n Start small and look for a pattern.\n Dx D x D x D x\n D(2x) = 2\nD 3 x3\n4 4 n n\nD2 (3x2 ) = D(6x) = 6\nD (4x ) = D (12x ) = D(24x) = 24\nn! ← we guess, based on the pattern we’re seeing here.\nThe notation n! is called “n factorial” and deﬁned by n! = n(n − 1) · · · 2 · 1 Proof by Induction: We’ve already checked the base case (n = 1). Induction step: Suppose we know Dn xn = n! (nth case). Show it holds for the (n + 1)st case. � � Dn+1 xn+1 = Dn Dxn+1 = Dn ((n + 1)xn ) = (n + 1)Dn xn = (n + 1)(n!) Dn+1 xn+1 Proved! = (n + 1)!'
7308,'lecture','en',6378,'2006-09-01','2010-06-28','Lecture 5: Implicit differentiation, inverses',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.01 Single Variable Calculus\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;Lecture 5\nLecture 5 Implicit Diﬀerentiation and Inverses\nImplicit Diﬀerentiation\nd a Example 1. (x ) = axa−1 . dx We proved this by an explicit computation for a = 0, 1, 2, .... From this, we also got the formula for a = −1, −2, .... Let us try to extend this formula to cover rational numbers, as well: m a= ; n We want to compute m y=xn where m and n are integers. so ny n−1 dy dy = mxm−1 . Solve for : dx dx\ndy . We can say y n = xm dx\ndy m xm−1 = dx n y n−1\nm We know that y = x( n ) is a function of x.\ndy dx\nSo,\ndy dx\n� � m xm−1 n y n−1 � � m xm−1 n (xm/n )n−1 m xm−1 n xm(n−1)/n m (m−1)− m(n−1) n x n m n(m−1)−m(n−1) n x n m nm−n−nm+m n x n m m−n n xn n m m −1 xn n\nThis is the same answer as we were hoping to get! Example 2. Equation of a circle with a radius of 1: x2 +y 2 = 1 which we can write as y 2 = 1−x2 . √ So y = ± 1 − x2 . Let us look at the positive case:\ny dy dx\n + 1 − x2 = (1 − x2 ) 2\n � � −1 1 −x −x (1 − x2 ) 2 (−2x) = √ = 2 2 y 1−x 1;;Now, let’s do the same thing, using implicit diﬀerentiation. x2 + y 2 � d � 2 x + y2 dx d 2 d 2 (x ) + (y ) dx dx Applying chain rule in the second term, dy dx dy 2y dx dy dx Same answer! 2x + 2y Example 3. = = = 0 −2x −x y = = = 1 d (1) = 0 dx 0\ny 3 + xy 2 + 1 = 0. In this case, it’s not easy to solve for y as a function of x. Instead, dy we use implicit diﬀerentiation to ﬁnd . dx 3y 2 We can now solve for dy dy + y 2 + 2xy = 0 dx dx\ndy in terms of y and x. dx dy (3y 2 + 2xy) dx dy dx = = −y 2 3y 2 −y 2 + 2xy\nInverse Functions\nIf y = f (x) and g(y) = x, we call g the inverse function of f , f −1 : x = g(y) = f −1 (y) Now, let us use implicit diﬀerentiation to ﬁnd the derivative of the inverse function. y f (y) d −1 (f (y)) dx By the chain rule: d −1 dy (f (y)) = dy dx and\n d −1 (f (y)) = dy 1 1\nf (x) x d (x) = 1 dx;;So, implicit diﬀerentiation makes it possible to ﬁnd the derivative of the inverse function. Example. y = arctan(x) tan y d [tan(y)] dx d dy [tan(y)] dy dx � � 1 dy 2 (y) cos dx dy dx = = = = = x dx = 1 dx 1 1 cos2 (y) = cos2 (arctan(x))\nThis form is messy. Let us use some geometry to simplify it.\ny 1\n(1+x2)1/2\nx\nFigure 1: Triangle with angles and lengths corresponding to those in the example illustrating diﬀerentiation using\nthe inverse function arctan\nIn this triangle, tan(y) = x so\n arctan(x) = y\n The Pythagorian theorem tells us the length of the hypotenuse: � h = 1 + x2 From this, we can ﬁnd cos(y) = √ From this, we get cos (y) =\n1 1 + x2 �2 = 1 1 + x2\n1 √ 1 + x2 3;;So, dy 1 = dx 1 + x2 In other words, d 1 arctan(x) = dx 1 + x2\nGraphing an Inverse Function.\nSuppose y = f (x) and g(y) = f −1 (y) = x. To graph g and f together we need to write g as a function of the variable x. If g(x) = y, then x = f (y), and what we have done is to trade the variables x and y. This is illustrated in Fig. 2 f −1 (f (x)) = x f (f −1 (x)) = x f −1 ◦ f (x) = x f ◦ f −1 (x) = x\ny\nf(x)\ny=x g(x)\nb=f(a)\na=f-1(b)\nFigure 2: You can think about f −1 as the graph of f reﬂected about the line y = x'
7309,'lecture','en',6378,'2006-09-01','2010-06-28','Lecture 6: Exponential and log - Logarithmic differentiation; hyperbolic functions',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.01 Single Variable Calculus\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;Lecture 6\nLecture 6: Exponential and Log, Logarithmic Diﬀerentiation, Hyperbolic Functions\nTaking the derivatives of exponentials and logarithms\nBackground\nWe always assume the base, a, is greater than 1. a0 = 1; ax1 +x2 (ax1 )\nx2\np q\na1 = a; ax1 ax2\na2 = a · a;\na\na x1 x2 √ q ap (where p and q are integers)\nTo deﬁne ar for real numbers r, ﬁll in by continuity.\nToday’s main task: ﬁnd\nWe can write\nd x a dx\nd x ax+Δx − ax a = lim Δx→0 dx Δx\nWe can factor out the ax :\n ax+Δx − ax aΔx − 1 aΔx\n − 1 = lim ax = ax lim Δx→0 Δx→0 Δx→0 Δx Δx Δx lim Let’s call aΔx − 1 Δx→0 Δx We don’t yet know what M (a) is, but we can say M (a) ≡ lim d x a = M (a)ax dx Here are two ways to describe M (a): 1. Analytically M (a) = d x a at x = 0. dx\n� a0+Δx − a0 d x� Indeed, M (a) = lim = a � Δx→0 Δx dx �x=0;;ax\nM(a) (slope of ax at x=0)\nFigure 1: Geometric deﬁnition of M (a) 2. Geometrically, M (a) is the slope of the graph y = ax at x = 0. The trick to ﬁguring out what M (a) is is to beg the question and deﬁne e as the number such that M (e) = 1. Now can we be sure there is such a number e? First notice that as the base a increases, the graph ax gets steeper. Next, we will estimate the slope M (a) for a = 2 and a = 4 geometrically. Look at the graph of 2x in Fig. 2. The secant line from (0, 1) to (1, 2) of the graph y = 2x has slope 1. Therefore, the slope of y = 2x at x = 0 is less: M (2) < 1 (see Fig. 2). 1 1 Next, look at the graph of 4x in Fig. 3. The secant line from (− , ) to (1, 0) on the graph of 2 2 y = 4x has slope 1. Therefore, the slope of y = 4x at x = 0 is greater than M (4) > 1 (see Fig. 3). Somewhere in between 2 and 4 there is a base whose slope at x = 0 is 1.;;y=2x\nslope = 1 (1,2) e n t li n eca slope M(2)\ns\nFigure 2: Slope M (2) < 1\ny=4x\nt lin secan\neM lop s\ne\nFigure 3: Slope M (4) > 1;;Thus we can deﬁne e to be the unique number such that M (e) = 1 or, to put it another way, eh − 1 =1 h→0 h lim or, to put it still another way, d x (e ) = 1 dx\n What is d x (e )? dx We just deﬁned M (e) = 1, and at x = 0 d\n x (e ) = M (e)ex . So dx\nd x (e ) = ex dx\nNatural log (inverse function of ex )\nTo understand M (a) better, we study the natural log function ln(x). This function is deﬁned as follows: If y = ex , then ln(y) = x (or) If w = ln(x), then ex = w Note that ex is always positive, even if x is negative. Recall that ln(1) = 0; ln(x) < 0 for 0 < x < 1; ln(x) > 0 for x > 1. Recall also that\nln(x1 x2 ) = ln x1 + ln x2 Let us use implicit diﬀerentiation to ﬁnd d ln(x). dx = = = = = w = ln(x). We want to ﬁnd dw . dx\new d w (e ) dx d w dw (e ) dw dx w dw e dx dw dx\nx d (x) dx 1 1 1 1 = ew x\nd 1 (ln(x)) = dx x 4;;Finally, what about\nd x (a )? dx\nThere are two methods we can use: Method 1: Write base e and use chain rule. Rewrite a as eln(a) . Then, � �x ax = eln(a) = ex ln(a)\nThat looks like it might be tricky to diﬀerentiate. Let’s work up to it: d x e dx d 3x e dx = and by the chain rule, = 3e3x ex\nRemember, ln(a) is just a constant number– not a variable! Therefore, d (ln a)x e dx = or (ln a)e(ln a)x\nd x (a ) = ln(a) · ax dx Recall that d x (a ) = M (a) ·\nax dx M (a) = ln(a).\nSo now we know the value of M (a):\nEven if we insist on starting with another base, like 10, the natural logarithm appears:\n d x 10 = (ln 10)10x dx The base e may seem strange at ﬁrst. But, it comes up everywhere. After a while, you’ll learn to appreciate just how natural it is. Method 2: Logarithmic Diﬀerentiation. The idea is to ﬁnd u = f (x). d d f (x) by ﬁnding ln(f (x)) instead. Sometimes this approach is easier. Let dx dx � � d d ln(u) du 1 du ln(u) = = dx du dx u dx\nSince u = f and\ndu = f � , we can also write dx (ln f )� = f� f or f � = f (ln f )�;;Apply this to f (x) = ax . ln f (x) = x ln a =⇒ d d d ln(f ) = ln(ax ) = (x ln(a)) = ln(a). dx dx dx\n(Remember, ln(a) is a constant, not a variable.) Hence, d f� d x (ln f ) = ln(a) =⇒ = ln(a) =⇒ f � = ln(a)f =⇒ a = (ln a)ax dx f dx\nExample 1.\nd x (x ) = ? dx\nWith variable (“moving”) exponents, you should use either base e or logarithmic diﬀerentiation. In this example, we will use the latter. f ln f (ln f )\nxx x ln x � � 1 1 · (ln x) + x = ln(x) + 1 x f� f\n(ln f )� Therefore,\nf � = f (ln f )� = xx (ln(x) + 1) If you wanted to solve this using the base e approach, you would say f = ex ln x and diﬀerentiate it using the chain rule. It gets you the same answer, but requires a little more writing. � �k 1 1+ . k→∞ k\nExample 2. Use logs to evaluate lim\nBecause the exponent k changes, it is better to ﬁnd the limit of the logarithm. ��\nk→∞\nlim ln\n1 1+ k\n�k �\nWe know that ln\n1 1+ k\n�k �\n = k ln 1 + k\n� � 1 → 0. This expression has two competing parts, which balance: k → ∞ while ln 1 + k �� � � �k � � � 1 ln 1 + k 1 1 ln(1 + h) 1 ln 1 + = k ln 1 + = = (with h = ) 1 k k h k k Next, because ln 1 = 0 �� �k �\n 1 ln(1 + h) − ln(1)\n ln 1 + = k h;;Take the limit: h =\n1 → 0 as k → ∞, so that k � ln(1 + h) − ln(1) d � = ln(x)� =1 h→0 h dx x=1 lim\nIn all, � �k 1 lim ln 1 + = 1. k→∞ k � �k 1 We have just found that ak = ln[ 1 + ] → 1 as k → ∞. k � �k 1 If bk = 1 + , then bk = eak → e1 as k → ∞. In other words, we have evaluated the limit we k wanted: � �k 1 lim 1 + =e k→∞ k Remark 1. We never ﬁgured out what the exact numerical value of e was. Now we can use this limit formula; k = 10 gives a pretty good approximation to the actual value of e. Remark 2. Logs are used in all sciences and even in ﬁnance. Think about the stock market. If I say the market fell 50 points today, you’d need to know whether the market average before the drop was 300 points or 10, 000. In other words, you care about the percent change, or the ratio of the change to the starting value: f � (t) d = ln(f (t)) f (t) dt'
7310,'lecture','en',6378,'2006-09-01','2010-06-28','Lecture 7: Hyperbolic functions (cont.) and exam 1 review',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.01 Single Variable Calculus\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;Lecture 7\nLecture 7: Continuation and Exam Review\nHyperbolic Sine and Cosine\nHyperbolic sine (pronounced “sinsh”): sinh(x) = Hyperbolic cosine (pronounced “cosh”): ex + e−x 2 � x � d d e − e−x ex − (−e−x ) sinh(x) = = = cosh(x) dx dx 2 2 cosh(x) = Likewise, d cosh(x) = sinh(x) dx (Note that this is diﬀerent from Important identity:\n cosh2 (x) − sinh2 (x) = 1\n Proof: cosh2 (x) − sinh2 (x) cosh2 (x) − sinh2 (x) � = = �2 � x �2 ex + e−x e − e−x − 2 2 � 1 � 2x � 1 � 2x 1 e + 2ex e−x + e−2x − e − 2 + e−2x = (2 + 2) = 1 4 4 4 d cos(x).) dx ex − e−x 2\nWhy are these functions called “hyperbolic”? Let u = cosh(x) and v = sinh(x), then u2 − v 2 = 1 which is the equation of a hyperbola. Regular trig functions are “circular” functions. If u = cos(x) and v = sin(x), then u2 + v 2 = 1 which is the equation of a circle.;;Exam 1 Review\nGeneral Diﬀerentiation Formulas\n(u + v)� (cu)� (uv)� � u �� v d f (u(x)) dx = = = = = u� + v � cu� u� v + uv � (product rule) u� v − uv � (quotient rule) v2 f � (u(x)) · u� (x) (chain rule)\nYou can remember the quotient rule by rewriting � u �� = (uv −1 )� v and applying the product rule and chain rule.\nImplicit diﬀerentiation\nLet’s say you want to ﬁnd y � from an equation like y 3 + 3xy 2 = 8 d Instead of solving for y and then taking its derivative, just take of the whole thing. In this dx example, 3y 2 y � + 6xyy � + 3y 2 (3y 2 + 6xy)y � y� = = = 0 −3y 2 −3y 2 3y 2 + 6xy\nNote that this formula for y � involves both x and y. Implicit diﬀerentiation can be very useful for taking the derivatives of inverse functions. For instance,\n y = sin−1 x ⇒ sin y = x\n Implicit diﬀerentiation yields (cos y)y � = 1 and y� = 1 1 =√ cos y 1 − x2;;Speciﬁc diﬀerentiation formulas\nYou will be responsible for knowing formulas for the derivatives and how to deduce these formulas from previous information: xn , sin−1 x, tan−1 x, sin x, cos x, tan x, sec x, ex , ln x . For example, let’s calculate d sec x: dx\nd d 1 −(− sin x) sec x = = = tan x sec x dx dx cos x cos2 x You may be asked to ﬁnd d d sin x or cos x, using the following information: dx dx sin(h) h cos(h) − 1 lim h→0 h\nh→0\nlim\nRemember the deﬁnition of the derivative: d f (x + Δx) − f (x) f (x) = lim Δx→0 dx Δx\nTying up a loose end\nd r How to ﬁnd x , where r is a real (but not necessarily rational) number? All we have done so far dx is the case of rational numbers, using implicit diﬀerentiation. We can do this two ways: 1st method: base e eln x � ln x �r e = er ln x d r ln x d r e = er ln x (r ln x) = er ln x dx dx x � � r r r−1 x = rx x\nx xr d r x dx d r x dx\n2nd method: logarithmic diﬀerentiation f� f = xr = r ln x r = x � � r = xr = rxr−1 x = 3\n(ln f )� f ln f (ln f )� f � = f (ln f )�;;Finally, in the ﬁrst lecture I promised you that you’d learn to diﬀerentiate anything— even something as complicated as d x tan−1 x e dx So let’s do it! d uv e dx Substituting, d x tan−1 x e dx = euv d (uv) = euv (u� v + uv � ) dx\nex tan\nx\ntan−1 x + x\n1 1 + x2'
7326,'lecture','en',6379,'2007-09-06','2009-09-10','Lecture 1: Dot product',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 1. – Thu, Sept 6, 2007 Handouts: syllabus; PS1; ﬂashcards.\nGoal of multivariable calculus: tools to handle problems with several parameters – functions of several variables. � � Vectors. A vector (notation: A) has a direction, and a length (|A|). It is represented by � a directed line segment. In a coordinate system it’s expressed by components: in space, A = ˆ . (Recall in space x-axis points to the lower-left, y to the right, z up). �a1 , a2 , a3 � = a1ˆ + a2ˆ + a3 k ı j Scalar multiplication Formula for length? Showed√ picture of �3, 2, 1� and used ﬂashcards to ask for its length. Most students got the right answer ( 14). � � You can explain why |A| = a2 + a2 + a2 by reducing to the Pythagorean theorem in the 1 2 3 � � plane (Draw a picture, showing A and its projection to the xy-plane, then derived |A| from length of projection + Pythagorean theorem). � � Vector addition: A +B by head-to-tail addition: Draw a picture in a parallelogram (showed how � + B and B − A); addition works componentwise, and it is true that � � the diagonals are A � � ı j ˆ A = 3ˆ + 2ˆ + k on the displayed example. Dot product. � � Deﬁnition: A ·\nB = a1 b1 + a2 b2 + a3 b3 (a scalar, not a vector). � � � � Theorem: geometrically, A · B = |A||B | cos θ.\n � � � � Explained the theorem as follows: ﬁrst, A · A = |A|2 cos 0 = |A|2 is consistent with the deﬁnition. � � � � � � Next, consider a triangle with sides A, B , C = A − B . Then the law of cosines gives |C |2 = � |2 + |B |2 − 2|A||B | cos θ, while we get � � � |A � � � � � � � � � � � |C |2 = C · C = (A − B ) · (A − B ) = |A|2 + |B|2 − 2A · B. Hence the theorem is a vector formulation of the law of cosines. � � A·B Applications. 1) computing lengths and angles: cos θ = . � � |A||B | Example: triangle in space with vertices P = (1, 0, 0), Q = (0, 1, 0), R = (0, 0, 2), ﬁnd angle at P : −→ −→ − − 1 PQ · PR �−1, 1, 0� · �−1, 0, 2� √ √ =√ , cos θ = −→ −→ = θ ≈ 71.5◦ . − − 2 5 10 |P Q ||P R | Note the sign of dot product: positive if angle less than 90◦ , negative if angle more than 90◦ , zero if perpendicular. 2) detecting orthogonality. Example: what is the set of points where x + 2y + 3z = 0? (possible answers: empty set, a point, a line, a plane, a sphere, none of the above, I don’t know). � Answer: plane; can see “by hand”, but more geometrically use dot product: call A = �1, 2, 3�, −→ − −→ − − � � � −→ P = (x, y, z), then A · OP = x + 2y + 3z = 0 ⇔ |A||OP | cos θ = 0 ⇔ θ = π/2 ⇔ A ⊥ OP . So we � get the plane through O with normal vector A.;;18.02 Lecture 2. – Fri, Sept 7, 2007 We’ve seen two applications of dot product: ﬁnding lengths/angles, and detecting orthogonality. � ˆ � ˆ A third one: ﬁnding components of a vector. If u is a unit vector, A · u = |A| cos θ is the component � � ı � ˆ of A along the direction of u. E.g., A · ˆ = component of A along x-axis. � Example: pendulum making an angle with vertical, force = weight of pendulum F pointing � along tangential downwards: then the physically important quantities are the components of F direction (causes pendulum’s motion), and along normal direction (causes string tension).\n1 Area. E.g. of a polygon in plane: break into triangles. Area of triangle = 2 base × height = 1 � � 2 |A||B | sin θ (= 1/2 area of parallelogram). Could get sin θ using dot product to compute cos θ and sin2 + cos2 = 1, but it gives an ugly formula. Instead, reduce to complementary angle θ� = π/2 − θ � � by considering A� = A rotated 90◦ counterclockwise (drew a picture). Then area of parallelogram � � � � � � = |A||B | sin θ = |A� ||B | cos θ� = A� · B . � � � Q: if A = �a1 , a2 �, then what is A� ? (showed picture, used ﬂashcards). Answer: A� = �−a2 , a1 �. (explained on picture). So area of parallelogram is �b1 , b2 � · �−a2 , a1 � = a1 b2 − a2 b1 . � � � � � B) = � a1 a2 � = a1 b2 − a2 b1 . � Determinant. Deﬁnition: det(A, � b1 b2 � � � � a1 a2 � � � = ± area of parallelogram.\n Geometrically:\n b1 b2 �\n� � The sign of 2D determinant has to do with whether B is counterclockwise\nor clockwise from A, without details.\n � � � � � � � � � a1 a2 a3 � � � � � � � � � � B, C) = � b1 b2 b3 � = a1 � b2 b3 �−a2 � b1 b3 �+a3 � b1 b2 �.\n � � Determinant in space: det(A, �\n c1 c2 �\n c1 c3 �\n c2 c3 �\n c1 c2 c3 �\n � � � Geometrically: det(A, B, C) = ± volume of parallelepiped. Referred to the notes for more about determinants. Cross-product. (only for 2 vectors in space); gives a vector, not a scalar (unlike dot-product). � � � ˆ ˆ k � � � � � � � j ˆ � � ı � a2 a3 � � a1 a3 � � � ˆ\n� a1 a2 �.\n � � � j� � Deﬁnition:\n A × B =\n� a1 a2 a3 � = ˆ\n� � � ı �\n b2 b3 �\n− ˆ\n b1 b3 �\n+ k �\n b1 b2 �\n � b1 b2 b3 � (the 3x3 determinant is a symbolic notation, the actual formula is the expansion). � � � � Geometrically: |A × B | = area of space parallelogram with sides A, B ; direction = normal to � � the plane containing A and B . How to decide between the two perpendicular directions = right-hand rule. 1) extend right hand � � � � in direction of A; 2) curl ﬁngers towards direction of B ; 3) thumb points in same direction as A ×B . ˆ Flashcard Question: ˆ × ˆ =? (answer: k, checked both by geometric description and by ı j calculation). � � � ˆ Triple product: volume of parallelepiped = area(base) · height = |B × C | (A · n), where n = ˆ � × C/|B × C |. So volume = A · (B × C ) = det(A, B, C). The latter identity can also be checked � � � � � � � � � B directly using components.'
7327,'lecture','en',6379,'2007-09-07','2009-09-10','Lecture 2: Determinants; cross product',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 1. – Thu, Sept 6, 2007 Handouts: syllabus; PS1; ﬂashcards.\nGoal of multivariable calculus: tools to handle problems with several parameters – functions of several variables. � � Vectors. A vector (notation: A) has a direction, and a length (|A|). It is represented by � a directed line segment. In a coordinate system it’s expressed by components: in space, A = ˆ . (Recall in space x-axis points to the lower-left, y to the right, z up). �a1 , a2 , a3 � = a1ˆ + a2ˆ + a3 k ı j Scalar multiplication Formula for length? Showed√ picture of �3, 2, 1� and used ﬂashcards to ask for its length. Most students got the right answer ( 14). � � You can explain why |A| = a2 + a2 + a2 by reducing to the Pythagorean theorem in the 1 2 3 � � plane (Draw a picture, showing A and its projection to the xy-plane, then derived |A| from length of projection + Pythagorean theorem). � � Vector addition: A +B by head-to-tail addition: Draw a picture in a parallelogram (showed how � + B and B − A); addition works componentwise, and it is true that � � the diagonals are A � � ı j ˆ A = 3ˆ + 2ˆ + k on the displayed example. Dot product. � � Deﬁnition: A ·\nB = a1 b1 + a2 b2 + a3 b3 (a scalar, not a vector). � � � � Theorem: geometrically, A · B = |A||B | cos θ.\n � � � � Explained the theorem as follows: ﬁrst, A · A = |A|2 cos 0 = |A|2 is consistent with the deﬁnition. � � � � � � Next, consider a triangle with sides A, B , C = A − B . Then the law of cosines gives |C |2 = � |2 + |B |2 − 2|A||B | cos θ, while we get � � � |A � � � � � � � � � � � |C |2 = C · C = (A − B ) · (A − B ) = |A|2 + |B|2 − 2A · B. Hence the theorem is a vector formulation of the law of cosines. � � A·B Applications. 1) computing lengths and angles: cos θ = . � � |A||B | Example: triangle in space with vertices P = (1, 0, 0), Q = (0, 1, 0), R = (0, 0, 2), ﬁnd angle at P : −→ −→ − − 1 PQ · PR �−1, 1, 0� · �−1, 0, 2� √ √ =√ , cos θ = −→ −→ = θ ≈ 71.5◦ . − − 2 5 10 |P Q ||P R | Note the sign of dot product: positive if angle less than 90◦ , negative if angle more than 90◦ , zero if perpendicular. 2) detecting orthogonality. Example: what is the set of points where x + 2y + 3z = 0? (possible answers: empty set, a point, a line, a plane, a sphere, none of the above, I don’t know). � Answer: plane; can see “by hand”, but more geometrically use dot product: call A = �1, 2, 3�, −→ − −→ − − � � � −→ P = (x, y, z), then A · OP = x + 2y + 3z = 0 ⇔ |A||OP | cos θ = 0 ⇔ θ = π/2 ⇔ A ⊥ OP . So we � get the plane through O with normal vector A.;;18.02 Lecture 2. – Fri, Sept 7, 2007 We’ve seen two applications of dot product: ﬁnding lengths/angles, and detecting orthogonality. � ˆ � ˆ A third one: ﬁnding components of a vector. If u is a unit vector, A · u = |A| cos θ is the component � � ı � ˆ of A along the direction of u. E.g., A · ˆ = component of A along x-axis. � Example: pendulum making an angle with vertical, force = weight of pendulum F pointing � along tangential downwards: then the physically important quantities are the components of F direction (causes pendulum’s motion), and along normal direction (causes string tension).\n1 Area. E.g. of a polygon in plane: break into triangles. Area of triangle = 2 base × height = 1 � � 2 |A||B | sin θ (= 1/2 area of parallelogram). Could get sin θ using dot product to compute cos θ and sin2 + cos2 = 1, but it gives an ugly formula. Instead, reduce to complementary angle θ� = π/2 − θ � � by considering A� = A rotated 90◦ counterclockwise (drew a picture). Then area of parallelogram � � � � � � = |A||B | sin θ = |A� ||B | cos θ� = A� · B . � � � Q: if A = �a1 , a2 �, then what is A� ? (showed picture, used ﬂashcards). Answer: A� = �−a2 , a1 �. (explained on picture). So area of parallelogram is �b1 , b2 � · �−a2 , a1 � = a1 b2 − a2 b1 . � � � � � B) = � a1 a2 � = a1 b2 − a2 b1 . � Determinant. Deﬁnition: det(A, � b1 b2 � � � � a1 a2 � � � = ± area of parallelogram.\n Geometrically:\n b1 b2 �\n� � The sign of 2D determinant has to do with whether B is counterclockwise\nor clockwise from A, without details.\n � � � � � � � � � a1 a2 a3 � � � � � � � � � � B, C) = � b1 b2 b3 � = a1 � b2 b3 �−a2 � b1 b3 �+a3 � b1 b2 �.\n � � Determinant in space: det(A, �\n c1 c2 �\n c1 c3 �\n c2 c3 �\n c1 c2 c3 �\n � � � Geometrically: det(A, B, C) = ± volume of parallelepiped. Referred to the notes for more about determinants. Cross-product. (only for 2 vectors in space); gives a vector, not a scalar (unlike dot-product). � � � ˆ ˆ k � � � � � � � j ˆ � � ı � a2 a3 � � a1 a3 � � � ˆ\n� a1 a2 �.\n � � � j� � Deﬁnition:\n A × B =\n� a1 a2 a3 � = ˆ\n� � � ı �\n b2 b3 �\n− ˆ\n b1 b3 �\n+ k �\n b1 b2 �\n � b1 b2 b3 � (the 3x3 determinant is a symbolic notation, the actual formula is the expansion). � � � � Geometrically: |A × B | = area of space parallelogram with sides A, B ; direction = normal to � � the plane containing A and B . How to decide between the two perpendicular directions = right-hand rule. 1) extend right hand � � � � in direction of A; 2) curl ﬁngers towards direction of B ; 3) thumb points in same direction as A ×B . ˆ Flashcard Question: ˆ × ˆ =? (answer: k, checked both by geometric description and by ı j calculation). � � � ˆ Triple product: volume of parallelepiped = area(base) · height = |B × C | (A · n), where n = ˆ � × C/|B × C |. So volume = A · (B × C ) = det(A, B, C). The latter identity can also be checked � � � � � � � � � B directly using components.'
7328,'lecture','en',6379,'2007-09-11','2009-09-10','Lecture 3: Matrices; inverse matrices',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 3. – Tue, Sept 11, 2007 Remark: A × B = −B × A, A × A = 0.\n Application of cross product: equation of plane through P1 , P2 , P3 : P = (x, y, z) is in the\n − → − → − − −− −− −→ − plane iﬀ det(P1 P , P1 P2 , P1 P3 ) = 0, or equivalently, P1 P · N = 0, where N is the normal vector −− −→ −− −→ N = P1 P2 × P1 P3 . I explained this geometrically, and showed how we get the same equation both ways. Matrices. Often quantities are related by linear transformations; e.g. changing coordinate systems, from P = (x1 , x2 , x3 ) to something more adapted to the problem, with new coordinates (u1 , u2 , u3 ). For example ⎧ ⎨ u1 = 2x1 + 3x2 + 3x3 u2 = 2x1 + 4x2 + 5x3 ⎩ u3 = x1 + x2 + 2x3 ⎡ ⎤⎡ ⎤ ⎡ ⎤ 2 3 3 x1 u1 Rewrite using matrix product: ⎣ 2 4 5 ⎦ ⎣ x2 ⎦ = ⎣ u2 ⎦, i.e. AX = U . u3 1 1 2 x3 Entries in the matrix product = dot product between rows multiply a 3x3 matrix by a column vector = 3x1 matrix). More generally, matrix multiplication AB: ⎡ ⎤ ⎡ ⎤ . 0 ⎡ 1 2 3 4 ⎢ . ⎥ ⎣ . . . . ⎦⎢ . 3 ⎥ = ⎣ . ⎣ . 0 ⎦ . . . . . . 2 of A and columns of X. (here we\n(Also explained one can set up A to the left, B to the top, then each entry of AB = dot product between row to its left and column above it). Note: for this to make sense, width of A must equal height of B. What AB means: BX = apply transformation B to vector X, so (AB)X = A(BX) = apply ﬁrst B then A. (so matrix multiplication is like composing transformations, but from right to left!) (Remark: matrix product is not commutative, AB is in general not the same as BA – one of the two need not even make sense if sizes not compatible). ⎡ ⎤ 1 0 0 I3×3 = ⎣ 0 1 0 ⎦ Identity matrix: identity transformation IX = X. 0 0 1 � Example: R = 0 −1 1 0 � = plane rotation by 90 degrees counterclockwise.\nRˆ = ˆ, Rˆ = −ˆ, R2 = −I. ı j j ı Inverse matrix. Inverse of a matrix A (necessarily square) is a matrix M = A−1 such that AM = M A = In . A−1 corresponds to the reciprocal linear relation. E.g., solution to linear system AX = U : can solve for X as function of U by X = A−1 U .;;Cofactor method to ﬁnd A−1 (eﬃcient for small matrices; for large matrices computer software 1 uses other algorithms): A−1 = det(A) adj(A) (adj(A) = “adjoint matrix”). ⎡ ⎤ 2 3 3\n Illustration on example: starting from A = ⎣ 2 4 5 ⎦\n ⎡ 1) matrix of⎤minors (= determinants formed by deleting one row and one column from A): � � 3 −1 −2 � � ⎣ 3 ⎦ (e.g. top-left is � 4 5 � = 3). 1 −1 � 1 2 � 3 4 2 ⎡ ⎤ + − + 3 +1 −2 1 +1 ⎦ 2) cofactors = ﬂip signs according to checkerboard diagram − + − : get ⎣ −3 + − + 3 −4 2 3) transpose = exchange rows / columns (read horizontally, write vertically) get the adjoint ⎡ ⎤ 3 −3 3 1 −4 ⎦ matrix M T = adj(A) = ⎣ 1 −2 1 2 ⎡ ⎤ 3 −3 3\n 4) divide by det(A) (here = 3): get A−1 = ⎣ 1 3 −2 1 2\n 18.02 Lecture 4. – Thu, Sept 13, 2007 Handouts: PS1 solutions; PS2. Equations of planes. Recall an equation of the form ax + by + cz = d deﬁnes a plane. 1) plane through origin with normal vector N = �1, 5, 10�: P = (x, y, z) is in the plane ⇔ −→ − N · OP = 0 ⇔ �1, 5, 10� · �x, y, z� = x + 5y + 10z = 0. Coeﬃcients of the equation are the components of the normal vector. 2) plane through P0 = (2, 1, −1) with same normal vector N = �1, 5, 10�: parallel to the previous −→ − one! P is in the plane ⇔ N · P0 P = 0 ⇔ (x − 2) + 5(y − 1) + 10(z + 1) = 0, or x + 5y + 10z = −3. Again coeﬃcients of equation = components of normal vector. (Note: the equation multiplied by a constant still deﬁnes the same plane). So, to ﬁnd the equation of a plane, we really need to look for the normal vector N ; we can e.g. ﬁnd it by cross-product of 2 vectors that are in the plane. Flashcard question: the vector v = �1, 2, −1� and the plane x + y + 3z = 5 are 1) parallel, 2) perpendicular, 3) neither? (A perpendicular vector would be proportional to the coeﬃcients, i.e. to �1, 1, 3�; let’s test if it’s in the plane: equivalent to being ⊥ N . We have v · N = 1 + 2 − 3 = 0 so v is parallel to the plane.) Interpretation of 3x3 systems. A 3x3 system asks for the intersection of 3 planes. Two planes intersect in a line, and usually the third plane intersects it in a single point (picture shown). The unique solution to AX = B is given by X = A−1 B.;;Exception: if the 3rd plane is parallel to the line of intersection of the ﬁrst two? What can happen? (asked on ﬂashcards for possibilities). If the line P1 ∩ P2 is contained in P3 there are inﬁnitely many solutions (the line); if it is parallel to P3 there are no solutions. (could also get a plane of solutions if all three equations are the same) These special cases correspond to systems with det(A) = 0. Then we can’t invert A to solve the 1 system: recall A−1 = det(A) adj(A). Theorem: A is invertible ⇔ det A �= 0. Homogeneous systems: AX = 0. Then all 3 planes pass through the origin, so there is the obvious (”trivial”) solution X = 0. If det A = 0 then this solution is unique: X = A−1 0 = 0. � Otherwise, if det A = 0 there are inﬁnitely many solutions (forming a line or a plane). Note: det A = 0 means det(N 1 , N 2 , N 3 ) = 0, where N i are the normals to the planes Pi . This means the parallelepiped formed by the N i has no area, i.e. they are coplanar (showed picture of 3 planes intersecting in a line, and their coplanar normals). The line of solutions is then perpendicular to the plane containing N i . For example we can get a vector along the line of intersection by taking a cross-product N 1 × N 2 . General systems: AX = B: compared to AX = 0, all the planes are shifted to parallel positions from their initial ones. If det A �= 0 then unique solution is X = A−1 B. If det A = 0, either there are inﬁnitely many solutions or there are no solutions. (We don’t have tools to decide whether it’s inﬁnitely many or none, although elimination will let us ﬁnd out). 18.02 Lecture 5. – Fri, Sept 14, 2007 Lines. We’ve seen a line as intersection of 2 planes. Other representation = parametric equation = as trajectory of a moving point. E.g. line through Q0 = (−1, 2, 2), Q1 = (1, 3, −1): moving point Q(t) starts at Q0 at t = 0, moves − − −− − − → − −→ −− −→ at constant speed along line, reaches Q1 at t = 1: its “velocity” is � = Q0 Q1 ; Q0 Q(t) = tQ0 Q1 . v On example: �x + 1, y − 2, z − 2� = t�2, 1, −3�, i.e. ⎧ ⎪x(t) = −1 + 2t, ⎨ y(t) = 2 + t, ⎪ ⎩ z(t) = 2 − 3t Lines and planes. Understand where lines and planes intersect.\n Flashcard question: relative positions of Q0 , Q1 with respect to plane x + 2y + 4z = 7? (same\n side, opposite sides, one is in the plane, can’t tell). (A sizeable number of students erroneously answered that one is in the plane.) Answer: plug coordinates into equation of plane: at Q0 , x+2y +4z = 11 > 7; at Q1 , x+2y +4z = 3 < 7; so opposite sides. Intersection of line Q0 Q1 with plane? When does the moving point Q(t) lie in the plane? Check: at Q(t), x + 2y + 4z = (−1 + 2t) + 2(2 + t) + 4(2 − 3t) = 11 − 8t, so condition is 11 − 8t = 7, or t = 1/2. Intersection point: Q(t = 1 ) = (0, 5/2, 1/2). 2 (What would happen if the line was parallel to the plane, or inside it. Answer: when plugging the coordinates of Q(t) into the plane equation we’d get a constant, equal to 7 if the line is contained in the plane – so all values of t are solutions – or to something else if the line is parallel to the plane – so there are no solutions.);;General parametric curves. Example: cycloid: wheel rolling on ﬂoor, motion of a point P on the rim. (Drew picture, then showed an applet illustrating the motion and plotting the cycloid). Position of P ? Choice of parameter: e.g., θ, the angle the wheel has turned since initial position. Distance wheel has travelled is equal to arclength on circumference of the circle = aθ. Setup: x-axis = ﬂoor, initial position of P = origin; introduce A = point of contact of wheel on −→ −→ −→ −→ − − − − ﬂoor, B = center of wheel. Decompose OP = OA + AB + BP .\n −→ − −→ − −→ − OA = �aθ, 0�; AB = �0, a�. Length of BP\n is a, and direction is θ from the (−y)-axis, so −→ − −→ − BP = �−a sin θ, −a cos θ�. Hence the position vector is OP = �aθ − a sin θ, a − a cos θ�. Q: What happens near bottom point? (ﬂashcards: corner point with ﬁnite slopes on left and right; looped curve; smooth graph with horizontal tangent; vertical tangent (cusp)).\n1 Answer: use Taylor approximation: for t → 0, f (t) ≈ f (0) + tf � (0) + 1 t2 f �� (0) + 6 t3 f ��� (0) + . . . . 2 3 /6 and cos θ ≈ 1 − θ 2 /2. So x(θ) � θ 3 /6, y(θ) � θ 2 /2 Hence for θ → 0, This gives sin θ ≈ θ − θ y/x � ( 1 θ2 )/( 1 θ3 ) = 3/θ → ∞: vertical tangent. 2 6'
7329,'lecture','en',6379,'2007-09-13','2009-09-10','Lecture 4: Square systems; equations of planes',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 3. – Tue, Sept 11, 2007 Remark: A × B = −B × A, A × A = 0.\n Application of cross product: equation of plane through P1 , P2 , P3 : P = (x, y, z) is in the\n − → − → − − −− −− −→ − plane iﬀ det(P1 P , P1 P2 , P1 P3 ) = 0, or equivalently, P1 P · N = 0, where N is the normal vector −− −→ −− −→ N = P1 P2 × P1 P3 . I explained this geometrically, and showed how we get the same equation both ways. Matrices. Often quantities are related by linear transformations; e.g. changing coordinate systems, from P = (x1 , x2 , x3 ) to something more adapted to the problem, with new coordinates (u1 , u2 , u3 ). For example ⎧ ⎨ u1 = 2x1 + 3x2 + 3x3 u2 = 2x1 + 4x2 + 5x3 ⎩ u3 = x1 + x2 + 2x3 ⎡ ⎤⎡ ⎤ ⎡ ⎤ 2 3 3 x1 u1 Rewrite using matrix product: ⎣ 2 4 5 ⎦ ⎣ x2 ⎦ = ⎣ u2 ⎦, i.e. AX = U . u3 1 1 2 x3 Entries in the matrix product = dot product between rows multiply a 3x3 matrix by a column vector = 3x1 matrix). More generally, matrix multiplication AB: ⎡ ⎤ ⎡ ⎤ . 0 ⎡ 1 2 3 4 ⎢ . ⎥ ⎣ . . . . ⎦⎢ . 3 ⎥ = ⎣ . ⎣ . 0 ⎦ . . . . . . 2 of A and columns of X. (here we\n(Also explained one can set up A to the left, B to the top, then each entry of AB = dot product between row to its left and column above it). Note: for this to make sense, width of A must equal height of B. What AB means: BX = apply transformation B to vector X, so (AB)X = A(BX) = apply ﬁrst B then A. (so matrix multiplication is like composing transformations, but from right to left!) (Remark: matrix product is not commutative, AB is in general not the same as BA – one of the two need not even make sense if sizes not compatible). ⎡ ⎤ 1 0 0 I3×3 = ⎣ 0 1 0 ⎦ Identity matrix: identity transformation IX = X. 0 0 1 � Example: R = 0 −1 1 0 � = plane rotation by 90 degrees counterclockwise.\nRˆ = ˆ, Rˆ = −ˆ, R2 = −I. ı j j ı Inverse matrix. Inverse of a matrix A (necessarily square) is a matrix M = A−1 such that AM = M A = In . A−1 corresponds to the reciprocal linear relation. E.g., solution to linear system AX = U : can solve for X as function of U by X = A−1 U .;;Cofactor method to ﬁnd A−1 (eﬃcient for small matrices; for large matrices computer software 1 uses other algorithms): A−1 = det(A) adj(A) (adj(A) = “adjoint matrix”). ⎡ ⎤ 2 3 3\n Illustration on example: starting from A = ⎣ 2 4 5 ⎦\n ⎡ 1) matrix of⎤minors (= determinants formed by deleting one row and one column from A): � � 3 −1 −2 � � ⎣ 3 ⎦ (e.g. top-left is � 4 5 � = 3). 1 −1 � 1 2 � 3 4 2 ⎡ ⎤ + − + 3 +1 −2 1 +1 ⎦ 2) cofactors = ﬂip signs according to checkerboard diagram − + − : get ⎣ −3 + − + 3 −4 2 3) transpose = exchange rows / columns (read horizontally, write vertically) get the adjoint ⎡ ⎤ 3 −3 3 1 −4 ⎦ matrix M T = adj(A) = ⎣ 1 −2 1 2 ⎡ ⎤ 3 −3 3\n 4) divide by det(A) (here = 3): get A−1 = ⎣ 1 3 −2 1 2\n 18.02 Lecture 4. – Thu, Sept 13, 2007 Handouts: PS1 solutions; PS2. Equations of planes. Recall an equation of the form ax + by + cz = d deﬁnes a plane. 1) plane through origin with normal vector N = �1, 5, 10�: P = (x, y, z) is in the plane ⇔ −→ − N · OP = 0 ⇔ �1, 5, 10� · �x, y, z� = x + 5y + 10z = 0. Coeﬃcients of the equation are the components of the normal vector. 2) plane through P0 = (2, 1, −1) with same normal vector N = �1, 5, 10�: parallel to the previous −→ − one! P is in the plane ⇔ N · P0 P = 0 ⇔ (x − 2) + 5(y − 1) + 10(z + 1) = 0, or x + 5y + 10z = −3. Again coeﬃcients of equation = components of normal vector. (Note: the equation multiplied by a constant still deﬁnes the same plane). So, to ﬁnd the equation of a plane, we really need to look for the normal vector N ; we can e.g. ﬁnd it by cross-product of 2 vectors that are in the plane. Flashcard question: the vector v = �1, 2, −1� and the plane x + y + 3z = 5 are 1) parallel, 2) perpendicular, 3) neither? (A perpendicular vector would be proportional to the coeﬃcients, i.e. to �1, 1, 3�; let’s test if it’s in the plane: equivalent to being ⊥ N . We have v · N = 1 + 2 − 3 = 0 so v is parallel to the plane.) Interpretation of 3x3 systems. A 3x3 system asks for the intersection of 3 planes. Two planes intersect in a line, and usually the third plane intersects it in a single point (picture shown). The unique solution to AX = B is given by X = A−1 B.;;Exception: if the 3rd plane is parallel to the line of intersection of the ﬁrst two? What can happen? (asked on ﬂashcards for possibilities). If the line P1 ∩ P2 is contained in P3 there are inﬁnitely many solutions (the line); if it is parallel to P3 there are no solutions. (could also get a plane of solutions if all three equations are the same) These special cases correspond to systems with det(A) = 0. Then we can’t invert A to solve the 1 system: recall A−1 = det(A) adj(A). Theorem: A is invertible ⇔ det A �= 0. Homogeneous systems: AX = 0. Then all 3 planes pass through the origin, so there is the obvious (”trivial”) solution X = 0. If det A = 0 then this solution is unique: X = A−1 0 = 0. � Otherwise, if det A = 0 there are inﬁnitely many solutions (forming a line or a plane). Note: det A = 0 means det(N 1 , N 2 , N 3 ) = 0, where N i are the normals to the planes Pi . This means the parallelepiped formed by the N i has no area, i.e. they are coplanar (showed picture of 3 planes intersecting in a line, and their coplanar normals). The line of solutions is then perpendicular to the plane containing N i . For example we can get a vector along the line of intersection by taking a cross-product N 1 × N 2 . General systems: AX = B: compared to AX = 0, all the planes are shifted to parallel positions from their initial ones. If det A �= 0 then unique solution is X = A−1 B. If det A = 0, either there are inﬁnitely many solutions or there are no solutions. (We don’t have tools to decide whether it’s inﬁnitely many or none, although elimination will let us ﬁnd out). 18.02 Lecture 5. – Fri, Sept 14, 2007 Lines. We’ve seen a line as intersection of 2 planes. Other representation = parametric equation = as trajectory of a moving point. E.g. line through Q0 = (−1, 2, 2), Q1 = (1, 3, −1): moving point Q(t) starts at Q0 at t = 0, moves − − −− − − → − −→ −− −→ at constant speed along line, reaches Q1 at t = 1: its “velocity” is � = Q0 Q1 ; Q0 Q(t) = tQ0 Q1 . v On example: �x + 1, y − 2, z − 2� = t�2, 1, −3�, i.e. ⎧ ⎪x(t) = −1 + 2t, ⎨ y(t) = 2 + t, ⎪ ⎩ z(t) = 2 − 3t Lines and planes. Understand where lines and planes intersect.\n Flashcard question: relative positions of Q0 , Q1 with respect to plane x + 2y + 4z = 7? (same\n side, opposite sides, one is in the plane, can’t tell). (A sizeable number of students erroneously answered that one is in the plane.) Answer: plug coordinates into equation of plane: at Q0 , x+2y +4z = 11 > 7; at Q1 , x+2y +4z = 3 < 7; so opposite sides. Intersection of line Q0 Q1 with plane? When does the moving point Q(t) lie in the plane? Check: at Q(t), x + 2y + 4z = (−1 + 2t) + 2(2 + t) + 4(2 − 3t) = 11 − 8t, so condition is 11 − 8t = 7, or t = 1/2. Intersection point: Q(t = 1 ) = (0, 5/2, 1/2). 2 (What would happen if the line was parallel to the plane, or inside it. Answer: when plugging the coordinates of Q(t) into the plane equation we’d get a constant, equal to 7 if the line is contained in the plane – so all values of t are solutions – or to something else if the line is parallel to the plane – so there are no solutions.);;General parametric curves. Example: cycloid: wheel rolling on ﬂoor, motion of a point P on the rim. (Drew picture, then showed an applet illustrating the motion and plotting the cycloid). Position of P ? Choice of parameter: e.g., θ, the angle the wheel has turned since initial position. Distance wheel has travelled is equal to arclength on circumference of the circle = aθ. Setup: x-axis = ﬂoor, initial position of P = origin; introduce A = point of contact of wheel on −→ −→ −→ −→ − − − − ﬂoor, B = center of wheel. Decompose OP = OA + AB + BP .\n −→ − −→ − −→ − OA = �aθ, 0�; AB = �0, a�. Length of BP\n is a, and direction is θ from the (−y)-axis, so −→ − −→ − BP = �−a sin θ, −a cos θ�. Hence the position vector is OP = �aθ − a sin θ, a − a cos θ�. Q: What happens near bottom point? (ﬂashcards: corner point with ﬁnite slopes on left and right; looped curve; smooth graph with horizontal tangent; vertical tangent (cusp)).\n1 Answer: use Taylor approximation: for t → 0, f (t) ≈ f (0) + tf � (0) + 1 t2 f �� (0) + 6 t3 f ��� (0) + . . . . 2 3 /6 and cos θ ≈ 1 − θ 2 /2. So x(θ) � θ 3 /6, y(θ) � θ 2 /2 Hence for θ → 0, This gives sin θ ≈ θ − θ y/x � ( 1 θ2 )/( 1 θ3 ) = 3/θ → ∞: vertical tangent. 2 6'
7330,'lecture','en',6379,'2007-09-14','2009-09-10','Lecture 5: Parametric equations for lines and curves',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 3. – Tue, Sept 11, 2007 Remark: A × B = −B × A, A × A = 0.\n Application of cross product: equation of plane through P1 , P2 , P3 : P = (x, y, z) is in the\n − → − → − − −− −− −→ − plane iﬀ det(P1 P , P1 P2 , P1 P3 ) = 0, or equivalently, P1 P · N = 0, where N is the normal vector −− −→ −− −→ N = P1 P2 × P1 P3 . I explained this geometrically, and showed how we get the same equation both ways. Matrices. Often quantities are related by linear transformations; e.g. changing coordinate systems, from P = (x1 , x2 , x3 ) to something more adapted to the problem, with new coordinates (u1 , u2 , u3 ). For example ⎧ ⎨ u1 = 2x1 + 3x2 + 3x3 u2 = 2x1 + 4x2 + 5x3 ⎩ u3 = x1 + x2 + 2x3 ⎡ ⎤⎡ ⎤ ⎡ ⎤ 2 3 3 x1 u1 Rewrite using matrix product: ⎣ 2 4 5 ⎦ ⎣ x2 ⎦ = ⎣ u2 ⎦, i.e. AX = U . u3 1 1 2 x3 Entries in the matrix product = dot product between rows multiply a 3x3 matrix by a column vector = 3x1 matrix). More generally, matrix multiplication AB: ⎡ ⎤ ⎡ ⎤ . 0 ⎡ 1 2 3 4 ⎢ . ⎥ ⎣ . . . . ⎦⎢ . 3 ⎥ = ⎣ . ⎣ . 0 ⎦ . . . . . . 2 of A and columns of X. (here we\n(Also explained one can set up A to the left, B to the top, then each entry of AB = dot product between row to its left and column above it). Note: for this to make sense, width of A must equal height of B. What AB means: BX = apply transformation B to vector X, so (AB)X = A(BX) = apply ﬁrst B then A. (so matrix multiplication is like composing transformations, but from right to left!) (Remark: matrix product is not commutative, AB is in general not the same as BA – one of the two need not even make sense if sizes not compatible). ⎡ ⎤ 1 0 0 I3×3 = ⎣ 0 1 0 ⎦ Identity matrix: identity transformation IX = X. 0 0 1 � Example: R = 0 −1 1 0 � = plane rotation by 90 degrees counterclockwise.\nRˆ = ˆ, Rˆ = −ˆ, R2 = −I. ı j j ı Inverse matrix. Inverse of a matrix A (necessarily square) is a matrix M = A−1 such that AM = M A = In . A−1 corresponds to the reciprocal linear relation. E.g., solution to linear system AX = U : can solve for X as function of U by X = A−1 U .;;Cofactor method to ﬁnd A−1 (eﬃcient for small matrices; for large matrices computer software 1 uses other algorithms): A−1 = det(A) adj(A) (adj(A) = “adjoint matrix”). ⎡ ⎤ 2 3 3\n Illustration on example: starting from A = ⎣ 2 4 5 ⎦\n ⎡ 1) matrix of⎤minors (= determinants formed by deleting one row and one column from A): � � 3 −1 −2 � � ⎣ 3 ⎦ (e.g. top-left is � 4 5 � = 3). 1 −1 � 1 2 � 3 4 2 ⎡ ⎤ + − + 3 +1 −2 1 +1 ⎦ 2) cofactors = ﬂip signs according to checkerboard diagram − + − : get ⎣ −3 + − + 3 −4 2 3) transpose = exchange rows / columns (read horizontally, write vertically) get the adjoint ⎡ ⎤ 3 −3 3 1 −4 ⎦ matrix M T = adj(A) = ⎣ 1 −2 1 2 ⎡ ⎤ 3 −3 3\n 4) divide by det(A) (here = 3): get A−1 = ⎣ 1 3 −2 1 2\n 18.02 Lecture 4. – Thu, Sept 13, 2007 Handouts: PS1 solutions; PS2. Equations of planes. Recall an equation of the form ax + by + cz = d deﬁnes a plane. 1) plane through origin with normal vector N = �1, 5, 10�: P = (x, y, z) is in the plane ⇔ −→ − N · OP = 0 ⇔ �1, 5, 10� · �x, y, z� = x + 5y + 10z = 0. Coeﬃcients of the equation are the components of the normal vector. 2) plane through P0 = (2, 1, −1) with same normal vector N = �1, 5, 10�: parallel to the previous −→ − one! P is in the plane ⇔ N · P0 P = 0 ⇔ (x − 2) + 5(y − 1) + 10(z + 1) = 0, or x + 5y + 10z = −3. Again coeﬃcients of equation = components of normal vector. (Note: the equation multiplied by a constant still deﬁnes the same plane). So, to ﬁnd the equation of a plane, we really need to look for the normal vector N ; we can e.g. ﬁnd it by cross-product of 2 vectors that are in the plane. Flashcard question: the vector v = �1, 2, −1� and the plane x + y + 3z = 5 are 1) parallel, 2) perpendicular, 3) neither? (A perpendicular vector would be proportional to the coeﬃcients, i.e. to �1, 1, 3�; let’s test if it’s in the plane: equivalent to being ⊥ N . We have v · N = 1 + 2 − 3 = 0 so v is parallel to the plane.) Interpretation of 3x3 systems. A 3x3 system asks for the intersection of 3 planes. Two planes intersect in a line, and usually the third plane intersects it in a single point (picture shown). The unique solution to AX = B is given by X = A−1 B.;;Exception: if the 3rd plane is parallel to the line of intersection of the ﬁrst two? What can happen? (asked on ﬂashcards for possibilities). If the line P1 ∩ P2 is contained in P3 there are inﬁnitely many solutions (the line); if it is parallel to P3 there are no solutions. (could also get a plane of solutions if all three equations are the same) These special cases correspond to systems with det(A) = 0. Then we can’t invert A to solve the 1 system: recall A−1 = det(A) adj(A). Theorem: A is invertible ⇔ det A �= 0. Homogeneous systems: AX = 0. Then all 3 planes pass through the origin, so there is the obvious (”trivial”) solution X = 0. If det A = 0 then this solution is unique: X = A−1 0 = 0. � Otherwise, if det A = 0 there are inﬁnitely many solutions (forming a line or a plane). Note: det A = 0 means det(N 1 , N 2 , N 3 ) = 0, where N i are the normals to the planes Pi . This means the parallelepiped formed by the N i has no area, i.e. they are coplanar (showed picture of 3 planes intersecting in a line, and their coplanar normals). The line of solutions is then perpendicular to the plane containing N i . For example we can get a vector along the line of intersection by taking a cross-product N 1 × N 2 . General systems: AX = B: compared to AX = 0, all the planes are shifted to parallel positions from their initial ones. If det A �= 0 then unique solution is X = A−1 B. If det A = 0, either there are inﬁnitely many solutions or there are no solutions. (We don’t have tools to decide whether it’s inﬁnitely many or none, although elimination will let us ﬁnd out). 18.02 Lecture 5. – Fri, Sept 14, 2007 Lines. We’ve seen a line as intersection of 2 planes. Other representation = parametric equation = as trajectory of a moving point. E.g. line through Q0 = (−1, 2, 2), Q1 = (1, 3, −1): moving point Q(t) starts at Q0 at t = 0, moves − − −− − − → − −→ −− −→ at constant speed along line, reaches Q1 at t = 1: its “velocity” is � = Q0 Q1 ; Q0 Q(t) = tQ0 Q1 . v On example: �x + 1, y − 2, z − 2� = t�2, 1, −3�, i.e. ⎧ ⎪x(t) = −1 + 2t, ⎨ y(t) = 2 + t, ⎪ ⎩ z(t) = 2 − 3t Lines and planes. Understand where lines and planes intersect.\n Flashcard question: relative positions of Q0 , Q1 with respect to plane x + 2y + 4z = 7? (same\n side, opposite sides, one is in the plane, can’t tell). (A sizeable number of students erroneously answered that one is in the plane.) Answer: plug coordinates into equation of plane: at Q0 , x+2y +4z = 11 > 7; at Q1 , x+2y +4z = 3 < 7; so opposite sides. Intersection of line Q0 Q1 with plane? When does the moving point Q(t) lie in the plane? Check: at Q(t), x + 2y + 4z = (−1 + 2t) + 2(2 + t) + 4(2 − 3t) = 11 − 8t, so condition is 11 − 8t = 7, or t = 1/2. Intersection point: Q(t = 1 ) = (0, 5/2, 1/2). 2 (What would happen if the line was parallel to the plane, or inside it. Answer: when plugging the coordinates of Q(t) into the plane equation we’d get a constant, equal to 7 if the line is contained in the plane – so all values of t are solutions – or to something else if the line is parallel to the plane – so there are no solutions.);;General parametric curves. Example: cycloid: wheel rolling on ﬂoor, motion of a point P on the rim. (Drew picture, then showed an applet illustrating the motion and plotting the cycloid). Position of P ? Choice of parameter: e.g., θ, the angle the wheel has turned since initial position. Distance wheel has travelled is equal to arclength on circumference of the circle = aθ. Setup: x-axis = ﬂoor, initial position of P = origin; introduce A = point of contact of wheel on −→ −→ −→ −→ − − − − ﬂoor, B = center of wheel. Decompose OP = OA + AB + BP .\n −→ − −→ − −→ − OA = �aθ, 0�; AB = �0, a�. Length of BP\n is a, and direction is θ from the (−y)-axis, so −→ − −→ − BP = �−a sin θ, −a cos θ�. Hence the position vector is OP = �aθ − a sin θ, a − a cos θ�. Q: What happens near bottom point? (ﬂashcards: corner point with ﬁnite slopes on left and right; looped curve; smooth graph with horizontal tangent; vertical tangent (cusp)).\n1 Answer: use Taylor approximation: for t → 0, f (t) ≈ f (0) + tf � (0) + 1 t2 f �� (0) + 6 t3 f ��� (0) + . . . . 2 3 /6 and cos θ ≈ 1 − θ 2 /2. So x(θ) � θ 3 /6, y(θ) � θ 2 /2 Hence for θ → 0, This gives sin θ ≈ θ − θ y/x � ( 1 θ2 )/( 1 θ3 ) = 3/θ → ∞: vertical tangent. 2 6'
7331,'lecture','en',6379,'2007-09-18','2009-09-10','Lecture 6: Velocity, acceleration - Kepler\'s second law',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 6. – Tue, Sept 18, 2007 Handouts: Practice exams 1A and 1B.\nˆ Velocity and acceleration. Last time: position vector �(t) = x(t)ˆ + y(t)ˆ [+z(t)k].\n r ı j E.g., cycloid: �(t) = �t − sin t, 1 − cos t�.\n r d� r dx dy\n Velocity vector: � (t) = v = � , �. E.g., cycloid: � (t) = �1 − cos t, sin t�. (at t = 0, � = � v v 0: dt dt dt translation and rotation motions cancel out, while at t = π they add up and � = �2, 0�). v � √ Speed (scalar): |� |. E.g., cycloid: |� | = v v (1 − cos t)2 + sin2 t = 2 − 2 cos t. (smallest at t = 0, 2π, ..., largest at t = π). d� v Acceleration: � (t) = a . E.g., cycloid: � (t) = �sin t, cos t� (at t = 0 � = �0, 1� is vertical). a a dt r r Remark: the speed is | d� |, which is NOT the same as d|�| ! dt dt ds Arclength, unit tangent vector. s = distance travelled along trajectory. = speed = |� |. v dt Can recover length of trajectory by integrating ds/dt, but this is not always easy... e.g. the length � 2π √ of an arch of cycloid is 0 2 − 2 cos t dt (can’t do). � v d� r d� ds r ˆ ˆ ds = T |� |. ˆv Unit tangent vector to trajectory: T = . We have: = =T v dt ds dt dt |� | ˆ In interval Δt: Δ� ≈ T Δs, dividing both sides by Δt and taking the limit Δt → 0 gives us the r above identity. Kepler’s 2nd law. (illustration of eﬃciency of vector methods) Kepler 1609, laws of planetary motion: the motion of planets is in a plane, and area is swept out by the line from the sun to the planet at a constant rate. Newton (about 70 years later) explained this using laws of gravitational attraction. Kepler’s law in vector form: area swept out in Δt is area ≈ 1 |\n × Δ�\nΔt r r| v| 2 � 2 r d 1 So dt (area) = 2 |� × � | is constant. r v Also, �\n× � is perpendicular to plane of motion, so dir(� × � = constant. Hence, Kepler’s 2nd\n r v r v) law says: � × � = constant. r v d The usual product rule can be used to diﬀerentiate vector functions: dt (� · � dt (� × � being a b), d a b), careful about non-commutativity of cross-product. d d� r d� v (� × � ) = r v ×� +�× v r = � × � + � × � = � × �. v v r a r a dt dt dt � So Kepler’s law ⇔ � × � = constant ⇔ � × � = 0 ⇔ � //� ⇔ the force F is central.\n r v r a a r (so Kepler’s law really means the force is directed //�; it also applies to other central forces –\n r e.g. electric charges.) 18.02 Lecture 7. – Thu, Sept 20, 2007 Handouts: PS2 solutions, PS3. Review. Material on the test = everything seen in lecture. The exam is similar to the practice exams, or very slightly harder. The main topics are (Problem numbers refer to Practice 1A): � 1) vectors, dot product. A · B = |A||B| cos θ = ai bi . Finding angles. (e.g. Problem 1.);;2) cross-product, area of space triangles 1 |A × B|; equations of planes (coeﬃcients of equation 2 = components of normal vector) (e.g. Problem 5.) 3) matrices, inverse matrix, linear systems (e.g. Problem 3.) 4) ﬁnding parametric equations by decomposing position vector as a sum; velocity, acceleration; diﬀerentiating vector identities (e.g. Problems 2,4,6).'
7332,'lecture','en',6379,'2007-09-20','2009-09-10','Lecture 7: Review',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 6. – Tue, Sept 18, 2007 Handouts: Practice exams 1A and 1B.\nˆ Velocity and acceleration. Last time: position vector �(t) = x(t)ˆ + y(t)ˆ [+z(t)k].\n r ı j E.g., cycloid: �(t) = �t − sin t, 1 − cos t�.\n r d� r dx dy\n Velocity vector: � (t) = v = � , �. E.g., cycloid: � (t) = �1 − cos t, sin t�. (at t = 0, � = � v v 0: dt dt dt translation and rotation motions cancel out, while at t = π they add up and � = �2, 0�). v � √ Speed (scalar): |� |. E.g., cycloid: |� | = v v (1 − cos t)2 + sin2 t = 2 − 2 cos t. (smallest at t = 0, 2π, ..., largest at t = π). d� v Acceleration: � (t) = a . E.g., cycloid: � (t) = �sin t, cos t� (at t = 0 � = �0, 1� is vertical). a a dt r r Remark: the speed is | d� |, which is NOT the same as d|�| ! dt dt ds Arclength, unit tangent vector. s = distance travelled along trajectory. = speed = |� |. v dt Can recover length of trajectory by integrating ds/dt, but this is not always easy... e.g. the length � 2π √ of an arch of cycloid is 0 2 − 2 cos t dt (can’t do). � v d� r d� ds r ˆ ˆ ds = T |� |. ˆv Unit tangent vector to trajectory: T = . We have: = =T v dt ds dt dt |� | ˆ In interval Δt: Δ� ≈ T Δs, dividing both sides by Δt and taking the limit Δt → 0 gives us the r above identity. Kepler’s 2nd law. (illustration of eﬃciency of vector methods) Kepler 1609, laws of planetary motion: the motion of planets is in a plane, and area is swept out by the line from the sun to the planet at a constant rate. Newton (about 70 years later) explained this using laws of gravitational attraction. Kepler’s law in vector form: area swept out in Δt is area ≈ 1 |\n × Δ�\nΔt r r| v| 2 � 2 r d 1 So dt (area) = 2 |� × � | is constant. r v Also, �\n× � is perpendicular to plane of motion, so dir(� × � = constant. Hence, Kepler’s 2nd\n r v r v) law says: � × � = constant. r v d The usual product rule can be used to diﬀerentiate vector functions: dt (� · � dt (� × � being a b), d a b), careful about non-commutativity of cross-product. d d� r d� v (� × � ) = r v ×� +�× v r = � × � + � × � = � × �. v v r a r a dt dt dt � So Kepler’s law ⇔ � × � = constant ⇔ � × � = 0 ⇔ � //� ⇔ the force F is central.\n r v r a a r (so Kepler’s law really means the force is directed //�; it also applies to other central forces –\n r e.g. electric charges.) 18.02 Lecture 7. – Thu, Sept 20, 2007 Handouts: PS2 solutions, PS3. Review. Material on the test = everything seen in lecture. The exam is similar to the practice exams, or very slightly harder. The main topics are (Problem numbers refer to Practice 1A): � 1) vectors, dot product. A · B = |A||B| cos θ = ai bi . Finding angles. (e.g. Problem 1.);;2) cross-product, area of space triangles 1 |A × B|; equations of planes (coeﬃcients of equation 2 = components of normal vector) (e.g. Problem 5.) 3) matrices, inverse matrix, linear systems (e.g. Problem 3.) 4) ﬁnding parametric equations by decomposing position vector as a sum; velocity, acceleration; diﬀerentiating vector identities (e.g. Problems 2,4,6).'
7500,'lecture','en',6379,'2007-09-25','2009-09-10','Lecture 8: Level curves; partial derivatives; tangent plane approximation',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 8. – Tue, Sept 25, 2007 Functions of several variables. Recall: for a function of 1 variable, we can plot its graph, and the derivative is the slope of the tangent line to the graph. Plotting graphs of functions of 2 variables: examples z = −y, z = 1 − x2 − y 2 , using slices by the coordinate planes. (derived carefully). Contour plot: level curves f (x, y) = c. Amounts to slicing the graph by horizontal planes z = c. Showed 2 examples from “real life”: a topographical map, and a temperature map, then did the examples z = −y and z = 1 − x2 − y 2 . Showed more examples of computer plots (z = x2 + y 2 , z = y 2 − x2 , and another one). Contour plot gives some qualitative info about how f varies when we change x, y. (shown an example where increasing x leads f to increase). Partial derivatives. ∂f f (x0 + Δx, y0 ) − f (x0 , y0 ) fx = = lim ; same for fy . ∂x Δx→0 Δx Geometric interpretation: fx , fy are slopes of tangent lines of vertical slices of the graph of f (ﬁxing y = y0 ; ﬁxing x = x0 ). How to compute: treat x as variable, y as constant. Example: f (x, y) = x3 y + y 2 , then fx = 3x2 y, fy = x3 + 2y. 18.02 Lecture 9. – Thu, Sept 27, 2007 Handouts: PS3 solutions, PS4. Linear approximation Interpretation of fx , fy as slopes of slices of the graph by planes parallel to xz and yz planes. Linear approximation formula: Δf ≈ fx Δx + fy Δy. Justiﬁcation: fx and fy give slopes of two lines tangent to the graph: y = y0 , z = z0 + fx (x0 , y0 )(x − x0 ) and x = x0 , z = z0 + fy (x0 , y0 )(y − y0 ). We can use this to get the equation of the tangent plane to the graph: z = z0 + fx (x0 , y0 )(x − x0 ) + fy (x0 , y0 )(y − y0 ). Approximation formula = the graph is close to its tangent plane. Min/max problems. At a local max or min, fx = 0 and fy = 0 (since (x0 , y0 ) is a local max or min of the slice). Because 2 lines determine tangent plane, this is enough to ensure that tangent plane is horizontal (approximation formula: Δf � 0, or rather, |Δf | � |Δx|, |Δy|). Def of critical point: (x0 , y0 ) where fx = 0 and fy = 0. A critical point may be a local min, local max, or saddle. Example: f (x, y) = x2 − 2xy + 3y 2 + 2x − 2y. Critical point: fx = 2x − 2y + 2 = 0, fy = −2x + 6y − 2 = 0, gives (x0 , y0 ) = (−1, 0) (only one critical point).;;Is it a max, min or saddle? (pictures shown of each type). Systematic answer: next lecture. For today: observe f = (x − y)2 + 2y 2 + 2x − 2y = (x − y + 1)2 + 2y 2 − 1 ≥ −1, so minimum. Least squares. Set up problem: experimental data (xi , yi ) (i = 1, . . . , n), want to ﬁnd a best-ﬁt line y = ax + b (the unknowns here are a, b, not x, y!) � Deviations: yi − (axi + b); want to minimize the total square deviation D = i (yi − (axi + b))2 . ∂D ∂D = 0 and = 0 leads to a 2 × 2 linear system for a and b (done in detail as in Notes LS): ∂a ∂b �� � �� � � x2 a + xi b = xi yi i �� � � xi a + nb = yi\nLeast-squares setup also works in other cases: e.g. exponential laws y = ceax (taking logarithms: ln y = ln c + ax, so setting b = ln c we reduce to linear case); or quadratic laws y = ax2 + bx + c (minimizing total square deviation leads to a 3 × 3 linear system for a, b, c). Example: Moore’s Law (number of transistors on a computer chip increases exponentially with time): showed interpolation line on a log plot.\n18.02 Lecture 10. – Fri, Sept 28, 2007 Second derivative test. Recall critical points can be local min (w = x2 + y 2 ), local max (w = −x2 − y 2 ), saddle (w = 2 − x2 ); slides shown of each type. y Goal: determine type of a critical point, and ﬁnd the global min/max. Note: global min/max may be either at a critical point, or on the boundary of the domain/at inﬁnity. We start with the case of w = ax2 + bxy + cy 2 , at (0, 0). Example from Tuesday: w = x2 −2xy+3y 2 : completing the square, w = (x−y)2 +2y 2 , minimum. b b b2 1 b If a �= 0, then w = a(x2 + xy)+cy 2 = a(x+ y)2 +(c− )y 2 = (4a2 (x+ y)2 +(4ac−b2 )y 2 ). a 2a 4a 2a 4a 3 cases: if 4ac − b2 > 0, same signs, if a > 0 then minimum, if a < 0 then maximum; if 4ac − b2 < 0, opposite signs, saddle; if 4ac − b2 = 0, degenerate case. � x � x This is related to the quadratic formula: w = y 2 a( )2 + b( ) + c . y y 2 −4ac < 0 then no roots, so at2 +bt+c has a constant sign, and w is either always nonnegative If b or always nonpositive (min or max). If b2 − 4ac > 0 then at2 + bt + c crosses zero and changes sign, so w can have both signs, saddle. General case: second derivative test. ∂2f We look at second derivatives: fxx = , fxy , fyx , fyy . Fact: fxy = fyx . ∂x2 Given f and a critical point (x0 , y0 ), set A = fxx (x0 , y0 ), B = fxy (x0 , y0 ), C = fyy (x0 , y0 ), then: – if AC − B 2 > 0 then: if A > 0 (or C), local min; if A < 0, local max. – if AC − B 2 < 0 then saddle.;;– if AC − B 2 = 0 then can’t conclude.\n Checked quadratic case (fxx = 2a = A, fxy = b = B, fyy = 2c = C, then AC − B 2 = 4ac − b2 ).\n General justiﬁcation: quadratic approximation formula (Taylor series at order 2):\n Δf � fx (x − x0 ) + fy (y − y0 ) + 1 fxx (x − x0 )2 + fxy (x − x0 )(y − y0 ) + 1 fyy (y − y0 )2 . 2 2 At a critical point, Δf � A (x − x0 )2 + B(x − x0 )(y − y0 ) + C (y − y0 )2 . In degenerate case, would 2 2 need higher order derivatives to conclude. NOTE: the global min/max of a function is not necessarily at a critical point! Need to check boundary / inﬁnity.\n1 xy , for x > 0, y > 0. 1 fx = 1 − x1y = 0, fy = 1 − xy\n2 = 0. So x2 y = 1, xy 2 = 1, only critical 2 fxx = 2/x3 y, fxy = 1/x2 y 2 , fyy = 2/xy 3 . So A = 2, B = 1, C = 2.\n Question: type of critical point? Answer: AC − B 2 = 2 · 2 − 1 > 0, A\nExample: f (x, y) = x + y +\npoint is (1, 1).\n= 2 > 0, local min.\n What about the maximum? Answer: f → ∞ near boundary (x → 0 or y → 0) and at inﬁnity.'
7501,'lecture','en',6379,'2007-09-27','2009-09-10','Lecture 9: Max-min problems; least squares',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 8. – Tue, Sept 25, 2007 Functions of several variables. Recall: for a function of 1 variable, we can plot its graph, and the derivative is the slope of the tangent line to the graph. Plotting graphs of functions of 2 variables: examples z = −y, z = 1 − x2 − y 2 , using slices by the coordinate planes. (derived carefully). Contour plot: level curves f (x, y) = c. Amounts to slicing the graph by horizontal planes z = c. Showed 2 examples from “real life”: a topographical map, and a temperature map, then did the examples z = −y and z = 1 − x2 − y 2 . Showed more examples of computer plots (z = x2 + y 2 , z = y 2 − x2 , and another one). Contour plot gives some qualitative info about how f varies when we change x, y. (shown an example where increasing x leads f to increase). Partial derivatives. ∂f f (x0 + Δx, y0 ) − f (x0 , y0 ) fx = = lim ; same for fy . ∂x Δx→0 Δx Geometric interpretation: fx , fy are slopes of tangent lines of vertical slices of the graph of f (ﬁxing y = y0 ; ﬁxing x = x0 ). How to compute: treat x as variable, y as constant. Example: f (x, y) = x3 y + y 2 , then fx = 3x2 y, fy = x3 + 2y. 18.02 Lecture 9. – Thu, Sept 27, 2007 Handouts: PS3 solutions, PS4. Linear approximation Interpretation of fx , fy as slopes of slices of the graph by planes parallel to xz and yz planes. Linear approximation formula: Δf ≈ fx Δx + fy Δy. Justiﬁcation: fx and fy give slopes of two lines tangent to the graph: y = y0 , z = z0 + fx (x0 , y0 )(x − x0 ) and x = x0 , z = z0 + fy (x0 , y0 )(y − y0 ). We can use this to get the equation of the tangent plane to the graph: z = z0 + fx (x0 , y0 )(x − x0 ) + fy (x0 , y0 )(y − y0 ). Approximation formula = the graph is close to its tangent plane. Min/max problems. At a local max or min, fx = 0 and fy = 0 (since (x0 , y0 ) is a local max or min of the slice). Because 2 lines determine tangent plane, this is enough to ensure that tangent plane is horizontal (approximation formula: Δf � 0, or rather, |Δf | � |Δx|, |Δy|). Def of critical point: (x0 , y0 ) where fx = 0 and fy = 0. A critical point may be a local min, local max, or saddle. Example: f (x, y) = x2 − 2xy + 3y 2 + 2x − 2y. Critical point: fx = 2x − 2y + 2 = 0, fy = −2x + 6y − 2 = 0, gives (x0 , y0 ) = (−1, 0) (only one critical point).;;Is it a max, min or saddle? (pictures shown of each type). Systematic answer: next lecture. For today: observe f = (x − y)2 + 2y 2 + 2x − 2y = (x − y + 1)2 + 2y 2 − 1 ≥ −1, so minimum. Least squares. Set up problem: experimental data (xi , yi ) (i = 1, . . . , n), want to ﬁnd a best-ﬁt line y = ax + b (the unknowns here are a, b, not x, y!) � Deviations: yi − (axi + b); want to minimize the total square deviation D = i (yi − (axi + b))2 . ∂D ∂D = 0 and = 0 leads to a 2 × 2 linear system for a and b (done in detail as in Notes LS): ∂a ∂b �� � �� � � x2 a + xi b = xi yi i �� � � xi a + nb = yi\nLeast-squares setup also works in other cases: e.g. exponential laws y = ceax (taking logarithms: ln y = ln c + ax, so setting b = ln c we reduce to linear case); or quadratic laws y = ax2 + bx + c (minimizing total square deviation leads to a 3 × 3 linear system for a, b, c). Example: Moore’s Law (number of transistors on a computer chip increases exponentially with time): showed interpolation line on a log plot.\n18.02 Lecture 10. – Fri, Sept 28, 2007 Second derivative test. Recall critical points can be local min (w = x2 + y 2 ), local max (w = −x2 − y 2 ), saddle (w = 2 − x2 ); slides shown of each type. y Goal: determine type of a critical point, and ﬁnd the global min/max. Note: global min/max may be either at a critical point, or on the boundary of the domain/at inﬁnity. We start with the case of w = ax2 + bxy + cy 2 , at (0, 0). Example from Tuesday: w = x2 −2xy+3y 2 : completing the square, w = (x−y)2 +2y 2 , minimum. b b b2 1 b If a �= 0, then w = a(x2 + xy)+cy 2 = a(x+ y)2 +(c− )y 2 = (4a2 (x+ y)2 +(4ac−b2 )y 2 ). a 2a 4a 2a 4a 3 cases: if 4ac − b2 > 0, same signs, if a > 0 then minimum, if a < 0 then maximum; if 4ac − b2 < 0, opposite signs, saddle; if 4ac − b2 = 0, degenerate case. � x � x This is related to the quadratic formula: w = y 2 a( )2 + b( ) + c . y y 2 −4ac < 0 then no roots, so at2 +bt+c has a constant sign, and w is either always nonnegative If b or always nonpositive (min or max). If b2 − 4ac > 0 then at2 + bt + c crosses zero and changes sign, so w can have both signs, saddle. General case: second derivative test. ∂2f We look at second derivatives: fxx = , fxy , fyx , fyy . Fact: fxy = fyx . ∂x2 Given f and a critical point (x0 , y0 ), set A = fxx (x0 , y0 ), B = fxy (x0 , y0 ), C = fyy (x0 , y0 ), then: – if AC − B 2 > 0 then: if A > 0 (or C), local min; if A < 0, local max. – if AC − B 2 < 0 then saddle.;;– if AC − B 2 = 0 then can’t conclude.\n Checked quadratic case (fxx = 2a = A, fxy = b = B, fyy = 2c = C, then AC − B 2 = 4ac − b2 ).\n General justiﬁcation: quadratic approximation formula (Taylor series at order 2):\n Δf � fx (x − x0 ) + fy (y − y0 ) + 1 fxx (x − x0 )2 + fxy (x − x0 )(y − y0 ) + 1 fyy (y − y0 )2 . 2 2 At a critical point, Δf � A (x − x0 )2 + B(x − x0 )(y − y0 ) + C (y − y0 )2 . In degenerate case, would 2 2 need higher order derivatives to conclude. NOTE: the global min/max of a function is not necessarily at a critical point! Need to check boundary / inﬁnity.\n1 xy , for x > 0, y > 0. 1 fx = 1 − x1y = 0, fy = 1 − xy\n2 = 0. So x2 y = 1, xy 2 = 1, only critical 2 fxx = 2/x3 y, fxy = 1/x2 y 2 , fyy = 2/xy 3 . So A = 2, B = 1, C = 2.\n Question: type of critical point? Answer: AC − B 2 = 2 · 2 − 1 > 0, A\nExample: f (x, y) = x + y +\npoint is (1, 1).\n= 2 > 0, local min.\n What about the maximum? Answer: f → ∞ near boundary (x → 0 or y → 0) and at inﬁnity.'
7503,'lecture','en',6379,'2007-09-28','2009-09-10','Lecture 10: Second derivative test; boundaries and infinity',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 8. – Tue, Sept 25, 2007 Functions of several variables. Recall: for a function of 1 variable, we can plot its graph, and the derivative is the slope of the tangent line to the graph. Plotting graphs of functions of 2 variables: examples z = −y, z = 1 − x2 − y 2 , using slices by the coordinate planes. (derived carefully). Contour plot: level curves f (x, y) = c. Amounts to slicing the graph by horizontal planes z = c. Showed 2 examples from “real life”: a topographical map, and a temperature map, then did the examples z = −y and z = 1 − x2 − y 2 . Showed more examples of computer plots (z = x2 + y 2 , z = y 2 − x2 , and another one). Contour plot gives some qualitative info about how f varies when we change x, y. (shown an example where increasing x leads f to increase). Partial derivatives. ∂f f (x0 + Δx, y0 ) − f (x0 , y0 ) fx = = lim ; same for fy . ∂x Δx→0 Δx Geometric interpretation: fx , fy are slopes of tangent lines of vertical slices of the graph of f (ﬁxing y = y0 ; ﬁxing x = x0 ). How to compute: treat x as variable, y as constant. Example: f (x, y) = x3 y + y 2 , then fx = 3x2 y, fy = x3 + 2y. 18.02 Lecture 9. – Thu, Sept 27, 2007 Handouts: PS3 solutions, PS4. Linear approximation Interpretation of fx , fy as slopes of slices of the graph by planes parallel to xz and yz planes. Linear approximation formula: Δf ≈ fx Δx + fy Δy. Justiﬁcation: fx and fy give slopes of two lines tangent to the graph: y = y0 , z = z0 + fx (x0 , y0 )(x − x0 ) and x = x0 , z = z0 + fy (x0 , y0 )(y − y0 ). We can use this to get the equation of the tangent plane to the graph: z = z0 + fx (x0 , y0 )(x − x0 ) + fy (x0 , y0 )(y − y0 ). Approximation formula = the graph is close to its tangent plane. Min/max problems. At a local max or min, fx = 0 and fy = 0 (since (x0 , y0 ) is a local max or min of the slice). Because 2 lines determine tangent plane, this is enough to ensure that tangent plane is horizontal (approximation formula: Δf � 0, or rather, |Δf | � |Δx|, |Δy|). Def of critical point: (x0 , y0 ) where fx = 0 and fy = 0. A critical point may be a local min, local max, or saddle. Example: f (x, y) = x2 − 2xy + 3y 2 + 2x − 2y. Critical point: fx = 2x − 2y + 2 = 0, fy = −2x + 6y − 2 = 0, gives (x0 , y0 ) = (−1, 0) (only one critical point).;;Is it a max, min or saddle? (pictures shown of each type). Systematic answer: next lecture. For today: observe f = (x − y)2 + 2y 2 + 2x − 2y = (x − y + 1)2 + 2y 2 − 1 ≥ −1, so minimum. Least squares. Set up problem: experimental data (xi , yi ) (i = 1, . . . , n), want to ﬁnd a best-ﬁt line y = ax + b (the unknowns here are a, b, not x, y!) � Deviations: yi − (axi + b); want to minimize the total square deviation D = i (yi − (axi + b))2 . ∂D ∂D = 0 and = 0 leads to a 2 × 2 linear system for a and b (done in detail as in Notes LS): ∂a ∂b �� � �� � � x2 a + xi b = xi yi i �� � � xi a + nb = yi\nLeast-squares setup also works in other cases: e.g. exponential laws y = ceax (taking logarithms: ln y = ln c + ax, so setting b = ln c we reduce to linear case); or quadratic laws y = ax2 + bx + c (minimizing total square deviation leads to a 3 × 3 linear system for a, b, c). Example: Moore’s Law (number of transistors on a computer chip increases exponentially with time): showed interpolation line on a log plot.\n18.02 Lecture 10. – Fri, Sept 28, 2007 Second derivative test. Recall critical points can be local min (w = x2 + y 2 ), local max (w = −x2 − y 2 ), saddle (w = 2 − x2 ); slides shown of each type. y Goal: determine type of a critical point, and ﬁnd the global min/max. Note: global min/max may be either at a critical point, or on the boundary of the domain/at inﬁnity. We start with the case of w = ax2 + bxy + cy 2 , at (0, 0). Example from Tuesday: w = x2 −2xy+3y 2 : completing the square, w = (x−y)2 +2y 2 , minimum. b b b2 1 b If a �= 0, then w = a(x2 + xy)+cy 2 = a(x+ y)2 +(c− )y 2 = (4a2 (x+ y)2 +(4ac−b2 )y 2 ). a 2a 4a 2a 4a 3 cases: if 4ac − b2 > 0, same signs, if a > 0 then minimum, if a < 0 then maximum; if 4ac − b2 < 0, opposite signs, saddle; if 4ac − b2 = 0, degenerate case. � x � x This is related to the quadratic formula: w = y 2 a( )2 + b( ) + c . y y 2 −4ac < 0 then no roots, so at2 +bt+c has a constant sign, and w is either always nonnegative If b or always nonpositive (min or max). If b2 − 4ac > 0 then at2 + bt + c crosses zero and changes sign, so w can have both signs, saddle. General case: second derivative test. ∂2f We look at second derivatives: fxx = , fxy , fyx , fyy . Fact: fxy = fyx . ∂x2 Given f and a critical point (x0 , y0 ), set A = fxx (x0 , y0 ), B = fxy (x0 , y0 ), C = fyy (x0 , y0 ), then: – if AC − B 2 > 0 then: if A > 0 (or C), local min; if A < 0, local max. – if AC − B 2 < 0 then saddle.;;– if AC − B 2 = 0 then can’t conclude.\n Checked quadratic case (fxx = 2a = A, fxy = b = B, fyy = 2c = C, then AC − B 2 = 4ac − b2 ).\n General justiﬁcation: quadratic approximation formula (Taylor series at order 2):\n Δf � fx (x − x0 ) + fy (y − y0 ) + 1 fxx (x − x0 )2 + fxy (x − x0 )(y − y0 ) + 1 fyy (y − y0 )2 . 2 2 At a critical point, Δf � A (x − x0 )2 + B(x − x0 )(y − y0 ) + C (y − y0 )2 . In degenerate case, would 2 2 need higher order derivatives to conclude. NOTE: the global min/max of a function is not necessarily at a critical point! Need to check boundary / inﬁnity.\n1 xy , for x > 0, y > 0. 1 fx = 1 − x1y = 0, fy = 1 − xy\n2 = 0. So x2 y = 1, xy 2 = 1, only critical 2 fxx = 2/x3 y, fxy = 1/x2 y 2 , fyy = 2/xy 3 . So A = 2, B = 1, C = 2.\n Question: type of critical point? Answer: AC − B 2 = 2 · 2 − 1 > 0, A\nExample: f (x, y) = x + y +\npoint is (1, 1).\n= 2 > 0, local min.\n What about the maximum? Answer: f → ∞ near boundary (x → 0 or y → 0) and at inﬁnity.'
7504,'lecture','en',6379,'2007-10-02','2009-09-10','Lecture 11: Differentials; chain rule',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 11. –\nTue, Oct 2, 2007\nDiﬀerentials. Recall in single variable calculus: y =√ (x) ⇒ dy = f � (x) dx. Example: y = sin−1 (x) ⇒ x = sin y, f dx = cos y dy, so dy/dx = 1/ cos y = 1/ 1 − x2 . Total diﬀerential: f = f (x, y, z) ⇒ df = fx dx + fy dy + fz dz. This is a new type of object, with its own rules for manipulating it (df is not the same as Δf ! The textbook has it wrong.) It encodes how variations of f are related to variations of x, y, z. We can use it in two ways: 1. as a placeholder for approximation formulas: Δf ≈ fx Δx + fy Δy + fz Δz. 2. divide by dt to get the chain rule: if x = x(t), y = y(t), z = z(t), then f becomes a function df dx dy dz of t and = fx + fy + fz dt dt dt dt Example: w = x2 y + z, dw = 2xy dx + x2 dy + dz. If x = t, y = et , z = sin t then the chain rule gives dw/dt = (2tet ) 1 + (t2 ) et + cos t, same as what we obtain by substitution into formula for w and one-variable diﬀerentiation. Can justify the chain rule in 2 ways: 1. dx = x� (t) dt, dy = y � (t) dt, dz = z � (t) dt, so substituting we get dw = fx dx + fy dy + fz dz = fx x� (t) dt + fy y � (t) dt + fz z � (t) dt, hence dw/dt. 2. (more rigorous): Δw � fx Δx + fy Δy + fz Δz, divide both sides by Δt and take limit as Δt → 0. Applications of chain rule: Product and quotient formulas for derivatives: f = uv, u = u(t), v = v(t), then d(uv)/dt = fu u� + fv v � = vu� + uv � . Similarly with g = u/v, d(u/v)/dt = gu u� + gv v � = (1/v) u� + (−u/v 2 ) v � = (u� v − uv � )/v 2 . Chain rule with more variables: for example w = f (x, y), x = x(u, v), y = y(u, v). Then dw = fx dx + fy dy = fx (xu du + xv dv) + fy (yu du + yv dv) = (fx xu + fy yu ) du + (fx xv + fy yv ) dv. Identifying coeﬃcients of du and dv we get ∂f /∂u = fx xu + fy yu and similarly for ∂f /∂v. It\'s not legal to “simplify by ∂x”. Example: polar coordinates: x = r cos θ, y = r sin θ. Then fr = fx xr + fy yr = cos θ fx + sin θ fy , and similarly fθ . 18.02 Lecture 12. – Thu, Oct 4, 2007\nHandouts: PS4 solutions, PS5. Gradient. dw dx dy dz dw d� r Recall chain rule: = wx + wy + wz . In vector notation: = �w · . dt dt dt dt dt dt Deﬁnition: �w = �wx , wy , wz � – GRADIENT VECTOR.\n Theorem: �w is perpendicular to the level surfaces w = c.\n Example 1: w = ax + by + cz, then w = d is a plane with normal vector �w = �a, b, c�.\n Example 2: w = x2 + y 2 , then w = c are circles, �w = �2x, 2y� points radially out so ⊥ circles.\n Example 3: w = x2 − y 2 , shown on applet (Lagrange multipliers applet with g disabled).;;�w is a vector whose value depends on the point (x, y) where we evaluate w. Proof: take a curve � = �(t) contained inside level surface w = c. Then velocity � = d�/dt is in r r v r the tangent plane, and by chain rule, dw/dt = �w · d�/dt = 0, so � ⊥ �w. This is true for every � r v v in the tangent plane. Application: tangent plane to a surface. Example: tangent plane to x2 + y 2 − z 2 = 4 at (2, 1, 1): gradient is �2x, 2y, −2z� = �4, 2, −2�; tangent plane is 4x + 2y − 2z = 8. (Here we could also solve � for z = x2 + y 2 − 4 and use linear approximation formula, but in general we can’t.) (Another way to get the tangent plane: dw = 2x dx + 2y dy − 2z dz = 4dx + 2dy − 2dz. So Δw ≈ 4Δx + 2Δy − 2Δz. The level surface is Δw = 0, its tangent plane approximation is 4Δx + 2Δy − 2Δz = 0, i.e. 4(x − 2) + 2(y − 1) − 2(z − 1) = 0, same as above). Directional derivative. Rate of change of w as we move (x, y) in an arbitrary direction. Take a unit vector u = �a, b�, and look at straight line trajectory �(s) with velocity u, given by ˆ r ˆ x(s) = x0 + as, y(s) = y0 + bs. (unit speed, so s is arclength!) dw Notation: . ds |u ˆ Geometrically: slice of graph by a vertical plane (not parallel to x or y axes anymore). Directional derivative is the slope. Shown on applet (Functions of two variables), with w = x2 + y 2 + 1, and rotating slices through a point of the graph. dw d� r Know how to calculate dw/ds by chain rule: = �w · = �w · u. ˆ ds |u ds ˆ Geometric interpretation: dw/ds = �w · u = |�w| cos θ. Maximal for cos θ = 1, when u is in ˆ ˆ direction of �w. Hence: direction of �w is that of fastest increase of w, and |�w| is the directional derivative in that direction. We have dw/ds = 0 when u ⊥ �w, i.e. when u is tangent to direction ˆ ˆ of level surface.\nFri, Oct 5, 2007 (estimated – written before lecture)\nPractice exams 2A and 2B are on course web page. Lagrange multipliers. Problem: min/max when variables are constrained by an equation g(x, y, z) = c. � Example: ﬁnd point of xy = 3 closest to origin ? I.e. minimize x2 + y 2 , or better f (x, y) = x2 + y 2 , subject to g(x, y) = xy = 3. Illustrated using Lagrange multipliers applet. Observe on picture: at the minimum, the level curves are tangent to each other, so the normal vectors �f and �g are parallel. So: there exists λ (“multiplier”) such that �f = λ�g. We replace the constrained min/max problem in 2 variables with equations involving 3 variables x, y, λ: ⎧ ⎧ ⎪fx = λgx ⎪2x = λy\n ⎨ ⎨ i.e. here f = λgy 2y = λx\n ⎪ y ⎪ ⎩\n g = c\n xy = 3.;;� 2x − λy = 0 In general solving may be hard and require a computer. Here, linear algebra: −λx + 2y = 0 2 = 0. So λ = ±2. No solutions requires either x = y = 0 (impossible, since xy = 3), or det = 4 − λ √ √ √ √ for λ = −2, while λ = 2 gives ( 3, 3) and (− 3, − 3). (Checked on applet that �f = 2�g at minimum). Why the method works: at constrained min/max, moving in any direction along the constraint df ˆ surface g = c should give df /ds = 0. So, for any u tangent to {g = c}, ds |u = �f · u = 0, i.e. ˆ ˆ u ⊥ �f . Therefore �f is normal to tangent plane to g = c, and so is �g, hence the gradient ˆ vectors are parallel. Warning: method doesn’t say whether we have a min or a max, and second derivative test doesn’t apply with constrained variables. Need to answer using geometric argument or by comparing values of f . Advanced example: surface-minimizing pyramid. Triangular-based pyramid with given triangle as base and given volume V , using as little surface area as possible. Note: V = 1 Abase h, so height h is ﬁxed, top vertex moves in a plane z = h. 3 We can set up problem in coordinates: base vertices P1 = (x1 , y1 , 0), P2 , P3 , and top vertex P = (x, y, h). Then areas of faces = 1 |P� 1 × P� 2 |, etc. Calculations to ﬁnd critical point of P P 2 function of (x, y) are very hard. Key idea: use variables adapted to the geometry, instead of (x, y): let a1 , a2 , a3 = lengths of sides of the base triangle; u1 , u2 , u3 = distances in the xy-plane from the projection of� to the P sides of the base triangle. Then each face is a triangle with base length ai and height u2 + h2 i (using Pythagorean theorem). � � � So we must minimize f (u1 , u2 , u3 ) = 1 a1 u2 + h2 + 1 a2 u2 + h2 + 1 a3 u2 + h2 . 1 2 3 2 2 2 Constraint? (asked using ﬂashcards; this was a bad choice, very few students responded at all.) Decomposing base into 3 smaller triangles with heights ui , we must have g(u1 , u2 , u3 ) = 1 1 1 2 a1 u1 + 2 a2 u2 + 2 a3 u3 = Abase . Lagrange multiplier method: �f = λ�g gives a1 u a1 � 1 = λ , similarly for u2 and u3 . 2 u 2 + h2 2 1 u1 u2 u3 We conclude λ = � 2 = � 2 = � 2 , hence u1 = u2 = u3 , so P lies above the 2 2 u1 + h u2 + h u 3 + h2 incenter.'
7505,'lecture','en',6379,'2007-10-04','2009-09-10','Lecture 12: Gradient; directional derivative; tangent plane',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 11. –\nTue, Oct 2, 2007\nDiﬀerentials. Recall in single variable calculus: y =√ (x) ⇒ dy = f � (x) dx. Example: y = sin−1 (x) ⇒ x = sin y, f dx = cos y dy, so dy/dx = 1/ cos y = 1/ 1 − x2 . Total diﬀerential: f = f (x, y, z) ⇒ df = fx dx + fy dy + fz dz. This is a new type of object, with its own rules for manipulating it (df is not the same as Δf ! The textbook has it wrong.) It encodes how variations of f are related to variations of x, y, z. We can use it in two ways: 1. as a placeholder for approximation formulas: Δf ≈ fx Δx + fy Δy + fz Δz. 2. divide by dt to get the chain rule: if x = x(t), y = y(t), z = z(t), then f becomes a function df dx dy dz of t and = fx + fy + fz dt dt dt dt Example: w = x2 y + z, dw = 2xy dx + x2 dy + dz. If x = t, y = et , z = sin t then the chain rule gives dw/dt = (2tet ) 1 + (t2 ) et + cos t, same as what we obtain by substitution into formula for w and one-variable diﬀerentiation. Can justify the chain rule in 2 ways: 1. dx = x� (t) dt, dy = y � (t) dt, dz = z � (t) dt, so substituting we get dw = fx dx + fy dy + fz dz = fx x� (t) dt + fy y � (t) dt + fz z � (t) dt, hence dw/dt. 2. (more rigorous): Δw � fx Δx + fy Δy + fz Δz, divide both sides by Δt and take limit as Δt → 0. Applications of chain rule: Product and quotient formulas for derivatives: f = uv, u = u(t), v = v(t), then d(uv)/dt = fu u� + fv v � = vu� + uv � . Similarly with g = u/v, d(u/v)/dt = gu u� + gv v � = (1/v) u� + (−u/v 2 ) v � = (u� v − uv � )/v 2 . Chain rule with more variables: for example w = f (x, y), x = x(u, v), y = y(u, v). Then dw = fx dx + fy dy = fx (xu du + xv dv) + fy (yu du + yv dv) = (fx xu + fy yu ) du + (fx xv + fy yv ) dv. Identifying coeﬃcients of du and dv we get ∂f /∂u = fx xu + fy yu and similarly for ∂f /∂v. It\'s not legal to “simplify by ∂x”. Example: polar coordinates: x = r cos θ, y = r sin θ. Then fr = fx xr + fy yr = cos θ fx + sin θ fy , and similarly fθ . 18.02 Lecture 12. – Thu, Oct 4, 2007\nHandouts: PS4 solutions, PS5. Gradient. dw dx dy dz dw d� r Recall chain rule: = wx + wy + wz . In vector notation: = �w · . dt dt dt dt dt dt Deﬁnition: �w = �wx , wy , wz � – GRADIENT VECTOR.\n Theorem: �w is perpendicular to the level surfaces w = c.\n Example 1: w = ax + by + cz, then w = d is a plane with normal vector �w = �a, b, c�.\n Example 2: w = x2 + y 2 , then w = c are circles, �w = �2x, 2y� points radially out so ⊥ circles.\n Example 3: w = x2 − y 2 , shown on applet (Lagrange multipliers applet with g disabled).;;�w is a vector whose value depends on the point (x, y) where we evaluate w. Proof: take a curve � = �(t) contained inside level surface w = c. Then velocity � = d�/dt is in r r v r the tangent plane, and by chain rule, dw/dt = �w · d�/dt = 0, so � ⊥ �w. This is true for every � r v v in the tangent plane. Application: tangent plane to a surface. Example: tangent plane to x2 + y 2 − z 2 = 4 at (2, 1, 1): gradient is �2x, 2y, −2z� = �4, 2, −2�; tangent plane is 4x + 2y − 2z = 8. (Here we could also solve � for z = x2 + y 2 − 4 and use linear approximation formula, but in general we can’t.) (Another way to get the tangent plane: dw = 2x dx + 2y dy − 2z dz = 4dx + 2dy − 2dz. So Δw ≈ 4Δx + 2Δy − 2Δz. The level surface is Δw = 0, its tangent plane approximation is 4Δx + 2Δy − 2Δz = 0, i.e. 4(x − 2) + 2(y − 1) − 2(z − 1) = 0, same as above). Directional derivative. Rate of change of w as we move (x, y) in an arbitrary direction. Take a unit vector u = �a, b�, and look at straight line trajectory �(s) with velocity u, given by ˆ r ˆ x(s) = x0 + as, y(s) = y0 + bs. (unit speed, so s is arclength!) dw Notation: . ds |u ˆ Geometrically: slice of graph by a vertical plane (not parallel to x or y axes anymore). Directional derivative is the slope. Shown on applet (Functions of two variables), with w = x2 + y 2 + 1, and rotating slices through a point of the graph. dw d� r Know how to calculate dw/ds by chain rule: = �w · = �w · u. ˆ ds |u ds ˆ Geometric interpretation: dw/ds = �w · u = |�w| cos θ. Maximal for cos θ = 1, when u is in ˆ ˆ direction of �w. Hence: direction of �w is that of fastest increase of w, and |�w| is the directional derivative in that direction. We have dw/ds = 0 when u ⊥ �w, i.e. when u is tangent to direction ˆ ˆ of level surface.\nFri, Oct 5, 2007 (estimated – written before lecture)\nPractice exams 2A and 2B are on course web page. Lagrange multipliers. Problem: min/max when variables are constrained by an equation g(x, y, z) = c. � Example: ﬁnd point of xy = 3 closest to origin ? I.e. minimize x2 + y 2 , or better f (x, y) = x2 + y 2 , subject to g(x, y) = xy = 3. Illustrated using Lagrange multipliers applet. Observe on picture: at the minimum, the level curves are tangent to each other, so the normal vectors �f and �g are parallel. So: there exists λ (“multiplier”) such that �f = λ�g. We replace the constrained min/max problem in 2 variables with equations involving 3 variables x, y, λ: ⎧ ⎧ ⎪fx = λgx ⎪2x = λy\n ⎨ ⎨ i.e. here f = λgy 2y = λx\n ⎪ y ⎪ ⎩\n g = c\n xy = 3.;;� 2x − λy = 0 In general solving may be hard and require a computer. Here, linear algebra: −λx + 2y = 0 2 = 0. So λ = ±2. No solutions requires either x = y = 0 (impossible, since xy = 3), or det = 4 − λ √ √ √ √ for λ = −2, while λ = 2 gives ( 3, 3) and (− 3, − 3). (Checked on applet that �f = 2�g at minimum). Why the method works: at constrained min/max, moving in any direction along the constraint df ˆ surface g = c should give df /ds = 0. So, for any u tangent to {g = c}, ds |u = �f · u = 0, i.e. ˆ ˆ u ⊥ �f . Therefore �f is normal to tangent plane to g = c, and so is �g, hence the gradient ˆ vectors are parallel. Warning: method doesn’t say whether we have a min or a max, and second derivative test doesn’t apply with constrained variables. Need to answer using geometric argument or by comparing values of f . Advanced example: surface-minimizing pyramid. Triangular-based pyramid with given triangle as base and given volume V , using as little surface area as possible. Note: V = 1 Abase h, so height h is ﬁxed, top vertex moves in a plane z = h. 3 We can set up problem in coordinates: base vertices P1 = (x1 , y1 , 0), P2 , P3 , and top vertex P = (x, y, h). Then areas of faces = 1 |P� 1 × P� 2 |, etc. Calculations to ﬁnd critical point of P P 2 function of (x, y) are very hard. Key idea: use variables adapted to the geometry, instead of (x, y): let a1 , a2 , a3 = lengths of sides of the base triangle; u1 , u2 , u3 = distances in the xy-plane from the projection of� to the P sides of the base triangle. Then each face is a triangle with base length ai and height u2 + h2 i (using Pythagorean theorem). � � � So we must minimize f (u1 , u2 , u3 ) = 1 a1 u2 + h2 + 1 a2 u2 + h2 + 1 a3 u2 + h2 . 1 2 3 2 2 2 Constraint? (asked using ﬂashcards; this was a bad choice, very few students responded at all.) Decomposing base into 3 smaller triangles with heights ui , we must have g(u1 , u2 , u3 ) = 1 1 1 2 a1 u1 + 2 a2 u2 + 2 a3 u3 = Abase . Lagrange multiplier method: �f = λ�g gives a1 u a1 � 1 = λ , similarly for u2 and u3 . 2 u 2 + h2 2 1 u1 u2 u3 We conclude λ = � 2 = � 2 = � 2 , hence u1 = u2 = u3 , so P lies above the 2 2 u1 + h u2 + h u 3 + h2 incenter.'
7506,'lecture','en',6379,'2007-10-05','2009-09-10','Lecture 13: Lagrange multipliers',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 11. –\nTue, Oct 2, 2007\nDiﬀerentials. Recall in single variable calculus: y =√ (x) ⇒ dy = f � (x) dx. Example: y = sin−1 (x) ⇒ x = sin y, f dx = cos y dy, so dy/dx = 1/ cos y = 1/ 1 − x2 . Total diﬀerential: f = f (x, y, z) ⇒ df = fx dx + fy dy + fz dz. This is a new type of object, with its own rules for manipulating it (df is not the same as Δf ! The textbook has it wrong.) It encodes how variations of f are related to variations of x, y, z. We can use it in two ways: 1. as a placeholder for approximation formulas: Δf ≈ fx Δx + fy Δy + fz Δz. 2. divide by dt to get the chain rule: if x = x(t), y = y(t), z = z(t), then f becomes a function df dx dy dz of t and = fx + fy + fz dt dt dt dt Example: w = x2 y + z, dw = 2xy dx + x2 dy + dz. If x = t, y = et , z = sin t then the chain rule gives dw/dt = (2tet ) 1 + (t2 ) et + cos t, same as what we obtain by substitution into formula for w and one-variable diﬀerentiation. Can justify the chain rule in 2 ways: 1. dx = x� (t) dt, dy = y � (t) dt, dz = z � (t) dt, so substituting we get dw = fx dx + fy dy + fz dz = fx x� (t) dt + fy y � (t) dt + fz z � (t) dt, hence dw/dt. 2. (more rigorous): Δw � fx Δx + fy Δy + fz Δz, divide both sides by Δt and take limit as Δt → 0. Applications of chain rule: Product and quotient formulas for derivatives: f = uv, u = u(t), v = v(t), then d(uv)/dt = fu u� + fv v � = vu� + uv � . Similarly with g = u/v, d(u/v)/dt = gu u� + gv v � = (1/v) u� + (−u/v 2 ) v � = (u� v − uv � )/v 2 . Chain rule with more variables: for example w = f (x, y), x = x(u, v), y = y(u, v). Then dw = fx dx + fy dy = fx (xu du + xv dv) + fy (yu du + yv dv) = (fx xu + fy yu ) du + (fx xv + fy yv ) dv. Identifying coeﬃcients of du and dv we get ∂f /∂u = fx xu + fy yu and similarly for ∂f /∂v. It\'s not legal to “simplify by ∂x”. Example: polar coordinates: x = r cos θ, y = r sin θ. Then fr = fx xr + fy yr = cos θ fx + sin θ fy , and similarly fθ . 18.02 Lecture 12. – Thu, Oct 4, 2007\nHandouts: PS4 solutions, PS5. Gradient. dw dx dy dz dw d� r Recall chain rule: = wx + wy + wz . In vector notation: = �w · . dt dt dt dt dt dt Deﬁnition: �w = �wx , wy , wz � – GRADIENT VECTOR.\n Theorem: �w is perpendicular to the level surfaces w = c.\n Example 1: w = ax + by + cz, then w = d is a plane with normal vector �w = �a, b, c�.\n Example 2: w = x2 + y 2 , then w = c are circles, �w = �2x, 2y� points radially out so ⊥ circles.\n Example 3: w = x2 − y 2 , shown on applet (Lagrange multipliers applet with g disabled).;;�w is a vector whose value depends on the point (x, y) where we evaluate w. Proof: take a curve � = �(t) contained inside level surface w = c. Then velocity � = d�/dt is in r r v r the tangent plane, and by chain rule, dw/dt = �w · d�/dt = 0, so � ⊥ �w. This is true for every � r v v in the tangent plane. Application: tangent plane to a surface. Example: tangent plane to x2 + y 2 − z 2 = 4 at (2, 1, 1): gradient is �2x, 2y, −2z� = �4, 2, −2�; tangent plane is 4x + 2y − 2z = 8. (Here we could also solve � for z = x2 + y 2 − 4 and use linear approximation formula, but in general we can’t.) (Another way to get the tangent plane: dw = 2x dx + 2y dy − 2z dz = 4dx + 2dy − 2dz. So Δw ≈ 4Δx + 2Δy − 2Δz. The level surface is Δw = 0, its tangent plane approximation is 4Δx + 2Δy − 2Δz = 0, i.e. 4(x − 2) + 2(y − 1) − 2(z − 1) = 0, same as above). Directional derivative. Rate of change of w as we move (x, y) in an arbitrary direction. Take a unit vector u = �a, b�, and look at straight line trajectory �(s) with velocity u, given by ˆ r ˆ x(s) = x0 + as, y(s) = y0 + bs. (unit speed, so s is arclength!) dw Notation: . ds |u ˆ Geometrically: slice of graph by a vertical plane (not parallel to x or y axes anymore). Directional derivative is the slope. Shown on applet (Functions of two variables), with w = x2 + y 2 + 1, and rotating slices through a point of the graph. dw d� r Know how to calculate dw/ds by chain rule: = �w · = �w · u. ˆ ds |u ds ˆ Geometric interpretation: dw/ds = �w · u = |�w| cos θ. Maximal for cos θ = 1, when u is in ˆ ˆ direction of �w. Hence: direction of �w is that of fastest increase of w, and |�w| is the directional derivative in that direction. We have dw/ds = 0 when u ⊥ �w, i.e. when u is tangent to direction ˆ ˆ of level surface.\nFri, Oct 5, 2007 (estimated – written before lecture)\nPractice exams 2A and 2B are on course web page. Lagrange multipliers. Problem: min/max when variables are constrained by an equation g(x, y, z) = c. � Example: ﬁnd point of xy = 3 closest to origin ? I.e. minimize x2 + y 2 , or better f (x, y) = x2 + y 2 , subject to g(x, y) = xy = 3. Illustrated using Lagrange multipliers applet. Observe on picture: at the minimum, the level curves are tangent to each other, so the normal vectors �f and �g are parallel. So: there exists λ (“multiplier”) such that �f = λ�g. We replace the constrained min/max problem in 2 variables with equations involving 3 variables x, y, λ: ⎧ ⎧ ⎪fx = λgx ⎪2x = λy\n ⎨ ⎨ i.e. here f = λgy 2y = λx\n ⎪ y ⎪ ⎩\n g = c\n xy = 3.;;� 2x − λy = 0 In general solving may be hard and require a computer. Here, linear algebra: −λx + 2y = 0 2 = 0. So λ = ±2. No solutions requires either x = y = 0 (impossible, since xy = 3), or det = 4 − λ √ √ √ √ for λ = −2, while λ = 2 gives ( 3, 3) and (− 3, − 3). (Checked on applet that �f = 2�g at minimum). Why the method works: at constrained min/max, moving in any direction along the constraint df ˆ surface g = c should give df /ds = 0. So, for any u tangent to {g = c}, ds |u = �f · u = 0, i.e. ˆ ˆ u ⊥ �f . Therefore �f is normal to tangent plane to g = c, and so is �g, hence the gradient ˆ vectors are parallel. Warning: method doesn’t say whether we have a min or a max, and second derivative test doesn’t apply with constrained variables. Need to answer using geometric argument or by comparing values of f . Advanced example: surface-minimizing pyramid. Triangular-based pyramid with given triangle as base and given volume V , using as little surface area as possible. Note: V = 1 Abase h, so height h is ﬁxed, top vertex moves in a plane z = h. 3 We can set up problem in coordinates: base vertices P1 = (x1 , y1 , 0), P2 , P3 , and top vertex P = (x, y, h). Then areas of faces = 1 |P� 1 × P� 2 |, etc. Calculations to ﬁnd critical point of P P 2 function of (x, y) are very hard. Key idea: use variables adapted to the geometry, instead of (x, y): let a1 , a2 , a3 = lengths of sides of the base triangle; u1 , u2 , u3 = distances in the xy-plane from the projection of� to the P sides of the base triangle. Then each face is a triangle with base length ai and height u2 + h2 i (using Pythagorean theorem). � � � So we must minimize f (u1 , u2 , u3 ) = 1 a1 u2 + h2 + 1 a2 u2 + h2 + 1 a3 u2 + h2 . 1 2 3 2 2 2 Constraint? (asked using ﬂashcards; this was a bad choice, very few students responded at all.) Decomposing base into 3 smaller triangles with heights ui , we must have g(u1 , u2 , u3 ) = 1 1 1 2 a1 u1 + 2 a2 u2 + 2 a3 u3 = Abase . Lagrange multiplier method: �f = λ�g gives a1 u a1 � 1 = λ , similarly for u2 and u3 . 2 u 2 + h2 2 1 u1 u2 u3 We conclude λ = � 2 = � 2 = � 2 , hence u1 = u2 = u3 , so P lies above the 2 2 u1 + h u2 + h u 3 + h2 incenter.'
7507,'lecture','en',6379,'2007-10-11','2009-09-10','Lecture 14: Non-independent variables',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 14.\nThu, Oct 11, 2007\nHandouts: PS5 solutions, PS6, practice exams 2A and 2B. Non-independent variables. Often we have to deal with non-independent variables, e.g. f (P, V, T ) where P V = nRT . Question: if g(x, y, z) = c then can think of z = z(x, y). What are ∂z/∂x, ∂z/∂y? 2 2 Example:\n x\n + yz + z 3 =\n 8 at (2, 3, 1). Take diﬀerential: 2x dx + z dy + (y + 3z\n ) dz =\n 0, i.e.\n 4 1 4 dx + dy + 6 dz = 0 (constraint g = c), or dz\n6 dx −\n 6 dy.\n So ∂z/∂x = −4/6 = −2/3 and\n ∂z/∂y =\n −1/6 (taking the coeﬃcients of dx and dy). Or equivalently: if y is held constant then we substitute dy = 0 to get dz = −4/6 dx, so ∂z/∂x = −4/6 = −2/3. In general: g(x, y, z) = c ⇒ gx dx + gy dy + gz dz = 0. If y held ﬁxed, get gx dx + gz dz = 0, i.e. dz = −gx /gz dx, and ∂z/∂x = −gx /gz . Warning: notation can be dangerous! For example:\n f (x, y) = x + y, ∂f /∂x = 1. Change of variables x = u, y = u + v then f = 2u + v, ∂f /∂u = 2.\n x = u but ∂f /∂x �= ∂f /∂u !!\n This is because ∂f /∂x means change x keeping y ﬁxed, while ∂f /∂u means change u keeping v\n ﬁxed, i.e. change x keeping y − x ﬁxed. � � ∂f When there’s ambiguity, we must precise what is held ﬁxed: = deriv. / x with y held ∂x y � � ∂f ﬁxed, = deriv. / u with v held ﬁxed. ∂u v � � � � � � ∂f ∂f ∂f � We now have = = . ∂u v ∂x v ∂x y In above example, we computed (∂z/∂x)y . When there is no risk of confusion we keep the old notation, by default ∂/∂x means we keep y ﬁxed. Example: area of a triangle with 2 sides a and b making an angle θ is A =\n 1 ab sin θ. Suppose\n 2 it’s a right triangle with b the hypothenuse, then constraint a = b cos θ. 3 ways in which rate of change of A w.r.t. θ makes sense: ∂A 1) view A = A(a, b, θ) independent variables, usual = Aθ (with a and b held ﬁxed). This ∂θ answers the question: a and b ﬁxed, θ changes, triangle stops being a right triangle, what happens to A? 2) constraint a = b cos θ, keep a ﬁxed, change θ, while b does what it must to satisfy the � � ∂A constraint: . ∂θ a 3) constraint a = b cos θ, keep b ﬁxed, change θ, while a does what it must to satisfy the � � ∂A constraint: . ∂θ b How to compute e.g. (∂A/∂θ)a ? [treat A as function of a and θ, while b = b(a, θ).]\n2 2 0) Substitution: a = b cos θ so b = a sec θ, A =\n 1 ab sin θ =\n 1 a\n tan θ, ( ∂A )a =\n 1 a\n sec2 θ. (Easiest\n 2 2 ∂θ 2 here, but it’s not always possible to solve for b)\n 1 2 a sin θ db,\n1) Total diﬀerentials: da = 0 (a ﬁxed), dA = Aθ dθ + Aa da + Ab db = 1 ab cos θ dθ +\n 1 b sin θ da +\n 2 2 and constraint ⇒ da = cos θ db − b sin θ dθ. Plugging in da = 0, we get db = b tan θ dθ;;and then 1 1 dA = ( ab cos θ + a sin θ b tan θ)dθ, 2 2 � ∂A ∂θ �\n1 1 1 = ab cos θ + a sin θ b tan θ = ab sec θ. 2 2 2\n2) Chain rule: (∂A/∂θ)a = Aθ (∂θ/∂θ)a + Aa (∂a/∂θ)a + Ab (∂b/∂θ)b = Aθ + Ab (∂b/∂θ)a . We ﬁnd (∂b/∂θ)a by using the constraint equation. [Ran out of time here]. Implicit diﬀerentiation of constraint a = b cos θ: we have 0 = (∂a/∂θ)a = (∂b/∂θ)a cos θ − b sin θ, so (∂b/∂θ)a = b tan θ, and hence � � ∂A 1 1 1 = ab cos θ + a sin θ b tan θ = ab sec θ. ∂θ a 2 2 2 The two systematic methods essentially involve calculating the same quantities, even though things are written diﬀerently.\n18.02 Lecture 15. – Fri, Oct 12, 2007 Review topics. – Functions of several variables, contour plots. – Partial derivatives, gradient; approximation formulas, tangent planes, directional derivatives. Note: partial diﬀerential equations (= equations involving partial derivatives of an unknown function) are very important in physics. E.g., heat equation: ∂f /∂t = k(∂ 2 f /∂x2 + ∂ 2 f /∂y 2 + ∂ 2 f /∂z 2 ) describes evolution of temperature over time. – Min/max problems: critical points, 2nd derivative test, checking boundary. (least squares won’t be on the exam) – Diﬀerentials, chain rule, change of variables. – Non-independent variables: Lagrange multipliers, and constrained partial derivatives. Re-explanation of how to compute constrained partials: say f = f (x, y, z) where g(x, y, z) = c. To ﬁnd (∂f /∂z)y : 1) using diﬀerentials: df = fx dx + fy dy + fz dz. We set dy = 0 since y held constant, and want to eliminate dx. For this we use the constraint: dg = gx dx + gy dy + gz dz = 0, so setting dy = 0 we get dx = −gz /gx dz. Plug into df : df = −fx gz /gx dz + gz dz, so (∂f /∂z)y = −fx gz /gx + gz . � � � � � � � � � � ∂f ∂f ∂x ∂f ∂y ∂f ∂z ∂x 2) using chain rule: = + + = fx + fz , while ∂z y ∂x ∂z y ∂y ∂z y ∂z ∂z y ∂z y � � � � � � � � � � ∂g ∂x ∂g ∂y ∂g ∂z ∂x ∂g 0= = + + = gx + gz ∂z y ∂x ∂z y ∂y ∂z y ∂z ∂z y ∂z y which gives (∂x/∂z)y and hence the answer.'
7508,'lecture','en',6379,'2007-10-12','2009-09-10','Lecture 15: Partial differential equations; review',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 14.\nThu, Oct 11, 2007\nHandouts: PS5 solutions, PS6, practice exams 2A and 2B. Non-independent variables. Often we have to deal with non-independent variables, e.g. f (P, V, T ) where P V = nRT . Question: if g(x, y, z) = c then can think of z = z(x, y). What are ∂z/∂x, ∂z/∂y? 2 2 Example:\n x\n + yz + z 3 =\n 8 at (2, 3, 1). Take diﬀerential: 2x dx + z dy + (y + 3z\n ) dz =\n 0, i.e.\n 4 1 4 dx + dy + 6 dz = 0 (constraint g = c), or dz\n6 dx −\n 6 dy.\n So ∂z/∂x = −4/6 = −2/3 and\n ∂z/∂y =\n −1/6 (taking the coeﬃcients of dx and dy). Or equivalently: if y is held constant then we substitute dy = 0 to get dz = −4/6 dx, so ∂z/∂x = −4/6 = −2/3. In general: g(x, y, z) = c ⇒ gx dx + gy dy + gz dz = 0. If y held ﬁxed, get gx dx + gz dz = 0, i.e. dz = −gx /gz dx, and ∂z/∂x = −gx /gz . Warning: notation can be dangerous! For example:\n f (x, y) = x + y, ∂f /∂x = 1. Change of variables x = u, y = u + v then f = 2u + v, ∂f /∂u = 2.\n x = u but ∂f /∂x �= ∂f /∂u !!\n This is because ∂f /∂x means change x keeping y ﬁxed, while ∂f /∂u means change u keeping v\n ﬁxed, i.e. change x keeping y − x ﬁxed. � � ∂f When there’s ambiguity, we must precise what is held ﬁxed: = deriv. / x with y held ∂x y � � ∂f ﬁxed, = deriv. / u with v held ﬁxed. ∂u v � � � � � � ∂f ∂f ∂f � We now have = = . ∂u v ∂x v ∂x y In above example, we computed (∂z/∂x)y . When there is no risk of confusion we keep the old notation, by default ∂/∂x means we keep y ﬁxed. Example: area of a triangle with 2 sides a and b making an angle θ is A =\n 1 ab sin θ. Suppose\n 2 it’s a right triangle with b the hypothenuse, then constraint a = b cos θ. 3 ways in which rate of change of A w.r.t. θ makes sense: ∂A 1) view A = A(a, b, θ) independent variables, usual = Aθ (with a and b held ﬁxed). This ∂θ answers the question: a and b ﬁxed, θ changes, triangle stops being a right triangle, what happens to A? 2) constraint a = b cos θ, keep a ﬁxed, change θ, while b does what it must to satisfy the � � ∂A constraint: . ∂θ a 3) constraint a = b cos θ, keep b ﬁxed, change θ, while a does what it must to satisfy the � � ∂A constraint: . ∂θ b How to compute e.g. (∂A/∂θ)a ? [treat A as function of a and θ, while b = b(a, θ).]\n2 2 0) Substitution: a = b cos θ so b = a sec θ, A =\n 1 ab sin θ =\n 1 a\n tan θ, ( ∂A )a =\n 1 a\n sec2 θ. (Easiest\n 2 2 ∂θ 2 here, but it’s not always possible to solve for b)\n 1 2 a sin θ db,\n1) Total diﬀerentials: da = 0 (a ﬁxed), dA = Aθ dθ + Aa da + Ab db = 1 ab cos θ dθ +\n 1 b sin θ da +\n 2 2 and constraint ⇒ da = cos θ db − b sin θ dθ. Plugging in da = 0, we get db = b tan θ dθ;;and then 1 1 dA = ( ab cos θ + a sin θ b tan θ)dθ, 2 2 � ∂A ∂θ �\n1 1 1 = ab cos θ + a sin θ b tan θ = ab sec θ. 2 2 2\n2) Chain rule: (∂A/∂θ)a = Aθ (∂θ/∂θ)a + Aa (∂a/∂θ)a + Ab (∂b/∂θ)b = Aθ + Ab (∂b/∂θ)a . We ﬁnd (∂b/∂θ)a by using the constraint equation. [Ran out of time here]. Implicit diﬀerentiation of constraint a = b cos θ: we have 0 = (∂a/∂θ)a = (∂b/∂θ)a cos θ − b sin θ, so (∂b/∂θ)a = b tan θ, and hence � � ∂A 1 1 1 = ab cos θ + a sin θ b tan θ = ab sec θ. ∂θ a 2 2 2 The two systematic methods essentially involve calculating the same quantities, even though things are written diﬀerently.\n18.02 Lecture 15. – Fri, Oct 12, 2007 Review topics. – Functions of several variables, contour plots. – Partial derivatives, gradient; approximation formulas, tangent planes, directional derivatives. Note: partial diﬀerential equations (= equations involving partial derivatives of an unknown function) are very important in physics. E.g., heat equation: ∂f /∂t = k(∂ 2 f /∂x2 + ∂ 2 f /∂y 2 + ∂ 2 f /∂z 2 ) describes evolution of temperature over time. – Min/max problems: critical points, 2nd derivative test, checking boundary. (least squares won’t be on the exam) – Diﬀerentials, chain rule, change of variables. – Non-independent variables: Lagrange multipliers, and constrained partial derivatives. Re-explanation of how to compute constrained partials: say f = f (x, y, z) where g(x, y, z) = c. To ﬁnd (∂f /∂z)y : 1) using diﬀerentials: df = fx dx + fy dy + fz dz. We set dy = 0 since y held constant, and want to eliminate dx. For this we use the constraint: dg = gx dx + gy dy + gz dz = 0, so setting dy = 0 we get dx = −gz /gx dz. Plug into df : df = −fx gz /gx dz + gz dz, so (∂f /∂z)y = −fx gz /gx + gz . � � � � � � � � � � ∂f ∂f ∂x ∂f ∂y ∂f ∂z ∂x 2) using chain rule: = + + = fx + fz , while ∂z y ∂x ∂z y ∂y ∂z y ∂z ∂z y ∂z y � � � � � � � � � � ∂g ∂x ∂g ∂y ∂g ∂z ∂x ∂g 0= = + + = gx + gz ∂z y ∂x ∂z y ∂y ∂z y ∂z ∂z y ∂z y which gives (∂x/∂z)y and hence the answer.'
7509,'lecture','en',6379,'2007-10-18','2009-09-10','Lecture 16: Double integrals',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 16. –\nThu, Oct 18, 2007\nHandouts: PS6 solutions, PS7. Double integrals. �b Recall integral in 1-variable calculus: a f (x) dx = area below graph y = f (x) over [a, b]. �� Now: double integral R f (x, y) dA = volume below graph z = f (x, y) over plane region R. � Cut R into small pieces ΔA ⇒ the volume is approximately f (xi , yi ) ΔAi . Limit as ΔA → 0 �� gives R f (x, y) dA. (picture shown) How to compute the integral? By taking slices: S(x) = area of the slice by a plane parallel to yz-plane (picture shown): then � xmax � volume = S(x) dx, and for given x, S(x) = f (x, y) dy.\nxmin\nIn the inner integral, x is a ﬁxed parameter, y is the integration variable. We get an iterated integral. Example 1: z = 1 − x2 − y 2 , region 0 ≤ x ≤ 1, 0 ≤ y ≤ 1 (picture shown): �\n(1 − x2 − y 2 ) dy dx.\n(note: dA = dy dx, limit of ΔA = Δy Δx for small rectangles). How to evaluate: � � � 1 1 3 1\n 2 2 2 1) inner integral (x is constant): (1 − x − y ) dy = (1 − x )y − y = (1 − x2 ) − = − x2 . 3 3 3 0 0 �1 � � 1 2 2 1 2 1 1 2) outer integral: ( − x2 ) dx = x − x3 = − = . 3 3 3 3 3 3 0 0 Example 2: same function over the quarter disc R : x2 + y 2 < 1 in the ﬁrst quadrant. How to ﬁnd the bounds of integration? Fix x constant: what is a slice parallel to y-axis? bounds √ for y = from y = 0 to y = 1 − x2 in the inner integral. For the outer integral: ﬁrst slice is x = 0, last slice is x = 1. So we get: � 1 � √1−x2 (1 − x2 − y 2 ) dy dx.\n(note the inner bounds depend on the outer variable x; the outer bounds are constants!) � �√1−x2 2 2 3 Inner: (1 − x )y − y /3 0 = (1 − x2 )3/2 . 3\n 2 π Outer: (1 − x2 )3/2 dx = · · · = . 8 0 3 (. . . = trig. substitution x = sin θ, dx = cos θ dθ, (1 − x2 )3/2 = cos3 θ. Then use double angle formulas... complicated! I carried out part of the calculation to show how it would be done but then stopped before the end to save time; students may be confused about what happened exactly.) Exchanging order of integration. �2�1 �1�2 dx dy = 0 0 dy dx, since region is a rectangle (shown). In general, more complicated! 0 0;;ey\n dy dx: inner integral has no formula. To exchange order:\n y\n 0 x √ 1) draw the region (here: x < y < x for 0 ≤ x ≤ 1 – picture drawn on blackboard).\n 2) ﬁgure out bounds in other direction: ﬁxing a value of y, what are the bounds for x? here: left border is x = y 2 , right is x = y; ﬁrst slice is y = 0, last slice is y = 1, so we get � 1 y � 1 � 1� y y e e 2 dx dy = (y − y ) dy = ey − yey dy = [−yey + 2ey ]1 = e − 2. 0 0 y2 y 0 y 0 � Example 3: (the last integration can be done either by parts, or by starting from the guess −yey and adjusting;). 18.02 Lecture 17. – Fri, Oct 19, 2007\nx\nIntegration in polar coordinates. (x = r cos θ, y = r sin θ): useful if either integrand or region have a simpler expression in polar coordinates. Area element: ΔA � (rΔθ) Δr (picture drawn of a small element with sides Δr and rΔθ). Taking Δθ, Δr → 0, we get dA = r dr dθ. �� � π/2 � 1 Example (same as last time): (1 − x2 − y 2 ) dx dy = (1 − r2 ) r dr dθ. 1 1 π1 π = . Outer: dθ = = . 4 4 24 8 0 0 �� In general: when setting up f r dr dθ, ﬁnd bounds as usual: given a ﬁxed θ, ﬁnd initial and ﬁnal values of r (sweep region by rays). Inner: 1 2 1 4 r − r 2 4 Applications. �� 1) The area of the region R is R 1 dA. Also, the total mass of a planar object with density δ = lim Δm/ΔA (mass per unit area, δ = δ(x, y) – if uniform material, constant) is given by: ΔA=0 �� M= δ dA.\nR\nx2 +y 2 ≤1, x≥0, y≥0 � π/2\n�� 1 f dA. The center of mass, or centroid, Area R of a plate with density δ is given by weighted average �� �� 1 1 x= ¯ x δ dA, y= ¯ y δ dA mass R mass R ¯ 2) recall the average value of f over R is f = 3) moment of inertia: physical equivalent of mass for rotational motion. (mass = how hard it is to impart translation motion; moment of inertia about some axis = same for rotation motion around that axis) Idea: kinetic energy for a single mass m at distance r rotating at angular speed ω = dθ/dt (so velocity v = rω) is 1 mv 2 = 1 mr2 ω 2 ; I0 = mr2 is the moment of inertia. 2 2 �� For a solid with density δ, I0 = r2 δ dA (moment of inertia / origin). (the rotational energy is 1 I0 ω 2 ). 2\nR;;�� Moment of inertia about an axis: I = is |y|, so\n(distance to axis)2 δ dA. E.g. about x-axis, distance �� y 2 δ dA.\nIx =\nExamples: 1) disk of radius a around its center (δ = 1): � 4 �a � 2π � a r πa4 2 I0 = r r dr dθ = 2π = . 4 0 2 0 0 2) same disk, about a point on the circumference? Setup: place origin at point so integrand is easier; diameter along x-axis; then polar equation of circle is r = 2a cos θ (explained on a picture). Thus � I0 =\n−π/2 0 π/2\n2a cos θ\n r2 r dr dθ = ... = πa4 .'
7510,'lecture','en',6379,'2007-10-19','2009-09-10','Lecture 17: Double integrals in polar coordinates; applications',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 16. –\nThu, Oct 18, 2007\nHandouts: PS6 solutions, PS7. Double integrals. �b Recall integral in 1-variable calculus: a f (x) dx = area below graph y = f (x) over [a, b]. �� Now: double integral R f (x, y) dA = volume below graph z = f (x, y) over plane region R. � Cut R into small pieces ΔA ⇒ the volume is approximately f (xi , yi ) ΔAi . Limit as ΔA → 0 �� gives R f (x, y) dA. (picture shown) How to compute the integral? By taking slices: S(x) = area of the slice by a plane parallel to yz-plane (picture shown): then � xmax � volume = S(x) dx, and for given x, S(x) = f (x, y) dy.\nxmin\nIn the inner integral, x is a ﬁxed parameter, y is the integration variable. We get an iterated integral. Example 1: z = 1 − x2 − y 2 , region 0 ≤ x ≤ 1, 0 ≤ y ≤ 1 (picture shown): �\n(1 − x2 − y 2 ) dy dx.\n(note: dA = dy dx, limit of ΔA = Δy Δx for small rectangles). How to evaluate: � � � 1 1 3 1\n 2 2 2 1) inner integral (x is constant): (1 − x − y ) dy = (1 − x )y − y = (1 − x2 ) − = − x2 . 3 3 3 0 0 �1 � � 1 2 2 1 2 1 1 2) outer integral: ( − x2 ) dx = x − x3 = − = . 3 3 3 3 3 3 0 0 Example 2: same function over the quarter disc R : x2 + y 2 < 1 in the ﬁrst quadrant. How to ﬁnd the bounds of integration? Fix x constant: what is a slice parallel to y-axis? bounds √ for y = from y = 0 to y = 1 − x2 in the inner integral. For the outer integral: ﬁrst slice is x = 0, last slice is x = 1. So we get: � 1 � √1−x2 (1 − x2 − y 2 ) dy dx.\n(note the inner bounds depend on the outer variable x; the outer bounds are constants!) � �√1−x2 2 2 3 Inner: (1 − x )y − y /3 0 = (1 − x2 )3/2 . 3\n 2 π Outer: (1 − x2 )3/2 dx = · · · = . 8 0 3 (. . . = trig. substitution x = sin θ, dx = cos θ dθ, (1 − x2 )3/2 = cos3 θ. Then use double angle formulas... complicated! I carried out part of the calculation to show how it would be done but then stopped before the end to save time; students may be confused about what happened exactly.) Exchanging order of integration. �2�1 �1�2 dx dy = 0 0 dy dx, since region is a rectangle (shown). In general, more complicated! 0 0;;ey\n dy dx: inner integral has no formula. To exchange order:\n y\n 0 x √ 1) draw the region (here: x < y < x for 0 ≤ x ≤ 1 – picture drawn on blackboard).\n 2) ﬁgure out bounds in other direction: ﬁxing a value of y, what are the bounds for x? here: left border is x = y 2 , right is x = y; ﬁrst slice is y = 0, last slice is y = 1, so we get � 1 y � 1 � 1� y y e e 2 dx dy = (y − y ) dy = ey − yey dy = [−yey + 2ey ]1 = e − 2. 0 0 y2 y 0 y 0 � Example 3: (the last integration can be done either by parts, or by starting from the guess −yey and adjusting;). 18.02 Lecture 17. – Fri, Oct 19, 2007\nx\nIntegration in polar coordinates. (x = r cos θ, y = r sin θ): useful if either integrand or region have a simpler expression in polar coordinates. Area element: ΔA � (rΔθ) Δr (picture drawn of a small element with sides Δr and rΔθ). Taking Δθ, Δr → 0, we get dA = r dr dθ. �� � π/2 � 1 Example (same as last time): (1 − x2 − y 2 ) dx dy = (1 − r2 ) r dr dθ. 1 1 π1 π = . Outer: dθ = = . 4 4 24 8 0 0 �� In general: when setting up f r dr dθ, ﬁnd bounds as usual: given a ﬁxed θ, ﬁnd initial and ﬁnal values of r (sweep region by rays). Inner: 1 2 1 4 r − r 2 4 Applications. �� 1) The area of the region R is R 1 dA. Also, the total mass of a planar object with density δ = lim Δm/ΔA (mass per unit area, δ = δ(x, y) – if uniform material, constant) is given by: ΔA=0 �� M= δ dA.\nR\nx2 +y 2 ≤1, x≥0, y≥0 � π/2\n�� 1 f dA. The center of mass, or centroid, Area R of a plate with density δ is given by weighted average �� �� 1 1 x= ¯ x δ dA, y= ¯ y δ dA mass R mass R ¯ 2) recall the average value of f over R is f = 3) moment of inertia: physical equivalent of mass for rotational motion. (mass = how hard it is to impart translation motion; moment of inertia about some axis = same for rotation motion around that axis) Idea: kinetic energy for a single mass m at distance r rotating at angular speed ω = dθ/dt (so velocity v = rω) is 1 mv 2 = 1 mr2 ω 2 ; I0 = mr2 is the moment of inertia. 2 2 �� For a solid with density δ, I0 = r2 δ dA (moment of inertia / origin). (the rotational energy is 1 I0 ω 2 ). 2\nR;;�� Moment of inertia about an axis: I = is |y|, so\n(distance to axis)2 δ dA. E.g. about x-axis, distance �� y 2 δ dA.\nIx =\nExamples: 1) disk of radius a around its center (δ = 1): � 4 �a � 2π � a r πa4 2 I0 = r r dr dθ = 2π = . 4 0 2 0 0 2) same disk, about a point on the circumference? Setup: place origin at point so integrand is easier; diameter along x-axis; then polar equation of circle is r = 2a cos θ (explained on a picture). Thus � I0 =\n−π/2 0 π/2\n2a cos θ\n r2 r dr dθ = ... = πa4 .'
7511,'lecture','en',6379,'2007-10-23','2009-09-10','Lecture 18: Change of variables',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 18. –\nTue, Oct 23, 2007\nChange of variables. Example 1: area of ellipse with semiaxes a and b: setting u = x/a, v = y/b, �� �� �� dx dy = ab du dv = ab du dv = πab.\n(x/a)2 +(y/b)2 <1 u2 +v 2 <1 1 a u2 +v 2 <1 1 (substitution works here as in 1-variable calculus: du = dx, dv = 1 dy, so du dv = ab dx dy. b In general, must ﬁnd out the scale factor (ratio between du dv and dx dy)? Example 2: say we set u = 3x−2y, v = x+y to simplify either integrand or bounds of integration. What is the relation between dA = dx dy and dA� = du dv? (area elements in xy- and uv-planes). Answer: consider a small rectangle of area ΔA = ΔxΔy, it becomes in uv-coordinates a paral­ lelogram of area ΔA� . Here the answer is independent of which rectangle we take, so we can take e.g. the unit square in xy-coordinates. � � � � �\n u 3 −2 x = , so this becomes a parallelogram with sides given by In the uv-plane, v\n 1 1 y\n vectors �3, 1� and �−2, 1� (picture drawn), and area = det =\n � = 5ΔA, in the limit dA� = 5dA, i.e. du dv = 5dx dy. So For any rectangle ΔA . . . dx dy = �� 1 . . . 5 du dv.\nGeneral case: approximation formula Δu ≈ ux Δx + uy Δy, Δv ≈ vx Δx + vy Δy, i.e. � � � � �� Δu ux uy Δx . ≈ Δv vx vy Δy A small xy-rectangle is approx. a parallelogram in uv-coords, but scale factor depends on x and y now. By the same argument as before, the scale factor is the determinant. � � ∂(u, v) � ux uy � � � . Then du dv = |\ndx dy.\n Deﬁnition: the Jacobian is J\n J ∂(x, y)\n � vx vy � (absolute value because area is the absolute value of the determinant).\n Example 1: polar coordinates x = r cos θ, y = r sin θ: � � � � ∂(x, y) � xr xθ � � cos θ −r sin θ � 2 � � =\n� � = r cos\n θ + r sin2 θ = r. =\n ∂(r, θ)\n � yr yθ � � sin θ\n r cos θ �\n So dx dy = r dr dθ, as seen before.\n �1�1 Example 2: compute 0 0 x2 y dx dy by changing to u = x, v = xy (usually motivation is to\n simplify either integrand or region; here neither happens, but we just illustrate the general method). � � � � � ux uy � � � ∂(u, v) � � =\n x, so du dv = x dx dy, i.e.\n 1) Area element: Jacobian is\n � � y x\n � vx vy � ∂(x, y)\n 1 dx dy = x du dv.\n1 2) Express integrand in terms of u, v: x2 y dx dy = x2 y x du dv = xy du dv = v du dv. 3) Find bounds (picture drawn): if we integrate du dv, then ﬁrst we keep v = xy constant, slice looks like portion of hyperbola (picture shown), parametrized by u = x. The bounds are: at the top boundary y = 1, so v/u = 1, i.e. u = v; at the right boundary, x = 1, so u = 1. So the inner;;integral is\nv\n. The ﬁrst slice is v = 0, the last is v = 1; so we get � 1� 1 v du dv.\n0 v\nBesides the picture in xy coordinates (a square sliced by hyperbolas), I also drew a picture in uv coordinates (a triangle), which some students may ﬁnd is an easier way of getting the bounds for u and v. 18.02 Lecture 19. – Thu, Oct 25, 2007\nHandouts: PS7 solutions; PS8. Vector ﬁelds. � F = Mˆ + Nˆ, where M = M (x, y), N = N (x, y): at each point in the plane we have a vector ı j � which depends on x, y. F Examples: velocity ﬁelds, e.g. wind ﬂow (shown: chart of winds over Paciﬁc ocean); force ﬁelds, e.g. gravitational ﬁeld. � � � Examples drawn on blackboard: (1) F = 2ˆ + ˆ (constant vector ﬁeld); (2) F = xˆ; (3) F = ı j ı � = −yˆ + xˆ (explained using that �−y, x� is �x, y� rotated 90◦ ı j xˆ + yˆ (radially outwards); (4) F ı j counterclockwise). Work and line integrals. � r W = (force).(distance) = F · Δ� for a small motion Δ�. Total work is obtained by summing these r along a trajectory C: get a “line integral” � � � � � r � W = F · d� = lim F · Δ�i . r\nC Δ�→0 r i\nTo evaluate the line integral, we observe C is parametrized by time, and give meaning to the � � r notation C F · d� by � � t2 � r� � r � d� dt. F · d� = F· dt C t1 � Example: F = −yˆ + xˆ, C is given by x = t, y = t2 , 0 ≤ t ≤ 1 (portion of parabola y = x2 from ı j (0,0) to (1,1)). Then we substitute expressions in terms of t everywhere: d� r dx dy � F = �−y, x� = �−t2 , t�, = � , � = �1, 2t�, dt dt dt � � 1 � 1 � 1 r 1 � r � d� dt = so F · d� = F· �−t2 , t� · �1, 2t� dt = t2 dt = . (in the end things always reduce dt 3 C 0 0 0 to a one-variable integral.) In fact, the deﬁnition of the line integral does not involve the parametrization: so the result is the same no matter which parametrization we choose. For example we could choose to parametrize � � π/2 � r the parabola by x = sin θ, y = sin2 θ, 0 ≤ θ ≤ π/2. Then we’d get C F · d� = 0 . . . dθ, which would be equivalent to the previous one under the substitution t = sin θ and would again be equal 1 to 3 . In practice we always choose the simplest parametrization! � New notation for line integral: F = �M, N �, and d� = �dx, dy� (this is in fact a diﬀerential: if we r divide both sides by dt we get the component formula for the velocity d�/dt). So the line integral r;;becomes\nC\n� r F · d� =\n� M dx + N dy.\nC\nThe notation is dangerous: this is not a sum of integrals w.r.t. x and y, but really a line integral along C. To evaluate one must express everything in terms of the chosen parameter. In the above example, we have x = t, y = t2 , so dx = dt, dy = 2t dt by implicit diﬀerentiation; then � � 1 � 1 1 2 −y dx + x dy = −t dt + t (2t) dt = t2 dt = 3 C 0 0 (same calculation as before, using diﬀerent notation). Geometric approach. d� r ds ˆ ˆ Recall velocity is = T (where s = arclength, T = unit tangent vector to trajectory). dt dt � � ˆ � r � ˆ So d� = T ds, and r F · d� = F · T ds. Sometimes the calculation is easier this way!\nC C\n� ˆ � Example: C = circle of radius a centered at origin, F = xˆ + yˆ, then F · T = 0 (picture drawn), ı j � � ˆ � · T ds = 0 ds = 0. so C F � � � � ˆ � � ˆ ı j Example: same C, F = −yˆ + xˆ, then F · T = |F | = a, so C F · T ds = a ds = a (2πa) = 2πa2 ; checked that we get the same answer if we compute using parametrization x = a cos θ, y = a sin θ. 18.02 Lecture 20. – Fri, Oct 26, 2007\nLine integrals continued. � � � � = Mˆ + Nˆ along a curve C: � · d� = � ˆ Recall: line integral of F ı j F r M dx + N dy = F · T ds. C C C � � � r Example: F = yˆ + xˆ, C F · d� for C = C1 + C2 + C3 enclosing sector of unit disk from 0 to ı j � π/4. (picture shown). Need to compute Ci y dx + x dy for each portion: � �1 1) x-axis: x = t, y = 0, dx = dt, dy = 0, 0 ≤ t ≤ 1, so C1 y dx + x dy = 0 0 dt = 0. Equivalently, � ˆ ı � � ˆ geometrically: along x-axis, y = 0 so F = xˆ while T = ˆ so j F ·\nT ds = 0.\nC1\n2) C2 : x = cos θ, y = sin θ, dx = − sin θ dθ, dy = cos θ dθ, 0 ≤ θ ≤ π . So\n 4 �π/4 � � � π/4 � π/4 1 1 sin(2θ) = . y dx + x dy = sin θ(− sin θ)dθ + cos θ cos θ dθ = cos(2θ)dθ = 2 2 C2 0 0 0\n1 1 3) C3 : line segment from ( √2 , √2 ) to (0, 0): could take x = 1 √ . 2 1 √ 2\n1 √ t, 2\ny = same, 0 ≤ t ≤ 1, ...\nbut easier: C3 backwards (“−C3 ”) is y = x = t, 0 ≤ t ≤ Work along −C3 is opposite of work along C3 . � � 0 � 1/√2 √ 1 1/ 2 y dx + x dy = t dt + t dt = − 2t dt = −[t2 ]0 =− . √ 2 C3 1/ 2 0 � � If F is a gradient ﬁeld, F = �f = fxˆ + fy ˆ (f is called “potential function”), then we can ı j simplify evaluation of line integrals by using the fundamental theorem of calculus. Fundamental theorem of calculus for line integrals:;;� �f · d� = f (P1 ) − f (P0 ) when C runs from P0 to P1 . r � � Equivalently with diﬀerentials: fx dx + fy dy = df = f (P1 ) − f (P0 ). Proof: C C � � t1 � t1 dx dy d �f · d� = r (fx + fy ) dt = (f (x(t), y(t)) dt = [f (x(t), y(t))]t1 = f (P1 ) − f (P0 ). t0 dt dt dt C t0 t0 � � E.g., in the above example, if we set f (x, y) = xy then �f = �y, x� = F . So can be calculated\njust by evaluating f = xy at end points. Picture shown of C, vector ﬁeld, and level curves. Consequences: for a gradient ﬁeld, we have: � � • Path independence: if C1 , C2 have same endpoints then C1 �f · d� = C2 �f · d� (both equal r r � to f (P1 ) − f (P0 ) by the theorem). So the line integral C �f · d� depends only on the end points, r not on the actual trajectory. � • Conservativeness: if C is a closed loop then C �f · d� = 0 (= f (P ) − f (P )). r � 1 1 (e.g. in above example, C = 0 + 2 − 2 = 0.) WARNING: this is only for gradient ﬁelds! � Example: F = −yˆ + xˆ is not a gradient ﬁeld: as seen Thursday, along C = circle of radius a ı j � 2 ˆ � //T ), � r � counterclockwise (F C F · d� = 2πa . Hence F is not conservative, and not a gradient ﬁeld. Physical interpretation. � � If the force ﬁeld F is the gradient of a potential f , then work of F = change in value of potential. � � E.g.: 1) F = gravitational ﬁeld, f = gravitational potential; 2) F = electrical ﬁeld; f = electrical � potential (voltage). (Actually physicists use the opposite sign convention, F = −�f ). Conservativeness means that energy comes from change in potential f , so no energy can be extracted from motion along a closed trajectory (conservativeness = conservation of energy: the change in kinetic energy equals the work of the force equals the change in potential energy). We have four equivalent properties: � � � r (1) F is conservative ( C F · d� = 0 for any closed curve C) � (2) F · d� is path independent (same work if same end points) r � � (3) F is a gradient ﬁeld: F = �f = fxˆ + fy ˆ. ı j (4) M dx + N dy is an exact diﬀerential (= fx dx + fy dy = df .) ((1) is equivalent to (2) by considering C1 , C2 with same endpoints, C = C1 − C2 is a closed loop. (3) ⇒ (2) is the FTC, ⇐ will be key to ﬁnding potential function: if we have path independence � (x,y) � then we can get f (x, y) by computing (0,0) F · d�. (3) and (4) are reformulations of the same r property).\nCi'
7512,'lecture','en',6379,'2007-10-25','2009-09-10','Lecture 19: Vector fields and line integrals in the plane',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 18. –\nTue, Oct 23, 2007\nChange of variables. Example 1: area of ellipse with semiaxes a and b: setting u = x/a, v = y/b, �� �� �� dx dy = ab du dv = ab du dv = πab.\n(x/a)2 +(y/b)2 <1 u2 +v 2 <1 1 a u2 +v 2 <1 1 (substitution works here as in 1-variable calculus: du = dx, dv = 1 dy, so du dv = ab dx dy. b In general, must ﬁnd out the scale factor (ratio between du dv and dx dy)? Example 2: say we set u = 3x−2y, v = x+y to simplify either integrand or bounds of integration. What is the relation between dA = dx dy and dA� = du dv? (area elements in xy- and uv-planes). Answer: consider a small rectangle of area ΔA = ΔxΔy, it becomes in uv-coordinates a paral­ lelogram of area ΔA� . Here the answer is independent of which rectangle we take, so we can take e.g. the unit square in xy-coordinates. � � � � �\n u 3 −2 x = , so this becomes a parallelogram with sides given by In the uv-plane, v\n 1 1 y\n vectors �3, 1� and �−2, 1� (picture drawn), and area = det =\n � = 5ΔA, in the limit dA� = 5dA, i.e. du dv = 5dx dy. So For any rectangle ΔA . . . dx dy = �� 1 . . . 5 du dv.\nGeneral case: approximation formula Δu ≈ ux Δx + uy Δy, Δv ≈ vx Δx + vy Δy, i.e. � � � � �� Δu ux uy Δx . ≈ Δv vx vy Δy A small xy-rectangle is approx. a parallelogram in uv-coords, but scale factor depends on x and y now. By the same argument as before, the scale factor is the determinant. � � ∂(u, v) � ux uy � � � . Then du dv = |\ndx dy.\n Deﬁnition: the Jacobian is J\n J ∂(x, y)\n � vx vy � (absolute value because area is the absolute value of the determinant).\n Example 1: polar coordinates x = r cos θ, y = r sin θ: � � � � ∂(x, y) � xr xθ � � cos θ −r sin θ � 2 � � =\n� � = r cos\n θ + r sin2 θ = r. =\n ∂(r, θ)\n � yr yθ � � sin θ\n r cos θ �\n So dx dy = r dr dθ, as seen before.\n �1�1 Example 2: compute 0 0 x2 y dx dy by changing to u = x, v = xy (usually motivation is to\n simplify either integrand or region; here neither happens, but we just illustrate the general method). � � � � � ux uy � � � ∂(u, v) � � =\n x, so du dv = x dx dy, i.e.\n 1) Area element: Jacobian is\n � � y x\n � vx vy � ∂(x, y)\n 1 dx dy = x du dv.\n1 2) Express integrand in terms of u, v: x2 y dx dy = x2 y x du dv = xy du dv = v du dv. 3) Find bounds (picture drawn): if we integrate du dv, then ﬁrst we keep v = xy constant, slice looks like portion of hyperbola (picture shown), parametrized by u = x. The bounds are: at the top boundary y = 1, so v/u = 1, i.e. u = v; at the right boundary, x = 1, so u = 1. So the inner;;integral is\nv\n. The ﬁrst slice is v = 0, the last is v = 1; so we get � 1� 1 v du dv.\n0 v\nBesides the picture in xy coordinates (a square sliced by hyperbolas), I also drew a picture in uv coordinates (a triangle), which some students may ﬁnd is an easier way of getting the bounds for u and v. 18.02 Lecture 19. – Thu, Oct 25, 2007\nHandouts: PS7 solutions; PS8. Vector ﬁelds. � F = Mˆ + Nˆ, where M = M (x, y), N = N (x, y): at each point in the plane we have a vector ı j � which depends on x, y. F Examples: velocity ﬁelds, e.g. wind ﬂow (shown: chart of winds over Paciﬁc ocean); force ﬁelds, e.g. gravitational ﬁeld. � � � Examples drawn on blackboard: (1) F = 2ˆ + ˆ (constant vector ﬁeld); (2) F = xˆ; (3) F = ı j ı � = −yˆ + xˆ (explained using that �−y, x� is �x, y� rotated 90◦ ı j xˆ + yˆ (radially outwards); (4) F ı j counterclockwise). Work and line integrals. � r W = (force).(distance) = F · Δ� for a small motion Δ�. Total work is obtained by summing these r along a trajectory C: get a “line integral” � � � � � r � W = F · d� = lim F · Δ�i . r\nC Δ�→0 r i\nTo evaluate the line integral, we observe C is parametrized by time, and give meaning to the � � r notation C F · d� by � � t2 � r� � r � d� dt. F · d� = F· dt C t1 � Example: F = −yˆ + xˆ, C is given by x = t, y = t2 , 0 ≤ t ≤ 1 (portion of parabola y = x2 from ı j (0,0) to (1,1)). Then we substitute expressions in terms of t everywhere: d� r dx dy � F = �−y, x� = �−t2 , t�, = � , � = �1, 2t�, dt dt dt � � 1 � 1 � 1 r 1 � r � d� dt = so F · d� = F· �−t2 , t� · �1, 2t� dt = t2 dt = . (in the end things always reduce dt 3 C 0 0 0 to a one-variable integral.) In fact, the deﬁnition of the line integral does not involve the parametrization: so the result is the same no matter which parametrization we choose. For example we could choose to parametrize � � π/2 � r the parabola by x = sin θ, y = sin2 θ, 0 ≤ θ ≤ π/2. Then we’d get C F · d� = 0 . . . dθ, which would be equivalent to the previous one under the substitution t = sin θ and would again be equal 1 to 3 . In practice we always choose the simplest parametrization! � New notation for line integral: F = �M, N �, and d� = �dx, dy� (this is in fact a diﬀerential: if we r divide both sides by dt we get the component formula for the velocity d�/dt). So the line integral r;;becomes\nC\n� r F · d� =\n� M dx + N dy.\nC\nThe notation is dangerous: this is not a sum of integrals w.r.t. x and y, but really a line integral along C. To evaluate one must express everything in terms of the chosen parameter. In the above example, we have x = t, y = t2 , so dx = dt, dy = 2t dt by implicit diﬀerentiation; then � � 1 � 1 1 2 −y dx + x dy = −t dt + t (2t) dt = t2 dt = 3 C 0 0 (same calculation as before, using diﬀerent notation). Geometric approach. d� r ds ˆ ˆ Recall velocity is = T (where s = arclength, T = unit tangent vector to trajectory). dt dt � � ˆ � r � ˆ So d� = T ds, and r F · d� = F · T ds. Sometimes the calculation is easier this way!\nC C\n� ˆ � Example: C = circle of radius a centered at origin, F = xˆ + yˆ, then F · T = 0 (picture drawn), ı j � � ˆ � · T ds = 0 ds = 0. so C F � � � � ˆ � � ˆ ı j Example: same C, F = −yˆ + xˆ, then F · T = |F | = a, so C F · T ds = a ds = a (2πa) = 2πa2 ; checked that we get the same answer if we compute using parametrization x = a cos θ, y = a sin θ. 18.02 Lecture 20. – Fri, Oct 26, 2007\nLine integrals continued. � � � � = Mˆ + Nˆ along a curve C: � · d� = � ˆ Recall: line integral of F ı j F r M dx + N dy = F · T ds. C C C � � � r Example: F = yˆ + xˆ, C F · d� for C = C1 + C2 + C3 enclosing sector of unit disk from 0 to ı j � π/4. (picture shown). Need to compute Ci y dx + x dy for each portion: � �1 1) x-axis: x = t, y = 0, dx = dt, dy = 0, 0 ≤ t ≤ 1, so C1 y dx + x dy = 0 0 dt = 0. Equivalently, � ˆ ı � � ˆ geometrically: along x-axis, y = 0 so F = xˆ while T = ˆ so j F ·\nT ds = 0.\nC1\n2) C2 : x = cos θ, y = sin θ, dx = − sin θ dθ, dy = cos θ dθ, 0 ≤ θ ≤ π . So\n 4 �π/4 � � � π/4 � π/4 1 1 sin(2θ) = . y dx + x dy = sin θ(− sin θ)dθ + cos θ cos θ dθ = cos(2θ)dθ = 2 2 C2 0 0 0\n1 1 3) C3 : line segment from ( √2 , √2 ) to (0, 0): could take x = 1 √ . 2 1 √ 2\n1 √ t, 2\ny = same, 0 ≤ t ≤ 1, ...\nbut easier: C3 backwards (“−C3 ”) is y = x = t, 0 ≤ t ≤ Work along −C3 is opposite of work along C3 . � � 0 � 1/√2 √ 1 1/ 2 y dx + x dy = t dt + t dt = − 2t dt = −[t2 ]0 =− . √ 2 C3 1/ 2 0 � � If F is a gradient ﬁeld, F = �f = fxˆ + fy ˆ (f is called “potential function”), then we can ı j simplify evaluation of line integrals by using the fundamental theorem of calculus. Fundamental theorem of calculus for line integrals:;;� �f · d� = f (P1 ) − f (P0 ) when C runs from P0 to P1 . r � � Equivalently with diﬀerentials: fx dx + fy dy = df = f (P1 ) − f (P0 ). Proof: C C � � t1 � t1 dx dy d �f · d� = r (fx + fy ) dt = (f (x(t), y(t)) dt = [f (x(t), y(t))]t1 = f (P1 ) − f (P0 ). t0 dt dt dt C t0 t0 � � E.g., in the above example, if we set f (x, y) = xy then �f = �y, x� = F . So can be calculated\njust by evaluating f = xy at end points. Picture shown of C, vector ﬁeld, and level curves. Consequences: for a gradient ﬁeld, we have: � � • Path independence: if C1 , C2 have same endpoints then C1 �f · d� = C2 �f · d� (both equal r r � to f (P1 ) − f (P0 ) by the theorem). So the line integral C �f · d� depends only on the end points, r not on the actual trajectory. � • Conservativeness: if C is a closed loop then C �f · d� = 0 (= f (P ) − f (P )). r � 1 1 (e.g. in above example, C = 0 + 2 − 2 = 0.) WARNING: this is only for gradient ﬁelds! � Example: F = −yˆ + xˆ is not a gradient ﬁeld: as seen Thursday, along C = circle of radius a ı j � 2 ˆ � //T ), � r � counterclockwise (F C F · d� = 2πa . Hence F is not conservative, and not a gradient ﬁeld. Physical interpretation. � � If the force ﬁeld F is the gradient of a potential f , then work of F = change in value of potential. � � E.g.: 1) F = gravitational ﬁeld, f = gravitational potential; 2) F = electrical ﬁeld; f = electrical � potential (voltage). (Actually physicists use the opposite sign convention, F = −�f ). Conservativeness means that energy comes from change in potential f , so no energy can be extracted from motion along a closed trajectory (conservativeness = conservation of energy: the change in kinetic energy equals the work of the force equals the change in potential energy). We have four equivalent properties: � � � r (1) F is conservative ( C F · d� = 0 for any closed curve C) � (2) F · d� is path independent (same work if same end points) r � � (3) F is a gradient ﬁeld: F = �f = fxˆ + fy ˆ. ı j (4) M dx + N dy is an exact diﬀerential (= fx dx + fy dy = df .) ((1) is equivalent to (2) by considering C1 , C2 with same endpoints, C = C1 − C2 is a closed loop. (3) ⇒ (2) is the FTC, ⇐ will be key to ﬁnding potential function: if we have path independence � (x,y) � then we can get f (x, y) by computing (0,0) F · d�. (3) and (4) are reformulations of the same r property).\nCi'
7513,'lecture','en',6379,'2007-10-26','2009-09-10','Lecture 20: Path independence and conservative fields',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 18. –\nTue, Oct 23, 2007\nChange of variables. Example 1: area of ellipse with semiaxes a and b: setting u = x/a, v = y/b, �� �� �� dx dy = ab du dv = ab du dv = πab.\n(x/a)2 +(y/b)2 <1 u2 +v 2 <1 1 a u2 +v 2 <1 1 (substitution works here as in 1-variable calculus: du = dx, dv = 1 dy, so du dv = ab dx dy. b In general, must ﬁnd out the scale factor (ratio between du dv and dx dy)? Example 2: say we set u = 3x−2y, v = x+y to simplify either integrand or bounds of integration. What is the relation between dA = dx dy and dA� = du dv? (area elements in xy- and uv-planes). Answer: consider a small rectangle of area ΔA = ΔxΔy, it becomes in uv-coordinates a paral­ lelogram of area ΔA� . Here the answer is independent of which rectangle we take, so we can take e.g. the unit square in xy-coordinates. � � � � �\n u 3 −2 x = , so this becomes a parallelogram with sides given by In the uv-plane, v\n 1 1 y\n vectors �3, 1� and �−2, 1� (picture drawn), and area = det =\n � = 5ΔA, in the limit dA� = 5dA, i.e. du dv = 5dx dy. So For any rectangle ΔA . . . dx dy = �� 1 . . . 5 du dv.\nGeneral case: approximation formula Δu ≈ ux Δx + uy Δy, Δv ≈ vx Δx + vy Δy, i.e. � � � � �� Δu ux uy Δx . ≈ Δv vx vy Δy A small xy-rectangle is approx. a parallelogram in uv-coords, but scale factor depends on x and y now. By the same argument as before, the scale factor is the determinant. � � ∂(u, v) � ux uy � � � . Then du dv = |\ndx dy.\n Deﬁnition: the Jacobian is J\n J ∂(x, y)\n � vx vy � (absolute value because area is the absolute value of the determinant).\n Example 1: polar coordinates x = r cos θ, y = r sin θ: � � � � ∂(x, y) � xr xθ � � cos θ −r sin θ � 2 � � =\n� � = r cos\n θ + r sin2 θ = r. =\n ∂(r, θ)\n � yr yθ � � sin θ\n r cos θ �\n So dx dy = r dr dθ, as seen before.\n �1�1 Example 2: compute 0 0 x2 y dx dy by changing to u = x, v = xy (usually motivation is to\n simplify either integrand or region; here neither happens, but we just illustrate the general method). � � � � � ux uy � � � ∂(u, v) � � =\n x, so du dv = x dx dy, i.e.\n 1) Area element: Jacobian is\n � � y x\n � vx vy � ∂(x, y)\n 1 dx dy = x du dv.\n1 2) Express integrand in terms of u, v: x2 y dx dy = x2 y x du dv = xy du dv = v du dv. 3) Find bounds (picture drawn): if we integrate du dv, then ﬁrst we keep v = xy constant, slice looks like portion of hyperbola (picture shown), parametrized by u = x. The bounds are: at the top boundary y = 1, so v/u = 1, i.e. u = v; at the right boundary, x = 1, so u = 1. So the inner;;integral is\nv\n. The ﬁrst slice is v = 0, the last is v = 1; so we get � 1� 1 v du dv.\n0 v\nBesides the picture in xy coordinates (a square sliced by hyperbolas), I also drew a picture in uv coordinates (a triangle), which some students may ﬁnd is an easier way of getting the bounds for u and v. 18.02 Lecture 19. – Thu, Oct 25, 2007\nHandouts: PS7 solutions; PS8. Vector ﬁelds. � F = Mˆ + Nˆ, where M = M (x, y), N = N (x, y): at each point in the plane we have a vector ı j � which depends on x, y. F Examples: velocity ﬁelds, e.g. wind ﬂow (shown: chart of winds over Paciﬁc ocean); force ﬁelds, e.g. gravitational ﬁeld. � � � Examples drawn on blackboard: (1) F = 2ˆ + ˆ (constant vector ﬁeld); (2) F = xˆ; (3) F = ı j ı � = −yˆ + xˆ (explained using that �−y, x� is �x, y� rotated 90◦ ı j xˆ + yˆ (radially outwards); (4) F ı j counterclockwise). Work and line integrals. � r W = (force).(distance) = F · Δ� for a small motion Δ�. Total work is obtained by summing these r along a trajectory C: get a “line integral” � � � � � r � W = F · d� = lim F · Δ�i . r\nC Δ�→0 r i\nTo evaluate the line integral, we observe C is parametrized by time, and give meaning to the � � r notation C F · d� by � � t2 � r� � r � d� dt. F · d� = F· dt C t1 � Example: F = −yˆ + xˆ, C is given by x = t, y = t2 , 0 ≤ t ≤ 1 (portion of parabola y = x2 from ı j (0,0) to (1,1)). Then we substitute expressions in terms of t everywhere: d� r dx dy � F = �−y, x� = �−t2 , t�, = � , � = �1, 2t�, dt dt dt � � 1 � 1 � 1 r 1 � r � d� dt = so F · d� = F· �−t2 , t� · �1, 2t� dt = t2 dt = . (in the end things always reduce dt 3 C 0 0 0 to a one-variable integral.) In fact, the deﬁnition of the line integral does not involve the parametrization: so the result is the same no matter which parametrization we choose. For example we could choose to parametrize � � π/2 � r the parabola by x = sin θ, y = sin2 θ, 0 ≤ θ ≤ π/2. Then we’d get C F · d� = 0 . . . dθ, which would be equivalent to the previous one under the substitution t = sin θ and would again be equal 1 to 3 . In practice we always choose the simplest parametrization! � New notation for line integral: F = �M, N �, and d� = �dx, dy� (this is in fact a diﬀerential: if we r divide both sides by dt we get the component formula for the velocity d�/dt). So the line integral r;;becomes\nC\n� r F · d� =\n� M dx + N dy.\nC\nThe notation is dangerous: this is not a sum of integrals w.r.t. x and y, but really a line integral along C. To evaluate one must express everything in terms of the chosen parameter. In the above example, we have x = t, y = t2 , so dx = dt, dy = 2t dt by implicit diﬀerentiation; then � � 1 � 1 1 2 −y dx + x dy = −t dt + t (2t) dt = t2 dt = 3 C 0 0 (same calculation as before, using diﬀerent notation). Geometric approach. d� r ds ˆ ˆ Recall velocity is = T (where s = arclength, T = unit tangent vector to trajectory). dt dt � � ˆ � r � ˆ So d� = T ds, and r F · d� = F · T ds. Sometimes the calculation is easier this way!\nC C\n� ˆ � Example: C = circle of radius a centered at origin, F = xˆ + yˆ, then F · T = 0 (picture drawn), ı j � � ˆ � · T ds = 0 ds = 0. so C F � � � � ˆ � � ˆ ı j Example: same C, F = −yˆ + xˆ, then F · T = |F | = a, so C F · T ds = a ds = a (2πa) = 2πa2 ; checked that we get the same answer if we compute using parametrization x = a cos θ, y = a sin θ. 18.02 Lecture 20. – Fri, Oct 26, 2007\nLine integrals continued. � � � � = Mˆ + Nˆ along a curve C: � · d� = � ˆ Recall: line integral of F ı j F r M dx + N dy = F · T ds. C C C � � � r Example: F = yˆ + xˆ, C F · d� for C = C1 + C2 + C3 enclosing sector of unit disk from 0 to ı j � π/4. (picture shown). Need to compute Ci y dx + x dy for each portion: � �1 1) x-axis: x = t, y = 0, dx = dt, dy = 0, 0 ≤ t ≤ 1, so C1 y dx + x dy = 0 0 dt = 0. Equivalently, � ˆ ı � � ˆ geometrically: along x-axis, y = 0 so F = xˆ while T = ˆ so j F ·\nT ds = 0.\nC1\n2) C2 : x = cos θ, y = sin θ, dx = − sin θ dθ, dy = cos θ dθ, 0 ≤ θ ≤ π . So\n 4 �π/4 � � � π/4 � π/4 1 1 sin(2θ) = . y dx + x dy = sin θ(− sin θ)dθ + cos θ cos θ dθ = cos(2θ)dθ = 2 2 C2 0 0 0\n1 1 3) C3 : line segment from ( √2 , √2 ) to (0, 0): could take x = 1 √ . 2 1 √ 2\n1 √ t, 2\ny = same, 0 ≤ t ≤ 1, ...\nbut easier: C3 backwards (“−C3 ”) is y = x = t, 0 ≤ t ≤ Work along −C3 is opposite of work along C3 . � � 0 � 1/√2 √ 1 1/ 2 y dx + x dy = t dt + t dt = − 2t dt = −[t2 ]0 =− . √ 2 C3 1/ 2 0 � � If F is a gradient ﬁeld, F = �f = fxˆ + fy ˆ (f is called “potential function”), then we can ı j simplify evaluation of line integrals by using the fundamental theorem of calculus. Fundamental theorem of calculus for line integrals:;;� �f · d� = f (P1 ) − f (P0 ) when C runs from P0 to P1 . r � � Equivalently with diﬀerentials: fx dx + fy dy = df = f (P1 ) − f (P0 ). Proof: C C � � t1 � t1 dx dy d �f · d� = r (fx + fy ) dt = (f (x(t), y(t)) dt = [f (x(t), y(t))]t1 = f (P1 ) − f (P0 ). t0 dt dt dt C t0 t0 � � E.g., in the above example, if we set f (x, y) = xy then �f = �y, x� = F . So can be calculated\njust by evaluating f = xy at end points. Picture shown of C, vector ﬁeld, and level curves. Consequences: for a gradient ﬁeld, we have: � � • Path independence: if C1 , C2 have same endpoints then C1 �f · d� = C2 �f · d� (both equal r r � to f (P1 ) − f (P0 ) by the theorem). So the line integral C �f · d� depends only on the end points, r not on the actual trajectory. � • Conservativeness: if C is a closed loop then C �f · d� = 0 (= f (P ) − f (P )). r � 1 1 (e.g. in above example, C = 0 + 2 − 2 = 0.) WARNING: this is only for gradient ﬁelds! � Example: F = −yˆ + xˆ is not a gradient ﬁeld: as seen Thursday, along C = circle of radius a ı j � 2 ˆ � //T ), � r � counterclockwise (F C F · d� = 2πa . Hence F is not conservative, and not a gradient ﬁeld. Physical interpretation. � � If the force ﬁeld F is the gradient of a potential f , then work of F = change in value of potential. � � E.g.: 1) F = gravitational ﬁeld, f = gravitational potential; 2) F = electrical ﬁeld; f = electrical � potential (voltage). (Actually physicists use the opposite sign convention, F = −�f ). Conservativeness means that energy comes from change in potential f , so no energy can be extracted from motion along a closed trajectory (conservativeness = conservation of energy: the change in kinetic energy equals the work of the force equals the change in potential energy). We have four equivalent properties: � � � r (1) F is conservative ( C F · d� = 0 for any closed curve C) � (2) F · d� is path independent (same work if same end points) r � � (3) F is a gradient ﬁeld: F = �f = fxˆ + fy ˆ. ı j (4) M dx + N dy is an exact diﬀerential (= fx dx + fy dy = df .) ((1) is equivalent to (2) by considering C1 , C2 with same endpoints, C = C1 − C2 is a closed loop. (3) ⇒ (2) is the FTC, ⇐ will be key to ﬁnding potential function: if we have path independence � (x,y) � then we can get f (x, y) by computing (0,0) F · d�. (3) and (4) are reformulations of the same r property).\nCi'
7514,'lecture','en',6379,'2007-10-30','2009-09-10','Lecture 21: Gradient fields and potential functions',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 21. –\nTue, Oct 30, 2007\nTest for gradient ﬁelds. � � Observe: if F = Mˆ + Nˆ is a gradient ﬁeld then Nx = My . Indeed, if F = �f then M = fx , ı j N = fy , so Nx = fyx = fxy = My . � Claim: Conversely, if F is deﬁned and diﬀerentiable at every point of the plane, and Nx = My , � ı j then F = Mˆ + Nˆ is a gradient ﬁeld. � � Example: F = −yˆ + xˆ: Nx = 1, My = −1, so F is not a gradient ﬁeld. ı j � Example: for which value(s) of a is F = (4x2 + axy)ˆ + (3y 2 + 4x2 )ˆ a gradient ﬁeld? Answer: ı j Nx = 8x, My = ax, so a = 8. � Finding the potential: if above test says F is a gradient ﬁeld, we have 2 methods to ﬁnd the potential function f . Illustrated for the above example (taking a = 8): Method 1: using line integrals (FTC backwards): � � r We know that if C starts at (0, 0) and ends at (x1 , y1 ) then f (x1 , y1 ) − f (0, 0) = C F · d�. Here f (0, 0) is just an integration constant (if f is a potential then so is f + c). Can also choose the simplest curve C from (0, 0) to (x1 , y1 ). Simplest choice: take C = portion of x-axis from (0, 0) to (x1 , 0), then vertical segment from (x1 , 0) to (x1 , y1 ) (picture drawn). � � � · d� = Then F r (4x2 + 8xy) dx + (3y 2 + 4x2 ) dy: C C1 +C2 � � � � x1 4 3 x1 4 2 Over C1 , 0 ≤ x ≤ x1 , y = 0, dy = 0: = (4x + 8x · 0) dx = x = x3 . 3 3 1 C 0 0 �1 � y1 � �y 3 Over C2 , 0 ≤ y ≤ y1 , x = x1 , dx = 0: = (3y 2 + 4x2 ) dy = y 3 + 4x2 y 01 = y1 + 4x2 y1 . 1 1 1\nC2 0\n4 3 So f (x1 , y1 ) = x3 + y1 + 4x2 y1 (+constant). 1 3 1 Method 2: using antiderivatives: We want f (x, y) such that (1) fx = 4x2 + 8xy, (2) fy = 3y 2 + 4x2 . Taking antiderivative of (1) w.r.t. x (treating y as a constant), we get f (x, y) = 4 x3 + 4x2 y+ 3 integration constant (independent of x). The integration constant still depends on y, call it g(y). So f (x, y) = 4 x3 + 4x2 y + g(y). Take partial w.r.t. y, to get fy = 4x2 + g � (y). 3 Comparing this with (2), we get g � (y) = 3y 2 , so g(y) = y 3 + c. Plugging into above formula for f , we ﬁnally get f (x, y) = 4 x3 + 4x2 y + y 3 + c. 3 Curl. � � � � r Now we have: Nx = My ⇔∗ F is a gradient ﬁeld ⇔ F is conservative: C F · d� = 0 for any closed curve. � (*): ⇒ only holds if F is deﬁned everywhere, or in a “simply-connected” region – see next week. � Failure of conservativeness is given by the curl of F : � Deﬁnition: curl(F ) = Nx − My . Interpretation of curl: for a velocity ﬁeld, curl = (twice) angular velocity of the rotation component of the motion.;;� � (Ex: F = �a, b� uniform translation, F = �x, y� expanding motion have curl zero; whereas � F = �−y, x� rotation at unit angular velocity has curl = 2). � � For a force ﬁeld, curl F = torque exerted on a test mass, measures how F imparts rotation motion. Force d For translation motion: = acceleration = (velocity). Mass dt Torque d For rotation eﬀects: = angular acceleration = (angular velocity). Moment of inertia dt 18.02 Lecture 22. – Thu, Nov 1, 2007\nHandouts: PS8 solutions, PS9, practice exams 3A and 3B. Green’s theorem. If C is a positively oriented closed curve enclosing a region R, then � �� � �� � · d� = � dA which means F r curl F M dx + N dy = (Nx − My ) dA.\nC R C R\n�� Example (reduce a complicated line integral to an easy ): Let C = unit circle centered at (2,0), counterclockwise. R = unit disk at (2, 0). Then � �� �� �� 1 2 −x −x −x −x ye dx + ( x − e ) dy = Nx − My dA = (x + e ) − e dA = x dA. 2 C R R R This is equal to area · x = π · 2 = 2π (or by direct computation of the iterated integral). (Note: ¯ direct calculation of the line integral would probably involve setting x = 2 + cos θ, y = sin θ, but then calculations get really complicated.) Application: proof of our criterion for gradient ﬁelds. � Theorem: if F = Mˆ + Nˆ is deﬁned and continuously diﬀerentiable in the whole plane, then ı j � is conservative (⇔ F is a gradient ﬁeld). � Nx = My ⇒ F � �� �� � r � � If Nx = My then by Green, C F · d� = R curl F dA = R 0 dA = 0. So F is conservative. � Note: this only works if F and its curl are deﬁned everywhere inside R. For the vector ﬁeld on PS8 Problem 2, we can’t do this if the region contains the origin – for example, the line integral � along the unit circle is non-zero even though curl(F ) is zero wherever it’s deﬁned. Proof of Green’s theorem. 2 preliminary remarks: � �� � �� 1) the theorem splits into two identities, C M dx = − R My dA and C N dy = R Nx dA. 2) additivity: if theorem is true for R1 and R2 then it’s true for the union R �� R1 ∪ R2 (picture = � � � �� �� shown): C = C1 + C2 (the line integrals along inner portions cancel out) and R = R1 + R2 . � �� Main step in the proof: prove C M dx = − R My dA for “vertically simple” regions: a < x < b, f0 (x) < y < f1 (x). (picture drawn). This involves calculations similar to PS5 Problem 3. LHS: break C into � four sides (C1 lower, C2 right vertical segment, C3 upper, C4 left vertical � segment); C2 M dx = C4 M dx = 0 since x = constant on C2 and C4 . So � b � � � � b = + = M (x, f0 (x)) dx − M (x, f1 (x)) dx\nC C1 C3 a a\n(using along C1 : parameter a ≤ x ≤ b, y = f0 (x); along C2 , x from b to a, hence − sign; y = f1 (x)).;;�� RHS: −\nR\n� b� My dA = −\na\nf1 (x)\n� My dy dx = −\na\nb\n(M (x, f1 (x)) − M (x, f0 (x)) dx (= LHS).\nf0 (x)\nFinally observe: any region R can be subdivided into � vertically simple pieces (picture shown); � �� �� for each piece Ci M dx = − Ri My dA, so by additivity C M dx = − R My dA. � �� Similarly C N dy = R Nx dA by subdividing into horizontally simple pieces. This completes the proof. � �� Example. The area of a region R can be evaluated using a line integral: for example, C x dy = R 1dA = area(R). This idea was used to build mechanical devices that measure area of arbitrary regions on a piece of paper: planimeters (photo of the actual object shown, and principle explained brieﬂy: as one moves its arm along a closed curve, the planimeter calculates the line integral of a suitable vector ﬁeld by means of an ingenious mechanism; at the end of the motion, one reads the area). 18.02 Lecture 23. – Fri, Nov 2, 2007\n� � � ˆ ˆ Flux. The ﬂux of a vector ﬁeld F across a plane curve C is C F · n ds, where n = normal vector ◦ clockwise from T . ˆ to C, rotated 90 � � ˆ � ˆ � We now have two types of line integrals: work, F · T ds, sums F · T = component of F in � � ˆ � ˆ � direction of C, along the curve C. Flux, F · n ds, sums F · n = component of F perpendicular to C, along the curve. � � ˆ If we break C into small pieces of length Δs, the ﬂux is (F · n) Δsi .\ni\n� Physical interpretation: if F is a velocity ﬁeld (e.g. ﬂow of a ﬂuid), ﬂux measures how much matter passes through C per unit time. � Look at a small portion of C: locally F is constant, what passes through portion of C in unit � � time is contents of a parallelogram with sides Δs and F (picture shown with F horizontal, and � ˆ portion of curve = diagonal line segment). The area of this parallelogram is Δs · height = Δs (F · n). (picture shown rotated with portion of C horizontal, at base of parallelogram). Summing these � � ˆ contributions along all of C, we get that (F · n) ds is the total ﬂow through C per unit time; counting positively what ﬂows towards the right of C, negatively what ﬂows towards the left of C, as seen from the point of view of a point travelling along C. � Example: C = circle of radius a counterclockwise, F = xˆ + yˆ (picture shown): along C, ı j � ˆ � ˆ � F //n, and |F | = a, so F · n = a. So � � � · n ds = F ˆ a ds = a length(C) = 2πa2 .\nC C\nMeanwhile, the ﬂux of −yˆ + xˆ across C is zero (ﬁeld tangent to C). ı j That was a geometric argument. What about the general situation when calculation of the line integral is required? ˆ ˆ ˆ ˆ Observe: d� = T ds = �dx, dy�, and n is T rotated 90◦ clockwise; so n ds = �dy, −dx�. r � So, if F = P ˆ + Qˆ (using new letters to make things look diﬀerent; of course we could call the ı j components M and N ), then � � � � · n ds = �P, Q� · �dy, −dx� = F ˆ −Q dx + P dy.\nC C C;;� � (or if F = �M, N �, C −N dx + M dy). So we can compute ﬂux using the usual method, by expressing x, y, dx, dy in terms of a parameter variable and substituting (no example given). � Green’s theorem for ﬂux. If C encloses R counterclockwise, and F = P ˆ + Qˆ, then ı j � �� � ˆ � � � F · n ds = div(F ) dA, where div(F ) = Px + Qy is the divergence of F .\nC R\n� Note: the counterclockwise orientation of C means that we count ﬂux of F out of R through C. � � � ˆ Proof: F · n ds = −Q dx + P dy. Call M = −Q and N = P , then apply usual Green’s C �� � C theorem M dx + N dy = (Nx − My ) dA to get C R � �� �� � −Q dx + P dy = (Px − (−Qy )) dA = div(F ) dA.\nC R R\nThis proof by “renaming” the components is�why we called the components P, Q instead of M, N . �� � = �M, N � the statement becomes If we call F −N dx + M dy = (Mx + Ny ) dA.\nC R\n�� � Example: in the above example (xˆ + yˆ across circle), div F = 2, so ﬂux = R 2 dA = ı j 2 area(R) = 2πa2 . If we translate C to a diﬀerent position (not centered at origin) (picture shown) then direct calculation of ﬂux is harder, but total ﬂux is still 2πa2 . Physical interpretation: in an incompressible ﬂuid ﬂow, divergence measures source/sink den­ sity/rate, i.e. how much ﬂuid is being added to the system per unit area and per unit time.'
7515,'lecture','en',6379,'2007-11-01','2009-09-10','Lecture 22: Green\'s theorem',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 21. –\nTue, Oct 30, 2007\nTest for gradient ﬁelds. � � Observe: if F = Mˆ + Nˆ is a gradient ﬁeld then Nx = My . Indeed, if F = �f then M = fx , ı j N = fy , so Nx = fyx = fxy = My . � Claim: Conversely, if F is deﬁned and diﬀerentiable at every point of the plane, and Nx = My , � ı j then F = Mˆ + Nˆ is a gradient ﬁeld. � � Example: F = −yˆ + xˆ: Nx = 1, My = −1, so F is not a gradient ﬁeld. ı j � Example: for which value(s) of a is F = (4x2 + axy)ˆ + (3y 2 + 4x2 )ˆ a gradient ﬁeld? Answer: ı j Nx = 8x, My = ax, so a = 8. � Finding the potential: if above test says F is a gradient ﬁeld, we have 2 methods to ﬁnd the potential function f . Illustrated for the above example (taking a = 8): Method 1: using line integrals (FTC backwards): � � r We know that if C starts at (0, 0) and ends at (x1 , y1 ) then f (x1 , y1 ) − f (0, 0) = C F · d�. Here f (0, 0) is just an integration constant (if f is a potential then so is f + c). Can also choose the simplest curve C from (0, 0) to (x1 , y1 ). Simplest choice: take C = portion of x-axis from (0, 0) to (x1 , 0), then vertical segment from (x1 , 0) to (x1 , y1 ) (picture drawn). � � � · d� = Then F r (4x2 + 8xy) dx + (3y 2 + 4x2 ) dy: C C1 +C2 � � � � x1 4 3 x1 4 2 Over C1 , 0 ≤ x ≤ x1 , y = 0, dy = 0: = (4x + 8x · 0) dx = x = x3 . 3 3 1 C 0 0 �1 � y1 � �y 3 Over C2 , 0 ≤ y ≤ y1 , x = x1 , dx = 0: = (3y 2 + 4x2 ) dy = y 3 + 4x2 y 01 = y1 + 4x2 y1 . 1 1 1\nC2 0\n4 3 So f (x1 , y1 ) = x3 + y1 + 4x2 y1 (+constant). 1 3 1 Method 2: using antiderivatives: We want f (x, y) such that (1) fx = 4x2 + 8xy, (2) fy = 3y 2 + 4x2 . Taking antiderivative of (1) w.r.t. x (treating y as a constant), we get f (x, y) = 4 x3 + 4x2 y+ 3 integration constant (independent of x). The integration constant still depends on y, call it g(y). So f (x, y) = 4 x3 + 4x2 y + g(y). Take partial w.r.t. y, to get fy = 4x2 + g � (y). 3 Comparing this with (2), we get g � (y) = 3y 2 , so g(y) = y 3 + c. Plugging into above formula for f , we ﬁnally get f (x, y) = 4 x3 + 4x2 y + y 3 + c. 3 Curl. � � � � r Now we have: Nx = My ⇔∗ F is a gradient ﬁeld ⇔ F is conservative: C F · d� = 0 for any closed curve. � (*): ⇒ only holds if F is deﬁned everywhere, or in a “simply-connected” region – see next week. � Failure of conservativeness is given by the curl of F : � Deﬁnition: curl(F ) = Nx − My . Interpretation of curl: for a velocity ﬁeld, curl = (twice) angular velocity of the rotation component of the motion.;;� � (Ex: F = �a, b� uniform translation, F = �x, y� expanding motion have curl zero; whereas � F = �−y, x� rotation at unit angular velocity has curl = 2). � � For a force ﬁeld, curl F = torque exerted on a test mass, measures how F imparts rotation motion. Force d For translation motion: = acceleration = (velocity). Mass dt Torque d For rotation eﬀects: = angular acceleration = (angular velocity). Moment of inertia dt 18.02 Lecture 22. – Thu, Nov 1, 2007\nHandouts: PS8 solutions, PS9, practice exams 3A and 3B. Green’s theorem. If C is a positively oriented closed curve enclosing a region R, then � �� � �� � · d� = � dA which means F r curl F M dx + N dy = (Nx − My ) dA.\nC R C R\n�� Example (reduce a complicated line integral to an easy ): Let C = unit circle centered at (2,0), counterclockwise. R = unit disk at (2, 0). Then � �� �� �� 1 2 −x −x −x −x ye dx + ( x − e ) dy = Nx − My dA = (x + e ) − e dA = x dA. 2 C R R R This is equal to area · x = π · 2 = 2π (or by direct computation of the iterated integral). (Note: ¯ direct calculation of the line integral would probably involve setting x = 2 + cos θ, y = sin θ, but then calculations get really complicated.) Application: proof of our criterion for gradient ﬁelds. � Theorem: if F = Mˆ + Nˆ is deﬁned and continuously diﬀerentiable in the whole plane, then ı j � is conservative (⇔ F is a gradient ﬁeld). � Nx = My ⇒ F � �� �� � r � � If Nx = My then by Green, C F · d� = R curl F dA = R 0 dA = 0. So F is conservative. � Note: this only works if F and its curl are deﬁned everywhere inside R. For the vector ﬁeld on PS8 Problem 2, we can’t do this if the region contains the origin – for example, the line integral � along the unit circle is non-zero even though curl(F ) is zero wherever it’s deﬁned. Proof of Green’s theorem. 2 preliminary remarks: � �� � �� 1) the theorem splits into two identities, C M dx = − R My dA and C N dy = R Nx dA. 2) additivity: if theorem is true for R1 and R2 then it’s true for the union R �� R1 ∪ R2 (picture = � � � �� �� shown): C = C1 + C2 (the line integrals along inner portions cancel out) and R = R1 + R2 . � �� Main step in the proof: prove C M dx = − R My dA for “vertically simple” regions: a < x < b, f0 (x) < y < f1 (x). (picture drawn). This involves calculations similar to PS5 Problem 3. LHS: break C into � four sides (C1 lower, C2 right vertical segment, C3 upper, C4 left vertical � segment); C2 M dx = C4 M dx = 0 since x = constant on C2 and C4 . So � b � � � � b = + = M (x, f0 (x)) dx − M (x, f1 (x)) dx\nC C1 C3 a a\n(using along C1 : parameter a ≤ x ≤ b, y = f0 (x); along C2 , x from b to a, hence − sign; y = f1 (x)).;;�� RHS: −\nR\n� b� My dA = −\na\nf1 (x)\n� My dy dx = −\na\nb\n(M (x, f1 (x)) − M (x, f0 (x)) dx (= LHS).\nf0 (x)\nFinally observe: any region R can be subdivided into � vertically simple pieces (picture shown); � �� �� for each piece Ci M dx = − Ri My dA, so by additivity C M dx = − R My dA. � �� Similarly C N dy = R Nx dA by subdividing into horizontally simple pieces. This completes the proof. � �� Example. The area of a region R can be evaluated using a line integral: for example, C x dy = R 1dA = area(R). This idea was used to build mechanical devices that measure area of arbitrary regions on a piece of paper: planimeters (photo of the actual object shown, and principle explained brieﬂy: as one moves its arm along a closed curve, the planimeter calculates the line integral of a suitable vector ﬁeld by means of an ingenious mechanism; at the end of the motion, one reads the area). 18.02 Lecture 23. – Fri, Nov 2, 2007\n� � � ˆ ˆ Flux. The ﬂux of a vector ﬁeld F across a plane curve C is C F · n ds, where n = normal vector ◦ clockwise from T . ˆ to C, rotated 90 � � ˆ � ˆ � We now have two types of line integrals: work, F · T ds, sums F · T = component of F in � � ˆ � ˆ � direction of C, along the curve C. Flux, F · n ds, sums F · n = component of F perpendicular to C, along the curve. � � ˆ If we break C into small pieces of length Δs, the ﬂux is (F · n) Δsi .\ni\n� Physical interpretation: if F is a velocity ﬁeld (e.g. ﬂow of a ﬂuid), ﬂux measures how much matter passes through C per unit time. � Look at a small portion of C: locally F is constant, what passes through portion of C in unit � � time is contents of a parallelogram with sides Δs and F (picture shown with F horizontal, and � ˆ portion of curve = diagonal line segment). The area of this parallelogram is Δs · height = Δs (F · n). (picture shown rotated with portion of C horizontal, at base of parallelogram). Summing these � � ˆ contributions along all of C, we get that (F · n) ds is the total ﬂow through C per unit time; counting positively what ﬂows towards the right of C, negatively what ﬂows towards the left of C, as seen from the point of view of a point travelling along C. � Example: C = circle of radius a counterclockwise, F = xˆ + yˆ (picture shown): along C, ı j � ˆ � ˆ � F //n, and |F | = a, so F · n = a. So � � � · n ds = F ˆ a ds = a length(C) = 2πa2 .\nC C\nMeanwhile, the ﬂux of −yˆ + xˆ across C is zero (ﬁeld tangent to C). ı j That was a geometric argument. What about the general situation when calculation of the line integral is required? ˆ ˆ ˆ ˆ Observe: d� = T ds = �dx, dy�, and n is T rotated 90◦ clockwise; so n ds = �dy, −dx�. r � So, if F = P ˆ + Qˆ (using new letters to make things look diﬀerent; of course we could call the ı j components M and N ), then � � � � · n ds = �P, Q� · �dy, −dx� = F ˆ −Q dx + P dy.\nC C C;;� � (or if F = �M, N �, C −N dx + M dy). So we can compute ﬂux using the usual method, by expressing x, y, dx, dy in terms of a parameter variable and substituting (no example given). � Green’s theorem for ﬂux. If C encloses R counterclockwise, and F = P ˆ + Qˆ, then ı j � �� � ˆ � � � F · n ds = div(F ) dA, where div(F ) = Px + Qy is the divergence of F .\nC R\n� Note: the counterclockwise orientation of C means that we count ﬂux of F out of R through C. � � � ˆ Proof: F · n ds = −Q dx + P dy. Call M = −Q and N = P , then apply usual Green’s C �� � C theorem M dx + N dy = (Nx − My ) dA to get C R � �� �� � −Q dx + P dy = (Px − (−Qy )) dA = div(F ) dA.\nC R R\nThis proof by “renaming” the components is�why we called the components P, Q instead of M, N . �� � = �M, N � the statement becomes If we call F −N dx + M dy = (Mx + Ny ) dA.\nC R\n�� � Example: in the above example (xˆ + yˆ across circle), div F = 2, so ﬂux = R 2 dA = ı j 2 area(R) = 2πa2 . If we translate C to a diﬀerent position (not centered at origin) (picture shown) then direct calculation of ﬂux is harder, but total ﬂux is still 2πa2 . Physical interpretation: in an incompressible ﬂuid ﬂow, divergence measures source/sink den­ sity/rate, i.e. how much ﬂuid is being added to the system per unit area and per unit time.'
7516,'lecture','en',6379,'2007-11-02','2009-09-10','Lecture 23: Flux; normal form of Green\'s theorem',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 21. –\nTue, Oct 30, 2007\nTest for gradient ﬁelds. � � Observe: if F = Mˆ + Nˆ is a gradient ﬁeld then Nx = My . Indeed, if F = �f then M = fx , ı j N = fy , so Nx = fyx = fxy = My . � Claim: Conversely, if F is deﬁned and diﬀerentiable at every point of the plane, and Nx = My , � ı j then F = Mˆ + Nˆ is a gradient ﬁeld. � � Example: F = −yˆ + xˆ: Nx = 1, My = −1, so F is not a gradient ﬁeld. ı j � Example: for which value(s) of a is F = (4x2 + axy)ˆ + (3y 2 + 4x2 )ˆ a gradient ﬁeld? Answer: ı j Nx = 8x, My = ax, so a = 8. � Finding the potential: if above test says F is a gradient ﬁeld, we have 2 methods to ﬁnd the potential function f . Illustrated for the above example (taking a = 8): Method 1: using line integrals (FTC backwards): � � r We know that if C starts at (0, 0) and ends at (x1 , y1 ) then f (x1 , y1 ) − f (0, 0) = C F · d�. Here f (0, 0) is just an integration constant (if f is a potential then so is f + c). Can also choose the simplest curve C from (0, 0) to (x1 , y1 ). Simplest choice: take C = portion of x-axis from (0, 0) to (x1 , 0), then vertical segment from (x1 , 0) to (x1 , y1 ) (picture drawn). � � � · d� = Then F r (4x2 + 8xy) dx + (3y 2 + 4x2 ) dy: C C1 +C2 � � � � x1 4 3 x1 4 2 Over C1 , 0 ≤ x ≤ x1 , y = 0, dy = 0: = (4x + 8x · 0) dx = x = x3 . 3 3 1 C 0 0 �1 � y1 � �y 3 Over C2 , 0 ≤ y ≤ y1 , x = x1 , dx = 0: = (3y 2 + 4x2 ) dy = y 3 + 4x2 y 01 = y1 + 4x2 y1 . 1 1 1\nC2 0\n4 3 So f (x1 , y1 ) = x3 + y1 + 4x2 y1 (+constant). 1 3 1 Method 2: using antiderivatives: We want f (x, y) such that (1) fx = 4x2 + 8xy, (2) fy = 3y 2 + 4x2 . Taking antiderivative of (1) w.r.t. x (treating y as a constant), we get f (x, y) = 4 x3 + 4x2 y+ 3 integration constant (independent of x). The integration constant still depends on y, call it g(y). So f (x, y) = 4 x3 + 4x2 y + g(y). Take partial w.r.t. y, to get fy = 4x2 + g � (y). 3 Comparing this with (2), we get g � (y) = 3y 2 , so g(y) = y 3 + c. Plugging into above formula for f , we ﬁnally get f (x, y) = 4 x3 + 4x2 y + y 3 + c. 3 Curl. � � � � r Now we have: Nx = My ⇔∗ F is a gradient ﬁeld ⇔ F is conservative: C F · d� = 0 for any closed curve. � (*): ⇒ only holds if F is deﬁned everywhere, or in a “simply-connected” region – see next week. � Failure of conservativeness is given by the curl of F : � Deﬁnition: curl(F ) = Nx − My . Interpretation of curl: for a velocity ﬁeld, curl = (twice) angular velocity of the rotation component of the motion.;;� � (Ex: F = �a, b� uniform translation, F = �x, y� expanding motion have curl zero; whereas � F = �−y, x� rotation at unit angular velocity has curl = 2). � � For a force ﬁeld, curl F = torque exerted on a test mass, measures how F imparts rotation motion. Force d For translation motion: = acceleration = (velocity). Mass dt Torque d For rotation eﬀects: = angular acceleration = (angular velocity). Moment of inertia dt 18.02 Lecture 22. – Thu, Nov 1, 2007\nHandouts: PS8 solutions, PS9, practice exams 3A and 3B. Green’s theorem. If C is a positively oriented closed curve enclosing a region R, then � �� � �� � · d� = � dA which means F r curl F M dx + N dy = (Nx − My ) dA.\nC R C R\n�� Example (reduce a complicated line integral to an easy ): Let C = unit circle centered at (2,0), counterclockwise. R = unit disk at (2, 0). Then � �� �� �� 1 2 −x −x −x −x ye dx + ( x − e ) dy = Nx − My dA = (x + e ) − e dA = x dA. 2 C R R R This is equal to area · x = π · 2 = 2π (or by direct computation of the iterated integral). (Note: ¯ direct calculation of the line integral would probably involve setting x = 2 + cos θ, y = sin θ, but then calculations get really complicated.) Application: proof of our criterion for gradient ﬁelds. � Theorem: if F = Mˆ + Nˆ is deﬁned and continuously diﬀerentiable in the whole plane, then ı j � is conservative (⇔ F is a gradient ﬁeld). � Nx = My ⇒ F � �� �� � r � � If Nx = My then by Green, C F · d� = R curl F dA = R 0 dA = 0. So F is conservative. � Note: this only works if F and its curl are deﬁned everywhere inside R. For the vector ﬁeld on PS8 Problem 2, we can’t do this if the region contains the origin – for example, the line integral � along the unit circle is non-zero even though curl(F ) is zero wherever it’s deﬁned. Proof of Green’s theorem. 2 preliminary remarks: � �� � �� 1) the theorem splits into two identities, C M dx = − R My dA and C N dy = R Nx dA. 2) additivity: if theorem is true for R1 and R2 then it’s true for the union R �� R1 ∪ R2 (picture = � � � �� �� shown): C = C1 + C2 (the line integrals along inner portions cancel out) and R = R1 + R2 . � �� Main step in the proof: prove C M dx = − R My dA for “vertically simple” regions: a < x < b, f0 (x) < y < f1 (x). (picture drawn). This involves calculations similar to PS5 Problem 3. LHS: break C into � four sides (C1 lower, C2 right vertical segment, C3 upper, C4 left vertical � segment); C2 M dx = C4 M dx = 0 since x = constant on C2 and C4 . So � b � � � � b = + = M (x, f0 (x)) dx − M (x, f1 (x)) dx\nC C1 C3 a a\n(using along C1 : parameter a ≤ x ≤ b, y = f0 (x); along C2 , x from b to a, hence − sign; y = f1 (x)).;;�� RHS: −\nR\n� b� My dA = −\na\nf1 (x)\n� My dy dx = −\na\nb\n(M (x, f1 (x)) − M (x, f0 (x)) dx (= LHS).\nf0 (x)\nFinally observe: any region R can be subdivided into � vertically simple pieces (picture shown); � �� �� for each piece Ci M dx = − Ri My dA, so by additivity C M dx = − R My dA. � �� Similarly C N dy = R Nx dA by subdividing into horizontally simple pieces. This completes the proof. � �� Example. The area of a region R can be evaluated using a line integral: for example, C x dy = R 1dA = area(R). This idea was used to build mechanical devices that measure area of arbitrary regions on a piece of paper: planimeters (photo of the actual object shown, and principle explained brieﬂy: as one moves its arm along a closed curve, the planimeter calculates the line integral of a suitable vector ﬁeld by means of an ingenious mechanism; at the end of the motion, one reads the area). 18.02 Lecture 23. – Fri, Nov 2, 2007\n� � � ˆ ˆ Flux. The ﬂux of a vector ﬁeld F across a plane curve C is C F · n ds, where n = normal vector ◦ clockwise from T . ˆ to C, rotated 90 � � ˆ � ˆ � We now have two types of line integrals: work, F · T ds, sums F · T = component of F in � � ˆ � ˆ � direction of C, along the curve C. Flux, F · n ds, sums F · n = component of F perpendicular to C, along the curve. � � ˆ If we break C into small pieces of length Δs, the ﬂux is (F · n) Δsi .\ni\n� Physical interpretation: if F is a velocity ﬁeld (e.g. ﬂow of a ﬂuid), ﬂux measures how much matter passes through C per unit time. � Look at a small portion of C: locally F is constant, what passes through portion of C in unit � � time is contents of a parallelogram with sides Δs and F (picture shown with F horizontal, and � ˆ portion of curve = diagonal line segment). The area of this parallelogram is Δs · height = Δs (F · n). (picture shown rotated with portion of C horizontal, at base of parallelogram). Summing these � � ˆ contributions along all of C, we get that (F · n) ds is the total ﬂow through C per unit time; counting positively what ﬂows towards the right of C, negatively what ﬂows towards the left of C, as seen from the point of view of a point travelling along C. � Example: C = circle of radius a counterclockwise, F = xˆ + yˆ (picture shown): along C, ı j � ˆ � ˆ � F //n, and |F | = a, so F · n = a. So � � � · n ds = F ˆ a ds = a length(C) = 2πa2 .\nC C\nMeanwhile, the ﬂux of −yˆ + xˆ across C is zero (ﬁeld tangent to C). ı j That was a geometric argument. What about the general situation when calculation of the line integral is required? ˆ ˆ ˆ ˆ Observe: d� = T ds = �dx, dy�, and n is T rotated 90◦ clockwise; so n ds = �dy, −dx�. r � So, if F = P ˆ + Qˆ (using new letters to make things look diﬀerent; of course we could call the ı j components M and N ), then � � � � · n ds = �P, Q� · �dy, −dx� = F ˆ −Q dx + P dy.\nC C C;;� � (or if F = �M, N �, C −N dx + M dy). So we can compute ﬂux using the usual method, by expressing x, y, dx, dy in terms of a parameter variable and substituting (no example given). � Green’s theorem for ﬂux. If C encloses R counterclockwise, and F = P ˆ + Qˆ, then ı j � �� � ˆ � � � F · n ds = div(F ) dA, where div(F ) = Px + Qy is the divergence of F .\nC R\n� Note: the counterclockwise orientation of C means that we count ﬂux of F out of R through C. � � � ˆ Proof: F · n ds = −Q dx + P dy. Call M = −Q and N = P , then apply usual Green’s C �� � C theorem M dx + N dy = (Nx − My ) dA to get C R � �� �� � −Q dx + P dy = (Px − (−Qy )) dA = div(F ) dA.\nC R R\nThis proof by “renaming” the components is�why we called the components P, Q instead of M, N . �� � = �M, N � the statement becomes If we call F −N dx + M dy = (Mx + Ny ) dA.\nC R\n�� � Example: in the above example (xˆ + yˆ across circle), div F = 2, so ﬂux = R 2 dA = ı j 2 area(R) = 2πa2 . If we translate C to a diﬀerent position (not centered at origin) (picture shown) then direct calculation of ﬂux is harder, but total ﬂux is still 2πa2 . Physical interpretation: in an incompressible ﬂuid ﬂow, divergence measures source/sink den­ sity/rate, i.e. how much ﬂuid is being added to the system per unit area and per unit time.'
7517,'lecture','en',6379,'2007-11-06','2009-09-10','Lecture 24: Simply connected regions; review',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 24. –\nTue, Nov 6, 2007\nSimply connected regions. [slightly diﬀerent from the actual notations used] Recall Green’s theorem: if C is a closed curve around R counterclockwise then line integrals can be expressed as double integrals: � �� � �� � · d� = � ) dA, � · n ds = � F r curl(F F ˆ div(F ) dA,\nC R C R\nwhere curl(Mˆ + Nˆ) = Nx − My , div(P ˆ + Qˆ) = Px + Qy . ı j ı j � must be deﬁned on the entire region R enclosed by C. For Green’s theorem to hold, F −yˆ + xˆ ı j � � , C = unit circle counterclockwise, then curl(F ) = Example: (same as in pset): F = 2 x + y2 −y ∂ x ∂ ( 2 )− ( 2 ) = · · · = 0. So, if we look at both sides of Green’s theorem: 2 ∂x x + y ∂y x + y 2 � �� �� � r � F · d� = 2π (from pset), curlF dA = 0 dA = 0 ?\nC R R\n� The problem is that R includes 0, where F is not deﬁned. Deﬁnition: a region R in the plane is simply connected if, given any closed curve in R, its interior region is entirely contained in R. Examples shown. � So: Green’s theorem applies safely when the domain in which F is deﬁned and diﬀerentiable is � is deﬁned on C, then it’s also deﬁned in simply connected: then we automatically know that, if F the region bounded by C. In the above example, can’t apply Green to the unit circle, because the domain of deﬁnition � of F is not simply connected. Still, we can apply Green’s theorem to an annulus (picture shown of a curve C � = unit circle counterclockwise + segment along x-axis + small circle around origin clockwise + back to the unit circle allong the x-axis, enclosing an annulus R� ). Then Green applies � �� � � � � r and says C � F · d� = R� 0 dA = 0; but line integral simpliﬁes to C � = C − C2 , where C = unit circle, C2 = small circle / origin; so line integral is actually the same on C and C2 (or any other curve encircling the origin). Review for Exam 3. 2 main objects: double integrals and line integrals. Must know how to set up and evaluate. Double integrals: drawing picture of region, taking slices to set up the iterated integral. Also in polar coordinates, with dA = r dr dθ (see e.g. Problem 2; not done) Remember: mass, centroid, moment of inertia. � For evaluation, need to know: usual basic integrals (e.g. dx ); integration by substitution (e.g. x � 1 � 2 t dt du √ , setting u = 1 + t2 ). Don’t need to know: complicated trigonometric √ = 1 + t2 � 1 2 u 0 integrals (e.g. cos4 θ dθ), integration by parts. Change of variables: recall method: � � ∂(u, v) � ux uy � �. Its absolute value gives ratio between du dv and dx dy. 1) Jacobian: =� ∂(x, y) � cx vy � 2) express integrand in terms of u, v.;;3) set up bounds in uv-coordinates by drawing picture. The actual example on the test will be reasonably simple (constant bounds, or circle in uv-coords). � � � � r � ˆ Line integrals: C F · d� = C F · T ds = C M dx + N dy. To evaluate, express both x, y in terms of a single parameter and substitute. � � � r � Special case: gradient ﬁelds. Recall: F is conservative ⇔ F · d� is path independent ⇔ F is � the gradient of some potential f ⇔ curl F = 0 (i.e. Nx = My ). If this is the case, then we can look for a potential using one of the two methods (antiderivatives, or line integral); and we can then use the FTC to avoid calculating the line integral. (cf. Problem 3). � � � ˆ Flux: F · n ds (= −Q dx + P dy). Geometric interpretation.\nC C\nGreen’s theorem (in both forms) (already written at beginning of lecture). 18.02 Lecture 25. – Fri, Nov 9, 2007\nHandouts: Exam 3 solutions.\n��� Triple integrals:\nR\nf dV (dV = volume element).\nExample 1: region between paraboloids z = x2 + y 2 and z = 4 − x2 − y 2 (picture drawn), e.g. ��� � ? � ? � 4−x2 −y2 volume of this region: 1 dV = dz dy dx.\nR ? ? x2 +y 2\nTo set up bounds, (1) for ﬁxed (x, y) ﬁnd bounds for z: here lower limit is z = x2 +y 2 , upper limit is z = 4 − x2 − y 2 ; (2) ﬁnd the shadow of R onto the xy-plane, i.e. set of values of (x, y) above which region lies. Here: R is widest at intersection of paraboloids, which is in plane z = 2; general method: for which (x, y) is z on top surface > z on bottom surface? Answer: when 4 − x2 − y 2 > x2 − y 2 , √ i.e. x2 + y 2 < 2. So we integrate over a disk of radius 2 in the xy-plane. By usual method to set up double integrals, we ﬁnally get: � √2 � √2−x2 � 4−x2 −y2 V = √ dz dy dx. √\n− 2 − 2−x2 x2 +y 2\nEvaluation would be easier if we used polar coordinates x = r cos θ, y = r sin θ, x2 + y 2 = r2 : then � 2π � √2 � 4−r2 V = dz r dr dθ.\n0 0 r2\n(evaluation easy, not done). Cylindrical coordinates. (r, θ, z), x = r cos θ, y = r sin θ. r measures distance from z-axis, θ measures angle from xz-plane (picture shown). Cylinder of radius a centered on z-axis is r = a (drawn); θ = 0 is a vertical half-plane (not drawn). Volume element: in rect. coords., dV = dx dy dz; in cylindrical coords., dV = r dr dθ dz. In both cases this is justiﬁed by considering a small box with height Δz and base area ΔA, then volume is ΔV = ΔA Δz. ��� Applications: Mass: M = R δ dV .;;1 ¯ f dV ; weighted average: f = f δ dV . M ass R R ��� 1 In particular, center of mass: (¯, y, z) where x = x ¯ ¯ ¯ x δ dV. M ass R (Note: can sometimes avoid calculation using symmetry, e.g. in above example x = y = 0). ¯ ¯ ��� Moment of inertia around an axis: I = (distance from axis)2 δ dV . R ��� ��� 2 2 About z-axis: Iz = r δ dV = (x + y 2 ) δ dV . (consistent with I0 in 2D case) R �R � � ��� 2 2 Similarly, about x and y axes: Ix = (y + z ) δ dV, Iy = (x2 + z 2 ) δ dV\nR R\n1 ¯ Average value of f over R: f = V ol\n(setting z = 0, this is consistent with previous deﬁnitions of Ix and Iy for plane regions). Example 2: moment of inertia Iz of solid cone between z = ar and z = b (δ = 1) (picture drawn): � � ��� � b � 2π � z/a πb5 2 2 Iz = r dV = r r dr dθ dz = . 10a4 R 0 0 0 (I explained how to ﬁnd bounds in order dr dθ dz: ﬁrst we ﬁx z, then slice for given z is the disk bounded by r = z/a; the ﬁrst slice is z = 0, the last one is z = b). Example 3: volume of region where z > 1 − y and x2 + y 2 + z 2 < 1? Pictures drawn: in space, slice by yz-plane, and projection to xy-plane. � The bottom surface is the plane z = 1 − y, the upper one is the sphere z = 1 − x2 − y 2 . So √ � 1−x2 −y2 � inner is dz. The shadow on the xy-plane = points where 1 − y < 1 − x2 − y 2 , i.e. 1−y � � squaring both sides, (1 − y)2 < 1 − x2 − y 2 i.e. x2 < 2y − 2y 2 , i.e. − 2y − 2y 2 < x < 2y − 2y 2 . So we get: � 1 � √2y−2y2 � √1−x2 −y2 dz dx dy. √\nBounds for y: either by observing that has solutions iﬀ 2y − y 2 > 0, i.e. 0 < y < 1, or by looking at picture where clearly leftmost point is on z-axis (y = 0) and rightmost point is at y = 1.\n2y−2y 2 1−y x2 < 2y − y 2'
7518,'lecture','en',6379,'2007-11-09','2009-09-10','Lecture 25: Triple integrals in rectangular and cylindrical coordinates',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 24. –\nTue, Nov 6, 2007\nSimply connected regions. [slightly diﬀerent from the actual notations used] Recall Green’s theorem: if C is a closed curve around R counterclockwise then line integrals can be expressed as double integrals: � �� � �� � · d� = � ) dA, � · n ds = � F r curl(F F ˆ div(F ) dA,\nC R C R\nwhere curl(Mˆ + Nˆ) = Nx − My , div(P ˆ + Qˆ) = Px + Qy . ı j ı j � must be deﬁned on the entire region R enclosed by C. For Green’s theorem to hold, F −yˆ + xˆ ı j � � , C = unit circle counterclockwise, then curl(F ) = Example: (same as in pset): F = 2 x + y2 −y ∂ x ∂ ( 2 )− ( 2 ) = · · · = 0. So, if we look at both sides of Green’s theorem: 2 ∂x x + y ∂y x + y 2 � �� �� � r � F · d� = 2π (from pset), curlF dA = 0 dA = 0 ?\nC R R\n� The problem is that R includes 0, where F is not deﬁned. Deﬁnition: a region R in the plane is simply connected if, given any closed curve in R, its interior region is entirely contained in R. Examples shown. � So: Green’s theorem applies safely when the domain in which F is deﬁned and diﬀerentiable is � is deﬁned on C, then it’s also deﬁned in simply connected: then we automatically know that, if F the region bounded by C. In the above example, can’t apply Green to the unit circle, because the domain of deﬁnition � of F is not simply connected. Still, we can apply Green’s theorem to an annulus (picture shown of a curve C � = unit circle counterclockwise + segment along x-axis + small circle around origin clockwise + back to the unit circle allong the x-axis, enclosing an annulus R� ). Then Green applies � �� � � � � r and says C � F · d� = R� 0 dA = 0; but line integral simpliﬁes to C � = C − C2 , where C = unit circle, C2 = small circle / origin; so line integral is actually the same on C and C2 (or any other curve encircling the origin). Review for Exam 3. 2 main objects: double integrals and line integrals. Must know how to set up and evaluate. Double integrals: drawing picture of region, taking slices to set up the iterated integral. Also in polar coordinates, with dA = r dr dθ (see e.g. Problem 2; not done) Remember: mass, centroid, moment of inertia. � For evaluation, need to know: usual basic integrals (e.g. dx ); integration by substitution (e.g. x � 1 � 2 t dt du √ , setting u = 1 + t2 ). Don’t need to know: complicated trigonometric √ = 1 + t2 � 1 2 u 0 integrals (e.g. cos4 θ dθ), integration by parts. Change of variables: recall method: � � ∂(u, v) � ux uy � �. Its absolute value gives ratio between du dv and dx dy. 1) Jacobian: =� ∂(x, y) � cx vy � 2) express integrand in terms of u, v.;;3) set up bounds in uv-coordinates by drawing picture. The actual example on the test will be reasonably simple (constant bounds, or circle in uv-coords). � � � � r � ˆ Line integrals: C F · d� = C F · T ds = C M dx + N dy. To evaluate, express both x, y in terms of a single parameter and substitute. � � � r � Special case: gradient ﬁelds. Recall: F is conservative ⇔ F · d� is path independent ⇔ F is � the gradient of some potential f ⇔ curl F = 0 (i.e. Nx = My ). If this is the case, then we can look for a potential using one of the two methods (antiderivatives, or line integral); and we can then use the FTC to avoid calculating the line integral. (cf. Problem 3). � � � ˆ Flux: F · n ds (= −Q dx + P dy). Geometric interpretation.\nC C\nGreen’s theorem (in both forms) (already written at beginning of lecture). 18.02 Lecture 25. – Fri, Nov 9, 2007\nHandouts: Exam 3 solutions.\n��� Triple integrals:\nR\nf dV (dV = volume element).\nExample 1: region between paraboloids z = x2 + y 2 and z = 4 − x2 − y 2 (picture drawn), e.g. ��� � ? � ? � 4−x2 −y2 volume of this region: 1 dV = dz dy dx.\nR ? ? x2 +y 2\nTo set up bounds, (1) for ﬁxed (x, y) ﬁnd bounds for z: here lower limit is z = x2 +y 2 , upper limit is z = 4 − x2 − y 2 ; (2) ﬁnd the shadow of R onto the xy-plane, i.e. set of values of (x, y) above which region lies. Here: R is widest at intersection of paraboloids, which is in plane z = 2; general method: for which (x, y) is z on top surface > z on bottom surface? Answer: when 4 − x2 − y 2 > x2 − y 2 , √ i.e. x2 + y 2 < 2. So we integrate over a disk of radius 2 in the xy-plane. By usual method to set up double integrals, we ﬁnally get: � √2 � √2−x2 � 4−x2 −y2 V = √ dz dy dx. √\n− 2 − 2−x2 x2 +y 2\nEvaluation would be easier if we used polar coordinates x = r cos θ, y = r sin θ, x2 + y 2 = r2 : then � 2π � √2 � 4−r2 V = dz r dr dθ.\n0 0 r2\n(evaluation easy, not done). Cylindrical coordinates. (r, θ, z), x = r cos θ, y = r sin θ. r measures distance from z-axis, θ measures angle from xz-plane (picture shown). Cylinder of radius a centered on z-axis is r = a (drawn); θ = 0 is a vertical half-plane (not drawn). Volume element: in rect. coords., dV = dx dy dz; in cylindrical coords., dV = r dr dθ dz. In both cases this is justiﬁed by considering a small box with height Δz and base area ΔA, then volume is ΔV = ΔA Δz. ��� Applications: Mass: M = R δ dV .;;1 ¯ f dV ; weighted average: f = f δ dV . M ass R R ��� 1 In particular, center of mass: (¯, y, z) where x = x ¯ ¯ ¯ x δ dV. M ass R (Note: can sometimes avoid calculation using symmetry, e.g. in above example x = y = 0). ¯ ¯ ��� Moment of inertia around an axis: I = (distance from axis)2 δ dV . R ��� ��� 2 2 About z-axis: Iz = r δ dV = (x + y 2 ) δ dV . (consistent with I0 in 2D case) R �R � � ��� 2 2 Similarly, about x and y axes: Ix = (y + z ) δ dV, Iy = (x2 + z 2 ) δ dV\nR R\n1 ¯ Average value of f over R: f = V ol\n(setting z = 0, this is consistent with previous deﬁnitions of Ix and Iy for plane regions). Example 2: moment of inertia Iz of solid cone between z = ar and z = b (δ = 1) (picture drawn): � � ��� � b � 2π � z/a πb5 2 2 Iz = r dV = r r dr dθ dz = . 10a4 R 0 0 0 (I explained how to ﬁnd bounds in order dr dθ dz: ﬁrst we ﬁx z, then slice for given z is the disk bounded by r = z/a; the ﬁrst slice is z = 0, the last one is z = b). Example 3: volume of region where z > 1 − y and x2 + y 2 + z 2 < 1? Pictures drawn: in space, slice by yz-plane, and projection to xy-plane. � The bottom surface is the plane z = 1 − y, the upper one is the sphere z = 1 − x2 − y 2 . So √ � 1−x2 −y2 � inner is dz. The shadow on the xy-plane = points where 1 − y < 1 − x2 − y 2 , i.e. 1−y � � squaring both sides, (1 − y)2 < 1 − x2 − y 2 i.e. x2 < 2y − 2y 2 , i.e. − 2y − 2y 2 < x < 2y − 2y 2 . So we get: � 1 � √2y−2y2 � √1−x2 −y2 dz dx dy. √\nBounds for y: either by observing that has solutions iﬀ 2y − y 2 > 0, i.e. 0 < y < 1, or by looking at picture where clearly leftmost point is on z-axis (y = 0) and rightmost point is at y = 1.\n2y−2y 2 1−y x2 < 2y − y 2'
7519,'lecture','en',6379,'2007-11-13','2009-09-10','Lecture 26: Spherical coordinates; surface area',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 26. –\nTue, Nov 13, 2007\nSpherical coordinates (ρ, φ, θ). ρ = rho = distance to origin. φ = ϕ = phi = angle down from z-axis. θ = same as in cylindrical coordinates. Diagram drawn in space, and picture of 2D slice by vertical plane with z, r coordinates. Formulas to remember: z = ρ cos φ, r = ρ sin φ (so x = ρ sin φ cos θ, y = ρ sin φ sin θ). � √ ρ = x2 + y 2 + z 2 = r2 + z 2 . The equation ρ = a deﬁnes the sphere of radius a centered at 0. On the surface of the sphere, φ is similar to latitude, except it’s 0 at the north pole, π/2 on the equator, π at the south pole. θ is similar to longitude. � φ = π/4 is a cone (asked using ﬂash cards) (z = r = x2 + y 2 ). φ = π/2 is the xy-plane. Volume element: dV = ρ2 sin φ dρ dφ dθ. To understand this formula, ﬁrst study surface area on sphere of radius a: picture shown of a “rectangle” corresponding to Δφ, Δθ, with sides = portion of circle of radius a, of length aΔφ, and portion of circle of radius r = a sin φ, of length rΔθ = a sin φΔθ. So ΔS ≈ a2 sin φ ΔφΔθ, which gives the surface element dS = a2 sin φ dφdθ. The volume element follows: for a small “box”, ΔV = ΔS Δρ, so dV = dρ dS = ρ2 sin φ dρdφdθ. Example: recall the complicated example at end of Friday’s lecture (region sliced by a plane inside unit sphere). After rotating coordinate system, the question becomes: volume of the portion √ of unit sphere above the plane z = 1/ 2? (picture drawn). This can be set up in cylindrical (left as exercise) or spherical coordinates. For ﬁxed φ, θ we √ slicing our region by rays straight out of the origin; ρ ranges from its value are on the plane z = 1/ 2 to its value on the sphere ρ = 1. Spherical coordinate equation of the plane: √ √ z = ρ cos φ = 1/ 2, so ρ = sec φ/ 2. The volume is: � 2π � π/4 � 1 ρ2 sin φ dρ dφ dθ.\nsec φ\n(Bound for φ explained by looking at a slice by vertical plane θ = constant: the edge of the region 1 is at z = r = √2 ). Evaluation: not done. Final answer: 2π 5π − √ . 3 6 2\nApplication to gravitation. Gravitational force exerted on mass m at origin by a mass ΔM at (x, y, z) (picture shown) G ΔM m �x, y, z� G ΔM m � � � is given by |F | = , dir(F ) = , i.e. F = �x, y, z�. (G = gravitational ρ ρ3 ρ2 constant). If instead of a point mass we have a solid with density δ, then we must integrate contributions to gravitational attraction from small pieces ΔM = δ ΔV . So ��� ��� Gm �x, y, z� z � δ dV, i.e. z-component is Fz = Gm δ dV, . . . F = ρ3 ρ3 R R If we can set up to use symmetry, then Fz can be computed nicely using spherical coordinates. General setup: place the mass m at the origin (so integrand is as above), and place the solid � so that the z-axis is an axis of symmetry. Then F = �0, 0, Fz � by symmetry, and we have only one;;component to compute. Then ��� ��� ��� z ρ cos φ 2 Fz = Gm δ dV = Gm δ ρ sin φ dρ dφ dθ = Gm δ cos φ sin φ dρ dφ dθ. 3 ρ3 R ρ R R Example: Newton’s theorem: the gravitational attraction of a spherical planet with uniform density δ is the same as that of the equivalent point mass at its center.\n[[Setup: the sphere has radius a and is centered on the positive z-axis, tangent to xy-plane at the origin; the test mass is m at the origin. Then ��� � 2π � π/2 � 2a cos φ 4 GM m z Fz = Gm δ dV = Gm δ cos φ sin φ dρ dφ dθ = · · · = Gmδ πa = 3 3 a2 R ρ 0 0 0 where M = mass of the planet = 4 πa3 δ. (The bounds for ρ and φ need to be explained carefully, 3 by drawing a diagram of a vertical slice with z and r coordinate axes, and the inscribed right triangle with vertices the two poles of the sphere + a point on its surface, the hypothenuse is the diameter 2a and we get ρ = 2a cos φ for the spherical coordinate equation of the sphere).]] 18.02 Lecture 27. – Thu, Nov 15, 2007\nHandouts: PS10 solutions, PS11 Vector ﬁelds in space. ˆ � At every point in space, F = P ˆ + Qˆ + Rk, where P, Q, R are functions of x, y, z. ı j � Examples: force ﬁelds (gravitational force F = −c�x, y, z�/ρ3 ; electric ﬁeld E, magnetic ﬁeld B); velocity ﬁelds (ﬂuid ﬂow, v = v(x, y, z)); gradient ﬁelds (e.g. temperature and pressure gradients). Flux. � � � ˆ Recall: in 2D, ﬂux of a vector ﬁeld F across a curve C = C F · n ds. In 3D, ﬂux of a vector ﬁeld is a double integral: ﬂux through a surface, not a curve! �� � ˆ � ˆ F vector ﬁeld, S surface, n unit normal vector: Flux = F · n dS. � � ˆ ˆ Notation: dS = n dS. (We’ll see that dS is often easier to compute than n and dS). ˆ Remark: there are 2 choices for n (choose which way is counted positively!) Geometric interpretation of ﬂux: � As in 2D, if F = velocity of a ﬂuid ﬂow, then ﬂux = ﬂow per unit time across S. Cut S into small pieces, then over each small piece: what passes through ΔS in unit time is the � contents of a parallelepiped with base ΔS and third side given by F . � ˆ Volume of box = base × height = (F · n) ΔS. • Examples: ˆ � 1) F = xˆ + yˆ + zk through sphere of radius a centered at 0. ı j 1 1 ˆ ˆ n = a �x, y, z� (other choice: − a �x, y, z�; traditionally choose n pointing out). �� �� 1 � ˆ � ˆ ˆ F · n = �x, y, z� · n = a (x2 + y 2 + z 2 ) = a, so S F · ndS = S a dS = a (4πa2 ).;;2 ˆ � ˆ � 2) Same sphere, H = zk: H · n = za . �� �� 2 � 2π � π 2 � π z 4 a cos2 φ 2 � � H · dS = dS = a sin φ dφdθ = 2πa3 cos2 φ sin φ dφ = πa3 . 3 a a S S 0 0 0\nSetup. Sometimes we have an easy geometric argument, but in general we must compute the � ˆ surface integral. The setup requires the use of two parameters to describe the surface, and F · n dS must be expressed in terms of them. How to do this depends on the type of surface. For now, formulas to remember: ˆ ˆ 0) plane z = a parallel to xy-plane: n = ±k, dS = dx dy. (similarly for planes // xz or yz-plane). 1 ˆ 1) sphere of radius a centered at origin: use φ, θ (substitute ρ = a for evaluation); n = a �x, y, z�, dS = a2 sin φ dφ dθ. ˆ 2) cylinder of radius a centered on z-axis: use z, θ (substitute r = a for evaluation): n is radially 1 ˆ out in horizontal directions away from z-axis, i.e. n = a �x, y, 0�; and dS = a dz dθ (explained by drawing a picture of a “rectangular” piece of cylinder, ΔS = (Δz) (aΔθ)). ˆ 3) graph z = f (x, y): use x, y (substitute z = f (x, y)). We’ll see on Friday that n and dS ˆ separately are complicated, but n dS = �−fx , −fy , 1� dx dy. 18.02 Lecture 28. – Fri, Nov 16, 2007\n�� � � ˆ Last time, we deﬁned the ﬂux of F through surface S as F · n dS, and saw how to set up in various cases. Continue with more: Flux through a graph. If S is the graph of some function z = f (x, y) over a region R of xy-plane: use x and y as variables. Contribution of a small piece of S to ﬂux integral? Consider portion of S lying above a small rectangle Δx Δy in xy-plane. In linear approximation it is a parallelogram. (picture shown) The vertices are (x, y, f (x, y)); (x + Δx, y, f (x + Δx, y)); (x, y + Δy, f (x, y + Δy)); etc. Linear approximation: f (x + Δx, y) � f (x, y) + Δx fx (x, y), and f (x, y + Δy) � f (x, y) + Δy fy (x, y). So the sides of the parallelogram are �Δx, 0, Δx fx � and �0, Δy, Δy fy �, and � � � ˆ ˆ k � ˆ � ı j � � ΔS = (Δx �1, 0, fx �) × (Δy �0, 1, fy �) = ΔxΔy � 1 0 fx � = �−fx , −fy , 1�ΔxΔy. � � � 0 1 fy � � So dS = ±�−fx , −fy , 1�dx dy. �\n �−fx , −fy , 1� 2 2 � ˆ (From this we can get n = dir(dS ) = � and dS\n S |\n fx + fy + 1 dx dy. The d �\n 2 2 fx + fy + 1 √ conversion factor · · · between dS and dA relates area on S to area of projection in xy-plane.) ˆ � • Example: ﬂux of F = zk through S = portion of paraboloid z = x2 + y 2 above unit disk, oriented with normal pointing up (and into the paraboloid): geometrically ﬂux should be > 0 ˆ (asked using ﬂashcards). We have n dS = �−2x, −2y, 1� dx dy, and �� �� �� � 2π � 1 2 2 � · dS = � F z dx dy = (x + y ) dx dy = r2 r dr dθ = π/2.\nS S S 0 0\nParametric surfaces. If we can describe S by parametric equations x = x(u, v), y = y(u, v), � z = z(u, v) (i.e. � = �(u, v)), then we can set up ﬂux integrals using variables u, v. To ﬁnd dS , r r;;consider a small portion of surface corresponding to changes Δu and Δv in parameters, it’s a parallelogram with sides �(u + Δu, v) − �(u, v) ≈ (∂�/∂u) Δu and (∂�/∂v) Δv, so r r r r � � � � � � r r r r � = ± ∂� Δu × ∂� Δv , � = ± ∂� × ∂� du dv. ΔS dS ∂u ∂v ∂u ∂v (This generalizes all formulas previously seen; but won’t be needed on exam). Implicit surfaces: If we have an implicitly deﬁned surface g(x, y, z) = 0, then we have a (non­ unit) normal vector N = �g. (similarly for a slanted plane, from equation ax + by + cz = d we get N = �a, b, c�). ˆ Unit normal n = ±N/|N|; surface element ΔS = ? Look at projection to xy-plane: ΔA = ˆ ΔS cos α = (N · k/|N|) ΔS (where α = angle between slanted surface element and horizontal: ˆ projection shrinks one direction by factor cos α = (N · k)/|N|, preserves the other). ˆ |N| |N|n N ˆ Hence dS = dx dy = ± dx dy. dA, and n dS = ˆ ˆ ˆ N·k N·k N ·\nk |N| dA, I forgot the absolute value).\n (In fact the ﬁrst formula should be dS = ˆ |N · k| Note: if S is vertical then the denominator is zero, can’t project to xy-plane any more (but one could project e.g. to the xz-plane). Example: if S is a graph, g(x, y, z) = z − f (x, y) = 0, then N = �gx , gy , gz � = �−fx , −fy , 1�, ˆ � N · k = 1, so we recover the formula dS = �−fx , −fy , 1�dx dy seen before. Divergence theorem. (“Gauss-Green theorem”) – 3D analogue of Green theorem for ﬂux. � If S is a closed surface bounding a region D, with normal pointing outwards, and F vector ﬁeld deﬁned and diﬀerentiable over all of D, then �� ��� ˆ � � � F · dS = div F dV, where div (P ˆ + Qˆ + Rk) = Px + Qy + Rz . ı j\nS D\nˆ � � Example: ﬂux of F = zk out of sphere of radius a (seen Thursday): div F = 0 + 0 + 1 = 1, so � · dS = 3 vol(D) = 4πa3 /3. � SF\n� Physical interpretation (mentioned very quickly and verbally only): div F = source rate = ﬂux generated per unit volume. So the divergence theorem says: the ﬂux outwards through S (net amount leaving D per unit time) is equal to the total amount of sources in D.'
7520,'lecture','en',6379,'2007-11-15','2009-09-10','Lecture 27: Vector fields in 3D; surface integrals and flux',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 26. –\nTue, Nov 13, 2007\nSpherical coordinates (ρ, φ, θ). ρ = rho = distance to origin. φ = ϕ = phi = angle down from z-axis. θ = same as in cylindrical coordinates. Diagram drawn in space, and picture of 2D slice by vertical plane with z, r coordinates. Formulas to remember: z = ρ cos φ, r = ρ sin φ (so x = ρ sin φ cos θ, y = ρ sin φ sin θ). � √ ρ = x2 + y 2 + z 2 = r2 + z 2 . The equation ρ = a deﬁnes the sphere of radius a centered at 0. On the surface of the sphere, φ is similar to latitude, except it’s 0 at the north pole, π/2 on the equator, π at the south pole. θ is similar to longitude. � φ = π/4 is a cone (asked using ﬂash cards) (z = r = x2 + y 2 ). φ = π/2 is the xy-plane. Volume element: dV = ρ2 sin φ dρ dφ dθ. To understand this formula, ﬁrst study surface area on sphere of radius a: picture shown of a “rectangle” corresponding to Δφ, Δθ, with sides = portion of circle of radius a, of length aΔφ, and portion of circle of radius r = a sin φ, of length rΔθ = a sin φΔθ. So ΔS ≈ a2 sin φ ΔφΔθ, which gives the surface element dS = a2 sin φ dφdθ. The volume element follows: for a small “box”, ΔV = ΔS Δρ, so dV = dρ dS = ρ2 sin φ dρdφdθ. Example: recall the complicated example at end of Friday’s lecture (region sliced by a plane inside unit sphere). After rotating coordinate system, the question becomes: volume of the portion √ of unit sphere above the plane z = 1/ 2? (picture drawn). This can be set up in cylindrical (left as exercise) or spherical coordinates. For ﬁxed φ, θ we √ slicing our region by rays straight out of the origin; ρ ranges from its value are on the plane z = 1/ 2 to its value on the sphere ρ = 1. Spherical coordinate equation of the plane: √ √ z = ρ cos φ = 1/ 2, so ρ = sec φ/ 2. The volume is: � 2π � π/4 � 1 ρ2 sin φ dρ dφ dθ.\nsec φ\n(Bound for φ explained by looking at a slice by vertical plane θ = constant: the edge of the region 1 is at z = r = √2 ). Evaluation: not done. Final answer: 2π 5π − √ . 3 6 2\nApplication to gravitation. Gravitational force exerted on mass m at origin by a mass ΔM at (x, y, z) (picture shown) G ΔM m �x, y, z� G ΔM m � � � is given by |F | = , dir(F ) = , i.e. F = �x, y, z�. (G = gravitational ρ ρ3 ρ2 constant). If instead of a point mass we have a solid with density δ, then we must integrate contributions to gravitational attraction from small pieces ΔM = δ ΔV . So ��� ��� Gm �x, y, z� z � δ dV, i.e. z-component is Fz = Gm δ dV, . . . F = ρ3 ρ3 R R If we can set up to use symmetry, then Fz can be computed nicely using spherical coordinates. General setup: place the mass m at the origin (so integrand is as above), and place the solid � so that the z-axis is an axis of symmetry. Then F = �0, 0, Fz � by symmetry, and we have only one;;component to compute. Then ��� ��� ��� z ρ cos φ 2 Fz = Gm δ dV = Gm δ ρ sin φ dρ dφ dθ = Gm δ cos φ sin φ dρ dφ dθ. 3 ρ3 R ρ R R Example: Newton’s theorem: the gravitational attraction of a spherical planet with uniform density δ is the same as that of the equivalent point mass at its center.\n[[Setup: the sphere has radius a and is centered on the positive z-axis, tangent to xy-plane at the origin; the test mass is m at the origin. Then ��� � 2π � π/2 � 2a cos φ 4 GM m z Fz = Gm δ dV = Gm δ cos φ sin φ dρ dφ dθ = · · · = Gmδ πa = 3 3 a2 R ρ 0 0 0 where M = mass of the planet = 4 πa3 δ. (The bounds for ρ and φ need to be explained carefully, 3 by drawing a diagram of a vertical slice with z and r coordinate axes, and the inscribed right triangle with vertices the two poles of the sphere + a point on its surface, the hypothenuse is the diameter 2a and we get ρ = 2a cos φ for the spherical coordinate equation of the sphere).]] 18.02 Lecture 27. – Thu, Nov 15, 2007\nHandouts: PS10 solutions, PS11 Vector ﬁelds in space. ˆ � At every point in space, F = P ˆ + Qˆ + Rk, where P, Q, R are functions of x, y, z. ı j � Examples: force ﬁelds (gravitational force F = −c�x, y, z�/ρ3 ; electric ﬁeld E, magnetic ﬁeld B); velocity ﬁelds (ﬂuid ﬂow, v = v(x, y, z)); gradient ﬁelds (e.g. temperature and pressure gradients). Flux. � � � ˆ Recall: in 2D, ﬂux of a vector ﬁeld F across a curve C = C F · n ds. In 3D, ﬂux of a vector ﬁeld is a double integral: ﬂux through a surface, not a curve! �� � ˆ � ˆ F vector ﬁeld, S surface, n unit normal vector: Flux = F · n dS. � � ˆ ˆ Notation: dS = n dS. (We’ll see that dS is often easier to compute than n and dS). ˆ Remark: there are 2 choices for n (choose which way is counted positively!) Geometric interpretation of ﬂux: � As in 2D, if F = velocity of a ﬂuid ﬂow, then ﬂux = ﬂow per unit time across S. Cut S into small pieces, then over each small piece: what passes through ΔS in unit time is the � contents of a parallelepiped with base ΔS and third side given by F . � ˆ Volume of box = base × height = (F · n) ΔS. • Examples: ˆ � 1) F = xˆ + yˆ + zk through sphere of radius a centered at 0. ı j 1 1 ˆ ˆ n = a �x, y, z� (other choice: − a �x, y, z�; traditionally choose n pointing out). �� �� 1 � ˆ � ˆ ˆ F · n = �x, y, z� · n = a (x2 + y 2 + z 2 ) = a, so S F · ndS = S a dS = a (4πa2 ).;;2 ˆ � ˆ � 2) Same sphere, H = zk: H · n = za . �� �� 2 � 2π � π 2 � π z 4 a cos2 φ 2 � � H · dS = dS = a sin φ dφdθ = 2πa3 cos2 φ sin φ dφ = πa3 . 3 a a S S 0 0 0\nSetup. Sometimes we have an easy geometric argument, but in general we must compute the � ˆ surface integral. The setup requires the use of two parameters to describe the surface, and F · n dS must be expressed in terms of them. How to do this depends on the type of surface. For now, formulas to remember: ˆ ˆ 0) plane z = a parallel to xy-plane: n = ±k, dS = dx dy. (similarly for planes // xz or yz-plane). 1 ˆ 1) sphere of radius a centered at origin: use φ, θ (substitute ρ = a for evaluation); n = a �x, y, z�, dS = a2 sin φ dφ dθ. ˆ 2) cylinder of radius a centered on z-axis: use z, θ (substitute r = a for evaluation): n is radially 1 ˆ out in horizontal directions away from z-axis, i.e. n = a �x, y, 0�; and dS = a dz dθ (explained by drawing a picture of a “rectangular” piece of cylinder, ΔS = (Δz) (aΔθ)). ˆ 3) graph z = f (x, y): use x, y (substitute z = f (x, y)). We’ll see on Friday that n and dS ˆ separately are complicated, but n dS = �−fx , −fy , 1� dx dy. 18.02 Lecture 28. – Fri, Nov 16, 2007\n�� � � ˆ Last time, we deﬁned the ﬂux of F through surface S as F · n dS, and saw how to set up in various cases. Continue with more: Flux through a graph. If S is the graph of some function z = f (x, y) over a region R of xy-plane: use x and y as variables. Contribution of a small piece of S to ﬂux integral? Consider portion of S lying above a small rectangle Δx Δy in xy-plane. In linear approximation it is a parallelogram. (picture shown) The vertices are (x, y, f (x, y)); (x + Δx, y, f (x + Δx, y)); (x, y + Δy, f (x, y + Δy)); etc. Linear approximation: f (x + Δx, y) � f (x, y) + Δx fx (x, y), and f (x, y + Δy) � f (x, y) + Δy fy (x, y). So the sides of the parallelogram are �Δx, 0, Δx fx � and �0, Δy, Δy fy �, and � � � ˆ ˆ k � ˆ � ı j � � ΔS = (Δx �1, 0, fx �) × (Δy �0, 1, fy �) = ΔxΔy � 1 0 fx � = �−fx , −fy , 1�ΔxΔy. � � � 0 1 fy � � So dS = ±�−fx , −fy , 1�dx dy. �\n �−fx , −fy , 1� 2 2 � ˆ (From this we can get n = dir(dS ) = � and dS\n S |\n fx + fy + 1 dx dy. The d �\n 2 2 fx + fy + 1 √ conversion factor · · · between dS and dA relates area on S to area of projection in xy-plane.) ˆ � • Example: ﬂux of F = zk through S = portion of paraboloid z = x2 + y 2 above unit disk, oriented with normal pointing up (and into the paraboloid): geometrically ﬂux should be > 0 ˆ (asked using ﬂashcards). We have n dS = �−2x, −2y, 1� dx dy, and �� �� �� � 2π � 1 2 2 � · dS = � F z dx dy = (x + y ) dx dy = r2 r dr dθ = π/2.\nS S S 0 0\nParametric surfaces. If we can describe S by parametric equations x = x(u, v), y = y(u, v), � z = z(u, v) (i.e. � = �(u, v)), then we can set up ﬂux integrals using variables u, v. To ﬁnd dS , r r;;consider a small portion of surface corresponding to changes Δu and Δv in parameters, it’s a parallelogram with sides �(u + Δu, v) − �(u, v) ≈ (∂�/∂u) Δu and (∂�/∂v) Δv, so r r r r � � � � � � r r r r � = ± ∂� Δu × ∂� Δv , � = ± ∂� × ∂� du dv. ΔS dS ∂u ∂v ∂u ∂v (This generalizes all formulas previously seen; but won’t be needed on exam). Implicit surfaces: If we have an implicitly deﬁned surface g(x, y, z) = 0, then we have a (non­ unit) normal vector N = �g. (similarly for a slanted plane, from equation ax + by + cz = d we get N = �a, b, c�). ˆ Unit normal n = ±N/|N|; surface element ΔS = ? Look at projection to xy-plane: ΔA = ˆ ΔS cos α = (N · k/|N|) ΔS (where α = angle between slanted surface element and horizontal: ˆ projection shrinks one direction by factor cos α = (N · k)/|N|, preserves the other). ˆ |N| |N|n N ˆ Hence dS = dx dy = ± dx dy. dA, and n dS = ˆ ˆ ˆ N·k N·k N ·\nk |N| dA, I forgot the absolute value).\n (In fact the ﬁrst formula should be dS = ˆ |N · k| Note: if S is vertical then the denominator is zero, can’t project to xy-plane any more (but one could project e.g. to the xz-plane). Example: if S is a graph, g(x, y, z) = z − f (x, y) = 0, then N = �gx , gy , gz � = �−fx , −fy , 1�, ˆ � N · k = 1, so we recover the formula dS = �−fx , −fy , 1�dx dy seen before. Divergence theorem. (“Gauss-Green theorem”) – 3D analogue of Green theorem for ﬂux. � If S is a closed surface bounding a region D, with normal pointing outwards, and F vector ﬁeld deﬁned and diﬀerentiable over all of D, then �� ��� ˆ � � � F · dS = div F dV, where div (P ˆ + Qˆ + Rk) = Px + Qy + Rz . ı j\nS D\nˆ � � Example: ﬂux of F = zk out of sphere of radius a (seen Thursday): div F = 0 + 0 + 1 = 1, so � · dS = 3 vol(D) = 4πa3 /3. � SF\n� Physical interpretation (mentioned very quickly and verbally only): div F = source rate = ﬂux generated per unit volume. So the divergence theorem says: the ﬂux outwards through S (net amount leaving D per unit time) is equal to the total amount of sources in D.'
7521,'lecture','en',6379,'2007-11-16','2009-09-10','Lecture 28: Divergence theorem',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 26. –\nTue, Nov 13, 2007\nSpherical coordinates (ρ, φ, θ). ρ = rho = distance to origin. φ = ϕ = phi = angle down from z-axis. θ = same as in cylindrical coordinates. Diagram drawn in space, and picture of 2D slice by vertical plane with z, r coordinates. Formulas to remember: z = ρ cos φ, r = ρ sin φ (so x = ρ sin φ cos θ, y = ρ sin φ sin θ). � √ ρ = x2 + y 2 + z 2 = r2 + z 2 . The equation ρ = a deﬁnes the sphere of radius a centered at 0. On the surface of the sphere, φ is similar to latitude, except it’s 0 at the north pole, π/2 on the equator, π at the south pole. θ is similar to longitude. � φ = π/4 is a cone (asked using ﬂash cards) (z = r = x2 + y 2 ). φ = π/2 is the xy-plane. Volume element: dV = ρ2 sin φ dρ dφ dθ. To understand this formula, ﬁrst study surface area on sphere of radius a: picture shown of a “rectangle” corresponding to Δφ, Δθ, with sides = portion of circle of radius a, of length aΔφ, and portion of circle of radius r = a sin φ, of length rΔθ = a sin φΔθ. So ΔS ≈ a2 sin φ ΔφΔθ, which gives the surface element dS = a2 sin φ dφdθ. The volume element follows: for a small “box”, ΔV = ΔS Δρ, so dV = dρ dS = ρ2 sin φ dρdφdθ. Example: recall the complicated example at end of Friday’s lecture (region sliced by a plane inside unit sphere). After rotating coordinate system, the question becomes: volume of the portion √ of unit sphere above the plane z = 1/ 2? (picture drawn). This can be set up in cylindrical (left as exercise) or spherical coordinates. For ﬁxed φ, θ we √ slicing our region by rays straight out of the origin; ρ ranges from its value are on the plane z = 1/ 2 to its value on the sphere ρ = 1. Spherical coordinate equation of the plane: √ √ z = ρ cos φ = 1/ 2, so ρ = sec φ/ 2. The volume is: � 2π � π/4 � 1 ρ2 sin φ dρ dφ dθ.\nsec φ\n(Bound for φ explained by looking at a slice by vertical plane θ = constant: the edge of the region 1 is at z = r = √2 ). Evaluation: not done. Final answer: 2π 5π − √ . 3 6 2\nApplication to gravitation. Gravitational force exerted on mass m at origin by a mass ΔM at (x, y, z) (picture shown) G ΔM m �x, y, z� G ΔM m � � � is given by |F | = , dir(F ) = , i.e. F = �x, y, z�. (G = gravitational ρ ρ3 ρ2 constant). If instead of a point mass we have a solid with density δ, then we must integrate contributions to gravitational attraction from small pieces ΔM = δ ΔV . So ��� ��� Gm �x, y, z� z � δ dV, i.e. z-component is Fz = Gm δ dV, . . . F = ρ3 ρ3 R R If we can set up to use symmetry, then Fz can be computed nicely using spherical coordinates. General setup: place the mass m at the origin (so integrand is as above), and place the solid � so that the z-axis is an axis of symmetry. Then F = �0, 0, Fz � by symmetry, and we have only one;;component to compute. Then ��� ��� ��� z ρ cos φ 2 Fz = Gm δ dV = Gm δ ρ sin φ dρ dφ dθ = Gm δ cos φ sin φ dρ dφ dθ. 3 ρ3 R ρ R R Example: Newton’s theorem: the gravitational attraction of a spherical planet with uniform density δ is the same as that of the equivalent point mass at its center.\n[[Setup: the sphere has radius a and is centered on the positive z-axis, tangent to xy-plane at the origin; the test mass is m at the origin. Then ��� � 2π � π/2 � 2a cos φ 4 GM m z Fz = Gm δ dV = Gm δ cos φ sin φ dρ dφ dθ = · · · = Gmδ πa = 3 3 a2 R ρ 0 0 0 where M = mass of the planet = 4 πa3 δ. (The bounds for ρ and φ need to be explained carefully, 3 by drawing a diagram of a vertical slice with z and r coordinate axes, and the inscribed right triangle with vertices the two poles of the sphere + a point on its surface, the hypothenuse is the diameter 2a and we get ρ = 2a cos φ for the spherical coordinate equation of the sphere).]] 18.02 Lecture 27. – Thu, Nov 15, 2007\nHandouts: PS10 solutions, PS11 Vector ﬁelds in space. ˆ � At every point in space, F = P ˆ + Qˆ + Rk, where P, Q, R are functions of x, y, z. ı j � Examples: force ﬁelds (gravitational force F = −c�x, y, z�/ρ3 ; electric ﬁeld E, magnetic ﬁeld B); velocity ﬁelds (ﬂuid ﬂow, v = v(x, y, z)); gradient ﬁelds (e.g. temperature and pressure gradients). Flux. � � � ˆ Recall: in 2D, ﬂux of a vector ﬁeld F across a curve C = C F · n ds. In 3D, ﬂux of a vector ﬁeld is a double integral: ﬂux through a surface, not a curve! �� � ˆ � ˆ F vector ﬁeld, S surface, n unit normal vector: Flux = F · n dS. � � ˆ ˆ Notation: dS = n dS. (We’ll see that dS is often easier to compute than n and dS). ˆ Remark: there are 2 choices for n (choose which way is counted positively!) Geometric interpretation of ﬂux: � As in 2D, if F = velocity of a ﬂuid ﬂow, then ﬂux = ﬂow per unit time across S. Cut S into small pieces, then over each small piece: what passes through ΔS in unit time is the � contents of a parallelepiped with base ΔS and third side given by F . � ˆ Volume of box = base × height = (F · n) ΔS. • Examples: ˆ � 1) F = xˆ + yˆ + zk through sphere of radius a centered at 0. ı j 1 1 ˆ ˆ n = a �x, y, z� (other choice: − a �x, y, z�; traditionally choose n pointing out). �� �� 1 � ˆ � ˆ ˆ F · n = �x, y, z� · n = a (x2 + y 2 + z 2 ) = a, so S F · ndS = S a dS = a (4πa2 ).;;2 ˆ � ˆ � 2) Same sphere, H = zk: H · n = za . �� �� 2 � 2π � π 2 � π z 4 a cos2 φ 2 � � H · dS = dS = a sin φ dφdθ = 2πa3 cos2 φ sin φ dφ = πa3 . 3 a a S S 0 0 0\nSetup. Sometimes we have an easy geometric argument, but in general we must compute the � ˆ surface integral. The setup requires the use of two parameters to describe the surface, and F · n dS must be expressed in terms of them. How to do this depends on the type of surface. For now, formulas to remember: ˆ ˆ 0) plane z = a parallel to xy-plane: n = ±k, dS = dx dy. (similarly for planes // xz or yz-plane). 1 ˆ 1) sphere of radius a centered at origin: use φ, θ (substitute ρ = a for evaluation); n = a �x, y, z�, dS = a2 sin φ dφ dθ. ˆ 2) cylinder of radius a centered on z-axis: use z, θ (substitute r = a for evaluation): n is radially 1 ˆ out in horizontal directions away from z-axis, i.e. n = a �x, y, 0�; and dS = a dz dθ (explained by drawing a picture of a “rectangular” piece of cylinder, ΔS = (Δz) (aΔθ)). ˆ 3) graph z = f (x, y): use x, y (substitute z = f (x, y)). We’ll see on Friday that n and dS ˆ separately are complicated, but n dS = �−fx , −fy , 1� dx dy. 18.02 Lecture 28. – Fri, Nov 16, 2007\n�� � � ˆ Last time, we deﬁned the ﬂux of F through surface S as F · n dS, and saw how to set up in various cases. Continue with more: Flux through a graph. If S is the graph of some function z = f (x, y) over a region R of xy-plane: use x and y as variables. Contribution of a small piece of S to ﬂux integral? Consider portion of S lying above a small rectangle Δx Δy in xy-plane. In linear approximation it is a parallelogram. (picture shown) The vertices are (x, y, f (x, y)); (x + Δx, y, f (x + Δx, y)); (x, y + Δy, f (x, y + Δy)); etc. Linear approximation: f (x + Δx, y) � f (x, y) + Δx fx (x, y), and f (x, y + Δy) � f (x, y) + Δy fy (x, y). So the sides of the parallelogram are �Δx, 0, Δx fx � and �0, Δy, Δy fy �, and � � � ˆ ˆ k � ˆ � ı j � � ΔS = (Δx �1, 0, fx �) × (Δy �0, 1, fy �) = ΔxΔy � 1 0 fx � = �−fx , −fy , 1�ΔxΔy. � � � 0 1 fy � � So dS = ±�−fx , −fy , 1�dx dy. �\n �−fx , −fy , 1� 2 2 � ˆ (From this we can get n = dir(dS ) = � and dS\n S |\n fx + fy + 1 dx dy. The d �\n 2 2 fx + fy + 1 √ conversion factor · · · between dS and dA relates area on S to area of projection in xy-plane.) ˆ � • Example: ﬂux of F = zk through S = portion of paraboloid z = x2 + y 2 above unit disk, oriented with normal pointing up (and into the paraboloid): geometrically ﬂux should be > 0 ˆ (asked using ﬂashcards). We have n dS = �−2x, −2y, 1� dx dy, and �� �� �� � 2π � 1 2 2 � · dS = � F z dx dy = (x + y ) dx dy = r2 r dr dθ = π/2.\nS S S 0 0\nParametric surfaces. If we can describe S by parametric equations x = x(u, v), y = y(u, v), � z = z(u, v) (i.e. � = �(u, v)), then we can set up ﬂux integrals using variables u, v. To ﬁnd dS , r r;;consider a small portion of surface corresponding to changes Δu and Δv in parameters, it’s a parallelogram with sides �(u + Δu, v) − �(u, v) ≈ (∂�/∂u) Δu and (∂�/∂v) Δv, so r r r r � � � � � � r r r r � = ± ∂� Δu × ∂� Δv , � = ± ∂� × ∂� du dv. ΔS dS ∂u ∂v ∂u ∂v (This generalizes all formulas previously seen; but won’t be needed on exam). Implicit surfaces: If we have an implicitly deﬁned surface g(x, y, z) = 0, then we have a (non­ unit) normal vector N = �g. (similarly for a slanted plane, from equation ax + by + cz = d we get N = �a, b, c�). ˆ Unit normal n = ±N/|N|; surface element ΔS = ? Look at projection to xy-plane: ΔA = ˆ ΔS cos α = (N · k/|N|) ΔS (where α = angle between slanted surface element and horizontal: ˆ projection shrinks one direction by factor cos α = (N · k)/|N|, preserves the other). ˆ |N| |N|n N ˆ Hence dS = dx dy = ± dx dy. dA, and n dS = ˆ ˆ ˆ N·k N·k N ·\nk |N| dA, I forgot the absolute value).\n (In fact the ﬁrst formula should be dS = ˆ |N · k| Note: if S is vertical then the denominator is zero, can’t project to xy-plane any more (but one could project e.g. to the xz-plane). Example: if S is a graph, g(x, y, z) = z − f (x, y) = 0, then N = �gx , gy , gz � = �−fx , −fy , 1�, ˆ � N · k = 1, so we recover the formula dS = �−fx , −fy , 1�dx dy seen before. Divergence theorem. (“Gauss-Green theorem”) – 3D analogue of Green theorem for ﬂux. � If S is a closed surface bounding a region D, with normal pointing outwards, and F vector ﬁeld deﬁned and diﬀerentiable over all of D, then �� ��� ˆ � � � F · dS = div F dV, where div (P ˆ + Qˆ + Rk) = Px + Qy + Rz . ı j\nS D\nˆ � � Example: ﬂux of F = zk out of sphere of radius a (seen Thursday): div F = 0 + 0 + 1 = 1, so � · dS = 3 vol(D) = 4πa3 /3. � SF\n� Physical interpretation (mentioned very quickly and verbally only): div F = source rate = ﬂux generated per unit volume. So the divergence theorem says: the ﬂux outwards through S (net amount leaving D per unit time) is equal to the total amount of sources in D.'
7522,'lecture','en',6379,'2007-11-20','2009-09-10','Lecture 29: Divergence theorem (cont.): applications and proof',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 29. –\nTue, Nov 20, 2007\nRecall statement of divergence theorem:\nS\n� F · dS =\nD\ndiv F dV .\nDel operator. � = �∂/∂x, ∂/∂y, ∂/∂z� (symbolic notation!) �f = �∂f /∂x, ∂f /∂y, ∂f /∂z� = gradient. � · F = �∂/∂x, ∂/∂y, ∂/∂z� · �P, Q, R� = Px + Qy + Rz = divergence. Physical interpretation. div F = source rate = ﬂux generated per unit volume. Imagine an ��� incompressible ﬂuid ﬂow (i.e. a given mass occupies a ﬁxed volume) with velocity F, then �� ˆ D div F dV = S F · n dS = ﬂux through S is the net amount leaving D per unit time = total amount of sources (minus sinks) in D. �� ��� � Proof of divergence theorem. To show S �P, Q, R� · dS = (P + Qy + Rz ) dV , we can �� ��� D x ˆ � separate into sum over components and just show S Rk · dS = Rz dV & same for P and Q. D If the region D is vertically simple, i.e. top and bottom surfaces are graphs, z1 (x, y) ≤ z ≤ z2 (x, y), with (x, y) in some region U of xy-plane: r.h.s. is ��� � � � z2 (x,y) �� � � Rz dV = Rz dz dx dy = (R(x, y, z2 (x, y)) − R(x, y, z1 (x, y)) dx dy.\nD U z1 (x,y) U\n�� �� ˆ � � Flux through top: dS = �−∂z2 /∂x, −∂z2 /∂y, 1�dx dy, so top Rk·dS = R(x, y, z2 (x, y)) dx dy. �� �� ˆ � � −R(x, y, z1 (x, y)) dx dy. Bottom: dS = −�−∂z1 /∂x, −∂z1 /∂y, 1�dx dy, so bottom Rk · dS = ˆ Sides: sides are vertical, n is horizontal, F is vertical so ﬂux = 0.\n Given any region D, decompose �� into vertically simple pieces (illustrated for a donut). Then\n it ��� = sum of pieces (clear), and S = sum of pieces since the internal boundaries cancel each D other. Diﬀusion equation: governs motion of smoke in (immobile) air (dye in solution, ...) � 2 � 2 2 ∂u 2u = k ∂ u + ∂ u + ∂ u , The equation is: = k� ∂t ∂x2 ∂y 2 ∂z 2 where u(x, y, z, t) = concentration of smoke; we’ll also introduce F = ﬂow of the smoke. It’s also the heat equation (u = temperature). Equation uses two inputs: 1) Physics: F = −k�u (ﬂow goes from highest to lowest concentration, faster if concentration changes more abruptly). �� ˆ 2) Flux and quantity of smoke are related: if D bounded by closed surface S, then S F · n dS = ��� d − dt D u dV . (ﬂux out of D = - variation of total amount of smoke inside D) ��� ∂ (This can be explained in terms of By diﬀerentiation under integral sign, the r.h.s. is − D ∂t u dV integral as a sum of u(xi , yi , zi , t)ΔVi and derivative of sum is sum of derivatives) and by divergence ��� theorem the l.h.s. is D div F dV . Dividing by volume of D, we get ��� ��� 1 ∂u 1 − dV = div F dV. vol(D) vol(D) D ∂t D Same average values over any region; taking limit as D shrinks to a point, get ∂u/∂t = −div F. Combining, we get the diﬀusion equation: ∂u/∂t = −div F = +kdiv (�u) = k�2 u.'
7523,'lecture','en',6379,'2007-11-27','2009-09-10','Lecture 30: Line integrals in space, curl, exactness and potentials',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 30. –\nTue, Nov 27, 2007\nHandouts: practice exams 4A and 4B. Clariﬁcation from end of last lecture: we derived the diﬀusion equation from 2 inputs. u = concentration, F = ﬂow, satisfy: 1) from physics: F = −k�u, 2) from divergence theorem: ∂u/∂t = −div F. Combining, we get the diﬀusion equation: ∂u/∂t = −div F = +kdiv (�u) = k�2 u. Line integrals in space. Force ﬁeld F = �P, Q, R�, curve C in space, d� = �dx, dy, dz� r � � ⇒ Work = C F ·\nd� = C P dx + Q dy + R dz. r Example: F = �yz, xz, xy�. C: x = t3 , y = t2 , z = t. 0 ≤ t ≤ 1. Then dx = 3t2 dt, dy = 2tdt,\n dz = dt and substitute: � � � 1 F · d� = r yzdx + xzdy + xydz = 6t5 dt = 1\nC C 0\n(In general, express (x, y, z) in terms of a single parameter: 1 degree of freedom) Same F, curve C � = segments from (0, 0, 0) to (1, 0, 0) to (1, 1, 0) to (1, 1, 1). In the xy-plane, ˆ r work. For the last segment, x = y = 1, dx = dy = 0, so z = 0 =⇒ F = xyk, so F · d� = 0, no � 1 F = �z, z, 1� and d� = �0, 0, dz�. We get 0 1 dz = 1. r Both give the same answer because F is conservative, in fact F = �(xyz). Recall the fundamental theorem of calculus for line integrals: � P1 �f · d� = f (P1 ) − f (P0 ). r\nP0\nGradient ﬁelds. F = �P, Q, R� = �fx , fy , fz � ? Then fxy = fyx , fxz = fzx , fyz = fzy , so Py = Qx , Pz = Rx , Qz = Ry . Theorem: F is a gradient ﬁeld if and only if these equalities hold (assuming deﬁned in whole space or simply connected region) ˆ Example: for which a, b is axyˆ + (x2 + z 3 )ˆ + (byz 2 − 4z 3 )k a gradient ﬁeld? ı j Py = ax = 2x = Qx so a = 2; Pz = 0 = 0 = Rx ; Qz = 3z 2 = bz 2 = Ry so b = 3. Systematic method to ﬁnd a potential: (carried out on above example) fx = 2xy, fy = x2 + z 3 , fz = 3yz 2 − 4z 3 : fx = 2xy ⇒ f (x, y, z) = x2 y + g(y, z). fy = x2 + gy = x2 + z 3 ⇒ gy = z 3 ⇒ g(y, z) = yz 3 + h(z), and f = x2 y + yz 3 + h(z). fz = 3yz 2 + h� (z) = 3yz 2 − 4z 3 ⇒ h� (z) = −4z 3 ⇒ h(z) = −z 4 + c, and f = x2 y + yz 3 − z 4 + c. �P Other method: f (x1 , y1 , z1 ) = f (0, 0, 0) + P01 F · d� (use a curve that gives an easy computation, r e.g. 3 segments parallel to axes). Curl: encodes by how much F fails to be conservative. ˆ curl �P, Q, R� = (Ry − Qz )ˆ + (Pz − Rx )ˆ + (Qx − Py )k. ı j;;How to remember the formula? Use the del operator � = �∂/∂x, ∂/∂y, ∂/∂z�.\n Recall from last week that � · F = �∂/∂x, ∂/∂y, ∂/∂z� · �P, Q, R� = Px + Qy + Rz = div F. � � ˆ � ˆ ˆ k � ı j � ∂ � ∂ ∂ Now we have: � × F =\n� ∂x ∂y ∂z � = curl F.\n � � � P Q R � Interpretation of curl for velocity ﬁelds: curl measures angular velocity. Example: rotation around z-axis at constant angular velocity ω (trajectories are circles centered on z-axis): v = �−ωy, ωx, 0�. ˆ ˆ Then � × v = ... = 0ˆ + 0ˆ + (ω + ω)k = 2ωk. So length of curl = twice angular velocity, and ı j direction = axis of rotation. A general motion can be complicated, but decomposes into various eﬀects. • curl measures the rotation component of a complex motion. 18.02 Lecture 31. – Thu, Nov 29, 2007\nHandouts: PS11 solutions, PS12.\n Stokes’ theorem is the 3D analogue of Green’s theorem for work (in the same sense as the\n divergence theorem is the 3D analogue of Green for ﬂux). � � ˆ � ˆ ˆ k � ı j � ∂ � ∂ ∂ Recall curl F = � × F =\n� ∂x ∂y ∂z � = �Ry − Qz , Pz − Rx , Qx − Py �. � � � P Q R � Stokes’ theorem: if C is a closed curve, and S any surface bounded by C, then � �� ˆ F · d� = r (� × F) · n dS.\nC S\nOrientation: compatibility of an orientation of C with an orientation of S (changing orientation changes sign on both sides of Stokes). ˆ Rule: if I walk along C in positive direction, with S to my left, then n is pointing up. (Various examples shown.) Another formulation (right-hand rule): if thumb points along C (1-D object), index ﬁnger towards ˆ S (2-D object), then middle ﬁnger points along n (3-D object). More examples shown. Example:\n Stokes vs.\n Green. If S is a portion of xy-plane bounded by a curve C coun­\n � � �� terclockwise, then C F · d� = C P dx + Q dy, by Green this is equal to S (Qx − Py ) dx dy = r �� �� ˆ ˆ S � × F · k dx dy = S � × F · n dS, so Green and Stokes say the same thing in this example. Remark. In Stokes’ theorem we are free to choose any surface S bounded by C! (e.g. if C = circle, S could be a disk, a hemisphere, a cone, ...) “Proof ” of Stokes. 1) if C and S are in the xy-plane then the statement follows from Green. 2) if C and S are in an arbitrary plane: this also reduces to Green in the given plane. Green/Stokes works in any plane because of geometric invariance of work, curl and ﬂux under rotations of space. They can be deﬁned in purely geometric terms so as not to depend on the coordinate system (x, y, z); equivalently, we can choose coordinates (u, v, w) adapted to the given plane, and work;;with those coordinates, the expressions of work, curl, ﬂux will be the familiar ones replacing x, y, z with u, v, w. 3) in general, we can decompose S into small pieces, each piece is nearly ﬂat (slanted plane); on each piece we have approximately work = ﬂux by Green’s theorem. When adding pieces, the line integrals over the inner boundaries cancel each other and we get the line integral over C; the ﬂux integrals add up to ﬂux through S. ˆ Example: verify Stokes for F = zˆ + xˆ + yk, C = unit circle in xy-plane (counterclockwise), ı j 2 − y2. S = piece of paraboloid z = 1 − x � � � Direct calculation: x = cos θ, y = sin θ, z = 0, so C F · d� = C z dx + x dy + y dz = C x dy = r � 2π 2 0 cos θ dθ = π. ˆ By Stokes: curl F = �1, 1, 1�, and n dS = �−fx , −fy , 1�dx dy = �2x, 2y, 1� dx dy. �� �� �� �= (� × F) · dS �(2x + 2y + 1) dx dy = 1 dx dy = area(disk) = π. S �� ( x dx dy = 0 by symmetry and similarly for y). 18.02 Lecture 32. – Fri, Nov 30, 2007\nStokes and path independence. Deﬁnition: a region is simply connected if every closed loop C inside it bounds some surface S inside it. Example: the complement of the z-axis is not simply connected (shown by considering a loop encircling the z-axis); the complement of the origin is simply connected. Topology: uses these considerations to classify for example surfaces in space: e.g., the mathemat­ ical proof that a sphere and a torus are “diﬀerent” surfaces is that the sphere is simply connected, the torus isn’t (in fact it has two “independent” loops that don’t bound). Recall: if F is a gradient ﬁeld then curl(F) = 0. � Conversely, Theorem: if �×F = 0 in a simply connected region then F is conservative (so F · d� r is path-independent and we can ﬁnd a potential). Proof: Assume R simply connected, � × F = 0, and consider two curves C1 and C� with same 2 � end points. Then C = C1 − C2 is a closed curve so bounds some S; C1 F · d� − C2 F · d� = r r � �� ˆ F · d� = S � × F · n dS = 0. r C Orientability. We can apply Stokes’ theorem to any surface S bounded by C... provided that it has a well-deﬁned normal vector! Counterexample shown: the M¨bius strip. It’s a one-sided o ˆ surface, so we can’t compute ﬂux through it (no possible consistent choice of orientation of n). Instead, if we want to apply Stokes to the boundary curve C, we must ﬁnd a two-sided surface with boundary C. (pictures shown). Stokes and surface independence. we S � In Stokes�� can choose any �� bounded by C: so if a same C bounds two surfaces S1 , S2 , then ˆ ˆ F · d� = S1 curl F · n dS = S2 curl F · n dS? Can we prove directly that the two ﬂux integrals r C are equal? ˆ Answer: change orientation of S2 ,�� then S = S1 − S2 is a closed surface with n outwards; so we ��� ˆ can apply the divergence theorem: S curl F · n dS = D div(curl F) dV . But div(curl F) = 0,;;always. (Checked by calculating in terms of components of F; also, symbolically: � · (� × F) = 0, much like u · (u × v) = 0 for genuine vectors). Review for Exam 4. We’ve seen three types of integrals, with diﬀerent ways of evaluating: ��� 1) f dV in rect., cyl., spherical coordinates (I re-explained the general setup and the formulas for dV ); applications: center of mass, moment of inertia, gravitational attraction. �� ˆ ˆ 2) surface integrals, ﬂux. Setting up S F · n dS, by knowing formulas for n dS. ˆ We have seen: planes parallel to coordinate planes (e.g. yz-plane: n = ±ˆ, dS = dy dz); spheres ı ˆ and cylinders (n = straight out/in from center or axis; dS = a dz dθ for cylinders, a2 sin φ dφdθ ˆ ˆ for spheres); if we can express z = f (x, y), n dS = ±�−fx , −fy , 1�dx dy (recall �. . . � is not n � (e.g. if S is given by g(x, y, z) = 0), and dx dy is not dS); if S has a given normal vector N � � ˆ ˆ n dS = ±N /(N · k) dx dy. � � 3) line integrals C F · d� (= C P dx + Q dy + R dz), evaluate by parameterizing C and expressing r in terms of a single variable. While these various types of integrals are completely diﬀerent in terms of interpretation and method of evaluation, we’ve seen some theorems that establish bridges between them: �� ��� �� ��� ˆ ˆ a) ( vs ) divergence theorem: S closed surface, n outwards, then S F·n dS = (div F) dV . � �� �D r �� b) ( vs ) Stokes’ theorem: C closed curve bounding S compatibly oriented, then C F · d� = ˆ S (� × F) · n dS. Both sides of these theorems are integrals of the types discussed above, and are evaluated by the usual methods! (even if the integrand happens to be a div or a curl). In fact, another conceptually similar bridge exists between no integral at all and line integral: � the fundamental theorem of calculus, f (P1 ) − f (P0 ) = C �f · d�. r One more topic: given F with curl F = 0, ﬁnding a potential function.'
7524,'lecture','en',6379,'2007-11-29','2009-09-10','Lecture 31: Stokes\' theorem',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 30. –\nTue, Nov 27, 2007\nHandouts: practice exams 4A and 4B. Clariﬁcation from end of last lecture: we derived the diﬀusion equation from 2 inputs. u = concentration, F = ﬂow, satisfy: 1) from physics: F = −k�u, 2) from divergence theorem: ∂u/∂t = −div F. Combining, we get the diﬀusion equation: ∂u/∂t = −div F = +kdiv (�u) = k�2 u. Line integrals in space. Force ﬁeld F = �P, Q, R�, curve C in space, d� = �dx, dy, dz� r � � ⇒ Work = C F ·\nd� = C P dx + Q dy + R dz. r Example: F = �yz, xz, xy�. C: x = t3 , y = t2 , z = t. 0 ≤ t ≤ 1. Then dx = 3t2 dt, dy = 2tdt,\n dz = dt and substitute: � � � 1 F · d� = r yzdx + xzdy + xydz = 6t5 dt = 1\nC C 0\n(In general, express (x, y, z) in terms of a single parameter: 1 degree of freedom) Same F, curve C � = segments from (0, 0, 0) to (1, 0, 0) to (1, 1, 0) to (1, 1, 1). In the xy-plane, ˆ r work. For the last segment, x = y = 1, dx = dy = 0, so z = 0 =⇒ F = xyk, so F · d� = 0, no � 1 F = �z, z, 1� and d� = �0, 0, dz�. We get 0 1 dz = 1. r Both give the same answer because F is conservative, in fact F = �(xyz). Recall the fundamental theorem of calculus for line integrals: � P1 �f · d� = f (P1 ) − f (P0 ). r\nP0\nGradient ﬁelds. F = �P, Q, R� = �fx , fy , fz � ? Then fxy = fyx , fxz = fzx , fyz = fzy , so Py = Qx , Pz = Rx , Qz = Ry . Theorem: F is a gradient ﬁeld if and only if these equalities hold (assuming deﬁned in whole space or simply connected region) ˆ Example: for which a, b is axyˆ + (x2 + z 3 )ˆ + (byz 2 − 4z 3 )k a gradient ﬁeld? ı j Py = ax = 2x = Qx so a = 2; Pz = 0 = 0 = Rx ; Qz = 3z 2 = bz 2 = Ry so b = 3. Systematic method to ﬁnd a potential: (carried out on above example) fx = 2xy, fy = x2 + z 3 , fz = 3yz 2 − 4z 3 : fx = 2xy ⇒ f (x, y, z) = x2 y + g(y, z). fy = x2 + gy = x2 + z 3 ⇒ gy = z 3 ⇒ g(y, z) = yz 3 + h(z), and f = x2 y + yz 3 + h(z). fz = 3yz 2 + h� (z) = 3yz 2 − 4z 3 ⇒ h� (z) = −4z 3 ⇒ h(z) = −z 4 + c, and f = x2 y + yz 3 − z 4 + c. �P Other method: f (x1 , y1 , z1 ) = f (0, 0, 0) + P01 F · d� (use a curve that gives an easy computation, r e.g. 3 segments parallel to axes). Curl: encodes by how much F fails to be conservative. ˆ curl �P, Q, R� = (Ry − Qz )ˆ + (Pz − Rx )ˆ + (Qx − Py )k. ı j;;How to remember the formula? Use the del operator � = �∂/∂x, ∂/∂y, ∂/∂z�.\n Recall from last week that � · F = �∂/∂x, ∂/∂y, ∂/∂z� · �P, Q, R� = Px + Qy + Rz = div F. � � ˆ � ˆ ˆ k � ı j � ∂ � ∂ ∂ Now we have: � × F =\n� ∂x ∂y ∂z � = curl F.\n � � � P Q R � Interpretation of curl for velocity ﬁelds: curl measures angular velocity. Example: rotation around z-axis at constant angular velocity ω (trajectories are circles centered on z-axis): v = �−ωy, ωx, 0�. ˆ ˆ Then � × v = ... = 0ˆ + 0ˆ + (ω + ω)k = 2ωk. So length of curl = twice angular velocity, and ı j direction = axis of rotation. A general motion can be complicated, but decomposes into various eﬀects. • curl measures the rotation component of a complex motion. 18.02 Lecture 31. – Thu, Nov 29, 2007\nHandouts: PS11 solutions, PS12.\n Stokes’ theorem is the 3D analogue of Green’s theorem for work (in the same sense as the\n divergence theorem is the 3D analogue of Green for ﬂux). � � ˆ � ˆ ˆ k � ı j � ∂ � ∂ ∂ Recall curl F = � × F =\n� ∂x ∂y ∂z � = �Ry − Qz , Pz − Rx , Qx − Py �. � � � P Q R � Stokes’ theorem: if C is a closed curve, and S any surface bounded by C, then � �� ˆ F · d� = r (� × F) · n dS.\nC S\nOrientation: compatibility of an orientation of C with an orientation of S (changing orientation changes sign on both sides of Stokes). ˆ Rule: if I walk along C in positive direction, with S to my left, then n is pointing up. (Various examples shown.) Another formulation (right-hand rule): if thumb points along C (1-D object), index ﬁnger towards ˆ S (2-D object), then middle ﬁnger points along n (3-D object). More examples shown. Example:\n Stokes vs.\n Green. If S is a portion of xy-plane bounded by a curve C coun­\n � � �� terclockwise, then C F · d� = C P dx + Q dy, by Green this is equal to S (Qx − Py ) dx dy = r �� �� ˆ ˆ S � × F · k dx dy = S � × F · n dS, so Green and Stokes say the same thing in this example. Remark. In Stokes’ theorem we are free to choose any surface S bounded by C! (e.g. if C = circle, S could be a disk, a hemisphere, a cone, ...) “Proof ” of Stokes. 1) if C and S are in the xy-plane then the statement follows from Green. 2) if C and S are in an arbitrary plane: this also reduces to Green in the given plane. Green/Stokes works in any plane because of geometric invariance of work, curl and ﬂux under rotations of space. They can be deﬁned in purely geometric terms so as not to depend on the coordinate system (x, y, z); equivalently, we can choose coordinates (u, v, w) adapted to the given plane, and work;;with those coordinates, the expressions of work, curl, ﬂux will be the familiar ones replacing x, y, z with u, v, w. 3) in general, we can decompose S into small pieces, each piece is nearly ﬂat (slanted plane); on each piece we have approximately work = ﬂux by Green’s theorem. When adding pieces, the line integrals over the inner boundaries cancel each other and we get the line integral over C; the ﬂux integrals add up to ﬂux through S. ˆ Example: verify Stokes for F = zˆ + xˆ + yk, C = unit circle in xy-plane (counterclockwise), ı j 2 − y2. S = piece of paraboloid z = 1 − x � � � Direct calculation: x = cos θ, y = sin θ, z = 0, so C F · d� = C z dx + x dy + y dz = C x dy = r � 2π 2 0 cos θ dθ = π. ˆ By Stokes: curl F = �1, 1, 1�, and n dS = �−fx , −fy , 1�dx dy = �2x, 2y, 1� dx dy. �� �� �� �= (� × F) · dS �(2x + 2y + 1) dx dy = 1 dx dy = area(disk) = π. S �� ( x dx dy = 0 by symmetry and similarly for y). 18.02 Lecture 32. – Fri, Nov 30, 2007\nStokes and path independence. Deﬁnition: a region is simply connected if every closed loop C inside it bounds some surface S inside it. Example: the complement of the z-axis is not simply connected (shown by considering a loop encircling the z-axis); the complement of the origin is simply connected. Topology: uses these considerations to classify for example surfaces in space: e.g., the mathemat­ ical proof that a sphere and a torus are “diﬀerent” surfaces is that the sphere is simply connected, the torus isn’t (in fact it has two “independent” loops that don’t bound). Recall: if F is a gradient ﬁeld then curl(F) = 0. � Conversely, Theorem: if �×F = 0 in a simply connected region then F is conservative (so F · d� r is path-independent and we can ﬁnd a potential). Proof: Assume R simply connected, � × F = 0, and consider two curves C1 and C� with same 2 � end points. Then C = C1 − C2 is a closed curve so bounds some S; C1 F · d� − C2 F · d� = r r � �� ˆ F · d� = S � × F · n dS = 0. r C Orientability. We can apply Stokes’ theorem to any surface S bounded by C... provided that it has a well-deﬁned normal vector! Counterexample shown: the M¨bius strip. It’s a one-sided o ˆ surface, so we can’t compute ﬂux through it (no possible consistent choice of orientation of n). Instead, if we want to apply Stokes to the boundary curve C, we must ﬁnd a two-sided surface with boundary C. (pictures shown). Stokes and surface independence. we S � In Stokes�� can choose any �� bounded by C: so if a same C bounds two surfaces S1 , S2 , then ˆ ˆ F · d� = S1 curl F · n dS = S2 curl F · n dS? Can we prove directly that the two ﬂux integrals r C are equal? ˆ Answer: change orientation of S2 ,�� then S = S1 − S2 is a closed surface with n outwards; so we ��� ˆ can apply the divergence theorem: S curl F · n dS = D div(curl F) dV . But div(curl F) = 0,;;always. (Checked by calculating in terms of components of F; also, symbolically: � · (� × F) = 0, much like u · (u × v) = 0 for genuine vectors). Review for Exam 4. We’ve seen three types of integrals, with diﬀerent ways of evaluating: ��� 1) f dV in rect., cyl., spherical coordinates (I re-explained the general setup and the formulas for dV ); applications: center of mass, moment of inertia, gravitational attraction. �� ˆ ˆ 2) surface integrals, ﬂux. Setting up S F · n dS, by knowing formulas for n dS. ˆ We have seen: planes parallel to coordinate planes (e.g. yz-plane: n = ±ˆ, dS = dy dz); spheres ı ˆ and cylinders (n = straight out/in from center or axis; dS = a dz dθ for cylinders, a2 sin φ dφdθ ˆ ˆ for spheres); if we can express z = f (x, y), n dS = ±�−fx , −fy , 1�dx dy (recall �. . . � is not n � (e.g. if S is given by g(x, y, z) = 0), and dx dy is not dS); if S has a given normal vector N � � ˆ ˆ n dS = ±N /(N · k) dx dy. � � 3) line integrals C F · d� (= C P dx + Q dy + R dz), evaluate by parameterizing C and expressing r in terms of a single variable. While these various types of integrals are completely diﬀerent in terms of interpretation and method of evaluation, we’ve seen some theorems that establish bridges between them: �� ��� �� ��� ˆ ˆ a) ( vs ) divergence theorem: S closed surface, n outwards, then S F·n dS = (div F) dV . � �� �D r �� b) ( vs ) Stokes’ theorem: C closed curve bounding S compatibly oriented, then C F · d� = ˆ S (� × F) · n dS. Both sides of these theorems are integrals of the types discussed above, and are evaluated by the usual methods! (even if the integrand happens to be a div or a curl). In fact, another conceptually similar bridge exists between no integral at all and line integral: � the fundamental theorem of calculus, f (P1 ) − f (P0 ) = C �f · d�. r One more topic: given F with curl F = 0, ﬁnding a potential function.'
7525,'lecture','en',6379,'2007-11-30','2009-09-10','Lecture 32: Stokes\' theorem (cont.); review',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 30. –\nTue, Nov 27, 2007\nHandouts: practice exams 4A and 4B. Clariﬁcation from end of last lecture: we derived the diﬀusion equation from 2 inputs. u = concentration, F = ﬂow, satisfy: 1) from physics: F = −k�u, 2) from divergence theorem: ∂u/∂t = −div F. Combining, we get the diﬀusion equation: ∂u/∂t = −div F = +kdiv (�u) = k�2 u. Line integrals in space. Force ﬁeld F = �P, Q, R�, curve C in space, d� = �dx, dy, dz� r � � ⇒ Work = C F ·\nd� = C P dx + Q dy + R dz. r Example: F = �yz, xz, xy�. C: x = t3 , y = t2 , z = t. 0 ≤ t ≤ 1. Then dx = 3t2 dt, dy = 2tdt,\n dz = dt and substitute: � � � 1 F · d� = r yzdx + xzdy + xydz = 6t5 dt = 1\nC C 0\n(In general, express (x, y, z) in terms of a single parameter: 1 degree of freedom) Same F, curve C � = segments from (0, 0, 0) to (1, 0, 0) to (1, 1, 0) to (1, 1, 1). In the xy-plane, ˆ r work. For the last segment, x = y = 1, dx = dy = 0, so z = 0 =⇒ F = xyk, so F · d� = 0, no � 1 F = �z, z, 1� and d� = �0, 0, dz�. We get 0 1 dz = 1. r Both give the same answer because F is conservative, in fact F = �(xyz). Recall the fundamental theorem of calculus for line integrals: � P1 �f · d� = f (P1 ) − f (P0 ). r\nP0\nGradient ﬁelds. F = �P, Q, R� = �fx , fy , fz � ? Then fxy = fyx , fxz = fzx , fyz = fzy , so Py = Qx , Pz = Rx , Qz = Ry . Theorem: F is a gradient ﬁeld if and only if these equalities hold (assuming deﬁned in whole space or simply connected region) ˆ Example: for which a, b is axyˆ + (x2 + z 3 )ˆ + (byz 2 − 4z 3 )k a gradient ﬁeld? ı j Py = ax = 2x = Qx so a = 2; Pz = 0 = 0 = Rx ; Qz = 3z 2 = bz 2 = Ry so b = 3. Systematic method to ﬁnd a potential: (carried out on above example) fx = 2xy, fy = x2 + z 3 , fz = 3yz 2 − 4z 3 : fx = 2xy ⇒ f (x, y, z) = x2 y + g(y, z). fy = x2 + gy = x2 + z 3 ⇒ gy = z 3 ⇒ g(y, z) = yz 3 + h(z), and f = x2 y + yz 3 + h(z). fz = 3yz 2 + h� (z) = 3yz 2 − 4z 3 ⇒ h� (z) = −4z 3 ⇒ h(z) = −z 4 + c, and f = x2 y + yz 3 − z 4 + c. �P Other method: f (x1 , y1 , z1 ) = f (0, 0, 0) + P01 F · d� (use a curve that gives an easy computation, r e.g. 3 segments parallel to axes). Curl: encodes by how much F fails to be conservative. ˆ curl �P, Q, R� = (Ry − Qz )ˆ + (Pz − Rx )ˆ + (Qx − Py )k. ı j;;How to remember the formula? Use the del operator � = �∂/∂x, ∂/∂y, ∂/∂z�.\n Recall from last week that � · F = �∂/∂x, ∂/∂y, ∂/∂z� · �P, Q, R� = Px + Qy + Rz = div F. � � ˆ � ˆ ˆ k � ı j � ∂ � ∂ ∂ Now we have: � × F =\n� ∂x ∂y ∂z � = curl F.\n � � � P Q R � Interpretation of curl for velocity ﬁelds: curl measures angular velocity. Example: rotation around z-axis at constant angular velocity ω (trajectories are circles centered on z-axis): v = �−ωy, ωx, 0�. ˆ ˆ Then � × v = ... = 0ˆ + 0ˆ + (ω + ω)k = 2ωk. So length of curl = twice angular velocity, and ı j direction = axis of rotation. A general motion can be complicated, but decomposes into various eﬀects. • curl measures the rotation component of a complex motion. 18.02 Lecture 31. – Thu, Nov 29, 2007\nHandouts: PS11 solutions, PS12.\n Stokes’ theorem is the 3D analogue of Green’s theorem for work (in the same sense as the\n divergence theorem is the 3D analogue of Green for ﬂux). � � ˆ � ˆ ˆ k � ı j � ∂ � ∂ ∂ Recall curl F = � × F =\n� ∂x ∂y ∂z � = �Ry − Qz , Pz − Rx , Qx − Py �. � � � P Q R � Stokes’ theorem: if C is a closed curve, and S any surface bounded by C, then � �� ˆ F · d� = r (� × F) · n dS.\nC S\nOrientation: compatibility of an orientation of C with an orientation of S (changing orientation changes sign on both sides of Stokes). ˆ Rule: if I walk along C in positive direction, with S to my left, then n is pointing up. (Various examples shown.) Another formulation (right-hand rule): if thumb points along C (1-D object), index ﬁnger towards ˆ S (2-D object), then middle ﬁnger points along n (3-D object). More examples shown. Example:\n Stokes vs.\n Green. If S is a portion of xy-plane bounded by a curve C coun­\n � � �� terclockwise, then C F · d� = C P dx + Q dy, by Green this is equal to S (Qx − Py ) dx dy = r �� �� ˆ ˆ S � × F · k dx dy = S � × F · n dS, so Green and Stokes say the same thing in this example. Remark. In Stokes’ theorem we are free to choose any surface S bounded by C! (e.g. if C = circle, S could be a disk, a hemisphere, a cone, ...) “Proof ” of Stokes. 1) if C and S are in the xy-plane then the statement follows from Green. 2) if C and S are in an arbitrary plane: this also reduces to Green in the given plane. Green/Stokes works in any plane because of geometric invariance of work, curl and ﬂux under rotations of space. They can be deﬁned in purely geometric terms so as not to depend on the coordinate system (x, y, z); equivalently, we can choose coordinates (u, v, w) adapted to the given plane, and work;;with those coordinates, the expressions of work, curl, ﬂux will be the familiar ones replacing x, y, z with u, v, w. 3) in general, we can decompose S into small pieces, each piece is nearly ﬂat (slanted plane); on each piece we have approximately work = ﬂux by Green’s theorem. When adding pieces, the line integrals over the inner boundaries cancel each other and we get the line integral over C; the ﬂux integrals add up to ﬂux through S. ˆ Example: verify Stokes for F = zˆ + xˆ + yk, C = unit circle in xy-plane (counterclockwise), ı j 2 − y2. S = piece of paraboloid z = 1 − x � � � Direct calculation: x = cos θ, y = sin θ, z = 0, so C F · d� = C z dx + x dy + y dz = C x dy = r � 2π 2 0 cos θ dθ = π. ˆ By Stokes: curl F = �1, 1, 1�, and n dS = �−fx , −fy , 1�dx dy = �2x, 2y, 1� dx dy. �� �� �� �= (� × F) · dS �(2x + 2y + 1) dx dy = 1 dx dy = area(disk) = π. S �� ( x dx dy = 0 by symmetry and similarly for y). 18.02 Lecture 32. – Fri, Nov 30, 2007\nStokes and path independence. Deﬁnition: a region is simply connected if every closed loop C inside it bounds some surface S inside it. Example: the complement of the z-axis is not simply connected (shown by considering a loop encircling the z-axis); the complement of the origin is simply connected. Topology: uses these considerations to classify for example surfaces in space: e.g., the mathemat­ ical proof that a sphere and a torus are “diﬀerent” surfaces is that the sphere is simply connected, the torus isn’t (in fact it has two “independent” loops that don’t bound). Recall: if F is a gradient ﬁeld then curl(F) = 0. � Conversely, Theorem: if �×F = 0 in a simply connected region then F is conservative (so F · d� r is path-independent and we can ﬁnd a potential). Proof: Assume R simply connected, � × F = 0, and consider two curves C1 and C� with same 2 � end points. Then C = C1 − C2 is a closed curve so bounds some S; C1 F · d� − C2 F · d� = r r � �� ˆ F · d� = S � × F · n dS = 0. r C Orientability. We can apply Stokes’ theorem to any surface S bounded by C... provided that it has a well-deﬁned normal vector! Counterexample shown: the M¨bius strip. It’s a one-sided o ˆ surface, so we can’t compute ﬂux through it (no possible consistent choice of orientation of n). Instead, if we want to apply Stokes to the boundary curve C, we must ﬁnd a two-sided surface with boundary C. (pictures shown). Stokes and surface independence. we S � In Stokes�� can choose any �� bounded by C: so if a same C bounds two surfaces S1 , S2 , then ˆ ˆ F · d� = S1 curl F · n dS = S2 curl F · n dS? Can we prove directly that the two ﬂux integrals r C are equal? ˆ Answer: change orientation of S2 ,�� then S = S1 − S2 is a closed surface with n outwards; so we ��� ˆ can apply the divergence theorem: S curl F · n dS = D div(curl F) dV . But div(curl F) = 0,;;always. (Checked by calculating in terms of components of F; also, symbolically: � · (� × F) = 0, much like u · (u × v) = 0 for genuine vectors). Review for Exam 4. We’ve seen three types of integrals, with diﬀerent ways of evaluating: ��� 1) f dV in rect., cyl., spherical coordinates (I re-explained the general setup and the formulas for dV ); applications: center of mass, moment of inertia, gravitational attraction. �� ˆ ˆ 2) surface integrals, ﬂux. Setting up S F · n dS, by knowing formulas for n dS. ˆ We have seen: planes parallel to coordinate planes (e.g. yz-plane: n = ±ˆ, dS = dy dz); spheres ı ˆ and cylinders (n = straight out/in from center or axis; dS = a dz dθ for cylinders, a2 sin φ dφdθ ˆ ˆ for spheres); if we can express z = f (x, y), n dS = ±�−fx , −fy , 1�dx dy (recall �. . . � is not n � (e.g. if S is given by g(x, y, z) = 0), and dx dy is not dS); if S has a given normal vector N � � ˆ ˆ n dS = ±N /(N · k) dx dy. � � 3) line integrals C F · d� (= C P dx + Q dy + R dz), evaluate by parameterizing C and expressing r in terms of a single variable. While these various types of integrals are completely diﬀerent in terms of interpretation and method of evaluation, we’ve seen some theorems that establish bridges between them: �� ��� �� ��� ˆ ˆ a) ( vs ) divergence theorem: S closed surface, n outwards, then S F·n dS = (div F) dV . � �� �D r �� b) ( vs ) Stokes’ theorem: C closed curve bounding S compatibly oriented, then C F · d� = ˆ S (� × F) · n dS. Both sides of these theorems are integrals of the types discussed above, and are evaluated by the usual methods! (even if the integrand happens to be a div or a curl). In fact, another conceptually similar bridge exists between no integral at all and line integral: � the fundamental theorem of calculus, f (P1 ) − f (P0 ) = C �f · d�. r One more topic: given F with curl F = 0, ﬁnding a potential function.'
7526,'lecture','en',6379,'2007-12-06','2009-09-10','Lecture 33: Topological considerations - Maxwell\'s equations',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 33. –\nThu, Dec 6, 2007\nHandouts: PS12 solutions; exam 4 solutions; review sheet and practice ﬁnal. Applications of div and curl to physics. Recall: curl of velocity ﬁeld = 2· angular velocity vector (of the rotation component of motion). ˆ ı j E.g., for uniform rotation about z-axis, v = ω(−yˆ + xˆ), and � × v = 2ωk. Curl singles out the rotation component of motion (while div singles out the stretching compo­ nent). Interpretation of curl for force ﬁelds. If we have a solid in a force ﬁeld (or rather an acceleration ﬁeld!) F such that the force exerted on Δm at (x, y, z) is F(x, y, z) Δm:��� recall the torque of the force about the origin is deﬁned as τ = � × F (for the entire solid, take r . . . δ dV ), and measures how F imparts rotation motion. Force d For translation motion: = acceleration = (velocity). Mass dt Torque d For rotation eﬀects: = angular acceleration = (angular velocity). Moment of inertia dt Force Torque Hence: curl( )=2 . Mass Moment of inertia Consequence: if F derives from a potential, then �×F = �×(�f ) = 0, so F does not induce any rotation motion. E.g., gravitational attraction by itself does not aﬀect Earth’s rotation. (not strictly true: actually Earth is deformable; similarly, friction and tidal eﬀects due to Earth’s gravitational attraction explain why the Moon’s rotation and revolution around Earth are synchronous). Div and curl of electrical ﬁeld. – part of Maxwell’s equations for electromagnetic ﬁelds. ρ � 1) Gauss-Coulomb law: � · E = (ρ = charge density, �0 = physical constant). �0 �� ��� Q � ˆ � By divergence theorem, can reformulate as: E · n dS = � · E dV = , where Q = �0 S D total charge inside the closed surface S. This formula tells how charges inﬂuence the electric ﬁeld; e.g., it governs the relation between voltage between the two plates of a capacitor and its electric charge. � ∂B � � 2) Faraday’s law: � × E = − (B = magnetic ﬁeld). ∂t � So in presence of a varying magnetic ﬁeld, E is no longer conservative: if we have � closed loop �a � d � r � ˆ of wire, we get a non-zero voltage (“induction” eﬀect). By Stokes, E · d� = − B · n dS. dt S C This principle is used e.g. in transformers in power adapters: AC runs through a wire looped around a cylinder, which creates an alternating magnetic ﬁeld; the ﬂux of this magnetic ﬁeld through another output wire loop creates an output voltage between its ends. � � � There are two more Maxwell equations, governing div and curl of B : � · B = 0, and � × B = � ∂E � � µ0 J + �0 µ0 (where J = current density). ∂t'
7527,'lecture','en',6379,'2007-12-06','2009-09-10','Lecture 34: Final review',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 33. –\nThu, Dec 6, 2007\nHandouts: PS12 solutions; exam 4 solutions; review sheet and practice ﬁnal. Applications of div and curl to physics. Recall: curl of velocity ﬁeld = 2· angular velocity vector (of the rotation component of motion). ˆ ı j E.g., for uniform rotation about z-axis, v = ω(−yˆ + xˆ), and � × v = 2ωk. Curl singles out the rotation component of motion (while div singles out the stretching compo­ nent). Interpretation of curl for force ﬁelds. If we have a solid in a force ﬁeld (or rather an acceleration ﬁeld!) F such that the force exerted on Δm at (x, y, z) is F(x, y, z) Δm:��� recall the torque of the force about the origin is deﬁned as τ = � × F (for the entire solid, take r . . . δ dV ), and measures how F imparts rotation motion. Force d For translation motion: = acceleration = (velocity). Mass dt Torque d For rotation eﬀects: = angular acceleration = (angular velocity). Moment of inertia dt Force Torque Hence: curl( )=2 . Mass Moment of inertia Consequence: if F derives from a potential, then �×F = �×(�f ) = 0, so F does not induce any rotation motion. E.g., gravitational attraction by itself does not aﬀect Earth’s rotation. (not strictly true: actually Earth is deformable; similarly, friction and tidal eﬀects due to Earth’s gravitational attraction explain why the Moon’s rotation and revolution around Earth are synchronous). Div and curl of electrical ﬁeld. – part of Maxwell’s equations for electromagnetic ﬁelds. ρ � 1) Gauss-Coulomb law: � · E = (ρ = charge density, �0 = physical constant). �0 �� ��� Q � ˆ � By divergence theorem, can reformulate as: E · n dS = � · E dV = , where Q = �0 S D total charge inside the closed surface S. This formula tells how charges inﬂuence the electric ﬁeld; e.g., it governs the relation between voltage between the two plates of a capacitor and its electric charge. � ∂B � � 2) Faraday’s law: � × E = − (B = magnetic ﬁeld). ∂t � So in presence of a varying magnetic ﬁeld, E is no longer conservative: if we have � closed loop �a � d � r � ˆ of wire, we get a non-zero voltage (“induction” eﬀect). By Stokes, E · d� = − B · n dS. dt S C This principle is used e.g. in transformers in power adapters: AC runs through a wire looped around a cylinder, which creates an alternating magnetic ﬁeld; the ﬂux of this magnetic ﬁeld through another output wire loop creates an output voltage between its ends. � � � There are two more Maxwell equations, governing div and curl of B : � · B = 0, and � × B = � ∂E � � µ0 J + �0 µ0 (where J = current density). ∂t'
7528,'lecture','en',6379,'2007-12-06','2009-09-10','Lecture 35: Final review (cont.)',NULL,';;MIT OpenCourseWare http://ocw.mit.edu\n18.02 Multivariable Calculus\nFall 2007\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms.;;18.02 Lecture 33. –\nThu, Dec 6, 2007\nHandouts: PS12 solutions; exam 4 solutions; review sheet and practice ﬁnal. Applications of div and curl to physics. Recall: curl of velocity ﬁeld = 2· angular velocity vector (of the rotation component of motion). ˆ ı j E.g., for uniform rotation about z-axis, v = ω(−yˆ + xˆ), and � × v = 2ωk. Curl singles out the rotation component of motion (while div singles out the stretching compo­ nent). Interpretation of curl for force ﬁelds. If we have a solid in a force ﬁeld (or rather an acceleration ﬁeld!) F such that the force exerted on Δm at (x, y, z) is F(x, y, z) Δm:��� recall the torque of the force about the origin is deﬁned as τ = � × F (for the entire solid, take r . . . δ dV ), and measures how F imparts rotation motion. Force d For translation motion: = acceleration = (velocity). Mass dt Torque d For rotation eﬀects: = angular acceleration = (angular velocity). Moment of inertia dt Force Torque Hence: curl( )=2 . Mass Moment of inertia Consequence: if F derives from a potential, then �×F = �×(�f ) = 0, so F does not induce any rotation motion. E.g., gravitational attraction by itself does not aﬀect Earth’s rotation. (not strictly true: actually Earth is deformable; similarly, friction and tidal eﬀects due to Earth’s gravitational attraction explain why the Moon’s rotation and revolution around Earth are synchronous). Div and curl of electrical ﬁeld. – part of Maxwell’s equations for electromagnetic ﬁelds. ρ � 1) Gauss-Coulomb law: � · E = (ρ = charge density, �0 = physical constant). �0 �� ��� Q � ˆ � By divergence theorem, can reformulate as: E · n dS = � · E dV = , where Q = �0 S D total charge inside the closed surface S. This formula tells how charges inﬂuence the electric ﬁeld; e.g., it governs the relation between voltage between the two plates of a capacitor and its electric charge. � ∂B � � 2) Faraday’s law: � × E = − (B = magnetic ﬁeld). ∂t � So in presence of a varying magnetic ﬁeld, E is no longer conservative: if we have � closed loop �a � d � r � ˆ of wire, we get a non-zero voltage (“induction” eﬀect). By Stokes, E · d� = − B · n dS. dt S C This principle is used e.g. in transformers in power adapters: AC runs through a wire looped around a cylinder, which creates an alternating magnetic ﬁeld; the ﬂux of this magnetic ﬁeld through another output wire loop creates an output voltage between its ends. � � � There are two more Maxwell equations, governing div and curl of B : � · B = 0, and � × B = � ∂E � � µ0 J + �0 µ0 (where J = current density). ∂t'
7721,'lecture','en',6300,'2006-03-13','2010-07-13','Urban photography of American cities',NULL,NULL
7722,'lecture','en',6300,'2006-03-20','2010-07-13','Photography of African American cultural landscapes',NULL,NULL
7723,'lecture','en',6300,'2006-04-03','2010-07-13','Secret games - collaborations with children',NULL,NULL
7724,'lecture','en',6300,'2006-04-10','2010-07-13','Photography and its role in rebuilding New Orleans',NULL,NULL
7726,'lecture','en',6300,'2006-04-24','2010-07-13','Inquiry and Sensing in photography',NULL,NULL
7727,'lecture','en',6300,'2006-05-01','2010-07-13','Social documentary photography',NULL,NULL
7728,'lecture','en',6300,'2006-05-08','2010-07-13','To see is the root of idea',NULL,NULL
7746,'lecture','en',6336,'2004-03-17','2010-07-21','Session 1','Heros, Tolkien, Lewis, Beowolf.',NULL
7747,'lecture','en',6336,'2004-03-31','2010-07-21','Session 2','Analyzing historical data, making sense of evidence, Why do history at all?',NULL
7762,'lecture','en',6337,'2004-02-09','2010-05-14','Session 1','* Introduction to the class and to the aesthetics of film; explanation of syllabus.\n\n* Discussion of \"The Lady Eve\" (1941), a film by Sturges, a contemporary of Orson Welles. Film will be shown in this week\'s class; scholar Marian Keane\'s commentary, an important example of a woman\'s perspective on the film, will be shown next week.\n\n* Looking at movies is an art form and a skill that requires training. Prof. Singer brings to this course the perspective of a philosopher, which is not the case in all film courses.\n\n* Singer\'s philosophy of teaching: he is willing to make himself available and put himself forward as an artist does; teaching is a form of self-expression, like art.\n\n* On philosophy in film and other media (versus the philosophy of film). The idea that film is a respectable art with philosophical content, not just entertainment, is fairly new within the academy (within the last 20 years).\n\n* How can films be philosophical? Singer\'s book Reality Transformed addresses this by looking at the concepts of formalism and realism together. Formalists can be characterized by their use of the camera, techniques of cinematography, structural issues (i.e., Hitchcock, who was a master of technique). Realists, as described by French theorist Andre Bazin, see the importance of film as part of the human desire to capture reality.\n\n* Singer argues that films can\'t be appreciated unless you savor what they mean; without technique, there is no meaning, and without meaning, technique has no human importance. Only when you see formalism and realism in constant dialectic and interaction can you appreciate what a film is capable of.\n\n* On the role of myths and mythmaking in film. How do stories reach people? Discussion of various myths of love and how they have been dealt with in film.\n\n* Continuing overview of syllabus and films to be screened throughout semester.\n\n* Review of course expectations and requirements.',NULL
7763,'lecture','en',6337,'2004-02-17','2010-05-14','Session 2','* Review of previous session.\n* How does one apply philosophical analysis of any sort to a work of art such as a movie?\n* What is the meaning of the tree of knowledge in the garden of Eden? How is this philosophically important?\n* There is an overlap between science, technology, and art. Mathematics can be thought of as a theoretical art.\n* Fundamental question of Reality Transformed: Formalists vs. Realists\n* Three Philosophical Filmmakers - all 3 filmmakers are both formalists and realists in their own ways.\n* Are films the modern medium of choice for myth-making and disseminating philosophy?\n* Hitchcock emphasizes \"reality effect\" - emphasis on formalism, but striving to bring out realism. Similar to realism portrayed in \"The Green Mile.\"\n* Assigning biblical characters to \"The Lady Eve.\" Which characters are Adam and Eve? Who is the snake?\n* The myth of the whore/virgin - can the two be harmonized in \"The Lady Eve\"? Jean journeys from one to the other throughout the movie.',NULL
7764,'lecture','en',6337,'2004-02-23','2010-05-14','Session 3','* Edward Song\'s comments on the week\'s reading and movie.\n* David Levinson\'s comments on the week\'s reading and movie.\n* Film can focus attention on different aspects of the performance with more specificity than a live performance. This is borne out in the commentary for \"The Lady Eve.\"\n* Discussion of camera work as described in Three Philosophical Filmmakers, as compared to the camera work in \"The Lady Eve.\"\n* Where / how is the character Charles in \"The Lady Eve\" likely to find love? What is the nature of love between human beings? Between humans and pets? How is this reflected in the cinematic voice of the filmmaker?\n* Discussion of the quality of the cinematography in \"Amélie,\" and the ideals of romantic love (Chekhov short story).\n* Did the character Eve in \"The Lady Eve\" sell out in the end of the movie?',NULL
7765,'lecture','en',6337,'2004-05-10','2010-05-14','Session 4','* Discussion of Miguel\'s paper #2 topics: \"Rebel Without a Cause\" and how teenagers deal with death.\n* Discussion of Edward\'s paper #2 topics: the ideological contrast presented by the knight and his squire in \"The Seventh Seal.\"\n* Discussion of David\'s paper #2 topics: Responding to Heidegger\'s position on death and religion, using \"The Seventh Seal.\"\n* Discussion of Cathy\'s paper #2 topics: Three main myths depicted in \"8 1/2.\"\n* Discussion of Terry\'s paper #2 topics: Theological representations in \"The Seventh Seal.\"\n* Discussion of Lauren\'s paper #2 topics: How does the meaning of life affect the outlook of each character in \"The Seventh Seal\"?\n* Discussion of Phillip\'s paper #2 topics: How imagination enhances meaning in life, as seen in \"Life Is Beautiful\" and \"Amélie.\"\n* Discussion of Peter\'s paper #2 topics: Contrast between self love and selfishness in relation to \"Pride and Prejudice.\"',NULL
8314,'external lecture','fr',8289,'2008-03-13','2010-08-02','Open Day briefing session for volunteers - Week 1',NULL,NULL
8315,'external lecture','fr',8289,'2008-03-20','2010-08-03','Open Day briefing session for volunteers - Week 2',NULL,NULL
8316,'external lecture','fr',8289,'2008-03-27','2010-08-03','Open Day briefing session for volunteers  - Week 3',NULL,NULL
8317,'external lecture','fr',8289,'2008-04-03','2010-08-03','Open Day briefing session for volunteers - Week 4',NULL,NULL
8318,'external lecture','fr',8289,'2008-04-06','2010-08-03','Table ronde: Les femmes et la science',NULL,NULL
8319,'external lecture','fr',8289,'2008-04-06','2010-08-03',' Les questions de Gaugin',NULL,NULL
8320,'external lecture','fr',8289,'2008-04-06','2010-08-03',' LHC : sur la piste des mystères de l’Univers',NULL,NULL
8321,'external lecture','en',8289,'2008-04-06','2010-08-03','Les super états: la superfluidité ',NULL,NULL
8322,'external lecture','fr',8289,'2008-04-06','2010-08-03','L\'aventure du LHC',NULL,NULL
8323,'external lecture','fr',8289,'2008-04-06','2010-08-03','L\'antimatière: de l\'espace au LHC',NULL,NULL
8324,'external lecture','fr',8289,'2008-04-06','2010-08-03','L\'histoire de l\'Internet et du WEB 1',NULL,NULL
8325,'external lecture','en',8289,'2008-04-06','2010-08-03','Particles and medicine',NULL,NULL
8326,'external lecture','fr',8289,'2008-04-06','2010-08-02','L\'histoire de l\'Internet et du WEB 2',NULL,NULL
8327,'external lecture','fr',8289,'2008-04-06','2010-08-02','La Grille, un ordinateur planétaire',NULL,NULL
8328,'external lecture','fr',8289,'2008-04-06','2010-08-02','Passage de Fred (C\'est pas sorcier)',NULL,NULL
8329,'external lecture','en',8289,'2008-04-06','2010-08-02','The unexpected side of the LHC',NULL,NULL
8331,'external lecture','en',8289,'2008-04-06','2010-08-02','Super statements: supraconductivity',NULL,NULL
8386,'lecture','en',6446,'2005-02-14','2010-03-05','Class 1: U.S. Planning and Realities of Post-war Iraq',NULL,NULL
8387,'lecture','en',6446,'2005-03-01','2010-03-05','Class 2: Politics and Society in Iraq in the 20th Century',NULL,NULL
8388,'lecture','en',6446,'2005-03-07','2010-03-05','Class 3: Comparative Insights: Marshall Plan, Japan, and Iraq',NULL,NULL
8389,'lecture','en',6446,'2005-04-04','2010-03-05','Class 4: Reconstructing \"a New Liberal Iraq\"',NULL,NULL
8390,'lecture','en',6446,'2005-04-11','2010-03-05','Class 5: Consolidating Iraqi Democracy: the Institutional Context',NULL,NULL
8391,'lecture','en',6446,'2005-04-25','2010-03-05','Class 6: The Arab Discourse on Iraq and the International Role',NULL,NULL
8392,'lecture','en',6446,'2005-05-04','2010-03-06','Class 11: The Discourse of Iraqis and Arabs on the Reconstruction of a New Iraq','Political Cartoons and Reflection by Noam Chomsky - Final presentation by Professor Yosef Jabareen of Arab political cartoons followed by reflections by Professor Noam Chomsky on the Iraqi occupation and the hegemonizing agenda of the U.S. in the Middle East.',NULL
8393,'lecture','en',6317,'2004-02-10','2010-07-28','Lecture 3: Newton\'s Method',NULL,NULL
8394,'lecture','en',6317,'2004-04-13','2010-07-28','Lecture 18: Duality Theory I',NULL,NULL
8395,'lecture','en',6317,'2004-05-03','2010-07-28','Lecture 23: Semidefinite Optimization I',NULL,NULL
8420,'lecture','en',6421,'2004-02-04','2009-12-18','Lecture 1: Who Develops Breakthrough New Products and Services - Users or Manufacturers?','Before thinking about how to do concept development, we will explore who does this activity. Specifically, is the concept developer really a manufacturer - or is it a product or service user?',NULL
8421,'lecture','en',6421,'2004-02-09','2009-12-18','Lecture 2: Systematic Generation of Ideas for \"Breakthrough\" New Products and Services - the \"Lead User Method\"','Users innovate when it is in their interest to do so. But not all user innovations will make a good product from a product manufacturer\'s standpoint. Therefore, manufacturers must identify and learn from \"lead\" users. 3M and other firms have learned to network their way to lead users and then combine lead user ideas with their own to create \"breakthrough\" new products and services. The reading for this lecture describes the 3M experience.',NULL
8422,'lecture','en',6421,'2004-03-01','2009-12-18','Lecture 4: Systematic Generation of Incremental Improvements to Existing Products and Services, Traditional Marketing Research Concept Generation Techniques','Traditional market research techniques are most advanced in consumer products fields. Here, user needs are analyzed via multiattribute techniques, marketing and R&D personnel then use this data to develop new product concepts. Finally, the market potential of these ideas is explored via \"focus groups\" of representative consumers, questionnaires, etc.',NULL
8774,'lecture','en',8653,'2009-07-10','2009-07-10','Opening',NULL,NULL
8775,'invited talk','en',8653,'2009-06-08','2009-07-10','Brains not Bullets? From Terrorism, Insurgencies and Drug Wars, to Street Gangs and World of Warcraft','In previous work, we suggested that common dynamical patterns underlie the evolution of irregular warfare and global terrorism. We offered a simple model to explain all these findings, based on a common ’soup’ of continually evolving attack units. This talk updates this line of research, in light of new results. In addition to confirming the robustness of our model, these results offer a quantitative explanation of why the insurgent war in Iraq, and the drug war in Colombia, have evolved in the way that they have – and how the emerging wars in Afghanistan and Mexico might evolve in the future. These findings strengthen our earlier hypothesis that the commonality of observed dynamics are a consequence of how humans naturally ’do’ conflict, irrespective of the individual conflict’s specific origin, geographic location, ideology, and religious issues. Having established the quantitative power of our model, we use it to predict the duration of wars, and test out the consequences of different intervention strategies. We then turn to look at the connection with transnational ’maras’, street gangs, and online gangs which form around Internet role-playing games such as World of Warcraft.',NULL
8776,'invited talk','en',8653,'2009-06-08','2009-07-10','Growing Sovereignty: Modeling the Shift from Indirect to Direct Rule','Drawing on theories of historical sociology, we model the emergence of the territorial state in early modern Europe. Our modeling effort focuses on systems change with respect to the shift from indirect to direct rule. We first introduce a one-dimensional model that captures the tradeoff between organizational and geographic distances. In a second step, we present an agent-based model that features states with a varying number of organizational levels. This model explicitly represents causal mechanisms of conquest and internal state-building through organizational bypass processes. The computational findings confirm our hypothesis that technological change is sufficient to trigger the emergence of modern, direct state hierarchies. Our theoretical findings indicate that the historical transformation from indirect to direct rule presupposes a logistical, rather than the commonly assumed exponential, form of the loss-of-strength gradient.',NULL
8777,'invited talk','en',8653,'2009-06-08','2009-07-14','Dynamics of Terrorist Groups','The behavior of terrorist groups may seem highly strategic and thus largely contingent (unpredictable), however, by taking a comparative approach in considering data on terrorist attacks, we find that surprising patterns emerge. In this talk, Ill describe recent work on discovering and understanding the structure of terrorist attacks over the past 40 years, and in particular the regular behavior of terrorist organizations. These results shed new light on the origin of severe terrorist attacks and point to fundamental constraints on the dynamics of terrorism.',NULL
8778,'invited talk','en',8653,'2009-06-08','2009-07-10','Policy Informatics for Complex Systems','Mental models are inadequate for coping with crises in complex socioeconomic systems. Modern information technology can support evidencebased policies using simulations to synthesize data. Synthetic data provide a natural representation of situations and hypothetical outcomes, suitable for use by policy-makers. This talk will explore issues arising in the emerging science of policy informatics: distinctions between support for planning or response efforts; determining requirements for resolution, fidelity, precision, and accuracy in synthetic data; communicating between model developers and stakeholders which includes designing informative experiments and interpreting outcomes; and assessing adequacy of models. Examples will be drawn from practical experiences\nwith the novel H1N1 influenza.',NULL
8779,'invited talk','en',8653,'2009-06-08','2009-07-10','Cooperation and Conflict in the Prisoner’s Dilemma and the Emergence of Norms','According to Thomas Hobbes’ Leviathan, ”the life of man [is] solitary, poor, nasty, brutish, and short”, and it would need powerful social institutions to establish social order. In reality, however, social cooperation can also arise spontaneously, based on local interactions rather than centralized control. The self-organization of cooperative behavior is particularly puzzling for social dilemmas related to sharing natural resources or creating common goods. Such situations are often described by the prisoner’s dilemma. Here, we report the sudden outbreak of predominant cooperation in a noisy world dominated by selfishness and defection, when individuals imitate superior strategies and show success driven migration. In our model, individuals are unrelated, and do not inherit behavioral traits. They defect or cooperate selfishly when the opportunity arises, and they do not know how often they will interact or have interacted with someone else. Moreover, our individuals have no reputation mechanism to form friendship networks, nor do they have the option of voluntary interaction or costly punishment. Therefore, the outbreak of prevailing cooperation, when directed motion is integrated in a game-theoretical model, is remarkable, particularly when random strategy mutations and random relocations challenge the formation and survival of cooperation clusters. Finally, new results will be presented on the issue of conflict in the prisoner’s dilemma and on the emergence of norms, when group dynamical effects are taken into account.',NULL
8780,'invited talk','en',8653,'2009-06-09','2009-07-10','Explaining and Forecasting the Psychological Component of Economic Activity','We develop a methodology for estimating the parameters of dynamic opinion or expectation formation processes with social interactions. We study a simple stochastic framework of a collective process of opinion formation by a group of agents who face a binary decision problem. The aggregate dynamics of the individuals’ decisions can be analyzed via the stochastic process governing the ensemble average of choices. Numerical approximations to the transient density for this ensemble average allow the evaluation of the likelihood function on the base of discrete observations of the social dynamics. This generic approach can be used to estimate the parameters of various opinion formation processes from a variety of available aggregate data. Our applications include: (i) identification of interaction effects in a well-known business climate index as well as (ii) analysis of sentiment data from the German stock market. In both cases we find strong evidence of strong social interactions with the potential of generating abrupt swings in the average mood of respondents. In this way, the psychological component or the imprints of animal spirits in economic data can be identified.',NULL
8781,'invited talk','en',8653,'2009-06-09','2009-07-10','Financially Constrained Business Fluctuations in an Evolving Network Economy','We explore the properties of a credit network characterized by inside credit, i.e. credit relationships connecting downstream (DS) and upstream (US) firms, and outside credit, i.e. credit relationships connecting firms and banks. The structure of the network changes over time due to the preferred-partner choice rule. The net worth of DS firms turns out to be the driver of growth and fluctuations. US production, in fact, is determined by demand of intermediate inputs on the part of DS firms. The output of simulations shows that a business cycle at the macroeconomic level can develop as a consequence of the complex interaction of the heterogeneous financial conditions of the agents involved. In this context we can study the emergence of bankruptcy chains. We can also\nreproduce the main facts of firms’ demography: power law distribution of firms’ size and Laplace ditribution of growth rates.',NULL
8782,'invited talk','en',8653,'2009-06-09','2009-07-10','Financial Regulation: An Attempt to Regulate Complexity','The talk reviews the main components of the financial crisis of 2007-09 from a complexity perspective and argues that two decades of ideology driven deregulation, the surge of securitization, the spreading of OTC\nderivatives and off balance sheet items, excessive leverage, collaterized debt obligations and structured investment vehicles led to the creation of a huge shadow banking system that became opaque and complex to\nsuch a degree as to be totally unknowable. Such a system is impossible to regulate. As a result of massive government interventions, partial or complete nationalization, and a series of collapses, the system is in the\nprocess of deleveraging, and a large body of new regulation is in the making. The talk will give a sketchy oversight of what is perhaps the most coherent set of proposals for the new regulation, due to the de Larosiere Committee. Finally, the idea of an adaptive regulatory regime will be put forward.',NULL
8783,'invited talk','en',8653,'2009-06-09','2009-07-10','Self-Organization and Finite Size Effects in Agent Models for Financial Markets','The deviation from a Random Walk behavior in financial time series have been identified as Stylized Facts (SF) and are common to all markets. The main ones are that fluctuations are much lager than those predicted from the standard economic theory (gaussian fluctuations), the clustering of volatility and a substantial non stationarity of all properties. Many Agent Based Models have been proposed to explain these phenomena and several are indeed able to reproduce some of them. However, the situation is still problematic becaus these models are typically rather complicated with various ad hoc assumptions. This has prevented a systhematic study of these effects. We have tried therefore to define a workable Agent based Model [1], which contains the essential elements, but in a mathematically simple and well defined framework. In addition we have considered some new important elements like the nonstationarity of the process with respect to the number of agents and the question of the self-organization. Namely why all markets evolve spontaneously towards the situation corresponding to the SF, considering that in all models this is restricted to a very narrow range of parameters. The SF are shown to correspond to finite size effects (with respect to time and to the number of agents N) which, however, can be active at different time scales. This implies that strict universality cannot be expected in\ndescribing these properties in terms of effecive critical exponents. The introduction of a threshold in the agents action (small price movements lead to no action) triggers the self-organization towards the intermittent\nstate corresponding to the SF. From these studies the herding phenomenon seems to be a crucial one beyond the standard theory as a triggering element of bubbles and crashs which develop spontaneously without a cause-effect relation. The model can also be used backwards to derive the strategies of the agents from the price time series. Other applications are under consideration like the problem of finite liquidity and the possibility that the reference fundamental price is subject to large fluctuations if one cnsiders that all markets are linked into a large network [2].',NULL
8785,'invited talk','en',8653,'2009-06-09','2009-07-10','Financial Bubbles, Real Estate Bubbles, Derivative Bubbles, and the Financial and Economic Crisis','The financial crisis of 2008, which started with an initially well-defined epicenter focused on mortgage backed securities (MBS), has been cascading into a global economic recession, whose increasing severity and uncertain duration had led and is continuing to lead to massive losses and damage for billions of people. Heavy central bank interventions and government spending programs have been launched worldwide and especially in the USA and Europe, in the hope to unfreeze credit and boltster consumption. Here, I present evidence and articulate a general framework that allows one to diagnose the fundamental cause of the unfolding financial and economic crisis: the accumulation of several bubbles and their interplay and mutual reinforcement has led to an illusion of a perpetual money machine allowing financial institutions to extract wealth from an unsustainable artificial process. Taking stock of this diagnostic, I conclude that many of the intervention to address the so-called liquidity crisis and to encouragemore consumption are ill-advised and even dangerous, given the lack of precautionary reserves that have been unaccumulated in the good times and the huge liabilities. The most interesting presents times constitute unique opportunities but also great challenges, for which I offer a few recommendations.',NULL
8786,'invited talk','en',8653,'2009-06-10','2009-07-10','Efficient Immunization Approaches to Avoid Epidemic Spreading','We will show how methods based on statistical physics and complex networks approaches may help to predict the appearing of crises such as epidemics. These methods also suggest efficient immunization strategies to coop with such crises. The epidemics could occur in social systems as well as in communication networks such computers or cellphones. The methods are based on the percolation theory approach which is extended to complex networks to include more realistic scenarios, such as the limited time of epidemics or the dynamical nature of links. Questions such as how to identify the most crucial spreaders and giving a limited amount of immunization doses, how to prioritize the recipients? will be also discussed.',NULL
8787,'invited talk','en',8653,'2009-06-10','2009-07-10','Planning for Pandemic Outbreaks with Large Scale Computational Models','We present a class of computational epidemic models that integrate transportation and census data on the worldwide scale. The defined models allow the analysis of the impact of complex mobility networks on the behavior of emergent disease spreading and the general issue of the predictive power offered by computational approaches. In this framework it is possible to tackle foundational issues by using the particle network approach and provide new mathematical and computational tools for the study of large scale epidemics. We will focus the discussion on the analysis of invasion thresholds and the definition of epidemic pathways. Based on these results we present the Global Epidemic Modeler (GEM) computational platform that can be used in the analysis of intervention and mitigation policies for emerging disease outbreak.',NULL
8788,'invited talk','en',8653,'2009-06-10','2009-07-10','Economic Fluctuations and Statistical Physics: Quantifying Extremely Rare and Much Less Rare Events','Recent analysis of truly huge quantities of empirical data suggests that classic economic theories not only fail for a few outliers, but that there occur similar outliers of every possible size. In fact, if one analyzes only a small data set (say 104 data points), then outliers appear to occur as “rare events.” However, when we analyze orders of magnitude more data (108 data points!), we find orders of magnitude more outliers - so ignoring them is not a responsible option, and studying their properties becomes a realistic goal. We find that the statistical properties of these “outliers” are identical to the statistical properties of everyday fluctuations. For example, a histogram giving the number of fluctuations of a given magnitude x for fluctuations ranging in magnitude from everyday fluctuations to extremely rare fluctuations that occur with a probability of only 10−8 is a perfect straight line in a double-log plot. \n  Two unifying principles that underlie much of the finance analysis we will present are scale invariance and universality [ R. N. Mantegna/HES, Introduction to Econophysics: Correlations & Complexity in Finance (Cambridge U. Press, 2000)]. Scale invariance is a property not about algebraic equations but rather about functional equations, which have as their solutions not numbers but rather functional forms - power laws.\nThe key idea of universality is that the identical set of “scaling laws” hold across diverse markets, and over diverse time periods. \n  We demonstrate the principles of scaling and universality by describing very recent unpublished work [HES/T. Preis/J. J. Schneider “New Laws Describing Trend Switching Processes in Financial Markets”, submitted]. For an intriguing variety of switching processes in nature, the underlying complex system abruptly changes at a specific “phase transition” point from one state to another in a highly discontinuous fashion. Examples of phase transitions range from magnetism in statistical physics to physiology and macroscopic social phenomena. Financial market fluctuations are characterized by many abrupt switchings on very short time scales from increasing “microtrends” to decreasing “microtrends”—and vice versa. We ask whether these ubiquitous switching processes have quantifiable features analogous to those present in phase transitions, and find striking scale-free behavior of the time intervals between transactions both before and after the switching occurs. We interpret our findings as being consistent with time-dependent collective behavior of financial market participants. We test the possible universality of our result by performing a parallel analysis of transaction volume fluctuations.',NULL
8789,'invited talk','en',8653,'2009-06-10','2009-07-10','Statistical Properties of Credit Networks',NULL,NULL
8790,'invited talk','en',8653,'2009-06-10','2009-07-10','Mechanisms of Systemic Risk: Contagion, Reinforcement, Redistribution','The term ’systemic risk’ commonly denotes the risk that a whole system consisting of many interacting agents fails. It is a macroscopic property which emerges from the nonlinear interactions of agents. In fact, ’systemic\nrisk’ already implies that the failure of the system cannot be fully explained by the failure of a single agent. Instead, one has to understand how such singular failures are able to spread through the whole system, affecting other agents. Here, in addition to network topology, dynamic mechanisms such as contagion (similar to epidemic processes or herding behavior), reinforcement (of prevailing trends), and redistribution (e.g. of load, stress, or debt) play a considerable role. The talk aims at categorizing some of the existing models in a common framework, first, and discussing a specific model of financial networks, afterwards, to elucidate the critical conditions for the breakdown of a system.',NULL
8791,'invited talk','en',8653,'2009-06-11','2009-07-10','Two Models of Collective Firm Bankruptcies','Two models of collective firm bankruptcies will be presented. The first one uses the Potts spin glass approach for firms rating evolution where two sources of defaults are taken into account: individual dynamics of economic development and ordering interactions between firms. We show that such a defined model leads to a phase transition, which results in collective defaults. In the case when the individual firm dynamics favors dumping of rating changes, there is an optimal strength of firms interactions from the risk point of view. For small interaction strength parameters there are many independent bankruptcies of individual companies. For large parameters there are giant collective defaults of firm clusters.\n  The second model represents defaults of companies in multi-stage supply chain networks. We introduced a modified approach that represents in more details the real economic environment in which firms are operating.\nWe focused on the influence of local processes on the global economic behaviour of the system and studied how the proposed modifications change the general properties of the model. To realistically simulate the economic environment of companies, we introduced the following features to the model: evolution of a supply chain network with the reconfiguration of links, price dispersion and the dynamics of prices and costs of production. At the certain point of the system’s evolution, the meta-stable structures of the network occur. As a result of the dynamics of prices and costs of production, we observed both the emergence of highly profitable supply chains with the high market share and the avalanches of bankruptcies.',NULL
8792,'invited talk','en',8653,'2009-06-11','2009-07-10','Prediction and its Limits in Socio-Economic Systems','Science recognizes a number of limitations to its power to predict the future of physical systems. Such limits typically stem from dynamical chaos or the impracticability of dealing with large numbers of variables. In this talk, I will review recent work pertaining to the limits of predictability in complex systems, and to novel features arising in systems involving adaptive agents, such as humans. The ”socio-physics” approach often elicits the criticism (from social scientists) that it ignores the ”reflexive” character of social reality – that valid insights into individual human behaviour, or social patterns, may quickly cause people to alter their behaviour, destroying the validity of those insights. I will argue that reflexitivity is a real phenomenon, but that it’s not a fundamental\nbarrier to socio-economic prediction, for two reasons. First, people under observation often become habituated to their environment and exhibit stable behaviour. Second, science is gaining an ability to model the reflexive process itself, by learning to model the process of human thinking. I’ll conclude by reviewing studies in political science which suggest that a key reflexive feedback driving many of the most recent financial crises has been the evolution of ”triangles” of power among government agencies, regulators and special interests, such as the financial industry. Any successful effort to prevent such crises may need to exert control over such feedbacks, and produce a regulatory framework that is in some sense ”lobby proof.”',NULL
8793,'invited talk','en',8653,'2009-06-11','2009-07-10','Travel and Social Capital: Some Empirical Evidence','The presentation will present a theoretical and empirical discussion of the links between the generalized costs of travel, the use of space and the (spatial) structure of social networks of the population.\n  After a brief historical overview of the changes in the generalized costs of travel and associated time-space compression of the industrialized countries, the question will be discussed what impact these changes should have on the structure of the social networks with respect to the size, overlap, spatial location.\n  The second part of the talk focuses on the empirical work done so far to provide empirical evidence for the theoretical expectations formulated above. The challenges inherent in the survey work will presented, as well as the key empirical results obtained so far.',NULL
8794,'invited talk','en',8653,'2009-06-11','2009-07-10','Microscopic Simulation of Tsunami-Related Evacuation of the City of Padang','The evacuation of whole cities or even regions is an important problem, as demonstrated by recent events such as the evacuation of Houston in the case of Hurricane Rita, or the evacuation of coastal cities in the case of tsunamis. A robust and flexible simulation framework for such large scale disasters helps to predict the evacuation process. Furthermore, it is possible to recognize bottlenecks in advance, so that an elimination of\nthose bottlenecks is possible. This should lead to a better preparedness for cities or regions that face a high risk of natural disasters. Existing methods are either geared towards smaller problems (e.g. Cellular Automata\ntechniques or methods based on differential equations) or are not microscopic (e.g. methods based on dynamic traffic assignment). Our work uses a technique that is both microscopic and capable to process large problems. The simulation is applied to the Indonesian city of Padang. The city faces a high risk of being inundated by an earth quake triggered tsunami.',NULL
8795,'invited talk','en',8653,'2009-06-11','2009-07-10','Macroscopic Modeling of Traffic in Congested Cities: Empirical Evidence, Analytical Derivations and Control Applications','Various theories have been proposed to describe vehicular traffic movement in cities on an aggregate level. They fall short to create a macroscopic model with variable inputs and outputs that could describe a rush hour dynamically. This work shows that a Macroscopic Fundamental Diagram (MFD) relating production (the product of average flow and network length) and accumulation (the product of average density and network length) exists for neighborhoods of cities in the order of 5 − 10 km2. It also demonstrates that conditional on accumulation large networks behave predictably and independently of their Origin-Destination tables. These results are based on analysis using simulation of large scale city networks and real data from urban metropolitan areas. Regularity conditions under which an MFD exists for different types of networks are proposed and tested. Further analysis of real data shows that an MFD is not a universal recipe that can describe any type of large network. For example, MFDs for spatially inhomogeneous networks or non-redundant networks, like freeway traffic systems, are highly scattered. An analytical model based on Variational Theory describes the connection between network structure and a network’s MFD for urban neighborhoods controlled\nat least in part by traffic signals. The MFD is applied to develop control strategies based on neighborhood accumulation and speeds and improve accessibility without the uncertainty inherent in forecast-based approaches.',NULL
8796,'invited talk','en',8653,'2009-06-11','2009-07-10','Statistical Physics and Social Systems: A Critical Perspective (The Case of Urban Mobility)','The application of Statistical Physics to social systems is mainly related to looking for macroscopic laws that are derived from experimental data average in time or space under the assumption that the averaged system\nis in a stationary state. The final goal is to correlate the statistical laws to the microscopic properties of the system: for example to understand the nature of the microscopic interactions or to point out the existence of interaction networks. However the probability theory suggests the existence of few classes of stationary distributions in the thermodynamics limit, so that the question is if a statistical physics approach could be able\nto point out the complex nature of the social systems. We have analyzed a GPS data base for individual mobility (2% of individual vehicles are monitored in Italy for insurance reasons) to look for statistical laws on path length distributions, elapsed time in the different activities related to mobility, flux distribution in the road network and frequency rank distribution for the individual destinations. We show as simple generic assumptions on the microscopic behavior could explain the existence of stationary macroscopic laws. Our conclusion is that the understanding of the system complexity requires dynamical data base for the microscopic behavior on a large scale time-dependent environment that allows to study the evolution of the transient states. Theoretical results on long range interacting systems suggest that the transient states may provide much more information of the microscopic interaction nature. Concerning human mobility the GPS data base will be improved in the next future by enhancing the recording time sampling and by increasing the sample size.',NULL
8797,'invited talk','en',8653,'2009-06-12','2009-07-10','Spiraling Toward Complete Markets and Financial Instability','The proliferation of financial instruments provides more opportunities to hedge risks, reducing transaction costs and making markets more complete. These predictions sharply contrasts with recent experience, where asymmetric information and imperfect competition have played a major role in turning expanding credit derivative markets into ”financial weapons of mass destruction”.\n  Here I argue that the escalation of market imperfections originates from the changes which take place in the nature of the market equilibria, when the repertoire of financial instruments expands. This is done in the limit of a large random economy, where a set of consumers invests in financial instruments engineered by banks, in order to optimize their future consumption.\n  I show that, even in the ideal case of perfect competition, where full information is available to all market participants, as markets approach completeness and transaction costs vanish, the equilibrium develops a marked vulnerability (or susceptibility) to market imperfections. Therefore, the onset of instability does not require large shocks, but it rather arises from the intrinsic nature of the equilibrium.\n  One particularly devastating effect is that, replicating portfolios used by banks to hedge new instruments, require trading volumes, within the financial sector, which diverge as the market approaches completeness. Such interbank market itself develops a divergent susceptibility, as the theoretical limit of complete markets is approached.\n  A similar approach shows that the expansion of derivative markets generates instability and large movements in underlying markets. These results suggest that the proliferation of financial instruments\nexacerbates the effects of market imperfections. In order to prevent an escalation of perverse effects, markets may necessitate institutional structures which are more and more conspicuous as they expand.',NULL
8798,'invited talk','en',8653,'2009-06-12','2009-07-10','The Role of Tie Strength in the Cohesion of the Society: A Tribute to Mark Granovetter','Electronic databases, from phone to emails logs, currently provide detailed records of human communication patterns, offering novel avenues to map and explore the structure of social and communication networks. We examine the communication patterns of millions of mobile phone users, allowing us to simultaneously study the local and the global structure of a society-wide communication network. We observe a coupling between interaction strengths and the networks local structure, and conclude that social networks are robust to the removal of the strong ties, but fall apart following a phase transition if the weak ties are removed. We show that this coupling significantly slows the diffusion process, resulting in dynamic trapping of information in communities, and find that when it comes to information diffusion, weak and strong ties are for different reasons both simultaneously ineffective.\n  Using the aggregate records of a mobile phone service provider about private voice calls of more than 4 million users we construct over 18 weeks a weighted network of interactions where the tie strength is taken proportional to the total duration of the calls. We introduce a measure of the link overlap and show that nodes (i.e., people) with strong links have a large friendship overlap. This way we prove for the first time the Granovetter hypothesis about the strength of weak ties at a societal scale. The network has a strongly modular structure with highly wired communities with strong ties, which are connected by weak links. \n  A global consequence of this structure is that the network connectedness is resilient against removal of strong links while it falls apart whenthe weak links are cancelled. \n  The intimate relationship between link weights and topology has strong influence on the dynamic properties of the network. Using the simplest diffusive spreading dynamics we demonstrated that the probability of getting new information (or, alternatively, getting infected) via a strong or weak link is low, in most cases links with an intermediate strength play the role of the transmitter. \n  In order to understand the peculiar interplay between topology and link weights we constructed a model of the social network. The model has strong simplifications and is based on elementary steps of link formation and tie strengthening. We deal with a constant number of nodes. In order to reach stationarity time to time a node is eliminated and, at the same time, a new one without any connections is born. Links are created either at random (with very low probability), or using already existing links (friends of friends get friends). An important element of the model is that whenever a link is used, there is a strengthening effect, described by a parameter σ. The resulting network describes well the qualitative features of the call network, including the strength of the weak ties and the trapping effect.',NULL
8799,'invited talk','en',8653,'2009-06-12','2009-07-10','The Weave of Social Life: How Social Interactions Shape the Individual','One of the deepest problems in the social sciences concerns the causal impact of society, that is, of properties of the group, on the properties of individuals. This problem arises because individuals affect the properties of groups and vice versa such that it is very difficult to get at causality. Here we take advantage of the possibility to affect the properties of internet communities to show that groups with a higher density of social interactions render their members generally more altruistic and trusting towards anonymous strangers. Moreover, a higher density of social interactions also causes a boost in trust towards those who reciprocate favours while it diminishes trust towards those who fail to reciprocate, thus generating a much stronger implicit punishment for untrustworthy individuals. Finally, increased social contact also enhances the strategic sophistication of individuals and raises the prevalence of Machiavellian strategies. These results indicate that the density of social interactions has a deep impact on individuals’ preferences, beliefs, and behaviors, lending support to sociological views of society.',NULL
8800,'invited talk','en',8653,'2009-06-12','2009-07-10','How Do Economies Grow, How Do They Interract, How Do They Fall and How Do They Recover?','The stochastic spatially extended generalized Lokta-Volterra approach was introduced a few years ago and was applied using analytical (field theory and statistical mechanics methods), numerically (computer experiments) and empirical (gathering and processing real data) techniques to a wide range of natural, biological, economic and social systems.\n  In this talk I will describe its recent application to the study of interactions between economic sectors, countries and blocks. The theory predicts robustly in a very wide range of conditions systematic regularities in the growth rates evolution of various subsystems.\n  The after-shocks J-curve phenomenon (economic decay and rebound induced by the emergence of singular growth centers) is revisited and more empirical support is given to the theory. In particular we show that the data support to the connection between the economic minimum and the crossover of the new emergent leading sector with the old decaying one. We describe the Growth Alignment Effect (GAE), its theoretical basis and demonstrate it empirically for numerous cases in the international and intranational economies. The GAE is the concept that in steady state the growth rates of the GDP per capita of the various system components align. We differentiate the GAE predictions from the usual convergence or divergence conceptual framework that dominated in economic studies until now.',NULL
8801,'invited talk','en',8653,'2009-06-12','2009-07-10','Robustness of Social Networks','Networks typically cease to be operational when they fall apart in disconnected pieces. This can be desired as in the case of criminal networks or should be avoided for instance in the case of communication systems.\nDestruction can happen randomly of due to a malicious attack. I will present various strategies of optimizing the robustness of networks preserving their degree distribution. A novel topology emerges. Applications to power networks, botnets, road systems and brain models will be discussed.',NULL
8802,'lecture','en',8653,'2009-06-12','2009-07-10','Closing of the Workshop',NULL,NULL
8804,'tutorial','en',8803,'2009-06-08','2009-07-10','Tutorial about Sociodynamics','Sociodynamics intends to provide an integrated strategy for mathematical modelling of collective dynamic processes in the human society. The approach is far more general than catastrophe theory: It comprises the full dynamics of key-variables, namely their chance behaviour as well as their quasi-deterministic evolution.It connects the bottom-up and top-down interaction between microlevel and macrolevel of the social system. The design principles start from the elementary dynamics of the key-variables in terms of socially interpretable probabilistic transition rates and end in evolution equations for them: The master equation for the probability distribution over key-variables comprises mean behaviour and fluctuations as well. The quasi-meanvalue-equations derivable from the master equation describe the mean evolution only.',NULL
8805,'lecture','en',8803,'2009-06-09','2009-07-10','How Crime Bursts Can Occur with Minor Changes in Retribution Policy','We model a system of interacting agents characterized by a given wealth and a certain criminal propensity, measured by an honesty coefficient. This honesty is related to intrinsic factors, like moral barriers, and extrinsic ones, as the risk of being imprisoned if committing an offense. In the simulation the honesty level of the agents is variable, and a function of the level of punition, on one hand, and on the contact with other agents (learning or contagion effect) on the other hand. The number of crimes per habitant is measured as a function of the probability of being caught. A sharp phase transition is observed as a function of the probability of punishment. That means that once criminality has attained a high level, the probability of retribution must considerably increase in order to come back to a state of low criminality. Also, some precursor signals are observed that indicate possible bursts of crime activity. We also analyze other consequences of criminality as the growth of the economy, the inequality in the wealth distribution (the Gini coefficient) and other relevant quantities under different scenarios of criminal activity and probabilities of apprehension.',NULL
8806,'lecture','en',8803,'2009-06-09','2009-07-14','Commitment as Unrewarded Behaviour','The purpose of my presentation on commitment is to show that in its core resides unrewarded behaviour, which is rare but essential to the conduct of social communities. Commitment is defined as an unequivocal behaviour of delivery, carried out under the worst conditions, when communities are unable to reward it. Unrewarded commitment is explored among 316 respondents. The newly defined commitment is mapped against conventional scales of commitment, and measures of perceived organizational power, perceived employment alternatives, personal values. Two types of unrewarded behaviour are identified: unrewarded commitment, which is not unrelated to traditional measures of commitment, such as affective and normative commitment, and extreme or Sisyphean unrewarded commitment, which displays organizational behaviour even with no affective, normative or instrumental attachment to the community.',NULL
8808,'lecture','en',8803,'2009-06-09','2009-07-10','Cooperation and Conflict in Wikipedia','We present a model of the collaborative process of document authoring that takes place in the free online encyclopedia Wikipedia. We consider the process of editing of a Wikipedia page by a group of agents with different opinions (points of view on the topic of the page), which are continuous variables, coupled with a time-inhomogeneous process for the WWW browsing to the page, in which motivational factors for the participation to the collaborative process affect the rate of visits to the page. The model of editing takes inspiration from response models of biological neurons. Social interactions between agents are thus mediated\nby the content of the page. In this original context of opinion dynamics, editors and regular users of Wikipedia are seen as actors having different objectives about what the point of view expressed by a Wikipedia page should be like, and modify it using a simple greedy heuristic. Interesting phenomena like the emergence of a shared, neutral point view may then be cast in the light of this dynamics of opinions. When the model of opinion dynamics is considered in isolation, simulations show that agents with opinions and rates of activity that are fixed in time converge on a pages opinion that reflect, on average, a shared point of view between.',NULL
8809,'lecture','en',8803,'2009-06-09','2009-07-10','Measuring the Response of a Social System','We study the relaxation response of a social system after endogenous and exogenous bursts of activity using the time series of daily views for nearly 5 million videos on YouTube. We find that most activity can be described accurately as a Poisson process. However, we also find hundreds of thousands of examples in which a burst of activity is followed by an ubiquitous power-law relaxation governing the timing of views. We find that these relaxation exponents cluster into three distinct classes and allow for the classification of collective human dynamics. This is consistent with an epidemic model on a social network containing two ingredients: a power-law distribution of waiting times between cause and action and an epidemic cascade of actions becoming the cause of\nfuture actions. This work is a conceptual extension of the fluctuation dissipation theorem to social systems and provides a unique framework for the investigation of timing in complex systems.',NULL
8810,'lecture','en',8803,'2009-06-10','2009-07-10','Nature’s Solution to the Problem of Biological Logistics','The ability of cells to survive and participate in a community, such as the human body, requires a logistical network that distributes nutrients, cellular contents, and information at biologically reasonable time-scales. How does a robust, adaptable system emerge from the sum of individual hard-wired molecular agents operating in a noisy environment? For example, motor proteins deliver cargo along intracellular filaments to appropriate sites in a network of molecular compartments whose connectivity is slowly becoming elucidated. However, surprisingly little is known about what these motor proteins do, specifically, (1) where they go in cells, (2) what they transport, and (3) how their activity is regulated. To address these basic questions, we modified motor proteins so they could be visualized in live cells and recovered with their physical binding partners. Individual motor proteins were also removed from cells to determine the overall effect on different cellular trafficking pathways. We found that different motor proteins are targeted to unique sub-cellular compartments and identified regulatory proteins resident in these compartments that could serve as molecular postal codes, or otherwise regulate the cycle of cargo binding and release. Overall, this provides an example of a biological solution to managing complex systems using a limited number of components. ',NULL
8811,'lecture','en',8803,'2009-06-10','2009-07-10','Do some Value-at-Risk Models Provoke Financial Market Destabilization? - An Agent-Based Financial Market Perspective','The aim of this paper is to explore the impact of different Value-at-Risk (VaR) models on the stability of financial markets. Based on a numerical analysis, we test how simple and more sophisticated Value-at-Risk\nmodels affect financial market stability. This is important to implement effective regulations to prevent financial market instability in advance. The Basel Committee of Banking and Supervision (BCBS) does not stipulate that banks use a special type of VaR model. Therefore, in practice, many banks use methods with quite simple assumptions. Testing the efficiency and reliability of different VaR models with different underlying assumptions was and still is an important strand of research. Here, mostly the accuracy of estimating a special quantile is exploited. In this study, we explore the adequacy of VaR models from another perspective. We adjust a heterogeneous agent model by integrating regulations of Basel II concerning market risk. For this purpose, we use the financial market model by Lux/Marchesi (1999/2000) that can replicate stylized facts of financial markets quite well. First results indicate that the formula for calculating the level of regulatory capital for market risk prescribed by the BCBS prohibits more market stability by the use of more sophisticated models.',NULL
8812,'lecture','en',8803,'2009-06-10','2009-07-10','Clustering Dynamics Through an Emerging Market Crash in the Global Crisis 2007-2009','We investigate the dynamics of stock clustering in the Johannesburg Stock Exchange (JSE), an emerging market, through the financial market crash of 2008. In particular we apply the fully unsupervised parameter free data clustering technique pioneered by Giada and Marsili (2002) to investigate the changing correlation structure of stocks, as well as clustering in daily market-wide activity, in a crisis. We compare our findings with an identical analysis of the London Stock Exchange through the same crisis period.',NULL
8813,'lecture','en',8803,'2009-06-10','2009-07-10','Early Signs of Financial Crises','For most diseases, it is always better to medically intervene earlier compared to later. This is because treatment at an early stage is generally more effective, and less expensive. The same is probably true for economies and financial markets. In the current global financial crisis, we have seen billions of dollars sunk into relief and stimulus packages, with hardly any positive result to show for the effort. The reason is clear: these intervention measures are too late. To implement more effective, and less costly economic and fiscal policies, it is important to detect the onset of a financial crisis early. At the same time, we do not want excessive reactions, when the market has merely caught a ’cold’. In this talk, I will describe recent work, based on the statistical segmentation and clustering analysis of financial time series data, that points to characteristic early signs prior to financial crises, characteristic early signs prior to a true recovery, and the characteristic time scales involved for both\nprocesses. By looking into a period that covers both the current crisis, as well as the most recent past crisis, we also hope to learn lessons on which intervention measures are effective, and which intervention measures\nare not.',NULL
8817,'lecture','en',8803,'2009-06-11','2009-07-10','Contagion of Norm Breaking vs the Number of Righteous People','The Norm Game introduced by Axelrod is investigated by computer simulations carried out for agents distributed in a random network. The agents are labeled as sinners or punishers after their first decision. The stationary state shows a bistable behaviour: all become sinners or all become punishers [1,2]. Here we show how this bistability changes when some amount of agents always break the norm or always punish.',NULL
8832,'opening','en',8751,'2009-06-01','2009-07-30','Welcome Speech at the MLSS 2009',NULL,NULL
8833,'tutorial','en',8751,'2009-06-01','2009-07-30','Kernel Methods and Support Vector Machines','Kernel methods have become a standard tool for pattern analysis during the last fifteen years since the introduction of support vector machines. We will introduce the key ideas and indicate how this approach to pattern analysis enables a relatively easy plug and play application of different tools. The problem of choosing and designing a kernel for specific types of data will also be considered and an overview of different kernels will be given.','Kernel Methods and Support Vector Machines;;Aim:;;What won’t be included:;;OVERALL STRUCTURE;;PART 1 STRUCTURE;;Pattern Analysis;;Defining patterns;;Pattern analysis algorithms;;Brief Historical Perspective;;Kernel methods;;Kernel methods approach;;Kernel methods embedding;;Worked example: Ridge Regression;;Possible pattern function;;Optimising the choice of g;;Primal solution;;Dual solution (1);;Dual solution (2);;Key ingredients of dual solution;;Applying the ‘kernel trick’;;A simple kernel example;;Implications of the kernel trick;;Implications of kernel algorithms;;Defining kernels;;Means and distances (1);;Means and distances (2);;Means and distances (3);;Means and distances (4);;Means and distances (5);;Means and distances (6);;Simple novelty detection;;OVERALL STRUCTURE;;mlss09us_shawe-taylor_kmsvm_Page_033;;Simple classification algorithm (1);;Simple classification algorithm (2);;Variance of projections (1);;Variance of projections (2);;Fisher discriminant (1);;Fisher discriminant (2);;Fisher discriminant (3);;Overview of remainder of tutorial;;Preprocessing;;Subspace methods;;Principal Components Analysis (1);;Principal Components Analysis (2);;Principal Components Analysis (3);;Kernel PCA (1);;Kernel PCA (2);;OVERALL STRUCTURE;;Part 3 structure;;Kernel algorithms;;Perceptron algorithm;;Margin Perceptron algorithm;;Support Vector Machines (SVM);;Margins in SVMs (1);;Margins in SVMs (2);;Form of the SVM bound;;Slack variable conversion;;Gives SVM Optimisation;;Dual form of the SVM problem;;Novelty detection (1);;Novelty detection (2);;Novelty detection (3);;Novelty detection (4);;OVERALL STRUCTURE;;Part 4 structure;;Kernel functions (1);;Kernel functions (2);;Kernel functions (3);;Kernel functions (4);;Kernel functions (5);;Kernel constructions (1);;Kernel constructions (2);;Subcomponents kernel (1);;Subcomponents kernel (2);;Graph kernels (1);;Graph kernels (2);;ANOVA kernels;;General Graph kernels;;Kernels for text (1);;Kernels for text (2);;Semantics for text (1);;Semantics for text (2);;Semantics for text (3);;Semantics for text (4);;String kernels (1);;String kernels (2);;Trie based p-spectrum kernels;;Gap weighted string kernels;;Tree kernels;;Probabilistic model kernels (1);;Probabilistic model kernels (2);;Fisher kernels (1);;Fisher kernels (2);;Fisher kernels (3);;Fisher kernels (4);;Conclusions;;Where to find out more;;mlss09us_shawe-taylor_kmsvm_Page_099;;mlss09us_shawe-taylor_kmsvm_Page_100;;mlss09us_shawe-taylor_kmsvm_Page_101;;mlss09us_shawe-taylor_kmsvm_Page_102;;mlss09us_shawe-taylor_kmsvm_Page_103'
8834,'lecture','en',8751,'2009-06-01','2009-07-30','Geometric Inference for Probability Distribution','Data often comes in the form of a point cloud sampled from an unknown compact subset of Euclidean space. The general goal of geometric inference is then to recover geometric and topological features (Betti numbers, curvatures,...) of this subset from the approximating point cloud data. In recent years, it appeared that the study of distance functions allows to address many of these questions successfully. However, one of the main limitations of this framework is that it does not cope well with outliers nor with background noise. In this talk, we will show how to extend the framework of distance functions to overcome this problem. Replacing compact subsets by measures, we will introduce a notion of distance function to a probability distribution.\nThese functions share many properties with classical distance functions, which makes them suitable for inference purposes. In particular, by considering appropriate level sets of these distance functions, it is possible to associate in a robust way topological and geometric features to a probability measure. If time permits, we will also mention a few other potential applications of this framework.','Geometric Inference for Probability distributions;;Motivation;;Geometric inference;;Distance functions for geometric inference;;Stability properties of the offsets;;The problem of outliers;;The three main ingredients for stability;;Replacing compact sets by measures;;Distance between measures;;Wasserstein distance;;The distance to a measure;;Unstability of µ -> σµ,m;;The distance function to a measure. (1);;The distance function to a measure. (2);;1-Concavity of the squared distance function;;Proposition;;Another expression for dµ,m0 (1);;Another expression for dµ,m0 (2);;Theorem;;Consequences of the previous properties;;Example : square with outliers (1);;Example : square with outliers (2);;A 3D example;;A reconstruction theorem;;k-NN density estimation vs distance to a measure (1);;k-NN density estimation vs distance to a measure (2);;k-NN density estimation vs distance to a measure (3);;k-NN density estimation vs distance to a measure (4);;Pushing data along the gradient of dµ,m0 (1);;Pushing data along the gradient of dµ,m0 (2);;Take-home messages'
8835,'lecture','en',8751,'2009-06-01','2009-07-30','PAC-Bayes Analysis: Background and Applications',NULL,'PAC-Bayes Analysis: Background and Applications;;mlss09us_shawe-taylor_pacbaba_Page_002;;mlss09us_shawe-taylor_pacbaba_Page_003;;mlss09us_shawe-taylor_pacbaba_Page_004;;mlss09us_shawe-taylor_pacbaba_Page_005;;Aims;;Outline;;General perspectives (1);;General perspectives (2);;General perspectives (3);;General perspectives (4);;General perspectives (5);;Historical notes: Frequentist approach (1);;Historical notes: Frequentist approach (2);;Historical notes: Frequentist approach (3);;Historical notes: Frequentist approach (4);;Historical notes: Frequentist approach (5);;Historical notes: Bayesian approach (1);;Historical notes: Bayesian approach (2);;Historical notes: Bayesian approach (3);;Historical notes: Bayesian approach (4);;Version space: evidence;;Evidence and generalisation (1);;Evidence and generalisation (2);;Evidence and generalisation (3);;Evidence and generalisation (4);;PAC-Bayes Theorem (1);;PAC-Bayes Theorem (2);;PAC-Bayes Theorem (3);;PAC-Bayes Theorem (4);;Definitions for main result - Prior and posterior distributions (1);;Definitions for main result - Prior and posterior distributions (2);;Definitions for main result - Prior and posterior distributions (3);;Definitions for main result - Error measures (1);;Definitions for main result - Error measures (2);;Definitions for main result - Error measures (3);;Definitions for main result - Error measures (4);;Definitions for main result - Assessing the posterior (1);;Definitions for main result - Assessing the posterior (2);;Definitions for main result - Generalisation error;;PAC-Bayes Theorem;;Finite Classes (1);;Finite Classes (2);;Linear classifiers and SVMs (1);;Linear classifiers and SVMs (2);;Linear classifiers and SVMs (3);;Linear classifiers and SVMs (4);;Linear classifiers (1);;Linear classifiers (2);;Linear classifiers (3);;PAC-Bayes Bound for SVM (1/2) (1);;PAC-Bayes Bound for SVM (1/2) (2);;PAC-Bayes Bound for SVM (1/2) (3);;PAC-Bayes Bound for SVM (1/2) (4);;PAC-Bayes Bound for SVM (2/2) (1);;PAC-Bayes Bound for SVM (2/2) (2);;PAC-Bayes Bound for SVM (2/2) (3);;PAC-Bayes Bound for SVM (2/2) (4);;PAC-Bayes Bound for SVM (2/2) (5);;PAC-Bayes Bound for SVM (2/2) (6);;PAC-Bayes Bound for SVM (2/2) (7);;PAC-Bayes Bound for SVM (2/2) (8);;PAC-Bayes Bound for SVM (2/2) (9);;PAC-Bayes Bound for SVM (2/2) (10);;PAC-Bayes Bound for SVM (2/2) (11);;PAC-Bayes Bound for SVM (2/2) (12);;PAC-Bayes Bound for SVM (2/2) (13);;PAC-Bayes Bound for SVM (2/2) (14);;PAC-Bayes Bound for SVM (2/2) (15);;PAC-Bayes Bound for SVM (2/2) (16);;Form of the SVM bound (1);;Form of the SVM bound (2);;Gives SVM Optimisation;;Slack variable conversion;;Learning the prior (1/3) (1);;Learning the prior (1/3) (2);;Learning the prior (1/3) (3);;Learning the prior (1/3) (4);;Learning the prior (1/3) (5);;Tightness of the new bound;;Model Selection with the new bound: results;;Model selection with p-SVM;;Tightness of the bound with p-SVM;;Maximum entropy learning (1);;Maximum entropy learning (2);;Maximum entropy learning (3);;Posterior distribution Q(w) (1);;Posterior distribution Q(w) (2);;Error expression;;Error expression proof;;Generalisation error;;Base result (1);;Base result (2);;Base result (3);;Interpretation (1);;Interpretation (2);;Interpretation (3);;Boosting the bound (1);;Boosting the bound (2);;Full result (1);;mlss09us_shawe-taylor_pacbaba_Page_101;;Full result (2);;Algorithmics (1);;Algorithmics (2);;Dual optimisation (1);;Dual optimisation (2);;Dual optimisation (3);;Dual optimisation (4);;Results: effect of varying T;;Results;;Gaussian Process Regression (1);;Gaussian Process Regression (2);;Gaussian Process Regression (3);;Gaussian Process Regression (4);;Applying PAC-Bayes theorem (1);;Applying PAC-Bayes theorem (2);;Applying PAC-Bayes theorem (3);;GP Result;;GP Experimental Results (1);;GP Experimental Results (2);;GP Experimental Results (3);;GP Experimental Results (4);;Stochastic Differential Equation Models (1);;Stochastic Differential Equation Models (2);;Stochastic Differential Equation Models (2);;Variational approximation (1);;Variational approximation (2);;Girsanov change of measure (1);;Girsanov change of measure (2);;KL divergence;;Variational approximation (1);;Variational approximation (2);;Algorithmics (1);;Algorithmics (2);;Error estimation (1);;Error estimation (2);;Error estimation (3);;Error estimation (4);;Generalisation analysis (1);;Generalisation analysis (2);;Generalisation analysis (3);;Error estimates (1);;Error estimates (2);;Error estimates (3);;Refining the distributions (1);;Refining the distributions (2);;Final result;;Small scale experiment (1);;Small scale experiment (2);;Small scale experiment (3);;Conclusions (1);;Conclusions (2);;Conclusions (3);;Conclusions (4);;Conclusions (5);;Conclusions (6);;Conclusions (7);;Conclusions (8);;Conclusions (9)'
8836,'lecture','en',8751,'2009-06-01','2009-07-30','Cut Locus and Topology from Point Data','A cut locus of a point p in a compact Riemannian manifold M is defined as the set of points where minimizing geodesics issued from p stop being minimizing. It is known that a cut locus contains most of the topological information of M. Our goal is to utilize this property of cut loci to decipher the topology of M from a point sample. Recently it has been shown that Rips complexes can be built from a point sample P of M systematically to compute the Betti numbers, the rank of the homology groups of M. Rips complexes can be computed easily and therefore are favored over others such as restricted Delaunay, alpha, Cech, and witness complex. However, the sizes of the Rips complexes tend to be large. Since the dimension of a cut locus is lower than that of the manifold M, a subsample of P approximating the cut locus is usually much smaller in size and hence admits a relatively small Rips complex. \nIn this talk we explore the above approach for point data sampled from surfaces embedded in any high dimensional Euclidean space. We present an algorithm that computes a subsample P\' of a sample P of a 2-manifold where P\' approximates a cut locus. Empirical results show that the first Betti number of M can be computed from the Rips complexes built on these subsamples. The sizes of these Rips complexes are much smaller than the one built on the original sample of M. \n\n','Cut Locus and Topology from Point Data;;Problem (1);;Problem (2);;Motivations (1);;Motivations (2);;Motivations (3);;Motivations (4);;Motivations (5);;Motivations (6);;Motivations (7);;Motivations (8);;Motivations (9);;A Critical Observation (1);;A Critical Observation (2);;Goal (1);;Goal (2);;Goal (3);;Geodesics and Cut Locus (1);;Geodesics and Cut Locus (2);;Geodesics and Cut Locus (3);;Geodesics and Cut Locus (4);;Cut Locus (1);;Cut Locus (2);;Geodesics and Cut Locus – distances (1);;Geodesics and Cut Locus – distances (2);;Geodesics and Cut Locus – distances (3);;Geodesics and Cut Locus – distances (4);;Injectivity Radius (1);;Injectivity Radius (2);;Surface Cut Locus – structural properties (1);;Surface Cut Locus – structural properties (2);;Tree and Cycle Points (1);;Tree and Cycle Points (2);;Tree and Cycle Points (3);;Tree and Cycle Points (4);;A Structural Property;;A Subset of C(p) (1);;A Subset of C(p) (2);;A Subset of C(p) (3);;A Subset of C(p) (4);;Geodesic Spread (1);;Geodesic Spread (2);;Geodesic Spread (3);;Geodesic Spread (4);;Geodesic Spread (5);;Geodesic Spread - example;;Geodesic Spread and Cut Locus Points (1);;Geodesic Spread and Cut Locus Points (2);;Geodesic Spread and Cut Locus Points (3);;Geodesic Spread and Cut Locus Points (4);;Geodesic Spread and Cut Locus Points (5);;Approximating Geodesic Paths and Spread (1);;Approximating Geodesic Paths and Spread (2);;Approximating Geodesic Paths and Spread (3);;Approximating Geodesic Paths and Spread (4);;Geodesic Approximation (1);;Geodesic Approximation (2);;Geodesic Approximation (3);;Spread Approximation (1);;Spread Approximation (2);;Cut Locus Approximation;;Cut Locus Approximation – justification of CUTLOCUS ;;Computing Homology – sampling density estimation (1);;Computing Homology – sampling density estimation (2);;Computing Homology – sampling density estimation (3);;Computing Homology – computing Betti numbers;;Computing Homology – time complexity (1);;Computing Homology – time complexity (2);;Computing Homology – time complexity (3);;Experiments (1);;Experiments (2);;Experiments (3);;Experiments (4);;Experiments (5);;Experiments (6);;Experiments (7);;Conclusion and Future Work (1);;Conclusion and Future Work (2);;Conclusion and Future Work (3);;Conclusion and Future Work (4);;Conclusion and Future Work (5);;Thank you'
8837,'tutorial','en',8751,'2009-06-02','2009-07-30','Graphical Models and Applications','Compressed sensing is a recent set of mathematical results showing that sparse signals can be exactly reconstructed from a small number of linear measurements. Interestingly, for ideal sparse signals with no measurement noise, random measurements allow perfect reconstruction while measurements based on principal component analysis (PCA) or independent component analysis (ICA) do not. At the same time, for other signal and noise distributions, PCA and ICA can significantly outperform random projections in terms of enabling reconstruction from a small number of measurements. In this paper we ask: given a training set typical of the signals we wish to measure, what are the optimal set of linear projections for compressed sensing? We show that the optimal projections are in general not the principal components nor the independent components of the data, but rather a seemingly novel set of projections that capture what is still uncertain about the signal, given the training set. We also show that the projections onto the learned uncertain components may far outperform random projections. This is particularly true in the case of natural images, where random projections have vanishingly small signal to noise ratio as the number of pixels becomes large. Joint work with Hyun-Sung Chang and Bill Freeman. \nI will give a brief introduction to questions of representation, learning and inference in probabilistic graphical models and illustrate these ideas in applications from our own work in computational biology and computer vision.',NULL
8838,'lecture','en',8751,'2009-06-02','2009-07-30','Euler Calculus and Topological Data Management','This talk covers the basic of an integral calculus based on Euler characteristic, and its utility in data problems, particularly in aggregation of redundant data and inverse problems over networks. This calculus is a blend of integral-geometric and sheaf theoretic techniques, and leads to surprisingly practical algorithms and computations. Qualitative versions of integral transforms for signal processing will be stressed.','euler calculus & data;;motivation;;tools;;euler calculus (1);;euler calculus (2);;sheaves;;∫h dχ;;integration (1);;integration (2);;problem (1);;problem (2);;counting;;computation;;example (1);;example (2);;some applications in minimal sensing;;waves;;wheels (1);;wheels (2);;numerical integration (1);;numerical integration (2);;ad hoc networks;;get real…;;real-valued integrands (1);;real-valued integrands (2);;real-valued integrands (3);;incomplete data (1);;incomplete data (2);;expected values;;integral transforms;;inversion;;fourier transform;;radon transform;;bessel transform;;open questions;;topological network topology;;closing credits…'
8839,'lecture','en',8751,'2009-06-02','2009-07-30','Seeking Interpretable Models for High Dimensional Data',' Extracting useful information from high-dimensional data is the focus of today\'s statistical research and practice. After broad success of statistical machine learning on prediction through regularization, interpretability is gaining attention and sparsity has been used as its proxy. With the virtues of both regularization and sparsity, Lasso (L1 penalized L2 minimization) has been very popular recently. In this talk, I would like to discuss the theory and pratcice of sparse modeling. First, I will give an overview of recent research on sparsity and explain what useful insights have been learned from theoretical analyses of Lasso. Second, I will present collaborative research with the Gallant Lab at Berkeley on building sparse models (linear, nonlinear, and graphical) that describe fMRI responses in primary visual cortex area V1 to natural images. ','Seeking Interpretable Models for High Dimensional Data;;Characteristics of Modern Data Problems;;Today’s Talk;;Understanding visual pathway;;Understanding visual pathway through fMRI;;Gallant Lab in Nature News;;Stimuli;;Stimulus to fMRI response;;Gabor Wavelet Pyramid;;Features;;“Neural” (fMRI) encoding for visual cortex V1;;Linear Encoding Model by Gallant Lab;;Modeling “history” at Gallant Lab;;Occam’s Razor;;Occam’s Razor via Model Selection in Linear Regression;;Model Selection Criteria;;Model Selection for image-fMRI problem;;Lasso: L1-norm as a penalty;;Lasso: computation and evaluation;;Model Selection Consistency of Lasso;;Model Selection Consistency of Lasso;;Irrepresentable condition (s=2, p=3): geomery;;Consistency of Lasso for Model Selection;;Model Selection Consistency of Lasso (p>>n);;Gaussian Graphical Model;;L1 penalized log Gaussian Likelihood;;Success prob’s dependence on n and p (Gaussian);;Success prob’s dependence on “model complexity” K and n;;Back to image-fMRI problem:Linear sparse encoding model on complex “cells”;;Our story on image-fMRI problem;;Other methods;;Validation correlation;;Comparison of the feature locations;;Our Story (cont);;SpAM V1 encoding model;;Prediction performance (R2);;Nonlinearities;;Identical Nonlinearity;;Identical-nonlinearity vs linearity: R^2 prediction;;Episode 3: nonlinearity via power transformations (classical stage);;Make it Gaussian;;Gaussianization of features improves prediction;;Episode 4: localized predictors;;Localized prediction;;After localization: view responses of a single voxel;;Localization does not work for all voxels;;Who is responsible? (on-going);;Some unlocalized voxels;;Episode 5: sparse graphical models (on-going);;Episode 6: building neighbor model (on-going);;Prediction (Neighbor compared to Global);;Summary;;Summary (cont);;Future work;;Acknowledgements;;mlss09us_yu_simhdd_Page_56;;mlss09us_yu_simhdd_Page_57;;mlss09us_yu_simhdd_Page_58;;mlss09us_yu_simhdd_Page_59;;mlss09us_yu_simhdd_Page_60;;mlss09us_yu_simhdd_Page_61;;mlss09us_yu_simhdd_Page_62;;mlss09us_yu_simhdd_Page_63;;mlss09us_yu_simhdd_Page_64;;mlss09us_yu_simhdd_Page_65;;mlss09us_yu_simhdd_Page_66;;mlss09us_yu_simhdd_Page_67;;mlss09us_yu_simhdd_Page_68;;mlss09us_yu_simhdd_Page_69;;mlss09us_yu_simhdd_Page_70'
8840,'lecture','en',8751,'2009-06-02','2009-07-30','Learning Dictionaries for Image Analysis and Sensing','Sparse representations have recently drawn much attention from the signal processing and learning communities. The basic underlying model consist of considering that natural images, or signals in general, admit a sparse decomposition in some redundant dictionary. This means that we can find a linear combination of a few atoms from the dictionary that lead to an efficient representation of the original signal. Recent results have shown that learning overcomplete non-parametric dictionaries for image representations, instead of using off-the-shelf ones, significantly improves numerous image and video processing tasks. \nIn this talk, I will first present our results on learning multiscale overcomplete dictionaries for color image and video restoration. I will present the framework and provide numerous examples showing state-of-the-art results. I will then briefly show how to extend this to image classification, deriving energies and optimization procedures that lead to learning non-parametric dictionaries for sparse representations optimized for classification. I will conclude by showing results on the extension of this to sensing and the learning of incoherent dictionaries. The work I present in this talk is the result of great collaborations with J. Mairal (ENS, Paris), F. Rodriguez (UofM/Spain), J. Martin-Duarte (UofM/Kodak), I. Ramirez (UofM), F. Lecumberry (UofM), F. Bach (ENS, Paris), M. Elad (Technion, Israel), J. Ponce (ENS, Paris), and A. Zisserman (ENS/Oxford). ','Learning sparse representationsto restore, classify, and sense images and videos;;Collaboration;;Overview;;Introduction I: Sparse and Redundant Representations;;Restorationby Energy Minimization;;The Sparseland Model for Images;;What Should the Dictionary D Be?;;Introduction II: Dictionary Learning;;Measure of Quality for D;;The K–SVD Algorithm –General;;Show me the pictures;;Change the Metric in the OMP;;Non-uniform noise;;Example: Non-uniform noise;;Example: Inpainting;;Example: Demoisaic;;Example: Inpainting;;Not enough fun yet?: Multiscale Dictionaries;;Learned multiscale dictionary (1);;Learned multiscale dictionary (2);;Color multiscale dictionaries;;Example;;Video inpainting;;Extending the Models;;Universal Coding and Incoherent Dictionaries;;Sparsity + Self-similarity=Group Sparsity;;Learning to Classify;;Global Dictionary ;;Barbara;;Boat;;Digits;;Which dictionary? How to learn them?;;Learning multiple reconstructive and discriminative dictionaries;;Texture classification;;Semi-supervised detection learning;;Learning a Single Discriminative and Reconstructive Dictionary;;Digits images: Robust to noise and occlusions;;Supervised Dictionary Learning;;Learning to Sense Sparse Images;;Motivation;;Some formulas….;;Design the dictionary and sensing together;;Just Believe the Pictures (1);;Just Believe the Pictures (2);;Just Believe the Pictures (3);;Conclusions;;Please do not use the wrong dictionaries…;;The end'
8841,'tutorial','en',8751,'2009-06-03','2009-07-30','Geometric Methods and Manifold Learning',NULL,'Geometric Methods and Manifold Learning;;High Dimensional Data;;Geometry and Data: The Central Dogma;;Manifold Learning;;Formal Justification;;Take Home Message;;Principal Components Analysis;;Manifold Model;;An Acoustic Example (1);;An Acoustic Example (2);;Solutions;;Acoustic Phonetics;;Vision Example;;Robotics;;Manifold Learning;;Differential Geometry;;Embedded manifolds;;Tangent space;;Tangent vectors and curves (1);;Tangent vectors and curves (2);;Tangent vectors as derivatives (1);;Tangent vectors as derivatives (2);;Riemannian geometry;;Length of curves and geodesics;;Gradient;;Exponential map;;Laplace-Beltrami operator;;Intrinsic Curvature;;Dimensionality Reduction;;Algorithmic framework (1);;Algorithmic framework (2);;Algorithmic framework (3);;Isomap;;Multidimensional Scaling (1);;Multidimensional Scaling (2);;Isomap;;Unfolding flat manifolds;;Locally Linear Embedding (1);;Locally Linear Embedding (2);;Laplacian and LLE;;Laplacian Eigenmaps (1);;Laplacian Eigenmaps (2);;Laplacian Eigenmaps (3);;Diffusion Distance;;Diffusion Maps;;Justification;;A Fundamental Identity;;Embedding;;PCA versus Laplacian Eigenmaps;;On the Manifold;;Curves on Manifolds;;Stokes Theorem;;Manifold Laplacian;;Properties of Laplacian;;The Circle: An Example;;From graphs to manifolds (1);;From graphs to manifolds (2);;Estimating Dimension from Laplacian;;Visualization;;Motion estimation;;Graphics, etc;;Recall;;Proof idea (pointwise convergence) (1);;Proof idea (pointwise convergence) (2);;Proof idea (pointwise convergence) (3);;Some difficulties (1);;Some difficulties (2);;The Heat Kernel;;Three Remarks on Noise;;NLDR: some references;;Unlabeled data;;Geometry of classification;;Intuition (1);;Intuition (2);;Intuition (3);;Intuition (4);;Manifold assumption (1);;Manifold assumption (2);;Manifold assumption (3);;Geodesic Nearest Neighbors;;Cluster assumption (1);;Cluster assumption (2);;Unlabeled data (1);;Unlabeled data (2);;Manifold assumption (1);;Manifold assumption (2);;Manifold assumption (3);;What is smooth? (1);;What is smooth? (2);;Geometry of clustering;;Spectral graph clustering (1);;Spectral graph clustering (2);;Spectral graph clustering (3);;Spectral graph clustering (4);;Graph Clustering: Mincut;;Graph Laplacian (1);;Graph Laplacian (2);;Consistency of spectral clustering;;Continuous Cheeger clustering;;Continuous spectral clustering;;Estimating volumes of cuts;;Clustering;;Future Directions'
8842,'invited talk','en',8751,'2009-06-03','2009-07-30','Examining the Relative Influence of Familial, Genetic, and Environmental Covariate Information in Flexible Risk Models','We present a novel method for examining the relative influence of familial, genetic and environmental covariate information in flexible nonparametric risk models. Our goal is investigating the relative importance of these three sources of information as they are associated with a particular outcome. To that end, we developed a method for incorporating arbitrary pedigree information in a smoothing spline ANOVA (SS-ANOVA) model. By expressing pedigree data as a positive semidefinite kernel matrix, the SS-ANOVA model is able to estimate a log-odds ratio as a multicomponent function of several variables: one or more functional components representing information from environmental covariates and/or genetic marker data and another representing pedigree relationships. We report a case study on models for retinal pigmentary abnormalities in the Beaver Dam Eye Study (BDES). Our model verifies known facts about the epidemiology of this eye lesion - found in eyes with early age-related macular degeneration (AMD) - and shows significantly increased predictive ability in models that include all three of the genetic, environmental and familial data sources. The case study also shows that models that contain only two of these data sources, that is, pedigree-environmental covariates or pedigree-genetic markers, or environmental covariates-genetic markers, have comparable predictive ability, while less than the model with all three. This result is consistent with the notions that genetic marker data encodes - at least partly - pedigree data, and that familial correlations encode shared environment data as well.','Examining the Relative Influence of Familial, Genetic and Covariate Information In Flexible Risk Models;;Abstract;;Outline;;The Log Likelihood for Bernoulli responses;;Penalized Log Likelihood Estimate;;Reproducing Kernel Hilbert Spaces (RKHS);;ANOVA Decomposition of Functions of Several Variables;;ANOVA Decomposition of Functions of Several Variables (continued) (1);;ANOVA Decomposition of Functions of Several Variables (continued) (2);;ANOVA Decomposition of Functions of Several Variables (continued) (3);;ANOVA Decomposition of Functions of Several Variables (continued) (4);;SS-ANOVA Model in the Beaver Dam Eye Study (1);;SS-ANOVA Model in the Beaver Dam Eye Study (2);;SS-ANOVA Model in the Beaver Dam Eye Study (3);;SS-ANOVA Model in the Beaver Dam Eye Study (4);;Modeling E/C, genetic and pedigree data in an extended SS-ANOVA model;;A Pedigree from BDES;;A Relationship (Sub)Graph From the Pedigree;;Relationship Data Encoded with RKE;;Relationship Data Encoded With RKE (continued);;Embedding of Pedigree by RKE;;Relationship Data Encoded With RKE (continued);;Qualitative Results;;Comparing Models by Their Area Under the (ROC) Curve (AUC);;Results;;Summary and Conclusions;;Further Work:'
8843,'lecture','en',8751,'2009-06-03','2009-07-30','Vision and Hodge Theory',' A general mathematical Hodge theory will be presented together with its relationship to spaces of images. ',NULL
8844,'lecture','en',8751,'2009-06-03','2009-07-30','Learning Deformable Models','It is widely recognized that the fundamental building block in high level computer vision is the deformable template, which represents realizations of an object class in the image as noisy geometric instantiations of an underlying model. The instantiations typically come from a subset of some group centered at the identity which act on the model or template. Thus in contrast to some machine learning applications where one tries to discover some unspecified manifold structure, here it is entirely determined by the group action and the model. Given a choice of group action and family of template models a major challenge is to use a sample of images of the object to estimate the model and the distribution on the group. The primary obstacle is that the instantiations or group elements that produced each image are unobserved. I will describe a general formulation of this problem and then show some practical applications to object detection and recognition. ','Learning deformable models;;Why modeling?;;Modeling object appearance (1);;Modeling object appearance (2);;Mathematical formulation;;Template estimation;;Unobserved deformations;;Example: handwritten digits;;Transforming to oriented edges;;Deforming the data;;Simplest background model;;Mixtures;;Mixture models for the `micro-world\' (1);;Mixture models for the `micro-world\' (2);;Modulo deformations (1);;Modulo deformations (2);;Structured library of parts;;Part based representation;;Simple non-linear deformations;;Patchwork model: gray levels;;Training a POP model;;Training a POP model continued (1);;Training a POP model continued (2);;Training a POP model continued (3);;Conclusion'
8845,'lecture','en',8751,'2009-06-03','2009-07-30','Statistical Classification and Cluster Processes','After an introduction to the notion of an exchangeable random partition, we continue with a more detailed discussion of the Ewens process and some of its antecedents. The concept of an exchangeable cluster process will be described, the main example being the Gauss-Ewens process. Some applications of cluster processes will be discussed, including problems of classification or supervised learning, and cluster analysis (unsupervised learning). A second type of probabilistic model based on point processes is also described. By contrast, which the Gauss-Ewes cluster process, the domain associated with each class is more diffuse and not localized in the feature space. For both models, the classification problem is interpreted as the problem of computing the predictive distribution for the class of a new object having a given feature vector. In one case, this is a conditional distribution given the observed features, in the other a Papangelou conditional intensity. ','Probabilistic classification models;;Outline;;Statistical classification and discrimination;;Partitions;;The set En of partitions of [n];;Probability distributions on partitions;;Exchangeable partition process;;The Ewens partition process;;Other interpertations of the Ewens process;;Characterization of the Ewens distribution;;The Gauss-Ewens cluster process;;Exchangeability of cluster process;;Constructive version of Gauss-Ewens process;;Ordinary Gauss-Ewens process in R2;;Gauss-Ewens process with sub-clusters in R2;;Gauss-Ewens process with topological clusters;;Cluster models for classification w/o classes;;Explicit calculation of conditional distribution;;Block having maximum conditional probability;;A point process model for classification;;Point process distributions: outline for general X;;α-permanent: definition and properties;;Boson point process;;Boson multi-class model;;Classification distributions: labelled and unlabelled;;Example;;Density plot of predictive probability pr(red | data);;Algorithms for approximation;;References (1);;References (2);;References (3)'
8846,'tutorial','en',8751,'2009-06-04','2009-07-30','Theory, Methods and Applications of Active Learning','Traditional approaches to machine learning and statistical inference are passive, in the sense that all data are collected prior to analysis in a non-adaptive fashion. One can envision, however more active strategies in which information gleaned from previously collected data is used to guide the selection of new data. This talk discusses the emerging theory of such \"active learning\" methods. I will show that feedback between data analysis and data collection can be crucial for effective learning and inference. The talk will describe two active learning problems. First, I will consider binary-valued prediction (classification) problems, for which the prediction errors of passive learning methods can be exponentially larger than those of active learning. Second, I will discuss the role of active learning in the recovery of sparse vectors in noise. I will show that certain weak, sparse patterns are imperceptible from passive measurements, but can be recovered perfectly using selective sensing.','Theory, Methods and Applications of Active Learning;;mlss09us_nowak_castro_tmaal_Page_02;;mlss09us_nowak_castro_tmaal_Page_03;;mlss09us_nowak_castro_tmaal_Page_04;;mlss09us_nowak_castro_tmaal_Page_05;;mlss09us_nowak_castro_tmaal_Page_06;;mlss09us_nowak_castro_tmaal_Page_07;;mlss09us_nowak_castro_tmaal_Page_08;;mlss09us_nowak_castro_tmaal_Page_09;;mlss09us_nowak_castro_tmaal_Page_10;;mlss09us_nowak_castro_tmaal_Page_11;;mlss09us_nowak_castro_tmaal_Page_12;;mlss09us_nowak_castro_tmaal_Page_13;;mlss09us_nowak_castro_tmaal_Page_14;;mlss09us_nowak_castro_tmaal_Page_15;;mlss09us_nowak_castro_tmaal_Page_16;;mlss09us_nowak_castro_tmaal_Page_17;;mlss09us_nowak_castro_tmaal_Page_18;;Robot Scietist;;Hypothesis and Query/Feature Spaces;;A Simple Algorithm for Noiseless Active Learning;;mlss09us_nowak_castro_tmaal_Page_22;;mlss09us_nowak_castro_tmaal_Page_23;;mlss09us_nowak_castro_tmaal_Page_24;;mlss09us_nowak_castro_tmaal_Page_25;;mlss09us_nowak_castro_tmaal_Page_26;;mlss09us_nowak_castro_tmaal_Page_27;;mlss09us_nowak_castro_tmaal_Page_28;;mlss09us_nowak_castro_tmaal_Page_29;;mlss09us_nowak_castro_tmaal_Page_30;;mlss09us_nowak_castro_tmaal_Page_31;;mlss09us_nowak_castro_tmaal_Page_32;;mlss09us_nowak_castro_tmaal_Page_33;;mlss09us_nowak_castro_tmaal_Page_34;;mlss09us_nowak_castro_tmaal_Page_35;;Theory, Methods and Applications of Active Learning;;What can Active Learning do for Us?;;Outline;;A Simple Problem – Learning a Threshold;;Passive Learning – no noise;;Active Learning – no noise;;Probabilistic Framework for Classification;;Bayes Classifier (1);;Bayes Classifier (2);;Learning from Examples;;Expected Risk and Sample Complexity;;Excess Risk;;Passive Learning;;Active Learning;;Passive vs. Active Sampling;;The One Dimensional Threshold Problem;;Various Scenarios;;Characterizing the Noise Level;;Active Learning – Bounded Noise;;Burnashev-Zigangirov (BZ) Algorithm ‘73 (1);;Burnashev-Zigangirov (BZ) Algorithm ‘73 (2);;Active vs. Passive – Bounded Noise (1);;Active vs. Passive – Bounded Noise (2);;Unbounded Noise (1);;Unbounded Noise (2);;Active vs. Passive – Unbounded noise (1);;Active vs. Passive – Unbounded noise (2);;Lower Bound – Active Learning;;Lower Bound Proof Technique (1);;Lower Bound Proof Technique (2);;Proof Sketch;;From Probability to Expectation Bounds;;Lower Bound Proof – Passive Sampling;;Outline;;From 1D to Multiple Dimensions;;Multidimensional Settings;;Noise Condition – Transition Smoothness;;Active Learning for Boundary Fragments;;Estimating Boundary Fragments (1);;Estimating Boundary Fragments (2);;Upper and Lower Bounds;;Implication: General Classes;;Why are these Results Important?;;From Theory to Practice: Limitations of Boundary Fragment Model;;Theory, Methods and Applications of Active Learning;;Learning to Discover;;Laplace;;What is Active Learning ?;;Does active learning always help ?;;Why Active Learning? Understanding the Mind (1);;Why Active Learning? Understanding the Mind (2);;Visual Perception (1);;Visual Perception (2);;Visual Perception (3);;Visual Perception (4);;Visual Perception (5);;Why Active Learning? Understanding Complex Systems;;National Ecological Observation Network (NEON);;Learning by Queries;;Why Active Learning? Automating Science;;Machine Learning (Passive);;Active Learning;;Robot Scientist;;Hypothesis and Query/Feature Spaces;;A Simple Algorithm for Noiseless Active Learning;;Generalized Binary Search / Splitting Algorithm;;Flavors of Active Learning and Analysis;;What if there is noise or mismatch ?;;Active Learning for Classification;;Example;;Active Learning for Regression;;Active Learning for Image Processing;;Active Learning for Fun !;;Theoretical Foundations of Active Learning;;Passive Learning;;Semi-Supervised and Active Learning;;Learning Rates and Sample Complexity;;Research Questions;;A few success stories ;;Learning a decision hyperplane in Rd (1);;Learning a decision hyperplane in Rd (2);;Now you see it, now you don\'t'
8847,'invited talk','en',8751,'2009-06-04','2009-07-30','Sparse Representations from Inverse Problems to Pattern Recognition','Sparse representations are at the core of many low-level signal processing procedures and are used by most pattern recognition algorithms to reduce the dimension of the search space. Structuring sparse representations fro pattern recognition applications requires taking into account invariants relatively to physical deformations such as rotation scaling or illumination. Sparsity, invariants and stability are conflicting requirements which is a source of open problems. Structured sparse representations with locally linear vector spaces are introduced for super-resolution inverse problems and pattern recognition. ',NULL
8848,'lecture','en',8751,'2009-06-04','2009-07-30','Optimization Algorithms in Support Vector Machines ','This talk presents techniques for nonstationarity detection in the context of speech and audio waveforms, with broad application to any class of time series that exhibits locally stationary behavior. Many such waveforms, in particular information-carrying natural sound signals, exhibit a degree of controlled nonstationarity, and are often well modeled as slowly time-varying systems. The talk first describes the basic concepts of such systems and their analysis via local Fourier methods. Parametric approaches appropriate for speech are then introduced by way of time-varying autoregressive models, along with nonparametric approaches based on variation of time-localized estimates of the power spectral density of an observed random process, along with an efficient offline bootstrap procedure based on the Wold representation. Several real-world examples are given. ','Optimization Algorithms in Support Vector Machines;;Summary;;Themes;;Sparse / Regularized Optimization;;Regularized Formulations;;Example: Compressed Sensing;;Example: TV-regularized image denoising;;Example: Cancer Radiotherapy;;Example: Matrix Completion;;Solving Regularized Formulations;;SVM Classification: Primal;;Dual;;Kernel Trick, RKHS (1);;Kernel Trick, RKHS (2);;Solving the Primal and (Kernelized) Dual;;Solving the Dual;;Dual SVM: Coordinate Descent;;Dual SVM: Gradient Projection;;Dual SVM: Decomposition (1);;Dual SVM: Decomposition (2);;Dual SVM: Active-Set (1);;Dual SVM: Active-Set (2);;Dual SVM: Interior-Point;;Low-rank Approx + Active Set;;Solving the Primal;;Primal SVM: Cutting Plane (1);;Primal SVM: Cutting Plane (2);;Primal SVM: Stochastic Subgradient;;Stochastic Subgradient;;Stochastic Approximation Viewpoint;;Primal-Dual Approaches;;Discretized TV Denoising;;Min-Max Formulation;;PD Method for Semiparametric SVM Regression (1);;PD Method for Semiparametric SVM Regression (2);;PD Method for Semiparametric SVM Regression (3);;Alternative Formulations: ||kw||1;;Elastic Net;;SpaRSA (1);;SpaRSA (2);;Logistic Regression (1);;Logistic Regression (2);;References (1);;References (2);;References (3);;mlss09us_wright_oasvm_Page_46'
8849,'lecture','en',8751,'2009-06-04','2009-07-30','Unsupervised Learning for Stereo Vision ','We consider the problem of learning to estimate depth from stereo image pairs. This can be formulated as unsupervised learning - the training pairs are not labeled with depth. We have formulated an algorithm which maximizes conditional likelihood the left image given right image in a model that involves latent information (depth). This unsupervised learning algorithm implicitly trains shape from texture and shape from shading monocular depth cues. The talk will present pragmatic results in the stereo vision problem as well as a general formulation of models and methods for maximizing conditional likelihood in a latent variable model where we wish to interpret the latent information as \"labels\".','nsupervised Learning of Stereo Vision with Monocular Cues;;Scene Understanding;;Conditional Random Fields (Lafferty et al. 2001);;Hidden CRFs (Quattoni et al. 2007);;Related Formalisms;;Indirect CRFs;;Classical Stereo Vision as an Indirect CRF;;Unsupervised Parameter Tuning;;HOG Features;;HOG as a Surface Orientation Cue;;Analysis of Isotropic Textur;;A Slanted Plane Model;;The Energy Function;;Results;;Hard EM;;Max-Product Particle Belief Propagation;;Contrastive Divergence;;Contrastive Divergence for a Standard MRF Process;;Contrastive Divergence for a Differential Metropolis Process;;Warning;;Summary'
8850,'lecture','en',8751,'2009-06-04','2009-07-30','Learning Feature Hierarchies',NULL,'Learning Feature Hierarchies;;The Next Frontier in Machine Learning: Learning Representations;;The Traditional “Shallow” Architecture for Recognition;;The Next Challenge of ML, Vision (and Neuroscience);;Good Representations are Hierarchical;;“Deep” Learning: Learning Hierarchical Representations;;The Primate\'s Visual System is Deep;;Do we really need deep architectures?;;Why are Deep Architectures More Efficient?;;Feature Extraction in Computer Vision;;Trainable Feature Extraction: HubelWiesel Stage;;Deep Architecture: MultiStage HubelWiesel Architecture;;Deep Architecture: The Multistage HubelWiesel Architecture;;Convolutional Net: Supervised MultiStage HubelWiesel Arch.;;Supervised Training of Convolutional Network;;Supervised Convolutional Nets learn well with lots of data;;Deep Supervised ConvNets Work (with lots of labeled data);;NORB Generic Object Recognition Dataset;;Textured and Cluttered Datasets;;Face Detection: Results;;Face Detection and Pose Estimation: Results;;Face Detection with a Convolutional Net;;Visual Navigation for a Mobile Robot;;Industrial Applications of (supervised) ConvNets;;Problem: ConvNets don\'t work when labeled samples are scarse;;How Do We Learn Features from Unlabeled Samples?;;Deep Learning: Stack of Encoder/Decoders (1);;Deep Learning: Stack of Encoder/Decoders (2);;Deep Learning: Stack of Encoder/Decoders (3);;Deep Learning: Stack of Encoder/Decoders (4);;Training an Encoder/Decoder Module;;Each Stage is Trained as an Estimator of the Input Density;;Energy <> Probability;;The Intractable Normalization Problem;;Training an EnergyBased Model to Approximate a Density;;Training an EnergyBased Model with Gradient Descent;;Solving The Intractable Normalization problem;;Contrastive Divergence Trick [Hinton 2000] (1);;Contrastive Divergence Trick [Hinton 2000] (2);;The Main Insight [Ranzato et al. 2007];;Why Limit the Information Content of the Code? (1);;Why Limit the Information Content of the Code? (2);;Why Limit the Information Content of the Code? (3);;Why Limit the Information Content of the Code? (4);;Why Limit the Information Content of the Code? (5);;Why Limit the Information Content of the Code? (6);;Sparsity Penalty to Restrict the Code;;Sparse Decomposition with Linear Reconstruction;;Problem with Sparse Decomposition: It\'s slow;;Solution: Predictive Sparse Decomposition (PSD);;PSD: Inference;;PSD: Learning [Kavukcuoglu et al. 2009];;PSD: Learning Algorithm;;Decoder Basis Functions on MNIST;;PSD Training on Natural Image Patches;;Classification Error Rate on MNIST;;Classification Error Rate on MNIST;;Learned Features on natural patches: V1like receptive fields;;Learned Features: V1like receptive fields;;How well do PSD features work on Caltech101?;;Procedure for a singlestage system;;Using PSD Features for Recognition;;Feature Extraction (1);;Feature Extraction (2);;Feature Extraction (3);;Feature Extraction (4);;Feature Extraction (5);;Feature Extraction (6);;Feature Extraction (7);;Feature Extraction (8);;Feature Extraction (9);;Feature Extraction (10);;Feature Extraction (11);;Training Protocol;;Using PSD Features for Recognition (1);;Using PSD Features for Recognition (2);;Comparing Optimal Codes Predicted Codes on Caltech 101;;PSD Features are more stable;;PSD features are much cheaper to compute;;How Many 9x9 PSD features do we need?;;Training a MultiStage HubelWiesel Architecture with PSD;;Multistage HubelWiesel Architecture on Caltech101;;Multistage HubelWiesel Architecture;;Multistage HubelWiesel Architecture on Caltech101;;TwoStage Result Analysis;;Multistage HubelWiesel Architecture: Filters;;MNIST dataset (1);;MNIST dataset (2);;Why Random Filters Work?;;Small NORB dataset (1);;Small NORB dataset (2);;Learning Invariant Features [Kavukcuoglu et al. CVPR 2009];;Learning the filters and the pools (1);;Learning the filters and the pools (2);;Pinwheels?;;Invariance Properties Compared to SIFT;;Learning Invariant Features;;Recognition Accuracy on Caltech 101;;FPGA Custom Board: NYU ConvNet Proc;;DARPA/LAGR: Learning Applied to Ground Robotics;;Long Range Vision: Distance Normalization;;mlss09us_lecun_lfh_Page_102;;mlss09us_lecun_lfh_Page_103;;mlss09us_lecun_lfh_Page_104;;mlss09us_lecun_lfh_Page_105;;mlss09us_lecun_lfh_Page_106;;Long Range Vision Results (1);;Long Range Vision Results (2);;Long Range Vision Results (3);;mlss09us_lecun_lfh_Page_110;;mlss09us_lecun_lfh_Page_111;;mlss09us_lecun_lfh_Page_112;;mlss09us_lecun_lfh_Page_113;;mlss09us_lecun_lfh_Page_114;;mlss09us_lecun_lfh_Page_115;;mlss09us_lecun_lfh_Page_116;;mlss09us_lecun_lfh_Page_117;;mlss09us_lecun_lfh_Page_118;;The End'
8851,'lecture','en',8751,'2009-06-05','2009-07-30','Theory and Applications of Boosting','Boosting is a general method for producing a very accurate classification rule by combining rough and moderately inaccurate \"rules of thumb\". While rooted in a theoretical framework of machine learning, boosting has been found to perform quite well empirically. This tutorial will introduce the boosting algorithm AdaBoost, and explain the underlying theory of boosting, including explanations that have been given as to why boosting often does not suffer from overfitting, as well as some of the myriad other theoretical points of view that have been taken on this algorithm. Some practical applications and extensions of boosting will also be described. ','Theory and Applications of Boosting;;Example: ““How May I Help You?” (1);;Example: ““How May I Help You?”” (2);;The Boosting Approach;;Details;;Boosting;;Outline of Tutorial;;Brief Background;;Strong and Weak Learnability (1);;Strong and Weak Learnability (2);;Early Boosting Algorithms;;AdaBoost, [Freund & Schapire ’95);;Basic lgorithm and Core Theory;;A Formal Description of Boosting (1);;A Formal Description of Boosting (2);;A Formal Description of Boosting (3);;AdaBoost [with Freund] (1);;AdaBoost [with Freund] (2);;AdaBoost [with Freund] (3);;Toy Example;;Round 1;;Round 2;;Round 3;;Final Classifier;;Analyzing the Training Error (1);; Analyzing the Training Error (2);;Analyzing the Training Error (3);;Proof;;Proof (cont.) (1);;Proof (cont.) (2);;Proof (cont.) (3);;Proof (cont.) (4);;Proof (cont.) (5);;Proof (cont.) (6);;Proof (cont.) (7);;Proof (cont.) (8);;How Will Test Error Behave? (A First Guess);;Actual Typical Run;;A Better Story: The Margins Explanation [with Freund, Bartlett & Lee] (1);;A Better Story: The Margins Explanation [with Freund, Bartlett & Lee] (2);;A Better Story: The Margins Explanation [with Freund, Bartlett & Lee] (3);;Empirical Evidence: The Margin Distribution;;Theoretical Evidence: Analyzing Boosting Using Margins (1);;Theoretical Evidence: Analyzing Boosting Using Margins (2);;Theoretical Evidence: Analyzing Boosting Using Margins (3);;Theoretical Evidence: Analyzing Boosting Using Margins (4);;Theoretical Evidence: Analyzing Boosting Using Margins (5);;More Technically...;;Other Ways of Understanding AdaBoost;;Just a Game;;Game Theory (1);;Game Theory (2);;The Minmax Theorem (1);;The Minmax Theorem (2);;The Minmax Theorem (3);;The Boosting Game (1);;The Boosting Game (2);;The Boosting Game (3);;Boosting and the Minmax Theorem (1);;Boosting and the Minmax Theorem (2);;Boosting and the Minmax Theorem (3);;Boosting and the Minmax Theorem (4);;Boosting and the Minmax Theorem (5);;Boosting and the Minmax Theorem (6);;Boosting and the Minmax Theorem (7);;Idea for Boosting (1);;Idea for Boosting (2);;Idea for Boosting (3);;Boosting and Repeated Play (1);;Boosting and Repeated Play (2);;Boosting and Repeated Play (3);;Boosting and Repeated Play (4);;Boosting and Repeated Play (5);;Boosting and Repeated Play (6);;AdaBoost and Game Theory (1);;AdaBoost and Game Theory (2);;AdaBoost and Game Theory (3);;AdaBoost and Loss Minimization (1);;AdaBoost and Loss Minimization (2);;AdaBoost and Loss Minimization (3);;What AdaBoost Minimizes (1);;What AdaBoost Minimizes (2);;What AdaBoost Minimizes (3);;AdaBoost and Exponential Loss (1);;AdaBoost and Exponential Loss (2);;AdaBoost and Exponential Loss (3);;AdaBoost and Exponential Loss (4);;Coordinate Descent (1);;Coordinate Descent (2);;Functional Gradient Descent (1);;Functional Gradient Descent (2);;Functional Gradient Descent (3);;Functional Gradient Descent (4);;Estimating Conditional Probabilities (1);;Estimating Conditional Probabilities (2);;Calibration Curve;;Benefits of Loss-minimization View;;A Note of Caution (1);;A Note of Caution (2);;An Experiment (1);;An Experiment (2);;An Experiment (3);;An Experiment (cont.) (1);;An Experiment (cont.) (2);;A Dual Information-geometric Perspective (1);;A Dual Information-geometric Perspective (2);;A Dual Information-geometric Perspective (3);;An Iterative-projection Algorithm (1);;An Iterative-projection Algorithm (2);;An Iterative-projection Algorithm (3);;An Iterative-projection Algorithm (4);;An Iterative-projection Algorithm (5);;An Iterative-projection Algorithm (6);;AdaBoost is an Iterative Projection Algorithm (1);;AdaBoost is an Iterative Projection Algorithm (2);;AdaBoost is an Iterative Projection Algorithm (3);;AdaBoost as Iterative Projection (cont.) (1);;AdaBoost as Iterative Projection (cont.) (2);;Boosting as Maximum Entropy (1);;Boosting as Maximum Entropy (2);;Boosting as Maximum Entropy (3);;Boosting as Maximum Entropy (4);;Unifying the Two Cases (1);;Unifying the Two Cases (2);;Unifying the Two Cases (3);;Unifying the Two Cases (4);;Unifying the Two Cases (5);;Reformulating AdaBoost as Iterative Projection (1);;Reformulating AdaBoost as Iterative Projection (2);;Reformulated Optimization Problem;;Exponential Loss as Entropy Optimization (1);;Exponential Loss as Entropy Optimization (2);;Exponential Loss as Entropy Optimization (3);;Exponential Loss as Entropy Optimization (4);;Duality (1);;Duality (2);;Duality (3);;Duality (4);;Convergence of AdaBoost (1);;Convergence of AdaBoost (2);;Convergence of AdaBoost (3);;Convergence of AdaBoost (4);;Convergence of AdaBoost (5);;Convergence of AdaBoost (6);;Convergence of AdaBoost (7);;Experiments, Applications and Extensions;;Practical Advantages of AdaBoost;;Caveats;;UCI Experiments;;UCI Results;;Multiclass Problems (1);;Multiclass Problems (2);;Reducing Multiclass to Binary;;AdaBoost.MH;;Using Output Codes;;Output Codes (cont.);;Ranking Problems;;“Hard” Predictions Can Slow Learning (1);;“Hard” Predictions Can Slow Learning (2);;Confidence-rated Predictions (1);;Confidence-rated Predictions (2);;Confidence-rated Predictions (cont.);;Confidence-rated Predictions Help a Lot;;Application: Boosting for Text Categorization;;Weak Classifiers;;More Weak Classifiers (1);;More Weak Classifiers (2);;Finding Outliers;;Application: Human-computer Spoken Dialogue;;How It Works;;Need for Prior, Human Knowledge;;Results: AP-Titles;;Results: Helpdesk;;Problem: Labels are Expensive;;Active Learning;;Labeling Scheme;;Results: How-May-I-Help-You?;;Results: Letter;;Application: Detecting Faces;;Conclusions (1);;Conclusions (2);;References and questions'
8852,'invited talk','en',8751,'2009-06-05','2009-07-30','Generative Models for Image Analysis','A probabilistic grammar for the grouping and labeling of parts and objects, when taken together with pose and part-dependent appearance models, constitutes a generative scene model and a Bayesian framework for image analysis. To the extent that the generative model generates features, as opposed to pixel intensities, the inverse or posterior distribution on interpretations given images is based on incomplete information; feature vectors are generally insufficient to recover the original intensities. I will argue for fully generative scene models, meaning models that in principle generate actual digital pictures. I will outline an approach to the construction of fully generative models through an extension of context-sensitive grammars and a re-formulation of the popular template models for image fragments. Mostly I will focus on the problem of learning template models from image data. Since the model is fully specified (generative), at the pixel level, the templates can be learned by maximum likelihood. A training set of eyes, for example, yields an ensemble of left and right eyes, of familiar and natural character, but not actually coming from any particular individuals in the training set. The upshot is a mixture distribution on image patches, consisting of a set of templates and a set of conditional patch distributions - one for each template. One way to test the model is to examine samples. I will show how to sample from the mixture distribution and I will show sample sets of eyes, mouths, and generic background. Another way to test the model is to use it for detection, recognition, or classification. I will show the results of a test on ethnic classification based on the eye region of faces.','Generative Models for Image Analysis;;Bayesian (generative) image models Feature distributions and data distributions Conditional modeling Sampling and the choice of null distribution Other applications of conditional modeling;;I. Bayesian (generative) image models;;II. Feature distributions and data distributions;;e.g. detection and recognition of eyes;;Use maximum likelihood…but what is the likelihood?;;III. Conditional modeling;;Conditional modeling: a perturbation of the null distribution;;Estimation;;Example: learning eye templates (1);;Example: learning eye templates (2);;Example: learning eye templates (3);;Example: learning eye templates (4);;Example: learning (right) eye templates (1);;Example: learning (right) eye templates (2);;How good are the templates?  A classification experiment… (1);;How good are the templates?  A classification experiment… (2);;Other examples: noses 16 templates multiple scales, shifts, and rotations ;;Other examples: mixture of noses and mouths;;Other examples: train on 58 faces …half with glasses…half without  (1);;Other examples: train on 58 faces …half with glasses…half without (2);;Other examples: train random patches (“sparse representation”);;Other examples: coarse representation;;IV. Sampling and the choice of null distribution;;(approximate) sampling… (1);;(approximate) sampling… (2);;(approximate) sampling… (3);;(approximate) sampling… (4);;(approximate) sampling… (5);;V. Other applications of conditional modeling ;;2. Gibbs sampling;;3. Hierarchical models and the Markov Dilemma;; Hierarchical models and the Markov Dilemma (1);; Hierarchical models and the Markov Dilemma (2);; Hierarchical models and the Markov Dilemma (3);;PATTERN SYNTHESIS = PATTERN ANALYSIS, Ulf Grenander'
8853,'lecture','en',8751,'2009-06-05','2009-07-30','On Surrogate Loss Functions, f-Divergences and Decentralized Detection','In 1951, David Blackwell published a seminal paper - widely cited in economics - in which a link was established between the risk based on 0-1 loss and a class of functionals known as f-divergences. The latter functionals have since come to play an important role in several areas of signal processing and information theory, including decentralized detection. Yet their role in these fields has largely been heuristic. We show that an extension of Blackwell´s programme provides a solid foundation for the use of f-divergences in decentralized detection, as well as in more general problems of experimental design. Our extension is based on a connection between f-divergences and the class of so-called surrogate loss funcions - computationally-inspired upper bounds on 0-1 loss that have become central in the machine learning literature on classification. (Joint work with XuanLong Nguyen and Martin Wainwright.)','f-Divergences and Surrogate Loss Functions;;Motivating Example: Decentralized Detection;;Decentralized Detection;;Decentralized Detection (cont.);;Perspectives;;f-divergences (Ali-Silvey Distances);;Why the f-divergence?;;Machine Learning Perspective;;Margin-Based Surrogate Loss Functions;;Estimation Based on a Convex Surrogate Loss;;Some Theory for Surrogate Loss Functions;;Outline;;Setup;;Profiling;;Some Examples;;Link between -losses and f-divergences;;Conjugate Duality;;Link between -losses and f-divergences;;The Easy Direction:  → f;;The f →  Direction Has a Constructive Consequence;;Example – Hellinger distance;;Example – Variational distance;;Example – Kullback-Leibler divergence;;Bayes Consistency for Choice of (Q, );;Setup (1);;Setup (2);;Bayes Consistency for Choice of (Q, );;Universal Equivalence of Loss Functions;;An Equivalence Theorem;;Estimation of Divergences;;Existing Work;;Main Idea;;Kullback-Leibler Divergence;;M-Estimation Procedure;;Convex Empirical Risk with Penalty;;Convergence Rates;;Results (1);;Results (2);;mlss09us_jordan_slffddd_Page_39;;Conclusions'
8854,'lecture','en',8751,'2009-06-05','2009-07-30','Similarity-Based Classifiers: Problems and Solutions ','Similarity-based learning assumes one is given similarities between samples to learn from, and can be considered a special case of graph-based learning where the graph is given and fully-connected. Such problems arise frequently in computer vision, bioinformatics, and problems involving human judgment. We will review the field of similarity-based classification and describe the main problems encountered in adapting standard algorithms for this problem, including different approaches to approximating indefinite similarities by kernels. We will motivate why local methods lessen the indefinite similarity problem, and show that a kernelized linear interpolation and local kernel ridge regression can be profitably applied to such similarity-based classification problems by framing them as weighted nearest-neighbor classifiers. Eight real datasets will be used to compare state-of-the-art methods and illustrate the open challenges in this field. \n\n','Similarity-based Classifiers:Problems and Solutions;;Classifying based on similarities;;the Similarity-based Classification Problem (1);;the Similarity-based Classification Problem (2);;the Similarity-based Classification Problem (3);;Examples of Similarity Functions;;Approaches to Similarity-based Classification (1);;Approaches to Similarity-based Classification (2);;Can we treat similarities as kernels? (1);;Can we treat similarities as kernels? (2);;Can we treat similarities as kernels? (3);;Example: Amazon similarity (1);;Example: Amazon similarity (2);;Example: Amazon similarity (3);;Well, let’s just make S be a kernel matrix (1);;Well, let’s just make S be a kernel matrix (2);;Well, let’s just make S be a kernel matrix (3);;Well, let’s just make S be a kernel matrix (4);;Well, let’s just make S be a kernel matrix (5);;Approaches to Similarity-based Classification (3);;Let the similarities to the training samples be features;;Table (1);;Table (2);;Approaches to Similarity-based Classification (4);;Weighted Nearest-Neighbors (1);;Weighted Nearest-Neighbors (2);;Design Goals for the Weights (1);;Design Goals for the Weights (2);;Design Goals for the Weights (3);;Design Goals for the Weights (4);;Linear Interpolation Weights (1);;Linear Interpolation Weights (2);;LIME weights (1);;LIME weights (2);;LIME weights (3);;LIME weights (4);;Kernelize Linear Interpolation (Chen et al. JMLR 2009) ;;Kernelize Linear Interpolation (1);;Kernelize Linear Interpolation (2);;KRI Weights Satisfy Design Goals (1);;KRI Weights Satisfy Design Goals (2);;KRI Weights Satisfy Design Goals (4);;KRI Weights Satisfy Design Goals (5);;KRI Weights Satisfy Design Goals (6);;Weighted k-NN: Example 1;;Weighted k-NN: Example 2;;Weighted k-NN: Example 3;;Table (3);;Table (5);;Table (6);;Table (7);;Approaches to Similarity-based Classification (5);;Generative Classifiers (1);;Generative Classifiers (2);;Similarity Discriminant Analysis (Cazzanti and Gupta, ICML 2007, 2008, 2009) (1);;Similarity Discriminant Analysis (Cazzanti and Gupta, ICML 2007, 2008, 2009) (2);;Some Conclusions, Performance depends heavily on oddities of each dataset;;Some Conclusions, Weighted k-NN with affinity-diversity weights work well;;Some Conclusions, Preliminary: Reg. Local SDA works well;;Some Conclusions, Probabilities useful ;;Some Conclusions, Local models useful ;;Lots of Open Questions;;Code/Data/Papers: idl.ee.washington.edu/similaritylearning;;Training and Test Consistency;;Data Sets (1);;Data Sets (2);;SVM Review;;mlss09us_gupta_sbcps_Page_68;;mlss09us_gupta_sbcps_Page_69;;mlss09us_gupta_sbcps_Page_70;;mlss09us_gupta_sbcps_Page_71;;mlss09us_gupta_sbcps_Page_72;;mlss09us_gupta_sbcps_Page_73;;mlss09us_gupta_sbcps_Page_74'
8855,'lecture','en',8751,'2009-06-05','2009-07-30','What Do Unique Games, Structural Biology and the Low-Rank Matrix Completion Problem Have In Common','We will formulate several data-driven applications as MAX2LIN and d-to-1 games, and show how to (approximately) solve them using efficient spectral and semidefinite program relaxations. The relaxations perform incredibly well in the presence of a large number of outlier measurements that cannot be satisfied. We use random matrix theory to prove that the algorithms almost achieve the information theoretic Shannon bound. The underlying group structure of the different applications (like SO(2), SO(3), GL(n), etc.) is heavily exploited. Applications include: cryo-electron microscopy and NMR spectroscopy for 3D protein structuring, low-rank matrix completion, clock synchronization, and surface reconstruction in computer vision and optics. Partly joint with Yoel Shkolnisky, Ronald Coifman and Fred Sigworth (Yale); Mihai Cucuringu and Yaron Lipman (Princeton); and Yosi Keller (Bar Ilan).','What do unique games, structural biology and the low-rank matrix completion problem have in common?;;Outline;;Sensor Network Localization and NMR Spectroscopy;;Low-Rank Matrix Completion;;Noise Model: Outliers;;Cryo Electron Microscopy: Projection Images;;Projection Images: Toy Example;;E. coli ribosome: sample images;;Class Averaging: Improve SNR;;Current clustering method (Penczek, Zhu, Frank 1996);;Small World Graph on RP2;;Max-2-Lin-mod-2;;Eigenvector Method;;SDP approach;;The complete graph case – only for mathematical intuition;;Wigner’s Semi-Circle Law;;Spectral Gap;;Correlation and Regular Perturbations;;Experimental Correlations;;Small world graph on RP2;;Spectral graph theory and spherical harmonics;;Experimental Correlations;;Comparison with SDP;;Information Theory (1);;Information Theory (2);;Max-2-Lin-mod-L and Unique Games;;Fourier projection-slice theorem;;Angular Reconstitution (Van Heel, 1987);;Global Integration of Common Lines;;Integral Operator on SO(3);;Convolution and Fourier Transform on SO(3);;Spectrum: Semi-Circle;;Spectrum: Spherical Harmonics;;Reconstruction (1);;Reconstruction (2);;Groups;;Thank You!, Questions'
8883,'tutorial','en',8751,'2009-06-06','2009-07-30','Bounding Excess Risk in Machine Learning','We will discuss a general approach to the problem of bounding the excess risk of learning algorithms based on empirical risk minimization (possibly penalized). This approach has been developed in the recent years by several authors (among others: Massart; Bartlett, Bousquet and Mendelson; Koltchinskii). It is based on powerful concentration inequalities due to Talagrand as well as on a variety of tools of empirical processes theory (comparison inequalities, entropy and generic chaining bounds on Gaussian, empirical and Rademacher processes, etc.). It provides a way to obtain sharp excess risk bounds in a number of problems such as regression, density estimation and classification and for many different classes of learning methods (kernel machines, ensemble methods, sparse recovery). It also provides a general way to construct sharp data dependent bounds on excess risk that can be used in model selection and adaptation problems.','EXCESS RISK BOUNDS IN MACHINE LEARNING;;TOPICS;;EMPIRICAL RISK MINIMIZATION;;Risk minimization;;Problems;;A simple bound;;Vapnik and Chervonenkis, Dudley, Talagrand;;Empirical and Rademacher Processes;;Rademacher Process, Global Rademacher Complexity;;Symmetrization Inequality;;Contraction Inequality;;Several Bounds on E Rn k;;Example 1. Finite Class;;Example 2. Shattering Numbers;;Example 3. VC-type classes;;Example 4. Larger Entropy;;Example 6. Subsets of RKHS;;Concentration Inequality;;Comparison of Empirical and Rademacher Processes;;Talagrand’s concentration inequality;;It is often used in combination with...;;“A Statistical Version” of Talagrand’s Inequality;;The same bounds hold for...;;Distribution Dependent Excess Risk Bounds, References:;;Some Definitions;;L2-diameter;;A consequence of Talagrand’s inequality (Bousquet’s version);;Reminder: a simple bound;;Sharper bounds: a heuristic approach;;Then the same argument as before shows that with a high probability...;;Moreover, one can repeat the argument again;;... the main excess risk bound..;;Theorem 1 ;;It follows from Theorem 1 that with probability at least...;;Continuity Modulus of Empirical Processes;;If F is P-Donsker, then...;;Mammen and Tsybakov (1999), Tsybakov (2004))...;;Excess Risk Bounds: k = 1;;Example 1 Linear Dimension, Example 2 VC-dimension;;Example 3 Metric Entropy, Example 4 Convex Hulls;;Example 5. Shattering Numbers;;Example 6 (Mendelson’s complexity);;L2-regression;;the regression function;;For a class G of functions g : S 7→ [0, 1], let;;On the other hand, n(F; ) can be bounded by a constant times...;;This yields (with a minor further work), for instance, the following result...;;Binary Classification;;Optimal Bayes classifier, The training error;;mlss09us_koltchinskii_berml_Page_50;;Tsybakov’s low noise condition;;which by taking t of the order...;;Mammen and Tsybakov (1999), Tsybakov (2004);;Massart’s low noise condition;;Define the following local capacity function of the class C (in spirit of Alexander (1987);;Gin´e and Koltchinskii (2006), Massart and Nedelec (2006);;Reminder (1);;Reminder (2);;Data Dependent Excess Risk Bounds, Rademacher process;;Let...;;Theorem 2 For all t > 0;;Model Selection References:;;Model Selection Framework;;mlss09us_koltchinskii_berml_Page_64;;mlss09us_koltchinskii_berml_Page_65;;mlss09us_koltchinskii_berml_Page_66;;mlss09us_koltchinskii_berml_Page_67;;mlss09us_koltchinskii_berml_Page_68;;mlss09us_koltchinskii_berml_Page_69;;mlss09us_koltchinskii_berml_Page_70;;mlss09us_koltchinskii_berml_Page_71;;mlss09us_koltchinskii_berml_Page_72;;mlss09us_koltchinskii_berml_Page_73;;mlss09us_koltchinskii_berml_Page_74;;mlss09us_koltchinskii_berml_Page_75;;mlss09us_koltchinskii_berml_Page_76;;mlss09us_koltchinskii_berml_Page_77;;mlss09us_koltchinskii_berml_Page_78;;mlss09us_koltchinskii_berml_Page_79'
8891,'lecture','en',5561,'2008-06-23','2009-07-15','OSS Tools to Support Collaborative Mobile Work Practices ','This lecture aims at better understanding the way currently mobile professionals work remotely in collaboration with others both within and beyond the company and matching these current ways of working with the most appropriate open source software (OSS) collaboration tools. This is achieved through addressing the current state of art in the mobility challenges and identifying what is working well or inefficiently in remote collaboration across four case studies. Evidences from the cases show that there is currently a little tool support for mobile work practices and better integration of the tools with companies existing internal systems may improve the productivity of the mobile workers. For researchers, a research lens is proposed to open up discussions and further concepts development with respect to mobile collaboration. For practitioners, a set of technical requirements and a list of corresponding OSS tools are presented to further elaborate the mobile working concept from their own context, with specific focus on the scenario of manager on business trip. The paper concludes in discussing open problems and proposing the research themes within the context of mobile collaboration.',NULL
8894,'lecture','en',5561,'2008-06-23','2009-07-15','Productivity in Collaboration-intensive Knowledge Work: The Collaboration Management Imperative','Collaboration is a hot issue, and is to an increasing extent recognised as a key driver of overall business performance, innovation capabilities and productivity. However, few companies methodically evaluate how well they perform in the area of collaboration, and few companies have implemented management and leadership principles to systematically improve collaborative performance. This article describes the commonly occurring mismatch between the potential impact of collaboration on business performance and the attention given to collaboration. Furthermore, the article explains why companies should approach collaboration strategically, and identify new ways of fostering and facilitating collaboration in a structured manner. The article proposes a value perspective on collaboration and provides a framework for classifying and managing different factors related to collaboration, and concludes with a list of specific action points for organisations that are interested in improving their collaborative performance and obtaining a higher Return on Investment (ROI) on their collaboration initiatives.',NULL
8895,'lecture','en',5561,'2008-06-23','2009-07-15','Collaborative Working Environments as Globalised Inquiry for All','With this lecture we are sharing our practical findings in the eSangathan Project, interpreted from the theoretical perspectives of Inquiring Communities and Collaborative Working Environment (CWE). We start by investigating the use of IT and CWE in support of Inquiring Communities among seniors working to create social innovations. We identify five different forms of Inquiring Communities: the Realistic, the Analytic, the Idealistic, the Dialectic and the Pragmatic. These communities we take to be basic and essential for communication and sharing of knowledge among human beings. As there are not very much evidence on the CWE support of all these five communities we use theories on Knowledge Management as a stepping stone, because there are substantial evidence of support for Knowledge Management by CWE, even though Knowledge Management lacks a sound theoretical foundation. As Knowledge Management only can illustrate the Realistic, the Analytic and the Idealistic types of Inquiring Communities we see a lack of support by CWEs for the most crucial aspects of communication and knowledge sharing, that among differences of opinion as in the Dialectical and Pragmatic communities. Finally we explicate findings on good practice in CWE as we have experienced them in the eSangathan project together with some important dilemmas for further investigations.',NULL
8896,'lecture','en',5561,'2008-06-23','2009-07-15','Achieving Interoperability in Grid-Enabled Virtual Organisation','Grid computing introduces a new paradigm for the realisation of efficient collaborative ICT infrastructures for VOs that has many advantages in comparison to other known approaches. However, due to some shortcomings with regard to industry VO requirements, practical uptake is still quite low, despite of the potential benefits. In this paper, we focus on three important issues regarding the achievement of efficient interoperability in grid-enabled VOs: (1) the appropriate handling of authorisation and authentication, (2) the role-based access to resources and services, and (3) the gridification of existing applications. We suggest an approach to extend Grid functionality by an addition- nal semantic service layer on top of the basic Grid middleware services. The services on this layer are grounded on three inter-related ontologies specified in OWL, in alignment with the Semantic Web paradigm. Reported are findings from the recently finished European project InteliGrid and the ongoing German project BauVOGrid.',NULL
8897,'lecture','en',5561,'2008-06-23','2009-07-15','How the idea of a Single European Electronic Market is turning into reality','The idea of a Single European Electronic Market (SEEM), described by the European Union and further elaborated within the European Project SEEMseed seems to be a good chance for Small, Medium and Micro Enterprises to seamlessly participate in the electronic market today and in the future. Even individuals may take advantage of the SEEM idea to actively benefit from electronic business within Europe. The overall goal of realizing a Single Electronic European Market is not easy attainable because of high complexity and fragmentation of the areas of interest. Under patronage and sponsorship of European Commission (above all 6th and 7th Framework Programme), several R&D project are currently running or soon to be started in order to foster the SEEM idea. Similar to this, CEN / ISSS has developed the project WS / eCAT. In this paper, we will describe and analyze the current efforts in this area and we will describe a meta-project called Simple On Line Catalog - to connect results of the existing projects, initiatives and studies and to cover them with an integral user interface, accessible to SME and Individuals across the borders and languages.',NULL
8898,'lecture','en',5561,'2008-06-23','2009-07-15','Validation of architectural targets in business components identification ','Component identification is one decisive task in designing software architectures for large component-based information systems, and especially the quality of business components identification plays an important role in concurrent enterprising. Methods that have been developed for this task yield component architectures that conform to these methods target functions. This paper validates the soundness of architectures resulting from systematic component identification with the BCI (business components identification) method. We could derive our results from a real-life industry project where we show that architecture qualities required by stakeholders are directly covered from a target architecture generated through BCI application.',NULL
8899,'lecture','en',5561,'2008-06-23','2009-07-15','An intelligent system to business and enterprise management - IDEA','IDEA system assists all the specific processes of an enterprise from the meat processing industry to support decision makers to manage performances by implementing the concepts Business Performance Management (BPM) and Business Intelligence (BI). IDEA system transforms data into information and then into knowledge being focused on business, technological and economical aspects specific to the meat processing enterprises helping them to realise an efficient use of their business policies, financial, human and material resources. IDEA system integrates solutions implemented in the software components to decision processes management, customer relation management and enterprise resources planning components. IDEA integrates the BPM organisation\'s processes with its CRM components and ERP components. IDEA system offers support for an intelligent management to business processes, manufacture flows and the enterprise resources. The tools considered in the development of IDEA system are oriented on business management, business workflow analysis, business performance management, OLAP (Online Analytical Processing), data modelling, data visualisation, report servers, AJAX (Asynchronous JavaScript and XML) technology.',NULL
8900,'lecture','en',5561,'2008-06-23','2009-07-15','The effects of various forms of inter-organizational trust on competitiveness','CIOPS (Cognitive Inter-organizational Production System) is an agent-based simulation model integrating structural and cognitive aspects of industry competitiveness. The model links firms profitability to the quality of their suppliers, thus firms purpose is to manage their cognitive space in order to find out the best supplier. This work analyses performance of firms using different decision making patterns which define the way clients select their suppliers. Four decision making patterns are observed: when firms make decisions using only their own past experiences, when they consider also others experiences, when they rely on reputations assigned to suppliers, and finally when they make decision randomly. Results show that decision making patterns based on others experiences and reputation are more profitable but that they are extremely sensitive to opportunist behaviours.',NULL
8901,'lecture','en',5561,'2008-06-23','2009-07-15','inContext: On Coupling and Sharing Context for Collaborative Teams','Present team members have difficulties in keeping the relations between their various, concurrent activities due to the lack of suitable tools supporting context coupling and sharing. Furthermore, collaboration services are hardly aware of related context of team members and their activities. Such awareness is required to adapt to the dynamics of collaborative teams. In this paper, we discuss the context coupling techniques provided by the inContext project. Utilizing the concept of activity-based context and Web services techniques, we can couple individual and team contexts at runtime, thus improving the context-awareness and adaptation of collaboration services such as email, shared calendars, instant messaging and document management.',NULL
8902,'lecture','en',5560,'2008-06-24','2009-07-15','Introduction to the Session','This session will show the results of the work in the project C@R. C@R project is an Integrated Project, funded by the IST programme of the European Commission\'s 6th Framework with a budget of EUR 15 million and 33 project partners. C@R aims to boost the use of ICT to promote rural development. According to this strategic goal, C@R will identify, develop and validate technological responses to actual barriers jeopardizing the sustainable development in rural areas. The project works in 7 Living labs in different countries, and manages different kind of activities in the rural environment, including traditional and new economic activities in rural areas. The project is developing products and services in different sectors, This session will present the results and findings in the framework of the project: the products and services developed, but also the methodologies developed in the project.',NULL
8903,'lecture','en',5560,'2008-06-24','2009-07-15','Enhancing an Open Service Oriented Architecture with Collaborative Functions for Rural Areas','Development in rural European areas face many barriers. The Collaboration@Rural (C@R) EU project aims to remove these barriers through Collaborative Technologies adopted among Rural Living Labs across Europe, and to substantially contribute to the definition of a user-centric Open Collaborative Architecture. The paper presents the threefold C@R Open Service Oriented Architecture approach in System, Software Architecture and Practical Implementation levels. We show that collaborative functions can be orchestrated and instantiated in a tailored process using a service broker that can register and manage them. By introducing control and data planes and a domain concept, the C@R architecture easily addresses different business models in a more natural way compared to other software platforms or service architectures. We also illustrate how the Software Architecture principles and specific components discussed are instantiated in the Spanish and South African Rural Living Labs.',NULL
8905,'lecture','en',5560,'2008-06-24','2009-07-15','The multiple side of collaborative working in Foscati Living Lab',NULL,NULL
8906,'lecture','en',5560,'2008-06-24','2009-07-15','Living Labs Fostering Open Innovation and Rural Development: Methodology and Results','Rural living labs constitute a new and not yet validated approach of enabling user driven ICT-based innovation initiatives geared towards economic and social development in rural areas. At the same time living labs provide a context for open innovation based on partnerships between all stakeholders. This paper discusses methodologies and strategies for developing, launching and operating rural living labs for innovative collaborative working environments, and presents initial results from the C@R Integrated Project. Three living labs cases are presented and compared: Homokháti in Hungary, Sekhukhune in South-Africa, and Cudillero in Spain. The process of establishing the living lab, the involvement of users, the experimentation and innovation processes, and the technical and business innovations and their impacts on the rural environment are being discussed in order to conclude about effective methodologies and strategies. Such methodologies and strategies include the establishment of stakeholder platforms, the creation of user communities, the cyclic and spiral approach to innovation, and the action research style of participative development. Initial results indicate that in order to be successful, such methodologies and strategies must be strongly tailored to the local situation.',NULL
8907,'lecture','en',5560,'2008-06-24','2009-07-15','Conclusions',NULL,NULL
8908,'lecture','en',5561,'2008-06-24','2009-07-15','Open Collaborative Architecture Working Groups',NULL,NULL
8909,'lecture','en',5561,'2008-06-24','2009-07-15','The CoSpaces Software Framework ',NULL,NULL
8910,'lecture','en',5561,'2008-06-24','2009-07-15','Ecospace',NULL,NULL
8911,'lecture','en',5561,'2008-06-24','2009-07-15','C@R project ',NULL,NULL
8915,'lecture','en',5560,'2008-06-24','2009-07-15','Introduction to the workshop','Concurrent enterprising, and especially the new waves of innovation in collaborative networks, are the key issues of the ICE conference 2008. The education of CE-related aspects is an essential topic to prepare the future professionals to the increasing cooperative dimension of every business fields. This workshop addresses the issues related to cooperation in collective design education: methods, IT-tools, sociological aspects and so on. The papers relate different co-design experiments performed across Architecture students in France, Portugal, Germany and Canada. The workshop aims to bring together, discuss, and improve the innovative pedagogical scenarios, and to stimulate a pedagogical network of innovative cooperation-teaching methods.',NULL
8916,'lecture','en',5560,'2008-06-24','2009-07-15','Collaborative and Virtual Architectural Design in Second Life: FINC-AV experiment',NULL,NULL
8918,'lecture','en',5560,'2008-06-24','2009-07-15','Stimulating Collaborative Behaviour in Design Education',NULL,NULL
8919,'lecture','en',5561,'2008-06-23','2009-07-15','Critical Success Factors and Challenges to develop new Sustainable Supply Chains in India based on Swiss Experiences',NULL,NULL
8920,'lecture','en',5560,'2008-06-25','2009-07-15','COIN Project Introduction','By 2020 enterprise collaboration and interoperability services will become an invisible, pervasive and self-adaptive knowledge and business utility at disposal of the European networked enterprises from any industrial sector and domain in order to rapidly set-up, efficiently manage and effectively operate different forms of business collaborations, from the most traditional supply chains to the most advanced and dynamic business ecosystems.\nThe COIN project is developing an ICT integrated solution, in order to make enterprise collaboration and interoperability services available as a business utility for European networked enterprises. The objective of the COIN workshop is to present Enterprises Interoperability and Enterprise Collaboration scenarios, selected among the most promising cases in Europe, with the aim of collecting additional use requirements and initial implementation roadmaps, based on real industrial and socio-economic contexts.',NULL
8921,'lecture','en',5560,'2008-06-25','2009-07-15','The COIN Metaphore for EU Industry',NULL,NULL
8922,'lecture','en',5560,'2008-06-25','2009-07-15','COIN Results, Market Context, Targets',NULL,NULL
8923,'lecture','en',5560,'2008-06-25','2009-07-15','Coin end user - VEN Healthcare',NULL,NULL
8924,'lecture','en',5560,'2008-06-25','2009-07-15','Collaboration and Interoperability in the Andalusian Aeronautical Cluster',NULL,NULL
8925,'lecture','en',5560,'2008-06-25','2009-07-15','COIN business needs from the perspective of an Innovative IT Cluster at the Hungarian Association of IT Companies (IVSZ)',NULL,NULL
8926,'lecture','en',5560,'2008-06-25','2009-07-15','Early requirements collected from the end users',NULL,NULL
8927,'lecture','en',5560,'2008-06-25','2009-07-15','Pöyry case',NULL,NULL
8928,'lecture','en',5560,'2008-06-23','2009-07-15','Increased Efficiency in Customer Involvement in Configuration Processes: The SWOP Approach','Besides a higher complexity of products and services, trends and tendencies in nowadays industries show also a growing customer demand for reliable, fast and cheap as well as individual solutions for existing problems. Nevertheless, optimised engineering and production processes involving multidisciplinary input, dynamic working environments and multi- stakeholder interests across the life-cycle and supply chain of products and services still have not been achieved yet. Especially for complex products, the configuration process is getting more and more important for a successful and efficient sales process. In addition, it is essential for a company to store its technical know-how centrally but make it available cross-departmentally (Ulmer 2005).',NULL
8929,'lecture','en',5560,'2008-06-25','2009-07-15','Expected project results and use scenarios',NULL,NULL
8957,'lecture','en',5560,'2008-06-23','2009-07-15','Living Labs: new ways to enhance innovativeness in public sector services','The public sector is seen to play an important role as a facilitator of innovativeness and competitiveness in the private sector. Besides this important role the innovativeness in the public sector must also be promoted in new ways because of the new challenges facing public sector service production. This paper introduces the ideas of the emerging open innovation paradigm in the public sector context presenting a case for user involvement in the public sector service development context in the Lahti region in Finland. This paper also discusses in more wider terms the emerging role of the public sector as not only a facilitator of innovativeness in the private sector organisations, but also as a target of innovation policies and especially highlights new ways to involve the end-users of public sector services in producing innovations. The implications for the regional innovation system (RIS) are also discussed.',NULL
8958,'lecture','en',5560,'2008-06-23','2009-07-15','Best Practices, Innovation and Development: Experiences from Five Living Lab Innovation Environments','The Living Lab concept is based on open innovation and serves as a platform for different stakeholders in the innovation system (cities, companies, universities). There is a strong emphasis on user participation. The aim of this paper is to study in depth the experiences of Living Lab innovation environment/platform by qualitative case study method to gain more understanding of the best practices they have found in their activities, areas that need improvement and innovations coming out of these Living Labs. From the 14 Living Labs existing in Finland today, five were chosen for this stud. These represent different areas of industry and have a University of Applied Sciences involved.',NULL
8959,'lecture','en',5560,'2008-06-23','2009-07-15','Supporting innovative SME in innovation processes: The role of regional intermediaries','Innovation is crucial for growth in highly developed regions. Still, it remains a challenge to foster innovation deliberately. Regional intermediaries can play an important role and provide platforms that induce networks and conversations. Analysis of examples from Central Switzerland and from Extremadura, Spain, shows three patterns typical for the most innovative SME: To take time for creative thought: break and play effect; to mix people with different backgrounds and ideas: diverse people effect; and to support open and trustful communication: conversation effect. These effects can be summarized as the known cafeteria effect and be used on the regional level. Organizations like the Lucerne University of Applied Sciences or Fundecyt of Extremadura or many other organizations can use these effects as ingredients for creating innovation supportive environments where SME can experience the power of break and play, diverse people and open and trustful conversations.',NULL
8960,'lecture','en',5560,'2008-06-23','2009-07-15','Adaptability through open innovation, a complexity view on selectivity','Today\'s world is characterized by increasing complexity, uncertainty and change. Several authors have found in Complex Adaptive Systems (CAS) the basis for more suitable management models that should allow firms to adapt and survive under highly complex, uncertain and changing environments. The incorporation of external capabilities and knowledge through open innovation can increase an organization\'s adaptability because it amplifies significant differences and increases the number of transforming exchanges, through a higher interaction with external system agents. However, too much difference can generate a large number of possibilities, reducing momentum for action, and too many exchanges limits individual behaviour. Therefore, it is important to be selective so that organizations in pursuit of adaptability through open innovation don\'t fall into chaos. By using the example of the Engineering and Tooling sector, this paper explores the impact of open innovation on adaptability and the importance of selectivity and knowledge brokers.',NULL
8961,'lecture','en',5560,'2008-06-23','2009-07-15','Increased Efficiency in Customer Involvement in Configuration Processes: The SWOP Approach','Besides a higher complexity of products and services, trends and tendencies in nowadays industries show also a growing customer demand for reliable, fast and cheap as well as individual solutions for existing problems. Nevertheless, optimised engineering and production processes involving multidisciplinary input, dynamic working environments and multi- stakeholder interests across the life-cycle and supply chain of products and services still have not been achieved yet. Especially for complex products, the configuration process is getting more and more important for a successful and efficient sales process. In addition, it is essential for a company to store its technical know-how centrally but make it available cross-departmentally (Ulmer 2005).',NULL
8962,'lecture','en',5560,'2008-06-23','2009-07-15','Monitoring and Control of Collaborative Innovation in Small Firms’ networks','Collaborative innovations may be generated and well driven by strong visions and the progresses can be optimised by adequate monitoring and control. The paper specifies a verified framework for collaborative innovation for the case of small firms. Using the criticality concept it narrows down the attributes to be observed to a minimum set. The quantifications of these attributes provide for a reliable base for control and decision procedures ensuring the progress as well as the optimisation of collaborative innovations. The value bundles of all observable result in characteristics for control interventions that allow the set up of an efficient process control for collaborative innovation.',NULL
8963,'lecture','en',5560,'2008-06-25','2009-07-15','Context recognition in the wearIT@work project',NULL,NULL
8964,'lecture','en',5560,'2008-06-25','2009-07-15','The next 6 big things in mobile computing',NULL,NULL
8965,'lecture','en',5560,'2008-06-25','2009-07-15','An Approach to Systemic Innovation of Information Technology for Emergency Response',NULL,NULL
8966,'lecture','en',5560,'2008-06-25','2009-07-15','Does Wearable Computing Really Empower the Mobile Worker – findings from ethnographic studies',NULL,NULL
8967,'lecture','en',5560,'2008-06-25','2009-07-15','Exploiting Research Results in Practice',NULL,NULL
8969,'lecture','en',5561,'2008-06-24','2009-07-15','The Role of Collaborative Working Environments in Enabling Global Business','Tukej je treba dodat še folder gareis_rcw kot part dva videa noter... Sta dva avtorja in eno predavanje iz 2 delov!!!\n\n\n\n\nThe objective of this paper, based on early results of the New Global study, is to explore how globalisation of markets and industries affects the way companies are operating and collaborating, and to investigate the opportunities which global networking and global collaborative working opens up for market players including Europe\'s large number of SMEs. A core focus is on how ICT-enabled collaborative working environments (CWE) enable global operations and working. Based on an investigation of current trends and developments, this paper explores various types of collaboration settings in which CWEs enable new forms of global collaboration in teams, networks and communities. Initial results of case studies are presented to identify policies and strategies which could be applied to promote global collaboration of European companies.',NULL
8984,'lecture','en',5560,'2008-06-23','2009-07-15','Semantic Web Services as Foundation for Enterprise Interoperability',NULL,NULL
8985,'lecture','en',5560,'2008-06-23','2009-07-15','Organizational knowledge in enterprise systems',NULL,NULL
8986,'lecture','en',5560,'2008-06-23','2009-07-15','The CoSpaces Training System',NULL,NULL
8987,'lecture','en',5560,'2008-06-24','2009-07-15','What is sustainable innovation and why emerging markets?',NULL,NULL
8988,'lecture','en',5560,'2008-06-24','2009-07-15','CHINA: Deco-China',NULL,NULL
8989,'lecture','en',5560,'2008-06-23','2009-07-15','Applying Serious Games for Supporting Idea Generation in Collaborative Innovation Processes','The ideation process often called the fuzzy front-end to innovation is one of the most crucial steps when starting industrial- and especially collaborative innovation processes. There are numerous creativity techniques like brainstorming to be used in this early phase. This paper introduces another approach based on Serious Gaming. A game to structure the ideation process refQuest has been developed and is briefly described. Two early evaluations have been performed at the University of Bremen in order to verify that the approach supports idea generation in a structured approach and to get an overview on strengths and weaknesses for further enhancements. The approach used for this early evaluation of the refQuest game prototype was based on three different types of input: the observation and the exchange of information between the facilitator and the player, questionnaires comprising questions on the functionality, the utility and the usability of the software as well as questions dealing with the idea generation process, and direct observations during the game.',NULL
8990,'lecture','en',5560,'2008-06-23','2009-07-15','Computer Related Inventions, in particular Business Methods: Examination at the European Patent Office',NULL,NULL
8991,'lecture','en',5560,'2008-06-24','2009-07-15','“Experiences of R&D projects with Emerging Markets for Sustainable Innovation',NULL,NULL
8992,'lecture','en',5560,'2008-06-24','2009-07-15','INDIA: SWISSMAIN Indian Pilot',NULL,NULL
8996,'lecture','en',5561,'2008-06-24','2009-07-15','How European SMEs use ICT to engage in Global Virtual Collaboration',NULL,NULL
8997,'lecture','en',5560,'2008-06-24','2009-07-15','Cooperative Digital Studio 07-08',NULL,NULL
9020,'lecture','en',8830,'2009-06-22','2009-07-22','Automated detection of electrocardiographic diagnostic features through an interplay between Spatial Aggregation and Computational Geometry','Within the medical domain, Functional Imaging provides\nmethods for effectual visualization of diagnostically relevant\nnumeric fields, i.e. of spatially referenced measurements of\nvariables related to organ functions. Unveiling the salient\nphysical events that underly a functional image is most appropriately\naddressed by feature extraction methods that exploit\nthe domain-specific knowledge combined with spatial\nrelations at multiple abstraction levels and scales. The identification\nof specific patterns that are known to characterize\nclasses of pathologies provides an important support to the\ndiagnosis of disturbances, and the assessment of organ functions.\nIn this work we focus on Electrocardiographic diagnosis\nbased on epicardial activation fields. This kind of data,\nwhich can now be obtained non invasively from body surface\ndata through mathematical model-based reconstruction methods,\ncan hit electrical conduction pathologies that routine surface\nECGs may miss. However, their analysis/interpretation\nstill requires highly specialized skills that belong to few experts.\nGiven an epicardial activation field, the automated detection\nof salient patterns in it, grounded on the existing interpretation\nrationale, would represent a major contribution\ntowards the clinical use of such valuable tools whose diagnostic\npotential is still largely unexplored. We focus on epicardial\nactivation isochronal maps, which convey information\nabout the heart electric function in terms of the depolarization\nwavefront kinematics. An approach grounded on the integration\nof a Spatial Aggregation (SA) method with concepts\nborrowed from Computational Geometry provides a computational\nframework to extract, from the given activation data,\na few basic features that characterize the wavefront propagation,\nas well as a more specific set of diagnostic features\nthat identify an important class of heart rhythm pathologies,\nnamely reentry arrhythmias due to block of conduction.\nKeywords: Biomedical imaging; functional imaging; image\nbased diagnosis; spatial aggregation; computational geometry;\nelectrocardiography; cardiac electrical function.','Automated detection of electrocardiographic diagnostic features through an interplay between Spatial Aggregation and Computational Geometry;;Outline;;Functional Imaging & Image Based Diagnosis (1);;Functional Imaging & Image Based Diagnosis (2);;Functional Imaging & Image Based Diagnosis (3);;Core task is Feature Extraction;;Imaging of the cardiac electric activity;;An example: activation isochrones during VT;;Excitation starts here (breakthrough site);;Spatially dense isochrones ↓ very-slow conduction;;Conduction block ;;Conduction block Reentry propagation pattern;;Feature extraction problem;;Approach & Methods;;Spatial Aggregation;;Overview of the abstraction processes;;Double reentry circuit identification;;Algorithm (Gross skeleton) (1);;Algorithm (Gross skeleton) (2);;Algorithm (Gross skeleton) (3);;Algorithm (Gross skeleton) (4);;Choice of β * (1);;Choice of β * (2), (n = 30 perturbations, SNR = 148.3);;Choice of β * (3);;Choice of β * (4);;Some results;;Check for conduction blocks;;Classification of propagation lines;;Conclusions & future work;;Automated detection of electrocardiographic diagnostic features through an interplay between Spatial Aggregation and Computational Geometry;;qr09_tentoni_ade_01_Page_31;;qr09_tentoni_ade_01_Page_32'
9021,'lecture','en',8830,'2009-06-22','2009-07-22','Computing Human-Like Qualitative Topological Relations via Visual Routines','A core problem in spatial reasoning is finding an appropriate set of relationships to compute. This paper proposes that humans represent topological relationships between 2D regions using three basic, qualitative relations: contains, intersects, and overlaps-with. We show how these relations can be computed from sketched inputs using a model of mid-level perception. Results from a pilot experiment indicate that these three relationships suffice to explain people‟s judgments on four English spatial terms (“intersects”, “overlaps”, “connects to”, and “contains”), although a combination of the three is generally required for each term.','Computing Human-Like Qualitative Topological Relations via Visual Routines;;Cognitive Representations of Space;;2D Topological Relationships;;Is RCC8 a human cognitive representation? (1);;Is RCC8 a human cognitive representation? (2);;Is RCC8 a human cognitive representation? (3);;Is RCC8 a human cognitive representation? (4);;Three Topological Relations (1);;Three Topological Relations (2);;Three Topological Relations (3);;Three Topological Relations (4);;Three Topological Relations (5);;Overview (1);;Overview (2);;Overview (3);;Overview (4);;Visual Routines for Sketching;;VSS: Input;;VSS: Visual Representation;;Example Routine (1);;Example Routine (2);;Example Routine (3);;Example Routine (4);;Example Routine (5);;Example Routine (6);;Example Routine (7);;Example Routine (8);;Example Routine (9);;Example Routine (10);;Example Routine (11);;Example Routine (12);;Example Routine (13);;Example Routine (14);;Example Routine (15);;Our 2D Topological Relations;;Intersects(A,B) (1);;Intersects(A,B) (2);;Intersects(A,B) (3);;Intersects(A,B) (3);;Intersects(A,B) (4);;Intersects(A,B) (5);;Intersects(A,B) (5);;Overlaps-with(A,B) (1);;Overlaps-with(A,B) (2);;Overlaps-with(A,B) (3);;Overlaps-with(A,B) (4);;Contains(A,B) (1);;Contains(A,B) (2);;Contains(A,B) (3);;Contains(A,B) (4);;qr09_lovett_chl_01_Page_51;;Evaluation;;Experimental Paradigm (1);;Experimental Paradigm (2);;Psychological Study (1);;Psychological Study (2);;Evaluation (1);;Evaluation (2);;Evaluation (3);;Evaluation (4);;Evaluation (5);;Evaluation (6);;Evaluation: Two Questions;;Methods;;Analysis;;Results: Correlations (1);;Results: Correlations (2);;Results: Correlations (3);;Results: Correlations (4);;Alternate Hypotheses (1);;Alternate Hypotheses (2);;Alternate Hypotheses (3);;Alternate Hypotheses (4);;Alternate Hypotheses (5);;Alternate Hypotheses (6);;Optimal Weights (1);;Optimal Weights (2);;Optimal Weights (3);;Optimal Weights (4);;qr09_lovett_chl_01_Page_80;;Conclusion;;qr09_lovett_chl_01_Page_82;;qr09_lovett_chl_01_Page_83;;qr09_lovett_chl_01_Page_84;;qr09_lovett_chl_01_Page_85;;qr09_lovett_chl_01_Page_86;;qr09_lovett_chl_01_Page_87'
9022,'lecture','en',8830,'2009-06-22','2009-07-22','Commonsense Inference in Dynamic Spatial Systems “Phenomenal and Reasoning Requirements”','Spatial changes within an environment are typically\na result of interaction— actions and events—\noccurring within. Reasoning about such changes,\nwhen dealt with formally within the context of\nqualitative spatial calculi and logics of action and\nchange, poses several difficulties along multiple dimensions:\n(a) phenomenal requirements stemming\nfrom the dynamic nature of the spatial system (e.g.,\nappearing and disappearing objects), (b) reasoning\nrequirements (e.g., abductive explanation), (c)\ndomain-independent or epistemological (e.g., persistence,\nramification), and (d) aspects concerning\nthe need to satisfy the intrinsic (axiomatic) properties\nof the spatial calculi (e.g., compositional consistency)\nbeing modelled. This paper, encompassing\nthe phenomenal and reasoning aspects in (a)\nand (b) respectively, presents some instances that\ndemonstrate the role of commonsense reasoning\nand the non-monotonic inference patterns it necessitates\nwhilst representing and reasoning about dynamic\nspatial systems in general.','Commonsense Inference in Dynamic Spatial Systems;;Overview;;Commonsense Reasoning about the World;;iCub Simulator (1);;iCub Simulator (2);;High-level Reasoning + Low-level Control (1);;High-level Reasoning + Low-level Control (2);;High-level Reasoning + Low-level Control (3);;High-level Reasoning + Low-level Control (4);;High-level Reasoning + Low-level Control (5);;High-level Reasoning + Low-level Control (6);;Integrating Grounding, Action and Control (1);;Integrating Grounding, Action and Control (2);;Integrating Grounding, Action and Control (3);;Commonsense and Space;;Commonsense and Space - Motivation;;Some key tasks (1);;Some key tasks (2);;Some key tasks (3);;Some key tasks (4);;Some key tasks (5);;Some key tasks (6);;Basic Level (1);;Basic Level (2);;Scenario: Static Scene Description in Room Space;;Ontological Extensions for a Dynamic Setup (1);;Ontological Extensions for a Dynamic Setup (2);;Need a Dynamic Spatial Systems Perspective (1);;Need a Dynamic Spatial Systems Perspective (2);;Need a Dynamic Spatial Systems Perspective (3);;Need a Dynamic Spatial Systems Perspective (4);;Need a Dynamic Spatial Systems Perspective (5);;Need a Dynamic Spatial Systems Perspective (6);;Need a Dynamic Spatial Systems Perspective (7);;Need a Dynamic Spatial Systems Perspective (8);;Operationalising the Dynamic Spatial Systems Perspective (1);;Operationalising the Dynamic Spatial Systems Perspective (2);;Operationalising the Dynamic Spatial Systems Perspective (3);;Operationalising the Dynamic Spatial Systems Perspective (4);;Operationalising the Dynamic Spatial Systems Perspective (5);;Operationalising the Dynamic Spatial Systems Perspective (6);;Dynamic Spatial Systems in the Situation Calculus;;Default and Non-Monotonic Aspects of Spatial Reasoning;;Some notation (1);;Some notation (2);;Some notation (3);;Some notation (4);;Global Consistency and Ramifications (1);;Global Consistency and Ramifications (2);;Global Consistency and Ramifications (3);;Global compositional consistency (1);;Global compositional consistency (2);;Global compositional consistency (3);;Global compositional consistency (4);;Global compositional consistency: Final step (1);;Global compositional consistency: Final step (2);;Global compositional consistency: Final step (3);;Global compositional consistency: Final step (4);;Global compositional consistency: Final step (5);;2. Spatial property persistence (1);;2. Spatial property persistence (2);;2. Spatial property persistence (3);;2. Spatial property persistence (4);;3. Phenomenal aspects – Appearance and disappearance of objects;;Appearance and Disappearance of Objects (1);;Appearance and Disappearance of Objects (2);;Appearance and Disappearance of Objects (3);;Need default reasoning about ‘non-existence’ (1);;Need default reasoning about ‘non-existence’ (2);;Need default reasoning about ‘non-existence’ (3);;Need default reasoning about ‘non-existence’ (4);;Need default reasoning about ‘non-existence’ (5);;4. Reasoning requirement – Explanation tasks (1);;4. Reasoning requirement – Explanation tasks (2);;Structure of Abductive Explanation (1);;Structure of Abductive Explanation (2);;Structure of Abductive Explanation (3);;Structure of Abductive Explanation (4);;Structure of Abductive Explanation (5);;Structure of Abductive Explanation (6);;Structure of Abductive Explanation (7);;Structure of Abductive Explanation (8);;Structure of Abductive Explanation (9);;Structure of Abductive Explanation (10);;Structure of Abductive Explanation (11);;Structure of Abductive Explanation (12);;Structure of Abductive Explanation (13);;Modelling explanation abductively in the situation calculus;;Application Framework;;An Experimental Cognitive Robotics Framework;;Demo: High-level reasoning + low-level motion control;;Integration of Robotcub (YARP & iCub) Ongoing;;Outlook;;Action and Control;;Other application domains;;Conclusion'
9023,'lecture','en',8830,'2009-06-22','2009-07-22','Factored Envisioning','Envisioning has been used extensively to model behavior\nof physical systems. Envisioning generates\nthe qualitatively distinct possible behaviors without\nnumerically simulating every possible set of\ninput conditions and model parameters. This paper\napplies envisioning to analyze course of action\n(COA) diagrams to determine the qualitatively\ndistinct outcomes of military operations. In order\nto avoid the combinatorial explosion of possible\nstates, this envisioner factors non-interacting\nunits into separate envisionment threads. The envisioner\nuses Assumption-Based Truth Maintenance\nto further limit combinatorial explosion and estimate\nprobability of outcomes.We illustrate the performance\nof the factored envisioner on a variety of\nexamples provided by military experts. We analyze\nits scaling performance and demonstrate its ability\nto track operations from sparse observations.','Factored Envisioning;;The Problem;;Example;;Two Approaches (1);;Two Approaches (2);;CONOPS: Preplanning;;PDDL;;Model of Time (1);;Model of Time (2);;Model of Time (3);;Envision(Q) (1);;Envision(Q) (2);;Envision(Q) (3);;Envision(Q) (4);;Envision(Q) (5);;Envision(Q) (6);;Envision(Q) (7);;Roll up of parameters;;ATMS Representation;;PATMS: ATMS Mapping;;ATMS Structure for Merges;;ATMS Structure For Uncertain Transitions;;ATMS Structure For Joins;;Expected Success;;Expected Utility;;Mission Execution;;“Real” Data;;Message Arrives;;Also part of the system;;Challenges;;Summary'
9024,'lecture','en',8830,'2009-06-22','2009-07-22','Automated Critique of Sketched Designs in Engineering','Designers often use a series of sketches to explain how their design goes through different states or modes to achieve its intended function. Learning how to create such explanations turns out to be a difficult problem for engineering students. An au-tomated ―crash test dummy‖ to let students practice explanations would be desirable. This paper de-scribes how to carry out a core piece of the reason-ing needed in such system. We show how an open-domain sketch understanding system can be used to enter many aspects of such explanations, and how qualitative mechanics can be used to check the plausibility of the intended state transitions. The system is evaluated using a corpus of sketches based on designs from an engineering school de-sign & communications course.','Automated Critique of Sketched Mechanisms;;Outline;;Motivation;;Example Sketch of EDC project;;Long-term Goal: Design Buddy;;Outline - Algorithm;;Critique of Sketched Mechanisms;;Input: CogSketch (1);;Input: CogSketch (2);;Input: CogSketch (3);;Input: CogSketch (4);;Input: CogSketch (5);;Outline - State Transition Verification;;State Transition Verification;;Step 1/3: Derive Requirements (1);;Step 1/3: Derive Requirements (2);;Step 2/3: QM Predicts Behavior (1);;Step 2/3: QM Predicts Behavior (2);;Step 2/3: QM Predicts Behavior (3);;Step 3/3: Compare Results;;Outline - Evaluation;;Evaluation (1);;Evaluation (2);;Examples from EDC Projects (1);;Examples from EDC Projects (2);;Examples from EDC Projects (3);;Examples from EDC Projects (4);;Related Work;;Future Work;;qr09_wetzel_acs_01_Page_30;;qr09_wetzel_acs_01_Page_31'
9025,'lecture','en',8830,'2009-06-22','2009-07-22','Learning and Reasoning with Qualitative Models of Physical Behavior','Building models of the physical world from examples is an important challenge for qualitative reasoning systems. We describe a system that can learn intuitive models of physical behaviors from a corpus of multimodal, multi-state stimuli, consisting of sketches and text. The system extracts and temporally encodes exemplars from the stimuli and uses analogical generalization to abstract prototypical behaviors. Using statistical analysis, the system parameterizes these abstractions into qualitative representations for reasoning. We show that the explanations the system provides for new situations are consistent with those given by naïve students. Keywords: Cognitive modeling; conceptual change; misconceptions; naïve physics; qualitative reasoning','Learning and Reasoning with Qualitative Models of Physical Behavior;;Novices & Qualitative Physics (1);;Novices & Qualitative Physics (2);;Our System;;Multimodal Stimuli (1);;Multimodal Stimuli (2);;Encoding Exemplars;;Temporally Encoded Exemplars (1);;Temporally Encoded Exemplars (2);;SEQL Generalization;;Contextualized Generalizations;;Generalizing with SEQL (1);;Generalizing with SEQL (2);;Generalizing with SEQL (3);;Generalizing with SEQL (4);;Result of Generalizing with SEQL;;Generalization Anatomy;;Building Models;;Encapsulated Histories;;Filtering Generalizations;;Models from Generalizations;;Generating Encapsulated Histories;;Resulting Encapsulated Histories;;Reasoning with Learned Models;;Problem Solving Experiments;;Results from Brown (1994);;Results from the Force Concept Inventory;;Summary of Learning Results;;Simulation Results: Brown;;Simulation Results: FCI;;Conclusion;;Future Work;;Related Work;;Acknowledgments'
9026,'lecture','en',8830,'2009-06-22','2009-07-22','Intelligent Authoring of ’Graph of Microworlds’ for Adaptive Learning with Microworlds','In science education, it is important to sequence a set of\nmicroworlds (which means a system and its model limited\nfrom educational viewpoint) of various complexity\nadaptively to the context of learning. We previously\nproposed Graph of Microworlds (GMW), a framework\nfor indexing a set of microworlds based on their models.\nBy using GMW, it is possible to adaptively select\nthe microworld a student should learn next, and to assist\nhim in transferring between microworlds. However,\nit isn’t easy to describe GMW because an author must\nhave the expertise in the process of modeling. In this\nresearch, we propose a method for semi-automating the\ndescription of GMW by introducing the compositional\nmodeling mechanism. Our method assists an author\nin generating a set of indexed microworlds and also in\nconsidering educational meanings of the relations between\nthem. We present how to design such a function\nand also illustrate how it works. A preliminary test\nwith a prototype system showed the effectiveness of our\nmethod.','Intelligent Authoring of ‘Graph of Microworlds’ for Adaptive Learning with Microworlds;;Research Goal;;Background Adaptive sequencing of MWs;;Background GMW: Graph of Microworlds;;Background Educationally Meaningful Diff.;;Background Assisting Learners on GMW;;Problem: Describing GMW is difficult;;Method Assisting Authors in describing GMW;;Exclusive MAs/MFs;;Inferring the Diff. between Models;;Classification of Modeling Assumps;;Example;;Diffs Inferred by Prototype System;;Summary;;qr09_horiguchi_iag_01_Page_15;;qr09_horiguchi_iag_01_Page_16;;qr09_horiguchi_iag_01_Page_17;;qr09_horiguchi_iag_01_Page_18;;qr09_horiguchi_iag_01_Page_19;;qr09_horiguchi_iag_01_Page_20;;qr09_horiguchi_iag_01_Page_21;;qr09_horiguchi_iag_01_Page_22;;qr09_horiguchi_iag_01_Page_23;;qr09_horiguchi_iag_01_Page_24;;qr09_horiguchi_iag_01_Page_25'
9027,'lecture','en',8830,'2009-06-22','2009-07-22','Application of qualitative reasoning models in the scientific education of deaf students','Regarding the education of deaf students (in Brazil), three\nconditions have to be met in order to bring qualitative\nreasoning (QR) models into the classroom: (a) a bilingual\neducation should be provided, the Brazilian Sign Language\n(LIBRAS) being the first and Portuguese the second\nlanguage; (b) in the absence of scientific vocabulary in\nLIBRAS, it has to be created; (c) given the aural\nimpairment, which is cognitively compensated through an\nover-developed visual ability, a visually oriented pedagogy\nis needed. This paper describes how qualitative reasoning\nmay provide an adequate scenario to create a vocabulary in\nsign language for representing scientific concepts while\noffering support for the integration of visually-oriented\nmodels and simulations, and written Portuguese in\neducational activities.\nKey words: qualitative models, deaf, science education','Application of qualitative reasoning models in the scientific education of deaf students;;Motivation;;What has been done (in this work) to meet these requirements;;A model about global warming and climatic changes;;Didactic materials to explore the QR model;;QR models expressed in sign language;;Qualitative reasoning;;A DVD with the didactic material;;Validation;;Concluding…;;Acknowledgements'
9028,'lecture','en',8830,'2009-06-22','2009-07-22','Closeness and Distance Relations in Order of Magnitude Qualitative Reasoning via PDL','The syntax, semantics and an axiom system for an extension\nof Propositional Dynamic Logic (PDL) for order of magnitude\nqualitative reasoning which formalizes the concepts of\ncloseness and distance is introduced in this paper. In doing\nthis, we use some of the advantages of PDL: firstly, we exploit\nthe possibility of constructing complex relations from\nsimpler ones for defining the concept of closeness and other\nprogramming commands such as while . . . do and repeat . . .\nuntil; secondly, we employ its theoretical support in order to\nshow that the satisfiability problem is decidable. Moreover,\nthe specific axioms of our logic have been obtained from the\nminimal set of formulas needed in our definition of qualitative\nsum of small, medium and large numbers. We also present\nsome of the advantages of our approach on the basis of an\nexample.','Closeness and Distance Relations in Order of Magnitude Qualitative Reasoning via PDL;;Introduction;;Using Logic in Qualitative Reasoning;;Order of Magnitude Reasoning;;Introducing Propositional Dynamic Logic;;The language;;Some formulas for qualitative arithmetic;;Closeness and Distance;;A device to control the temperature (1);;A device to control the temperature (2);;Axiom system;;Axiom schemata for qualitative classes;;Axiom schemata for specic programs;;Decidability results ;;Conclusions and future work;;Conclusions;;Future work;;Thank you and Contact;;qr09_velasco_cdr_01_Page_19;;qr09_velasco_cdr_01_Page_20;;qr09_velasco_cdr_01_Page_21;;qr09_velasco_cdr_01_Page_22;;qr09_velasco_cdr_01_Page_23;;qr09_velasco_cdr_01_Page_24;;qr09_velasco_cdr_01_Page_25;;qr09_velasco_cdr_01_Page_26;;qr09_velasco_cdr_01_Page_27;;qr09_velasco_cdr_01_Page_28;;qr09_velasco_cdr_01_Page_29;;qr09_velasco_cdr_01_Page_30;;qr09_velasco_cdr_01_Page_31;;qr09_velasco_cdr_01_Page_32;;qr09_velasco_cdr_01_Page_33'
9029,'lecture','en',8830,'2009-06-22','2009-07-22','Incorporating Qualitative Equations in Process-Based Models','This paper explores the possibility of extending Processbased\nmodels with Qualitative differential equations.\nProcess-based modeling is a modeling technique that uses\ntwo-level approach for modeling dynamical systems. It\nmodels systems on a purely qualitative level in terms of\nentities and processes that involve those entities on one\nhand, and a quantitative level on which all entities and\nprocesses are given a quantitative formulation which is that\nautomatically translated into a set of ordinary differential\nequations. This paper aims to illustrate that this formalism\ncan be extended with an intermediate level of modeling\nwhich consists of qualitative equations.','Incorporating Qualitative Equations in Process‐Based Models;;Dynamical Systems;;Process‐Based Modeling;;Example: Aquatic ecosystem (1);;Example: Aquatic ecosystem (2);;Quantitative level;;Process‐based Model;;Ordinary Differential Equations;;Incorporating Qualitative Equations (1);;Incorporating Qualitative Equations (2);;Example: Aquatic ecosystem (3);;Example: Aquatic ecosystem (4);;Example: Aquatic ecosystem (5);;Conclusion & FW'
9030,'lecture','en',8830,'2009-06-23','2009-07-22','Using Qualitative Reasoning in Modelling Consensus in Group Decision-Making','Ordinal scales are commonly used in rating and evaluation\nprocesses. These processes usually involve group decision\nmaking by means of an experts’ committee. In this paper a\nmathematical framework based on the qualitative model of\nthe absolute orders of magnitude is considered. The entropy\nof a qualitatively described system is defined in this framework.\nOn the one hand, this enables us to measure the amount\nof information provided by each evaluator and, on the other\nhand, the coherence of the evaluation committee. The new\napproach is capable of managing situations where the assessment\ngiven by experts involves different levels of precision.\nThe use of the proposed measures within an automatic system\nfor group decision making will contribute towards avoiding\nthe potential subjectivity caused by conflicts of interests\nof the evaluators in the group.',NULL
9031,'lecture','en',8830,'2009-06-23','2009-07-22','Model Building Experiences using Garp3: Problems, Patterns and Debugging','Capturing conceptual knowledge in QR models is becoming\nof interest to a larger audience of domain experts.\nConsequently, we have been training several\ngroups to effectively create QR models during the last\nfew years. In this paper we describe our teaching experiences,\nthe issues the modellers encountered and the\nsolutions to solve them in the form of reusable patterns,\nand finally a structured way to debug models.','Model Building Experiences using Garp3: Problems, Patterns and Debugging;;Motivation: Usability to Formalization Bottleneck;;Trained Groups in QR Modelling;;Entities or Quantities?;;Configuration direction & naming;;Relation reification;;Influences & Proportionalities;;Causal Interactions;;Causal Chains;;Multiple Competing Influences;;Choosing Quantity Spaces;;{Small, Medium, High} considered harmful;;Actuators: External actuator (1/3);;Actuators: Equilibrium Seeking Mechanism (2/3);;Actuators: Competing Processes Pattern (3/3);;States in simulation;;Not all expected states;;No States;;Inconsistencies;;Conclusions & Future Work'
9032,'lecture','en',8830,'2009-06-23','2009-07-22','Dark Knowledge in Qualitative Reasoning: A Call to Arms','While people do qualitative reasoning, there is ample\nevidence that they do not always do it well. Two current\ncrises, human-induced climate change and the financial\nmeltdown, can be traced in part to faulty mental models.\nThe QR community has formalisms that can potentially help\nwith public education about such problems, but so far we\nhave not been very successful in doing so. We claim that\npart of the reason is that current QR accounts do not\nadequately incorporate experiential knowledge. We argue\nthat it is important to find better ways to improve public\nqualitative reasoning abilities, in part by helping people\nenlist their experience-based models via analogy.','Dark knowledge in Qualitative Reasoning: A call to Arms;;Example of the Problem;;Mental Models Matter;;Hypothesis: QR can help;;Overview;;Standard QR model;;Alternative: Experience-based modeling;;Culture as a Source of Experience;;Experience = Dark Knowledge in QR;;Experience-based QR (one version);;Learning mental models;;Analogies;;Analogy as knowledge integration;;Stocks & Flows (1);;Stocks & Flows (2);;Typical Incorrect Answers;;Techniques for using analogy effectively;;Bathtubs, revisited;;Bathtubs and Credit Cards;;Projecting backwards to understand differences;;Mr. Will on ice (1);;Mr. Will on ice (2);;QR can be subtle;;What is to be done?;;Building Experience-based Systems;;Better tools;;Summary;;Questions, suggestions?'
9033,'lecture','en',8830,'2009-06-24','2009-07-22','Order-of-Magnitude Based Link Analysis for False Identity Detection','Combating identity fraud is crucial and urgent as false identity\nhas become the common denominator of all serious\ncrime, including mafia trafficking and terrorism. Typical approaches\nto detecting the use of false identity rely on the\nsimilarity measure of textual and other content-based characteristics,\nwhich are usually not applicable in the case of deceptive\nand erroneous description. This barrier can be overcome\nthrough link information presented in communication\nbehaviors, financial interactions and social networks. Quantitative\nlink-based similarity measures have proven effective\nfor identifying similar problems in the Internet and publication\ndomains. However, these numerical methods only concentrate\non link structures, and fail to achieve accurate and\ncoherent interpretation of the information. Inspired by this\nobservation, this paper presents a novel qualitative similarity\nmeasure that makes use of multiple link properties to refine\nthe underlying similarity estimation process and consequently\nderive semantic-rich similarity descriptors. The approach\nis based on order-of-magnitude reasoning. Its applicability\nand performance are experimentally evaluated over a\nterrorism-related dataset, and further generalized with publication\ndata.','False Identity Detection;;Outline;;Background (1);;Background (2);;Attributed Identity;;False Identity Detection (1);;False Identity Detection (2);;Link Analysis;;Uniqueness Measure (1);;Uniqueness Measure (2);;OM-based Model (1);;OM-based Model (2);;OM-based Model (3);;OM-based Model (4);;OM-based Model (5);;OM-based Model (6);;Homogenisation (1);;Homogenisation (2);;OM-based Model (7);;OM-based Model (8);;OM-based Model (9);;OM-based Model (10);;Terrorist Data;;Example Data;;OMS Performance (1);;OMS Performance (2);;OMS Performance (3);;OMS Performance (4);;OMS Performance (5);;Conclusion'
9034,'lecture','en',8830,'2009-06-24','2009-07-22','QCM: A QP-Based Concept Map System','Qualitative representations have proven to be useful\nformalisms for capturing human mental models. As a result,\nqualitative modeling could become an important tool for\ncognitive science. Specifically, an environment in which\nqualitative representations can be used to explore mental\nmodels and different type of reasoning and simulations can\nbe performed on these models can be a useful tool for\ncognitive scientists. In this paper, we introduce the\nQualitative Concept Map system, designed for cognitive\nscientists, for building and simulating qualitative and\nBayesian models using qualitative process theory and\nBayesian inference.','QCM: A QP-Based Concept Map System;;Agenda;;QR and Cognitive Science;;Qualitative Concept Map System (1);;Qualitative Concept Map System (2);;Qualitative Concept Map System (3);;QCM: QP Mode (1);;QCM: QP Mode (2);;Automatic Extraction of Domain Theory and Scenario files (1);;Automatic Extraction of Domain Theory and Scenario files (2);;The Food Web Experiment (2007);;Results of the Experiment;;Example Transcript;;A Sample Network;;Meta-Pane;;A Sample Network;;Example: Heat Transfer;;Example: Heat Transfer Domain Theory;;Bayesian Mode (1);;Bayesian Mode (2);;Determining a Priori Probabilities using Qualitative Simulations (1);;Determining a Priori Probabilities using Qualitative Simulations (2) ;;Example;;Related Work (1);;Related Work (2);;Conclusions;;Acknowledgments;;qr09_dehghani_qcm_01_Page_28;;qr09_dehghani_qcm_01_Page_29'
9035,'lecture','en',8830,'2009-06-24','2009-07-22','Qualitative approximation to Dynamic TimeWarping similarity between time series data','Dynamic time warping (DTW) is a method for calculating\nthe similarity between two time series which can\noccur at different times or speeds. Although its effectiveness\nmade it very popular in several disciplines, its\ntime complexity of O(N2) makes it useful only for\nrelatively short time series. In this paper, we propose\na qualitative approximation Qualitative Dynamic Time\nWarping (QDTW) to DTW. QDTW reduces a time series\nlength by transforming it to qualitative time series.\nDTW is later calculated between qualitative time series.\nAs qualitative time series are normally much shorter\nthan their corresponding numerical time series, time to\ncompute their similarity is significantly reduced. Experimental\nresults have shown improved running time of up\nto three orders of magnitude, while prediction accuracy\nonly slightly decreased.','Qualitative approximation to Dynamic Time Warping similarity between time\nseries data;;Dynamic Time Warping (1/4);;Dynamic Time Warping (2/4);;Dynamic Time Warping (3/4);;Dynamic Time Warping (4/4);;Improvements of Dynamic Time Warping;;QDTW (1/3);;QDTW (2/3);;QING;;QDTW (3/3);;Experimental Evaluation (1/3);;Experimental Evaluation (2/3);;Experimental Evaluation (3/3);;Conclusion;;Thank you'
9036,'lecture','en',8830,'2009-06-24','2009-07-22','A qualitative model of the salmon life cycle in the context of river rehabilitation','A qualitative model was developed in Garp3 to capture and\nformalise knowledge about river rehabilitation and the\nmanagement of an Atlantic salmon population. The model\nintegrates information about the ecology of the salmon life\ncycle, the environmental factors that may limit the survival\nof key life stages and links with human activities such as\nagriculture, habitat rehabilitation and fishing. The overall\naim of the model was to explore the effects of rehabilitation\nin the context of a complete life cycle scenario. The\nscenarios and simulations produced were able to explore\nthese processes in the context of a complete life cycle, but at\nthis scale the simulations were time consuming. Therefore,\nin addition to these scenarios a series of smaller\ndemonstrator scenarios were developed that succinctly\nexplored individual concepts within the system.','A Qualitative model of the salmon life cycle\n  in the context of sustainable river\n        rehabilitation;;Content;;NatureNet-Redime;;Garp3 Software;;Model Background;;Salmon populations in the River Trent;;Atlantic salmon - Salmo salar;;Schematic life cycle;;Human Impacts – habitat degradation;;Human Impacts - connectivity;;Salmon Conservation – life-cycle models;;Entities and Agents;;Life-cycle scenarios;;Life stage representation;;Mortality and survival;;Quantity spaces -\nSemi-quantitative information;;Recruitment (1);;Recruitment (2);;Survival – limiting factors;;Human activities – Habitat quality (1);;Human activities – Habitat quality (2);;Survival – Dynamic control;;Modelling Issues and Solutions;;Value/derivative behaviour of Potential (1);;Value/derivative behaviour of Potential (2);;Value/derivative behaviour of Potential (3);;Derivative behaviour of Difference (1);;Derivative behaviour of Difference (2);;Life-cycle scenarios (1);;Life-cycle scenarios (2);;qr09_noble_qms_01_Page_31;;qr09_noble_qms_01_Page_32;;qr09_noble_qms_01_Page_33;;Concept Scenarios (1);;Concept Scenarios (2);;Conclusions – modelling “fixes”;;Conclusions - Complexity (1);;Conclusions - Complexity (2) ;;DynaLearn;;Thank you'
9037,'lecture','en',8830,'2009-06-24','2009-07-22','Evaluating the potential of Qualitative Reasoning to capture and communicate knowledge on sustainable catchment management','This paper presents the potential use of Qualitative\nReasoning (QR) to capture and communicate knowledge on\nsustainable catchment management. Based on a case study,\nqualitative models dealing with issues of a sustainable\ndevelopment of riverine landscapes were developed and\nimplemented using the Garp3 software following a general\nmodeling framework. The evaluation of the models and the\nQR approach by students and experts revealed the high\npotential of QR models to capture and communicate\ncomplex knowledge in an understandable and interesting\nmanner, mainly due to the ability of the presented approach\nto capture qualitative system dynamics and integrate ‘hard’\nand ‘soft’ facts in a structured way. In the future a library of\nexpert models might serve as an important source of\ninformation for both, education and management.','Evaluating the potential of Qualitative Reasoning to capture and communicate knowledge on sustainable catchment management ;;Content;;The problem;;The question;;The target;;The need for a qualitative way of modelling ;;The (potential) way;;A potential solution – the GARP3 software ;;Testing the Garp3 software via case studies ;;The Kamp valley;;A modelling framework for building QR models was developed within the NNR project;;Initial orientation: Concept map capturing the Kamp valley system;;System selection;;Structural model:;;Global behaviour;;Sub-model „Stakeholder participation“;;Sub-model „Quality of development plans“;;Sub-model „Government action for SD“;;Sub-model „Community fear influences gv action rate for SD“;;Simulation path & value history;;Model evaluation;;Summary: the model building and simulation process;;Summary: general evaluation results;;Conclusions;;Thank you'
9038,'lecture','en',8830,'2009-06-24','2009-07-22','Assessing the Ecological Impacts of Agriculture Intensification Through Qualitative Reasoning','How to feed the world without loosing what is left of\nbiodiversity? Two answers for this question are found in the\nliterature. On the one hand, the “Land Sparing” paradigm\nsuggests that increasing yield by means of intensive agricultural\nsystems would fulfill the needs of human population and save\nnatural landscapes. On the other hand, “Biodiversity Friendly\nFarming” argues that agricultural intensification has deep impacts\non both biodiversity and ecosystem properties and suggests that\nnon-intensive farming practices keep the ecological balance and\nstill may produce large quantities of high quality food (food\nsecurity). This work presents a Qualitative Reasoning (QR) model\nthat compares the impacts of intensive and non-intensive\nagriculture on water resources, biodiversity and productivity. The\nsimulations show the inefficiency of intensive agriculture in\nprotecting water resources and biodiversity, and the efficiency of\nnon-intensive approach in terms of food production and\necosystem conservation.',NULL
9082,'invited talk','en',8751,'2009-06-06','2009-07-30','Learning in Hierarchical Architectures: from Neuroscience to Derived Kernels','Understanding the processing of information in our cortex is a significant part of understanding how the brain works, arguably one of the greatest problems in science today. In particular, our visual abilities are computationally amazing: computer science is still far from being able to create a vision engine that imitates them. Thus, visual cortex and the problem of the computations it performs may well be a good proxy for the rest of the cortex and for intelligence itself. \nI will briefly review our work on developing a hierarchical feedforward architecture for object recognition based on the anatomy and the physiology of the primate visual cortex. These architectures compete with state-of-the-art computer vision systems; they mimic human performance on a specific but difficult natural image recognition task. I will sketch current work aimed at extending the model to the recognition of behaviors in time sequences of images and to accounting for attentional effects inhuman vision. \nI will then describe a new attempt (with S. Smale, L. Rosasco and J. Bouvrie) to develop a mathematics for hierarchical kernel machines centered around the notion of a recursively defined \"derived kernel\" and directly suggested by the model and the underlying neuroscience of the visual cortex.','Learning in Hierarchical Architectures: from Neuroscience to Derived Kernels;;Message of today (1);;Message of today (2);;Learning in Hierarchical Architectures: from Neuroscience to Derived Kernels;;Today’s supervised learning algorithms: sample complexity problem and shallow architectures;;mlss09us_poggio_lhandk_Page_06;;Supervised learning;;mlss09us_poggio_lhandk_Page_08;;Classical learning theory and Kernel Machines (Regularization in RKHS) (1);;Classical learning theory and Kernel Machines (Regularization in RKHS) (2);;Present learning algorithms: “high” sample complexity and shallow architectures;;mlss09us_poggio_lhandk_Page_12;;Visual Cortex: hierarchical architecture, from neuroscience to a class of models;;The Ventral Stream (1);;The Ventral Stream (2);;The Ventral Stream (3);;mlss09us_poggio_lhandk_Page_17;;The Ventral Stream (4);;The Ventral Stream (6);;The Ventral Stream;;The Ventral Stream (7);;Model of Visual Recognition (millions of units) based on neuroscience of cortex (1);;Model of Visual Recognition (millions of units) based on neuroscience of cortex (2);;Two operations, one circuit? (1);;Instead of Gaussian, normalized dot product;;Two operations, one circuit? (2);;Learning: supervised and unsupervised (1);;Learning: supervised and unsupervised (2);;Physiology, psychophysics, computer vision;;Hierarchical feedforward models of the ventral stream (1);;Hierarchical feedforward models of the ventral stream (2);;Hierarchical feedforward models of the ventral stream (3);;Rapid Categorization;;Hierarchical feedforward models of the ventral stream (3);;Hierarchical feedforward models of the ventral stream (4);;Hierarchical feedforward models of the ventral stream (5);;mlss09us_poggio_lhandk_Page_37;;mlss09us_poggio_lhandk_Page_38;;Models suggest new architectures for learning;;Hierarchical feedforward models of visual cortex may be wrong;;Derived Kernels;;Plan;;The goal;;The visual cortex model;;An Architecture of Patches;;Images as Functions;;Transformations;;Templates;;mlss09us_poggio_lhandk_Page_49;;Recursive Definition (1);;Recursive Definition (2);;Plan;;Invariance;;Examples: Discrimination Results for 1-D strings;;Hierarchy can reduce sample complexity: empirical support;;Summary;;Extensions (video+attention) and limitations of feedforward hierarchical models;;Extension to motion: model of the dorsal stream;;From neuroscience to models: extension to attention (1);;From neuroscience to models: extension to attention (2);;From neuroscience to models: extension to attention (3);;From neuroscience to models: extension to attention (4);;Limitations of present feedforward hierarchical models;;Collaborators in recent work'
9083,'lecture','en',8751,'2009-06-06','2009-07-30','More Data Less Work: Runtime As A Monotonically Decreasing Function of Data Set Size','We are used to studying runtime as an increasing function of the data set size, and are happy when this increase is not so bad (e.g. when the runtime increases linearly, or even polynomiall, with the data set size). Traditional runtime analysis of learning is also viewed this way, and studies how training runtime increases as more data is available. However, considering the true objective of training, which is to obtain a good predictor, I will argue that training runtime should actually be studied as a *decreasing* function of training set size. Focusing on training Support Vector Machines (SVMs) and combining ideas from optimization, statistical learning theory, and online methods. I will then present both theoretical and empirical results demonstrating how a simple stochastic subgradient descent approach indeed displays such monotonic decreasing behavior. I will also discuss a similar phenomena in the context of Gaussian mixture clustering, where it appears that excess data turns the problem from computationally intractable to computationally tractable. Joint work with Shai Shalev-Shwartz, Karthik Sridharan, Yoram Singer, Greg Shakhnarovich and Sam Roweis.','More Data, Less Work;;Outline;;Large Margin Linear Classification aka L2-regularized Linear Classification aka Support Vector Machines (1);;Large Margin Linear Classification aka L2-regularized Linear Classification aka Support Vector Machines (2);;SVM Training as an Optimization Problem;;More Data ⇒ More Work?;;SVM Training;;Error Decomposition;;The Double-Edged Sword;;PEGASOS: Stochastic (sub-)Gradient Descent;;Training Time (in seconds);;Runtime Analyzis;;Dependence on Data Set Size (1);;Dependence on Data Set Size (2);;Dependence on Data Set Size (3);;Dependence on Data Set Size: Traditional Optimization Approaches (1);;Dependence on Data Set Size: Traditional Optimization Approaches (2);;Beyond PEGASOS;;Clustering (by fitting a Gaussian mixture model) (1);;Clustering (by fitting a Gaussian mixture model) (2);;Effect of “Signal Strength”;;Computational and Information Limits in Clustering;;Dependence on dimensionality ( d) and number of clusters (k);;Dependence on the cluster separation;;Conclusions from Empirical Study;;Hardness as a Function of Dataset Size;;mlss09us_srebro_mdlwrmdfdss_Page_27;;mlss09us_srebro_mdlwrmdfdss_Page_28;;mlss09us_srebro_mdlwrmdfdss_Page_29;;More Data ⇒ Less Work'
9084,'lecture','en',8751,'2009-06-06','2009-07-30','On Finding Low Error Clusterings','There has been substantial work on approximation algorithms for clustering data under distance-based objective functions such as k-median, k-means, and min-sum objectives. This work is fueled in part by the hope that approximating these objectives well will indeed yield more accurate solutions. That is, for problems such as clustering proteins by function, or clustering images by subject, there is some unknown correct \"target\" clustering and the implicit assumption is that clusterings that are approximately optimal in terms of these distance-based measures are also approximately correct in terms of error with respect to the target. In this work we show that if we make this implicit assumption explicit - that is, if we assume that any c-approximation to the given clustering objective Phi is epsilon-close to the target - then we can produce clusterings that are O(epsilon)-close to the target, even for values c for which obtaining a c-approximation is NP-hard. In particular, for the k-median, k-means, and min-sum objectives, we show that we can achieve this guarantee for any constant c > 1. Our results shows how for these clustering objectives one can get much better guarantees on accuracy than those implied by results obtained so far in the approximation literature, by wisely using all the available information for the problem at hand.','Finding Low Error Clusterings;;Approximate clustering without the approximation;;Clustering comes up everywhere;;Formal Clustering Setup (1);;Formal Clustering Setup (2);;Standard theoretical approach (1);;Standard theoretical approach (2);;Formal Clustering Setup, Our Perspective (1);;Formal Clustering Setup, Our Perspective (2);;Formal Clustering Setup, Our Perspective (3);;Note on the Standard Approx. Algos Approach;;Positive Results (1);;Positive Results (2);;How can we use the (c,) k-median property to cluster, without solving k-median?;;Clustering from (c,) k-median prop (1);;Clustering from (c,) k-median prop (2);;Clustering from (c,) k-median prop (3);;Clustering from (c,) k-median prop (4);;Clustering from (c,) k-median prop (5);;Clustering from (c,) k-median prop (6);;Clustering from (c,) k-median prop (7);;Clustering from (c,) k-median prop (8);;Clustering from (c,) k-median prop (9);;Clustering from (c,) k-median prop (10);;O()-close ! -close (1);;O()-close ! -close (2);;Technical issues… (1);;Technical issues… (2);;Extensions: The inductive setting;;(c,) k-means and min-sum properties;;(c,) property; summary;;Extensions: the (º,c,) k-median prop (1);;Extensions: the (º,c,) k-median prop (2);;Extensions: the (º,c,) k-median prop (3);;Extensions: the (º,c,) k-median prop (4);;Extensions: the (º,c,) k-median prop (5);;Extensions: the (º,c,) k-median prop (6);;(c,) Property: Open problems;;Clustering: More General Picture (1);;Clustering: More General Picture (2);;Clustering: More General Picture (3);;mlss09us_balcan_flec_Page_42;;mlss09us_balcan_flec_Page_43'
9085,'lecture','en',8751,'2009-06-06','2009-07-30','How to Visualize the Unseeable',NULL,NULL
9086,'tutorial','en',8751,'2009-06-08','2009-07-30','Analysis of Clustering Procedures','Clustering procedures are notoriously short on rigorous guarantees. In this tutorial, I will cover some of the types of analysis that have been applied to clustering, and emphasize open problems that remain. Part I. Approximation algorithms for clustering Two popular cost functions for clustering are k-center and k-means. Both are NP-hard to optimize exactly. (a) Algorithms for approximately optimizing these cost functions. (b) Hierarchical versions of such clusterings. (c) Clustering when data is arriving in a streaming or online manner. Part II. Analysis of popular heuristics (a) How good is k-means? How fast is it? (b) Probabilistic analysis of EM. (c) What approximation ratio is achieved by agglomerative heuristics for hierarchial clustering? Part III. Statistical theory in clustering What aspects of the underlying data distribution are captured by the clustering of a finite sample from that distribution? (a) Consistency of k-means. (b) The cluster tree and linkage algorithms. (c) Rates for vector quantization.','Analysis of clustering procedures;;Two types of clustering;;How is the data presented?;;Analysis of clustering procedures;;Outline of tutorial;;Part I: Approximation algorithms for clustering;;Two cost functions for quantization;;An algorithm for k-center;;A constant-factor approximation?;;Complexity of k-center (1);;An algorithm for k-means;;A constant-factor approximation;;Complexity of k-means (2);;Hierarchical clustering (1);;A basic existence problem;;Hierarchical k-center (2);;Hierarchical k-center (3);;Hierarchical clustering: open problems;;Clustering online/streaming data;;Online k-center;;Streaming algorithm for k-means –1 (1);;Streaming algorithm for k-means –1 (2);;Streaming algorithm for k-means –1 (3);;Part II: Analysis of popular heuristics;;The k-means algorithm;;The EM algorithm;;EM: what is known?;;EM: two styles of analysis;;How to initialize EM?;;EM for mixtures of spherical Gaussians;;Hierarchical agglomerative clustering;;Guarantees for agglomerative clustering;;Part III: Statistical theory in clustering;;Consistency of k-means;;The cluster tree (1);;The cluster tree (2);;Converging to the cluster tree;;mlss09us_dasgupta_acp_Page_38;;mlss09us_dasgupta_acp_Page_39;;mlss09us_dasgupta_acp_Page_40'
9087,'invited talk','en',8751,'2009-06-08','2009-07-30','The Stability of the Contour of an Orientable 2-Manifold','Think of the view of the boundary of a solid shape as a projection of a 2-manifold to R^2. Its apparent contour is the projection of the critical points. Generalizing the projection to smooth mappings of a 2-manifold to R^2, we get the contour as the image of the points at which the derivative is not surjective. Measuring difference with the erosion distance (the Hausdorff distance between the complements), we prove that the contour is stable. Along the way, we introduce the by now well established method of persistent homology, including the stability of its diagrams, as well as an extension using zigzag modules. Joint work with Dmitriy Morozov and Amit Patel. ','Stability of the Contour, Chicago 2009;;Stability of the Contour;;I Mappings, (II Persistence, III Stress);;The Contour (1);;The Contour (2);;The Contour (3);;The Contour (4);;The Contour (5);;The Contour (6);;The Contour (7);;A Perturbation (1);;A Perturbation (2);;A Perturbation (3);;A Perturbation (4);;Distance Function (1);;Distance Function (2);;Distance Function (3);;Distance Function (4);;Distance Function (5);;Genericity (1);;Genericity (2);;Genericity (3);;Genericity (4);;(I Mappings), II Persistence, (III Stress);;Filtration (1);;Filtration (2);;Filtration (3);;Filtration (4);;Filtration (5);;Filtration (6);;Filtration (7);;Persistence diagrams (1);;Persistence diagrams (2);;Persistence diagrams (3);;Persistence diagrams (4);;Bottleneck Stability (1);;Bottleneck Stability (2);;Bottleneck Stability (3);;Bottleneck Stability (4);;Bottleneck Stability (5);;Local Contour Stability (1);;Local Contour Stability (2);;Local Contour Stability (3);;Local Contour Stability (4);;Local Contour Stability (5);;Proof (1);;Proof (2);;Proof (3);;Proof (4);;Proof (5);;Proof (6);;Local Contour Stability;;(I Mappings), II Persistence), II Stress;;Degree (1);;Degree (2);;Degree (3);;Degree (4);;Degree (5);;Degree (6);;Degree (7);;Stress Function (1);;Stress Function (2);;Stress Function (3);;Stress Function (4);;Stress Function (5);;Stress Function (6);;Stress Function (7);;Stress Function (8);;Stress Function (9);;Stress Function (10);;Stress Function (11);;Erosion (1);;Erosion (2);;Erosion (3);;Erosion (4);;Global Contour Stability (1);;Global Contour Stability (2);;Global Contour Stability (3);;Global Contour Stability (4);;Thank you;;mlss09us_edelsbrunner_sco2m_01_Page_81'
9088,'lecture','en',8751,'2009-06-08','2009-07-30','On a Theory of Similarity Functions for Learning and Clustering ','Kernel methods have become powerful tools in machine learning. They perform well in many applications, and there is also a well-developed theory of what makes a given kernel useful for a given learning problem. However, this theory requires viewing kernels as implicit (and often difficult to characterize) maps into high-dimensional spaces. In this talk I will describe work on developing a theory that just views a kernel as a measure of similarity between data objects, and describes the usefulness of a given kernel (or more general similarity function) in terms of fairly intuitive, direct properties of how the similarity function relates to the task at hand, without need to refer to any implicit spaces. I will also talk about an extension of this framework to learning from purely unlabeled data, i.e., clustering. In particular, one can ask how much stronger the properties of a similarity function should be (in terms of its relation to the unknown desired clustering) so that it can be used to cluster well: to learn well without any label information at all. We find that if we are willing to relax the objective a bit (for example, allow the algorithm to produce a hierarchical clustering that we will call successful if some pruning is close to the desired clustering), then this question leads to a number of interesting graph-theoretic and game-theoretic properties that are sufficient to cluster well. This work can be viewed defining a kind of PAC model for clustering. (This talk based on work joint with Maria-Florina Balcan, Santosh Vempala, and Nati Srebro). ','On a Theory of Similarity functions for Learning and Clustering;;2-minute version (1);;2-minute version (2);;2-minute version (3);;Part 1: On similarity functions for learning;;Theme of this part;;Kernels;;Example;;Moreover, generalize well if good Margin;;Limitations of the Current Theory;;A notion of a good similarity function that is;;A First Attempt (1);;A First Attempt (2);;A First Attempt (3);;A First Attempt: Not Broad Enough (1);;A First Attempt: Not Broad Enough (2);;Broader Definition (1);;Broader Definition (2);;Kernels and Similarity Functions (1);;Kernels and Similarity Functions (2);;Kernels and Similarity Functions (3);;Learning with Multiple Similarity Functions (1);;Learning with Multiple Similarity Functions (2);;Learning with Multiple Similarity Functions (3);;Learning with Multiple Similarity Functions (4);;Part 2: Can we use this angle to help think about clustering?;;Clustering comes up in many places;;Can model clustering like this;;What conditions on a similarity measure would be enough to allow one to cluster well? (1);;What conditions on a similarity measure would be enough to allow one to cluster well? (2);;What conditions on a similarity measure would be enough to allow one to cluster well? (3);;What conditions on a similarity measure would be enough to allow one to cluster well? (4);;What conditions on a similarity measure would be enough to allow one to cluster well? (5);;Let’s weaken our goals a bit…;;Then you can start getting somewhere…. (1);;Then you can start getting somewhere…. (2);;Analysis for slightly simpler version (1);;Analysis for slightly simpler version (2);;More sufficient properties (1);;More sufficient properties (2);;Can also analyze inductive setting;;Like a PAC model for clustering;;Summary (part II);;Wrap-up'
9089,'lecture','en',8751,'2009-06-08','2009-07-30','A Bahadur Type Representation of the Linear Support Vector Machine and its Relative Efficiency','The support vector machine has been used successfully in a variety of applications. Also on the theoretical front, its statistical properties including Bayes risk consistency have been examined rather extensively. Taking another look at the method, we investigate the asymptotic behavior of the linear support vector machine through Bahadur type representation of the coefficients established under appropriate conditions. Their asymptotic normality and statistical variability are derived on the basis of the representation. Furthermore, direct theoretical comparison is made with likelihood based approach to classification such as linear discriminant analysis and logistic regression in terms of the asymptotic relative efficiency, where the efficiency of a classification procedure is defined using the excess risk from the Bayes risk.','A Bahadur Type Representation of the Linear Support Vector Machine and its Relative Efficiency;;Outline;;Applications;;Classification;;Methods of Regularization (Penalization);;Maximum Margin Hyperplane;;Support Vector Machines;;Hinge Loss;;SVM in General;;Statistical Properties of SVM;;Main Questions;;Something New, Old, and Borrowed;;Preliminaries;;Population Version;;More on H();;Regularity Conditions;;Bahadur Representation;;Bahadur-type Representation of the Linear SVM;;Asymptotic Normality of bλ,n;;An Illustrative Example;;Example (1);;Example (2);;Distance and Margin;;Asymptotic Variance;;A Bivariate Normal Example;;Sampling Distributions of ˆ 0 and ˆ 1;;Type I Error Rates;;Excess Error;;Relative Efficiency;;Asymptotic Relative Efficiencies of SVM to LDA;;A Mixture of Two Gaussian Distributions;;As W Varies;;As B Varies;;As Dimension d Varies;;Concluding Remarks;;Reference'
9090,'lecture','en',8751,'2009-06-08','2009-07-30','Fitting a Graph to Vector Data ','We ask \"What is the right graph to fit to a set of vectors?\" We propose one solution that provides good answers to standard Machine Learning problems, that has interesting combinatorial properties, and that we can compute efficiently. Joint work with Jonathan Kelner and Samuel Daitch.','Fitting a Graph to Vector Data;;Find a natural weighted graph on V = {1, …, n} that is;;Helps solve TCS problems on the vectors;;Outline;;Standard ways to make graphs;;Our first proposal (1);;Our first proposal (2);;Motivation (1);;Motivation (2);;Motivation (3);;Motivation (4);;Motivation, tricky example (1);;Motivation, tricky example (2);;Motivation, tricky example (3);;Motivation, tricky example (4);;Motivation, tricky example (5);;Motivation, fixing bad example (1);;Motivation, fixing bad example (2);;Example (1);;Example (2);;Example (3);;Unique?;;Related to;;In terms of the graph Laplacian (1);;In terms of the graph Laplacian (2);;Sparse Solution;;Sparsity;;Degrees on real data (1);;Degrees on real data (2);;Example for which graphs are not unique;;Planarity (1);;Planarity (2);;Planarity, proof (1);;Planarity, proof (2);;Classification and Regression Experiments;;Classification Experiments (1);;Classification Experiments (2);;Classification Experiments (3);;Regression Error;;Clustering Experiments (0.1-soft) (1);;Clustering Experiments (0.1-soft) (2);;Choosing number vectors for spectral;;Quadratic Program for Edge Weights;;Objective function is quadratic;;Soft graph program (1);;Soft graph program (2);;Soft graph program, as NNLSQ;;Computing Soft graph quickly;;Computation Time (secs);;Approximate Sparse Solutions (1);;Approximate Sparse Solutions (2);;Sparsification (1);;Sparsification (2);;Lovasz’s Graphs;;Open Questions'
9091,'tutorial','en',8751,'2009-06-09','2009-07-30','An Overview of Compressed Sensing and Sparse Signal Recovery via L1 Minimization','In many applications, one often has fewer equations than unknowns. While this seems hopeless, the premise that the object we wish to recover is sparse or nearly sparse radically changes the problem, making the search for solutions feasible. This lecture will introduce sparsity as a key modeling tool together with a series of little miracles touching on many areas of data processing. These examples show that finding *that* solution to an underdetermined system of linear equations with minimum L1 norm, often returns the \'\'right\'\' answer. Further, there is by now a well-established body of work going by the name of compressed sensing, which asserts that one can exploit sparsity or compressibility when acquiring signals of general interest, and that one can design nonadaptive sampling techniques that condense the information in a compressible signal into a small amount of data - in fewer data points than were thought necessary. We will survey some of these theories and trace back some of their origins to early work done in the 50\'s. Because these theories are broadly applicable in nature, the tutorial will move through several applications areas that may be impacted such as signal processing, bio-medical imaging, machine learning and so on. Finally, we will discuss how these theories and methods have far reaching implications for sensor design and other types of designs.',NULL
9092,'invited talk','en',8751,'2009-06-09','2009-07-30','Spectral Graph Theory, Linear Solvers and Applications ','We discuss the development of combinatorial methods for solving symmetric diagonally dominate linear systems. Over the last fifteen years the computer science community has made substantial progress in fast solvers for SDD systems. For general SDD systems the upper bound is $0(m \\log^k n)$ for some constant $k$, where $m$ is the number of non-zero entries, due to Spielman and Teng. Newer methods, combinatorial multigrid, have linear time guarantee for the planar case and work very well in practice. Critical to the use of these new solvers has been the reduction of problems to the solution of SDD systems. We present some of these reductions, including several from image processing.','mlss09us_miller_sgtlsa_01_Page_001;;mlss09us_miller_sgtlsa_01_Page_002;;mlss09us_miller_sgtlsa_01_Page_003;;mlss09us_miller_sgtlsa_01_Page_004;;mlss09us_miller_sgtlsa_01_Page_005;;mlss09us_miller_sgtlsa_01_Page_006;;mlss09us_miller_sgtlsa_01_Page_007;;mlss09us_miller_sgtlsa_01_Page_008;;mlss09us_miller_sgtlsa_01_Page_009;;mlss09us_miller_sgtlsa_01_Page_010;;mlss09us_miller_sgtlsa_01_Page_011;;mlss09us_miller_sgtlsa_01_Page_012;;mlss09us_miller_sgtlsa_01_Page_013;;mlss09us_miller_sgtlsa_01_Page_014;;mlss09us_miller_sgtlsa_01_Page_015;;mlss09us_miller_sgtlsa_01_Page_016;;mlss09us_miller_sgtlsa_01_Page_017;;mlss09us_miller_sgtlsa_01_Page_018;;mlss09us_miller_sgtlsa_01_Page_019;;mlss09us_miller_sgtlsa_01_Page_020;;mlss09us_miller_sgtlsa_01_Page_021;;mlss09us_miller_sgtlsa_01_Page_022;;mlss09us_miller_sgtlsa_01_Page_023;;mlss09us_miller_sgtlsa_01_Page_024;;mlss09us_miller_sgtlsa_01_Page_025;;mlss09us_miller_sgtlsa_01_Page_026;;mlss09us_miller_sgtlsa_01_Page_027;;mlss09us_miller_sgtlsa_01_Page_028;;mlss09us_miller_sgtlsa_01_Page_029;;mlss09us_miller_sgtlsa_01_Page_030;;mlss09us_miller_sgtlsa_01_Page_031;;mlss09us_miller_sgtlsa_01_Page_032;;mlss09us_miller_sgtlsa_01_Page_033;;mlss09us_miller_sgtlsa_01_Page_034;;mlss09us_miller_sgtlsa_01_Page_035;;mlss09us_miller_sgtlsa_01_Page_036;;mlss09us_miller_sgtlsa_01_Page_037;;mlss09us_miller_sgtlsa_01_Page_038;;mlss09us_miller_sgtlsa_01_Page_039;;mlss09us_miller_sgtlsa_01_Page_040;;mlss09us_miller_sgtlsa_01_Page_041;;mlss09us_miller_sgtlsa_01_Page_042;;mlss09us_miller_sgtlsa_01_Page_043;;mlss09us_miller_sgtlsa_01_Page_044;;mlss09us_miller_sgtlsa_01_Page_045;;mlss09us_miller_sgtlsa_01_Page_046;;mlss09us_miller_sgtlsa_01_Page_047;;mlss09us_miller_sgtlsa_01_Page_048;;mlss09us_miller_sgtlsa_01_Page_049;;mlss09us_miller_sgtlsa_01_Page_050;;mlss09us_miller_sgtlsa_01_Page_051;;mlss09us_miller_sgtlsa_01_Page_052;;mlss09us_miller_sgtlsa_01_Page_053;;mlss09us_miller_sgtlsa_01_Page_054;;mlss09us_miller_sgtlsa_01_Page_055;;mlss09us_miller_sgtlsa_01_Page_056;;mlss09us_miller_sgtlsa_01_Page_057;;mlss09us_miller_sgtlsa_01_Page_058;;mlss09us_miller_sgtlsa_01_Page_059;;mlss09us_miller_sgtlsa_01_Page_060;;mlss09us_miller_sgtlsa_01_Page_061;;mlss09us_miller_sgtlsa_01_Page_062;;mlss09us_miller_sgtlsa_01_Page_063;;mlss09us_miller_sgtlsa_01_Page_064;;mlss09us_miller_sgtlsa_01_Page_065;;mlss09us_miller_sgtlsa_01_Page_066;;mlss09us_miller_sgtlsa_01_Page_067;;mlss09us_miller_sgtlsa_01_Page_068;;mlss09us_miller_sgtlsa_01_Page_069;;mlss09us_miller_sgtlsa_01_Page_070;;mlss09us_miller_sgtlsa_01_Page_071;;mlss09us_miller_sgtlsa_01_Page_072;;mlss09us_miller_sgtlsa_01_Page_073;;mlss09us_miller_sgtlsa_01_Page_074;;mlss09us_miller_sgtlsa_01_Page_075;;mlss09us_miller_sgtlsa_01_Page_076;;mlss09us_miller_sgtlsa_01_Page_077;;mlss09us_miller_sgtlsa_01_Page_078;;mlss09us_miller_sgtlsa_01_Page_079;;mlss09us_miller_sgtlsa_01_Page_080;;mlss09us_miller_sgtlsa_01_Page_081;;mlss09us_miller_sgtlsa_01_Page_082;;mlss09us_miller_sgtlsa_01_Page_083;;mlss09us_miller_sgtlsa_01_Page_084;;mlss09us_miller_sgtlsa_01_Page_085;;mlss09us_miller_sgtlsa_01_Page_086;;mlss09us_miller_sgtlsa_01_Page_087;;mlss09us_miller_sgtlsa_01_Page_088;;mlss09us_miller_sgtlsa_01_Page_089;;mlss09us_miller_sgtlsa_01_Page_090;;mlss09us_miller_sgtlsa_01_Page_091;;mlss09us_miller_sgtlsa_01_Page_092;;mlss09us_miller_sgtlsa_01_Page_093;;mlss09us_miller_sgtlsa_01_Page_094;;mlss09us_miller_sgtlsa_01_Page_095;;mlss09us_miller_sgtlsa_01_Page_096;;mlss09us_miller_sgtlsa_01_Page_097;;mlss09us_miller_sgtlsa_01_Page_098;;mlss09us_miller_sgtlsa_01_Page_099;;mlss09us_miller_sgtlsa_01_Page_100;;mlss09us_miller_sgtlsa_01_Page_101;;mlss09us_miller_sgtlsa_01_Page_102;;mlss09us_miller_sgtlsa_01_Page_103;;mlss09us_miller_sgtlsa_01_Page_104;;mlss09us_miller_sgtlsa_01_Page_105;;mlss09us_miller_sgtlsa_01_Page_106;;mlss09us_miller_sgtlsa_01_Page_107;;mlss09us_miller_sgtlsa_01_Page_108;;mlss09us_miller_sgtlsa_01_Page_109;;mlss09us_miller_sgtlsa_01_Page_110;;mlss09us_miller_sgtlsa_01_Page_111;;mlss09us_miller_sgtlsa_01_Page_112;;mlss09us_miller_sgtlsa_01_Page_113;;mlss09us_miller_sgtlsa_01_Page_114;;mlss09us_miller_sgtlsa_01_Page_115;;mlss09us_miller_sgtlsa_01_Page_116;;mlss09us_miller_sgtlsa_01_Page_117;;mlss09us_miller_sgtlsa_01_Page_118;;mlss09us_miller_sgtlsa_01_Page_119;;mlss09us_miller_sgtlsa_01_Page_120;;mlss09us_miller_sgtlsa_01_Page_121;;mlss09us_miller_sgtlsa_01_Page_122;;mlss09us_miller_sgtlsa_01_Page_123;;mlss09us_miller_sgtlsa_01_Page_124;;mlss09us_miller_sgtlsa_01_Page_125;;mlss09us_miller_sgtlsa_01_Page_126;;mlss09us_miller_sgtlsa_01_Page_127;;mlss09us_miller_sgtlsa_01_Page_128;;mlss09us_miller_sgtlsa_01_Page_129;;mlss09us_miller_sgtlsa_01_Page_130;;mlss09us_miller_sgtlsa_01_Page_131;;mlss09us_miller_sgtlsa_01_Page_132;;mlss09us_miller_sgtlsa_01_Page_133;;mlss09us_miller_sgtlsa_01_Page_134;;Spectral Graph Theory, Linear Solvers, and Applications;;Linear Systems;;Matrix Form;;Solving the General Case (1);;Solving the General Case (2);;An Easy Case (1);;An Easy Case (2);;An Easy Case (3);;Symmetric Matrices (1);;Symmetric Matrices (2);;Direct Methods Gaussian Elimination Matrices (1);;Direct Methods Gaussian Elimination Matrices (2);;Pivoting (1);;Pivoting (2);;Pivoting (2) ;;Pivoting (3);;Good Pivot Strategies (1);;Good Pivot Strategies (2);;Good Pivot Strategies (3);;Pure Iterative Methods (1);;Pure Iterative Methods (2);;Pure Iterative Methods (3);;Pure Iterative Methods (4);;Preconditioned Iterative Methods (1);;Preconditioned Iterative Methods (2);;Preconditioned Iterative Methods (3);;Classic Preconditioners (1);;Classic Preconditioners (2);;Classic Preconditioners (3);;Classic Preconditioners (4);;Graph Laplacian (1);;Graph Laplacian (2);;Graph Laplacian (3);;Graph Laplacian (4);;Graph Laplacian (5);;Classic Applications of the Laplacian (1);;Classic Applications of the Laplacian (2);;Classic Applications of the Laplacian (3);;Graph Laplacian’s and the Heat Equations;;Graph Laplacian’s and Random Walks;;Laplacian’s and Spring Mass Systems (1);;Laplacian’s and Spring Mass Systems (2);;Laplacian’s and Spring Mass Systems (3);;Spring Mass Systems;;Graph Laplacian’s and Maximum Flow;;Graph Laplacian’s and Convex Programming;;Spanning Tree Preconditioners (1);;Spanning Tree Preconditioners (2);;Spanning Tree Preconditioners (3);;Low Stretch Spanning Trees (1);;Low Stretch Spanning Trees (2);;Low Stretch Spanning Trees (3);;Low Stretch Spanning Trees (4);;Steiner Tree Preconditioners (1);;Steiner Tree Preconditioners (2);;Steiner Tree Preconditioners (3);;Steiner Tree Preconditioners (4);;Steiner Forest Preconditioners (1);;Steiner Forest Preconditioners (2);;Steiner Forest Preconditioners (3);;Steiner Forest Preconditioners (4);;Recursive Methods (1);;Recursive Methods (2);;The Error (1);;The Error (2);;The Error (3);;The Error (4);;Condition Number (1);;Condition Number (2);;Condition Number (3);;Condition Number (4);;Convergence Rates (1);;Convergence Rates (2);;Convergence Rates (3);;Generalized Condition Number (1);;Generalized Condition Number (2);;Generalized Condition Number (3);;Generalized Condition Number (4);;The Support (1);;The Support (2);;The Support (3);;Estimating Support ;;Estimating Support Example;;History of Planar Solvers (1);;History of Planar Solvers (2);;History of Planar Solvers (3);;History of Planar Solvers (4);;History of Planar Solvers (6);;General Laplacian Solver (1);;General Laplacian Solver (2);;General Laplacian Solver (3);;Symmetric Diagonally Dominate Systems (1);;Symmetric Diagonally Dominate Systems (2) ;;Symmetric Diagonally Dominate Systems (3);;Symmetric Diagonally Dominate Systems (4);;Symmetric Diagonally Dominate Systems (4);;Symmetric Diagonally Dominate Systems (5);;Basic Properties: Generalized Laplacian (1);;Basic Properties: Generalized Laplacian (2);;Basic Properties: Generalized Laplacian (3);;Solving Generalized Laplacian by Change of Variables (1);;Solving Generalized Laplacian by Change of Variables (2);;Solving Generalized Laplacian by Change of Variables (3);;Generalized Laplacians Example;;Change of Variables for Laplacians;;Orientable Generalized Laplacians (1);;Orientable Generalized Laplacians (2);;Orientable Generalized Laplacians (3);;Orientable Generalized Laplacians (4);;Orientable Generalized Laplacians (5);;Orientable Generalized Laplacians (6);;Orientable Generalized Laplacians (7);;Two-Fold Covers (1);;Two-Fold Covers (2);;Two-Fold Covers (3);;Two-Fold Covers (4);;Example: Two-Fold Cover;;Two-Fold Covers and Solving Generalized Laplacians (1);;Two-Fold Covers and Solving Generalized Laplacians (2);;Two-Fold Covers and Solving Generalized Laplacians (3);;Two-Fold Covers and Solving Generalized Laplacians (4);;SDD systems (1);;SDD systems (2);;SDD systems (3);;Spectral Graph Partitioning;;mlss09us_miller_sgtlsa_01_Page_126;;mlss09us_miller_sgtlsa_01_Page_127;;mlss09us_miller_sgtlsa_01_Page_128;;mlss09us_miller_sgtlsa_01_Page_129;;mlss09us_miller_sgtlsa_01_Page_130;;mlss09us_miller_sgtlsa_01_Page_131;;mlss09us_miller_sgtlsa_01_Page_132;;mlss09us_miller_sgtlsa_01_Page_133;;Open Questions'
9093,'lecture','en',8751,'2009-06-09','2009-07-30','Cheeger Cuts and p-Spectral Clustering','Spectral clustering has become in recent years one of the most popular clustering algorithm. In this talk I discuss a generalized version of spectral clustering based on the second eigenvector of the graph p-Laplacian, a non-linear generalization of the graph Laplacian. The clustering obtained for 1<=2 can be seen as an interpolation of the relaxation of the normalized cut (p=2) and the Cheeger cut (p=1). However, the main motivation for p-spectral clustering is the fact, that one can show that the cut value obtained by thresholding the second eigenvector of the p-Laplacian converges towards the optimal Cheeger cut as p tends to 1. I will also present an efficient implementation which allows to do p-spectral clustering for large scale datasets.','Cheeger Cuts and p-Spectral Clustering;;Roadmap;;Graph-based methods (1);;Graph-based methods (2);;Graph-based methods;;How to construct similarity graphs;;Illustration of different neighborhood graph types;;Clustering;;Normalized cut (1);;Normalized cut (2);;Limit of the normalized cut;;Limit of the normalized cut II;;Limit of the normalized cut III;;Discussion (1);;Discussion (2);;The graph Laplacian;;Relaxation of ratio cut;;Isoperimetric inequality;;The graph p-Laplacian;;Eigenvalues and eigenvectors of the p-Laplacian (1);;Eigenvalues and eigenvectors of the p-Laplacian (2);;Theoretical Motivation for p-Spectral Clustering;;Theoretical Motivation for p-Spectral Clustering II;;How to minimize F;;Experimental setting;;Experimental results - High-dimensional toy data;;How stable is the result ?;;Experimental results - USPS and MNIST;;Experimental results - USPS and MNIST;;Summary'
9094,'lecture','en',8751,'2009-06-09','2009-07-30','Multiscale Geometry and Harmonic Analysis of Data Bases ','We describe a method for geometrization of databases such as, questionnaires, or lists of sensor outputs. Interlacing multiscale diffusion geometries of rows and columns of a data matrix, results in a pair of language ontologies which are mutually supportive (certain words are used in certain contexts). This mutual geometry serves a structure of Harmonic Analysis and signal processing on the database. We will illustrate, on databases of audio (music), psychological questionnaires, science documents, images and many others. Joint work with Mata Gavish, Yale University.','Multiscale Analysis of Digital Data Bases (Matrices);;Goal (1);;Consider the problem;;Describing (1);;Describing (2);;Describing (3);;Describing (4);;Describing (5);;Describing (6);;Describing ( 7);;Describing (7);;A similar organization in the vocabulary of a body of Science (1);;A similar organization in the vocabulary of a body of Science (2);;A similar organization in the vocabulary of a body of Science (3);;A similar organization in the vocabulary of a body of Science (4);;A similar organization in the vocabulary of a body of Science (5);;A similar organization in the vocabulary of a body of Science (6);;A similar organization in the vocabulary of a body of Science (7);;A similar organization in the vocabulary of a body of Science (8);;Multiscale Geometric Analysis on Digital data clouds (1);;Multiscale Geometric Analysis on Digital data clouds (2);;Multiscale Geometric Analysis on Digital data clouds (3);;Diffusion Geometry (1);;Diffusion Geometryc (2);;Another similar construction for empirical data (1);;Another similar construction for empirical data (2);;Another similar construction for empirical data (3);;Another similar construction for empirical data (4);;Another similar construction for empirical data (5);;Another similar construction for empirical data (6);;Another similar construction for empirical data (7);;Another similar construction for empirical data (8);;Another similar construction for empirical data (9);;Another similar construction for empirical data (9);;Another similar construction for empirical data (11);;Another similar construction for empirical data (12);;Another similar construction for empirical data (13);;Another similar construction for empirical data (14);;Another similar construction for empirical data (15);;Another similar construction for empirical data (16);;Another similar construction for empirical data (17);;mlss09us_coifman_mghadb_01_Page_42'
9095,'lecture','en',8751,'2009-06-09','2009-07-30','Graphical Models for Speech Recognition: Articulatory and Audio-Visual Models','Since the 1980s, the main approach to automatic speech recognition has been using hidden Markov models (HMMs), in which each state corresponds to a phoneme or part of a phoneme in the context of the neighboring phonemes. Despite their crude approximation of the speech signal, and the large margin for improvement still remaining, HMMs have proven difficult to beat. In the last few years, there has been increasing interest in more complex graphical models for speech recognition, involving multiple streams of states. I will describe two such approaches, one modeling pronunciation variation as the result of the \"sloppy\" behavior of articulatory variables (the states of the lips, tongue, etc.) and the other modeling the audio and visual states in audio-visual speech recognition (i.e. recognition enhanced by \"lipreading\"). \n\n',NULL
9096,'tutorial','en',8751,'2009-06-10','2009-07-30','Semi-Supervised Learning','This tutorial covers classification approaches that utilize both labeled and unlabeled data. We will review self-training, Gaussian mixture models, co-training, multiview learning, graph-transduction and manifold regularization, transductive SVMs, and a PAC bound for semi-supervised learning. We then discuss some new development, including online semi-supervised learning, multi-manifold learning, and human semi-supervised learning. ','Tutorial on Semi-Supervised Learning;;New book;;Outline;;mlss09us_zhu_ssl_Page_004;;mlss09us_zhu_ssl_Page_005;;What is Semi-Supervised Learning? (1);;What is Semi-Supervised Learning? (2);;What is Semi-Supervised Learning? (3);;Motivations (1);;Motivations (2);;Example of hard-to-get labels;;Another example of hard-to-get labels;;Notations;;Semi-supervised vs. transductive learning (1);;Semi-supervised vs. transductive learning (2);;How can unlabeled data ever help? (1);;How can unlabeled data ever help? (2);;Self-training algorithm (1);;Self-training algorithm (2);;Self-training algorithm (3);;Self-training example: Propagating 1-Nearest-Neighbor;;Propagating 1-Nearest-Neighbor: now it works;;Propagating 1-Nearest-Neighbor: now it doesn’t;;Outline (2);;A simple example of generative models (1);;A simple example of generative models (2);;A simple example of generative models (3);;A simple example of generative models (4);;A simple example of generative models (5);;A simple example of generative models (6);;Generative model for semi-supervised learning (1);;Generative model for semi-supervised learning (2);;Generative model for semi-supervised learning (3);;Case study: GMM (1);;Case study: GMM (2);;The EM algorithm for GMM (1);;The EM algorithm for GMM (2);;The EM algorithm for GMM (3);;The EM algorithm for GMM (4);;The assumption of mixture models (1);;The assumption of mixture models (2);;The assumption of mixture models (3);;The assumption of mixture models (4);;The assumption of mixture models (5);;The assumption of mixture models (6);;Related: cluster-and-label (1);;Related: cluster-and-label (2);;Related: cluster-and-label (3);;Related: cluster-and-label (4);;Related: cluster-and-label (5);;Related: cluster-and-label (6);;Cluster-and-label: now it works, now it doesn’t (1);;Cluster-and-label: now it works, now it doesn’t (2);;Cluster-and-label: now it works, now it doesn’t (3);;Cluster-and-label: now it works, now it doesn’t (3);;Outline (3);;Two Views of an Instance (1);;Two Views of an Instance (2);;Quiz (1);;Quiz (2);;Co-training algorithm (1);;Co-training algorithm (2);;Co-training algorithm (3);;Co-training algorithm (4);;Co-training algorithm (5);;Co-training assumptions (1);;Co-training assumptions (2);;Co-training assumptions (3);;Multiview learning (1);;Multiview learning (2);;Multiview learning (3);;Multiview learning (4);;Multiview learning (5);;Outline (4);;Example: text classification;;When labeled data alone fails;;Unlabeled data as stepping stones;;Another example;;Graph-based semi-supervised learning (1);;Graph-based semi-supervised learning (2);;Graph-based semi-supervised learning (3);;Graph-based semi-supervised learning (4);;Graph-based semi-supervised learning (5);;The mincut algorithm (1);;The mincut algorithm (2) ;;The mincut algorithm (3);;The mincut algorithm (4);;The harmonic function (1);;The harmonic function (2);;The harmonic function (3);;The harmonic function (4);;An electric network interpretation;;A random walk interpretation;;An algorithm to compute harmonic function (1);;An algorithm to compute harmonic function (2);;The graph Laplacian;;Harmonic solution with Laplacian (1);;Harmonic solution with Laplacian (2);;Harmonic solution with Laplacian (3);;Harmonic solution with Laplacian (4);;Local and Global consistency ;;Manifold regularization;;Graph spectrum and SSL (1);;Graph spectrum and SSL (2);;Graph spectrum and SSL (3);;Graph spectrum and SSL (4);;Graph spectrum and SSL (5);;Graph spectrum and SSL (6);;Example graph spectrum;;When the graph assumption is wrong (1);;When the graph assumption is wrong (2);;Outline (5);;Semi-supervised Support Vector Machines (1);;Semi-supervised Support Vector Machines (2);;Standard soft margin SVMs (1);;Standard soft margin SVMs (2);;The S3VM objective function (1);;The S3VM objective function (2);;The S3VM objective function (3);;The hat loss on unlabeled data (1);;The hat loss on unlabeled data (2);;The hat loss on unlabeled data (3);;The hat loss on unlabeled data (4);;The S3VM algorithm (1);;The S3VM algorithm (2);;The S3VM algorithm (3);;Logistic regression (1);;Logistic regression (2);;Logistic regression (3);;Logistic regression (4);;Logistic regression (5);;Logistic regression (6);;Entropy regularization (1);;Entropy regularization (2);;Entropy regularization (3);;Entropy regularization (4);;Entropy regularization (5);;When the large margin assumption is wrong;;mlss09us_zhu_ssl_Page_139;;Outline (6);;SSL does not always help;;A computational theory for SSL (1);;A computational theory for SSL (2);;A computational theory for SSL (3);;A computational theory for SSL (4);;A computational theory for SSL (5);;PAC bound for SL (1);;PAC bound for SL (2);;PAC bound for SL (3);;PAC bound for SL (4);;PAC bound for SL (5);;PAC bound for SL (6);;PAC bound for SL (7);;PAC bound for SL (8);;PAC bound for SL (9);;PAC bound for SL (10);;PAC bound for SL (11);;Simple sample complexity for SL;;PAC bound for SSL (1);;PAC bound for SSL (2);;PAC bound for SSL (3);;PAC bound for SSL (4);;PAC bound for SSL (4);;PAC bound for SSL (5);;PAC bound for SSL (6);;PAC bound for SSL (7);;PAC bound for SSL (8);;Discussions on the PAC bound for SSL (1);;Discussions on the PAC bound for SSL (2);;Discussions on the PAC bound for SSL (3);;Discussions on the PAC bound for SSL (4);;Outline (7);;Life-long learning;;This is how children learn, too;;New paradigm: online semi-supervised learning (1);;New paradigm: online semi-supervised learning (2);;New paradigm: online semi-supervised learning (3);;New paradigm: online semi-supervised learning (4);;Online manifold regularization (1);;Online manifold regularization (2);;Online manifold regularization (3);;Online convex programming (1);;Online convex programming (2);;Online convex programming (3);;Online convex programming (4);;Online convex programming (5);;Sparse approximation by buffering (1);;Sparse approximation by buffering (2);;Sparse approximation by buffering (4);;mlss09us_zhu_ssl_Page_190;;Outline (8);;Multiple, intersecting manifolds;;Building Blocks: Local Covariance Matrix;;A Distance on Covariance Matrices (1);;A Distance on Covariance Matrices (2);;A Distance on Covariance Matrices (3);;Hellinger Distance (1);;Hellinger Distance (2);;Hellinger Distance (3);;Hellinger Distance (4);;A Sparse Graph (1);;A Sparse Graph (2);;A Sparse Graph (3);;Outline (9);;Do we learn from both labeled and unlabeled data? (1);;Do we learn from both labeled and unlabeled data? (2);;Zaki & Nosofsky 2007: self training? (1);;Zaki & Nosofsky 2007: self training? (2);;Zaki & Nosofsky 2007: self training? (3);;Zaki & Nosofsky 2007: self training? (4);;Zaki & Nosofsky 2007: self training? (5);;The Zaki & Nosofsky 2007 experiment (1);;The Zaki & Nosofsky 2007 experiment (2);;The Zaki & Nosofsky 2007 experiment (3);;Zhu et al. 2007: mixture model? (1);;Zhu et al. 2007: mixture model? (2);;Zhu et al. 2007: mixture model? (3);;Zhu et al. 2007: mixture model? (4);;Zhu et al. 2007: mixture model? (5);;Zhu et al. 2007: mixture model? (6);;Visual stimuli;;Observation 1: unlabeled data affects decision boundary (1);;mlss09us_zhu_ssl_Page_223;;mlss09us_zhu_ssl_Page_224;;Model fitting;;References'
9097,'invited talk','en',8751,'2009-06-10','2009-07-30','Matrix Completion via Convex Optimization: Theory and Algorithms','This talk considers a problem of considerable practical interest: the recovery of a data matrix from a sampling of its entries. In partially filled out surveys, for instance, we would like to infer the many missing entries. In the area of recommender systems, users submit ratings on a subset of entries in a database, and the vendor provides recommendations based on the user\'s preferences. Because users only rate a few items, we would like to infer their preference for unrated items (this is the famous Netflix problem). Formally, suppose that we observe m entries selected uniformly at random from a matrix. Can we complete the matrix and recover the entries that we have not seen? We show that perhaps surprisingly, one can recover low-rank matrices exactly from what appear to be highly incomplete sets of sampled entries; that is, from a minimally sampled set of entries. Further, perfect recovery is possible by solving a simple convex optimization program, namely, a convenient semidefinite program. A surprise is that our methods are optimal and succeed as soon as recovery is possible by any method whatsoever, no matter how intractable; this result hinges on powerful techniques in probability theory. Time permitting, we will also present a very efficient algorithm based on iterative singular value thresholding, which can complete matrices with about a billion entries in a matter of minutes on a personal computer.',NULL
9098,'lecture','en',8751,'2009-06-10','2009-07-30','Drifting Games, Boosting and Online Learning','Drifting games provide a new and useful framework for analyzing learning algorithms. In this talk I will present the framework and show how it is used to derive a new boosting algorithm, called RobustBoost and a new online prediction algorithm, called NormalHedge. I will present two sets of experiments using these algorithms on synthetic and real world data. The first set demonstrates that RobustBoost can learn from mislabeled training data. The second demonstrating an application of NormalHedge to the tracking moving objects.','Linear separation, drifting games & Boosting;;Adaboost is sensitive to label noise;;Robustboost - A new boosting algorithm;;Plan of talk;;Label noise and convex loss functions;;Label noise and convex loss functions;;Loss functions;;A hard case Long & Servedio ICML 2008 (1);;A hard case Long & Servedio ICML 2008 (2);;Boost by Majority and drifting games;;Boost by Majority (BBM);;BBM as a drifting game;;The continuous chip limit;;The boosting game lattice;;Initial configuration;;Booster assigns weights to examples;;Weak learner chooses subset with weight 1/2+γ which h1(x) classifies correctly (1);;Weak learner chooses subset with weight 1/2+γ which h1(x) classifies correctly (2);;Booster assigns weights to examples (2);;Weak learner chooses subset with weight 1/2+γ which h2(x) classifies correctly (3);;Weak learner chooses subset with weight 1/2+γ which h2(x) classifies correctly (4);;Booster assigns weights to examples (3);;Weak learner chooses subset with weight 1/2+γ which h3(x) classifies correctly (5);;Weak learner chooses subset with weight 1/2+γ which h3(x) classifies correctly (6);;Majority[h3(x)+ h3(x)+ h3(x)];;Weak Learner’s min/max strategy;;Potential;;Bin Potential;;Evolution of total potential;;Potential and weight for the boosting game;;t=1;;t=11;;t=21;;t=31;;t=41;;t=51;;t=61;;t=71;;t=81;;t=91;;t=101;;BBM/Logitboost/Adaboost;;High level summary;;Boosting in continuous time;;Why is BBM not practical?;;Letting time step decrease to zero;;The game lattice;;Using step Δs = ± 1 T (1);;Using step Δs = ± 1 T (2);;Using step Δs = ± 1 T (3);;Using step Δs = ± 1 T (4);;Using step Δs = ± 1 T (5);;mlssUsing step Δs = ± 1 T (6);;Potentials in continuous time;;Example: From BBM to Brownboost;;RobustBoost;;Robustboost (1);;Robustboost (2);;Experimental results;;Experimental Results on Long/Servedio synthetic example;;Adaboost on Long/Servedio;;LogitBoost on Long/Servedio;;Robustboost on Long/Servedio;;mlss09us_freund_dgbol_01_Page_64;;mlss09us_freund_dgbol_01_Page_65;;mlss09us_freund_dgbol_01_Page_66;;Logitboost 0% Noise;;Histogram (1);;Histogram (2);;Histogram (3);;Histogram (4);;Logitboost 20% Noise;;Histogram (5);;Histogram (6);;Histogram (7);;Histogram (8);;Histogram (9);;Robustboost 20% Noise ;;Histogram (10);;Histogram (11);;Histogram (12);;Histogram (13);;Histogram (14);;Histogram (15);;Histogram (16);;Histogram (17);;Histogram (18);;Plan of talk;;Questions'
9099,'lecture','en',8751,'2009-06-10','2009-07-30',' Recent Progress in Combinatorial Statistics ','I will discuss some recent progress in combinatorial statistics. In particular, I will describe progress in the areas of reconstructing graphical models, ML estimation of the Mallows model and diagnostics of MCMC. ','Some Recent Progress in Combinatorial Statistics ;;What is Combinatorial Statistics;;Example 1: Graphical Model reconstruction;;Markov random fields / Graphical Models;;Markov random fields / Graphical Models;;Reconstruction task for Markov random fields;;Reconstruction problem;;Related work (1);;Related work (2);;Reconstructing General Networks - New Results;;Intuition Behind Algorithms;;Example 2: Reconstruction of MRF with Hidden nodes;;Reconstruction versus distinguishing;;Distinguishing problems;;Hardness result with hidden nodes;;A possible objection;;Distinguishing problem for samplable distributions;;Example 3: Consensus Ranking and the Mallows Model;;The Mallows Model;;Related work (1);;Related work (2);;Sorting the Mallow’s Model;;Example 4: MCMC Diagnostics;;Convergence Diagnostics;;Convergence Diagnostics in the Literature;;Diagnostic Algorithm;;Results - The General Case;;PSPACE complete problems;;Results - Polynomial Mixing;;Results - Mixing from a Given State;;Comb. Stat. vs. Common ML Approaches;;Conclusions and Questions;;Collaborators;;Thanks!'
9100,'lecture','en',8751,'2009-06-10','2009-07-30','MAP Estimation with Perfect Graphs','Efficiently finding the maximum a posteriori (MAP) configuration of a graphical model is an important problem which is often implemented using message passing algorithms and linear programming. The optimality of such algorithms is only well established for singly-connected graphs such as trees. Recently, along with others, we have shown that matching and b-matching also admit exact MAP estimation under max product belief propagation. This leads us to consider a generalization of trees, matchings and b-matchings: the fascinating family of so-called perfect graphs. While MAP estimation in general loopy graphical models is NP, for perfect graphs of a particular form, the problem is in P. This result leverages recent progress in defining perfect graphs (the strong perfect graph theorem which has been resolved after 4 decades), linear programming relaxations of MAP estimation and recent convergent message passing schemes. In particular, we convert any graphical model into a so-called nand Markov random field. This model is straightforward to relax into a linear program whose integrality can be established in general by testing for graph perfection. This perfection test is performed efficiently using a polynomial time algorithm. Alternatively, known decomposition tools from perfect graph theory may be used to prove perfection for certain graphs. Thus, a general graph framework is provided for determining when MAP estimation in any graphical model is in P, has an integral linear programming relaxation and is exactly recoverable by message passing.','MAP Estimation with Perfect Graphs;;Background, Matchings, Perfect Graphs, MAP Estimation;;Background on Perfect Graphs (1);;Background on Perfect Graphs (2);;Graphical Models;;MAP Estimation;;Max Product Message Passing;;Bipartite Matching (1);;Bipartite Generalized Matching (1);;Bipartite Generalized Matching (2);;Bipartite Matching (2);;Bipartite Generalized Matching (3);;Generalized Matching;;Unipartite Generalized Matching;;Unipartite Generalized Matching (1);;Unipartite Generalized Matching (2);;Unipartite Generalized Matching (3);;Back to Perfect Graphs (1);;Back to Perfect Graphs (2);;nand Markov Random Fields (1);;nand Markov Random Fields (2);;nand Markov Random Fields (3);;Packing Linear Programs (1);;Packing Linear Programs (2);;Packing Linear Programs (3);;Packing Linear Programs (4);;Perfect Graphs;;Strong Perfect Graph Theorem;;Recognition using Perfect Graphs Algorithm (1);;Recognition using Perfect Graphs Algorithm (2);;Recognition using Perfect Graphs Algorithm (3);;Recognition using Perfect Graphs Algorithm (4);;Proving Exact MAP for Tree Graphs (1);;Proving Exact MAP for Bipartite Matchings;;Proving Exact MAP for Bipartite Matchings;;Pruning NMRFs;;Convergent Message Passing (1);;Convergent Message Passing (2);;MAP Experiments (1);;MAP Experiments (2);;Conclusions;;Further Reading and Thanks'
9101,'invited talk','en',8751,'2009-06-11','2009-07-30','Inference for Networks','A great deal of attention has recently been paid to determining sub-communities on the basis of relations, corresponding to edges, between individuals, corresponding to vertices out of an unlabelled graph (Neman, SIAM Review 2003; Airoldi et al JMLR 2008; Leskovec & Kleinberg et al SIGKDD 2005) for probabilistic ergodic models of infinite unlabelled graphs. We drive consistency properties of the Newman-Girvon index, and develop an index with better consistency properties and better performance on simulated data sets. This is joint work with Aiyou Chen.','Consistency of Network Modularities;;Outline;;Community identication problem;;Ethnicity of students;;A Mathematical Formulation;;The Problem;;Approaches: Maximize Modularities;;Block Models (Holland, Laskey and Leinhardt 1983);;Frequentist Approach to Sub-community Identication;;The Swapping Algorithm;;Nonparametric Asymptotic Model for Unlabeled Graphs;;Ergodic Models;;Identiability;;Identiability (cont\'d);;Block Models as Approximations;;Prole Likelihood Modularities;;Asymptotic Approximation for Block Models;;Consistency of Modularities;;Conditions;;Global Consistency;;Estimation of Block Model Parameters;;Newman Girvan (NG);;Result;;Newman-Girvan NG: counter examples (1);;Newman-Girvan NG: counter examples (2);;Prole Likelihood;;Simulation;;Real Data: Private Branch Exchange;;Quicker Optimal Approach (1);;Quicker Optimal Approach (2);;Quicker Optimal Approach (3);;Discussion'
9102,'lecture','en',8751,'2009-06-11','2009-07-30','Cocktail Party Problem as Binary Classification','Speech segregation, or the cocktail party problem, has proven to be extremely challenging. Part of the challenge stems from the lack of a carefully analyzed computational goal. While the separation of every sound source in a mixture is considered the gold standard, I argue that such an objective is neither realistic nor what the human auditory system does. Motivated by the auditory masking phenomenon, we have suggested instead the ideal time-frequency (T-F) binary mask as a main goal for computational auditory scene analysis. Ideal binary masking retains the mixture energy in T-F units where the local signal-to-noise ratio exceeds a certain threshold, and rejects the mixture energy in other T-F units. Recent psychophysical evidence shows that ideal binary masking leads to large speech intelligibility improvements in noisy environments for both normal-hearing and hearing-impaired listeners. The effectiveness of the ideal binary mask implies that sound separation may be formulated as a case of binary classification, which opens the cocktail party problem to a variety of pattern classification and clustering methods. As an example, I discuss a recent system that segregates unvoiced speech by supervised classification of acoustic-phonetic features.','Cocktail Party Problem as Binary Classification;;Outline of presentation;;Real-world audition;;Sources of intrusion and distortion;;Cocktail party problem;;Approaches to Speech Segregation Problem;;Auditory scene analysis;;Computational auditory scene analysis;;Computational theory analysis;;What is the goal of CASA?;;Marrian three-level analysis;;Computational-theory analysis of ASA;;Computational-theory analysis of ASA (cont.);;Some alternative CASA goals;;Ideal binary mask as CASA goal;;IBM illustration;;Properties of IBM;;Subject tests of ideal binary masking;;Test conditions of Wang et al.’09;;Wang et al.’s results;;Speech perception of noise with binary gains;;Wang et al.’08 results;;Interim summary;;Unvoiced speech segregation as binary classification;;Unvoiced speech;;Unvoiced speech segregation;;Processing stages of Hu-Wang’08 model;;Auditory segmentation;;Smoothed intensity;;Segmentation result;;Grouping;;Speech/nonspeech classification;;Speech/nonspeech classification (cont.) (1);;Speech/nonspeech classification (cont.) (2);;Speech/nonspeech classification (cont.) (3);;Example of segregation;;SNR of segregated target;;Conclusion;;Credits'
9103,'lecture','en',8751,'2009-06-11','2009-07-30','Machine Learning in Acoustic Signal Processing','This tutorial presents a framework for understanding and comparing applications of pattern recognition in acoustic signal processing. Representative applications will be delimited by two binary features: (1) regression vs. (2) classification (inferred variables are continuous vs. discrete), (A) instantaneous vs. (B) dynamic. (1. Regression) problems include imaging and sound source tracking using a device with unknown properties, and inverse problems, e.g., articulatory estimation from speech audio. (2. Classification) problems include, e.g., the detection of syllable onsets and offsets in a speech signal, and the classification of non-speech audio events. (A. Instantaneous) inference is performed using a universal approximator (neural network, Gaussian mixture, kernel regression), constrained or regularized, if necessary, to reduce generalization error (resulting in a support vector machine, shrunk net, pruned tree, or boosted classifier combination). (B. Dynamic) inference methods apply prior knowledge of state transition probabilities, either in the form of a regularization term (e.g., using Bayesian inference) or in the form of set constraints (e.g., using linear programming) or both; examples include speech-to-text transcription, acoustic-to-articulatory inversion using a switching Kalman filter, and computation of the query presence probability in an audio information retrieval task.','Pattern Recognition in Acoustic Signal Processing;;Outline;;The Scientific Method;;The Pattern Recognition Method;;Example: PR in the Scientific Method;;Criteria for Choosing a Pattern Recognizer (1);;Criteria for Choosing a Pattern Recognizer (2);;Criteria for Choosing a Pattern Recognizer (3);; Criteria for Choosing a Pattern Recognizer (4);;Discriminative Training—Gradient Descent Methods;;Universal Approximators (1);;Universal Approximators (2);;Differentiable Error Metric (1);;Differentiable Error Metric (2);;Apply the Chain Rule;;Wrinkle #1: Recognition, Tracking;;Recursive Neural Nets: Example Application;;Wrinkle #2: Small Training Corpus;;Support Vector Machines: Example Application;;Wrinkle #3: Label Dynamics AND Small Dataset (1);;Wrinkle #3: Label Dynamics AND Small Dataset (2);;Wrinkle #3: Label Dynamics AND Small Dataset (3);;Bayesian Methods, Advantages and Disadvantages;;Hypothesis Space Example: Hidden Markov Model;;Learn the Distributions: Maximum Likelihood;;Apply Bayes’ Rule;;Bayesian Regression and Tracking;;Switching Kalman Smoother;;Switching Kalman Smoother: Example;;Hybrid Discriminative-Bayesian Systems;;Hybrid Training Methods;;Example: Landmark-Based Speech Recognizer;;Phone Recognition Accuracy vs. Mixture Size, Telephone Speech;;Example: RNN with Kalman Smoothing;;Example: Non-Speech Acoustic Event Detection;;Difficulty #1: Negative SNR;;Difficulty #2: Unknown Spectral Structure;;Discriminative Feature Selection for AED;;Bayes Error Rate;;Feature Selection Algorithms;;Acoustic Event Detection Results;;Bayesian Re-Estimation of Discriminative Nodes;;The Baum-Welch Algorithm;;Baum-Welch Back-Propagation;;The Problem of Spurious Maxima (1);;The Problem of Spurious Maxima (2);;The Problem of Spurious Maxima (3);;The Problem of Spurious Maxima (4);;The Problem of Spurious Maxima (5);;Methods for Avoiding Spurious Maxima;;The Reflecting Symplectic Transform;;SMLT+GMM for Phone Classification;;Conclusions (1);;Conclusions (2);;Conclusions (3);;Thank You!'
9104,'lecture','en',8751,'2009-06-11','2009-07-30','Nonlinear Dimension Reduction by Spectral Connectivity Analysis and Diffusion Coarse-Graining','For naturally occurring data, the dimension of the given input space is often very large while the data themselves have a low intrinsic dimensionality. Spectral kernel methods are non-linear techniques for transforming data into a coordinate system that efficiently reveal the geometric structure in particular, the connectivity of the data. In this talk, we will focus on one particular technique diffusion maps and diffusion coarse-graining; the construction is based on a Markov random walk on the data and offers a general scheme of simultaneously reorganizing and quantizing graphs and arbitrarily shaped data sets in high dimensions using intrinsic geometry. We show that clustering in embedding spaces is equivalent to compressing operators and that the quantization distortion in diffusion space bounds the error of compression of the operator, thus giving a rigorous justification and a precise measure of performance of k-means clustering in spectral embedding spaces. We will discuss two particular applications of diffusion coarse-graining: One application is choosing an appropriate set of prototype similar stellar population (SSP) spectra for parameter estimation of star formation history in galaxies. The other example is texture discrimination by a novel geometry-based metric on distributions. (Part of this work is joint with R.R. Coifman, S. Lafon, J. Richards and C. Schafer.)',NULL
9313,'opening','en',8954,'2009-07-08','2009-08-10','Welcome',NULL,NULL
9314,'tutorial','en',8954,'2009-07-08','2009-08-10','Warm-Up for BCI Physiology: Basic Concepts in the Transition from Cellular Microrecordings to Noninvasive Large-Scale EEG/MEG Signals','Macroscopic brain sigals, e.g., the noninvasively measured scalp EEG/MEG, correlate with mental states, such as movement intentions. This opens a new communication channel for paralyzed patients as their intentions can be \'read\' by computers and utilised for triggering technical devices. This entry-level tutorial will provide an intuitive introduction into the relevant brain anatomy and physiology and describe typical procedures as well as potential pitfalls when obtaining and analysing multichannel EEG/MEG data.',NULL
9315,'tutorial','en',8954,'2009-07-08','2009-08-10','Machine Learning and Signal Processing Tools for BCI','We will first provide a brief overview of Brain-Computer Interface from a machine learning and signal processing perspective. In particular showing the wealth, the complexity and the difficulties of the data available, a truly enormous challenge: In real-time a multi-variate very strongly noise contaminated data stream is to be processed and neuroelectric activities are to be accurately differentiated. We will then in detail discuss the components of the data analysis chain employed in modern BCI systems, spanning all aspects from preprocessing and feature extraction, adaptive vs. fixed classification and feedback design.','Machine Learning and Signal Processing Tools for BCI;;BBCI team:;;Noninvasive Brain-Computer Interface;;‚Brain Pong‘ with BBCI;;Noninvasive BCI: clinical applications;;EEG based noninvasive BCI;;The cerebral cocktail party problem;;BBCI paradigms;;Towards imaginations: Modulation of Brain Rhythms;;Variance I: Single-trial vs. Averaging;;Variance II: Trial to trial variability;;Variance III: inter subject variability [l vs r];;BCI with machine learning: training;;BBCI paradigms;;Playing with BCI: training session (20 min);;Machine learning approach to BCI: infer prototypical pattern;;BCI with machine learning: feedback;;Lecture Blankertz here;;BBCI Set-up;;bbci09_tutorial_mlasp_Page_020;;bbci09_tutorial_mlasp_Page_021;;bbci09_tutorial_mlasp_Page_022;;bbci09_tutorial_mlasp_Page_023;;bbci09_tutorial_mlasp_Page_024;;bbci09_tutorial_mlasp_Page_025;;bbci09_tutorial_mlasp_Page_026;;bbci09_tutorial_mlasp_Page_027;;bbci09_tutorial_mlasp_Page_028;;bbci09_tutorial_mlasp_Page_029;;bbci09_tutorial_mlasp_Page_030;;bbci09_tutorial_mlasp_Page_031;;bbci09_tutorial_mlasp_Page_032;;bbci09_tutorial_mlasp_Page_033;;bbci09_tutorial_mlasp_Page_034;;bbci09_tutorial_mlasp_Page_035;;bbci09_tutorial_mlasp_Page_036;;bbci09_tutorial_mlasp_Page_037;;bbci09_tutorial_mlasp_Page_038;;bbci09_tutorial_mlasp_Page_039;;bbci09_tutorial_mlasp_Page_040;;bbci09_tutorial_mlasp_Page_041;;bbci09_tutorial_mlasp_Page_042;;bbci09_tutorial_mlasp_Page_043;;Machine Learning and Signal Processing Tools for Brain-Computer Interfacing;;Topic of This Section;;Some Neurophysiological Background;;Experimental Design (1);;Experimental Design (2);;Single-subject ERPs in Hex-o-Spell;;Topographies of ERP Components;;Classication of Temporal Features;;Extraction of Spatial Features (1);;Extraction of Spatial Features (2);;The r2-Matrix of Differences;;Spatial Features;;Linear Classier as Spatial Filter;;Classication Results for Spatial Features;;Extraction of Spatio-Temporal Features;;Spatio-Temporal Features;;Classication Result for Spatio-Temporal Features;;Bias in Estimating Covariances (1);;Bias in Estimating Covariances (2);;A Remedy for Classication (1);;A Remedy for Classication (2);;Modelselection;;Regularized LDA at Work;;Investigating the Impact of Shrinkage (1);;Investigating the Impact of Shrinkage (2);;Investigating the Impact of Shrinkage (3);;ERP and Noise;;Spatial Structure of the Noise;;Understanding Spatial Filters (1);;Understanding Spatial Filters (2);;Impact of Shrinkage on the Spatial Filters;;A Novel Analytical Method;;Optimal Selection of Shrinkage Parameter (1);;Optimal Selection of Shrinkage Parameter (2);;Result of Classication with Shrinkage;;Results for the Classic Matrix Speller (1);;Results for the Classic Matrix Speller (2);;Summary of Spatio-Temporal Classication;;Topic of This Section;;Neurophysiology: Sensorimotor Rhythms (1);;Neurophysiology: Sensorimotor Rhythms (2);;Average Topography of Idle SMR;;Spatial Smearing;;The Need for Spatial Filtering;;Analysis of Motor Imagery Conditions: Spectra;;ERD Curves of Motor Imagery;;Common Spatial Pattern (CSP) Analysis;;CSP Analysis;;CSP More Practical (1);;CSP More Practical (2);;Training CSP-based Classication (1);;Training CSP-based Classication (2);;Summary: Training CSP-based Classication;;Applying CSP-based Classication;;Section: Caveats in Validation;;Hall of Pitfalls in Single-Trial EEG Analysis;;Block Design;;Slowly Changing Variables;;A Validation Test;;Results of the Validation Test (1);;Results of the Validation Test (1);;Further Comments and Summary;;References'
9316,'tutorial','en',8954,'2009-07-08','2009-08-10','About Learning, Predictions and Adaptivity of Brains and Machines','Using useful signals from the brain, and useful computer algorithms to improve brain machine interfaces.\nI will talk about the physiology of motor cortex and the nature of activity of population of neurons in motor cortex during Sensorimotor learning, movement preparation and execution. I will present the approach of internal models of the brain as the basis for learning and perception and use all of the above to show how our current knowledge can facilitate approaches to adaptive brain machine interfaces.','Learning and control of sensorimotor Functions in Motor Cortical Fields;;Acknowledgments;;The Edmond and Lily Center for Brain Sciences;;Outlines;;René Descartes 1569 - 1650;;The Sensory-motor Loop;;Quote;;Action is essential for learning and perception;;Modeling the Action-Perception Loop: “Internal Models”;;The Significance of Previous Knowledge;;Action-perception loop;;Kalman Filter;;Outlines;;Billions of nerve cells in many brain regions orchestrate behavior (1);;Billions of nerve cells in many brain regions orchestrate behavior (2);;Single Units Recordings;;The Voice of a single neuron in motor cortex;;The “Center Out” Task;;Directional Tuning of Single cells in motor cortex;;Hypothesis: 1.Each neurons has a “preferred direction” ;;2. A Population of neurons encodes accurately movement direction;;Simultaneous Recordings allow on-line inference of movements from Neuronal Activity: Example : OLE* / Linear Regression;;Multi channel recordings of brain signals;;Simultaneous Recordings and Spikes Sorting;;Simultaneous Recordings of ~200 Spikes Channels;;Local Field Potentials - LFP;;Outlines;;Sensorimotor Learning;;The hypothesis: The population code is shaped by learning;;Three learning tasks;;In All Experiments: Delayed Reaching Tasks;;1. Learning Reaching: More tuned cells as learning;;2. Learning Visuomotor Rotation;;After learning Visuomotor rotation of 45°;;Increased firing rate in selected population during learning Single units Activity changes only in the preparatory period;;Single units Trial-to-Trial Variability : Modulation only in the preparatory period!;;Modulation of Local Field Potentials Gamma Excess – Only During movement execution!;;LFP and Spikes reflect different aspects of Learning?;;After Learning: memory traces?;;After Learning: Better Representation of Learned movements;;Force Field Adaptation: Modulation of the whole population Depending on cells’ PDs!;;Intermediate Conclusions;;Outlines;;Neuronal signals;;BMI action-perception loop;;Model Requirments: Choosing a BMI algorithm (1);;Model Requirments: Choosing a BMI algorithm (2);;Kernel Auto Regressive Moving Average (KARMA):;;Kernel Auto Regressive Moving Average (KARMA): (2);;Modeling choices;;Learning;;Learning the model in BMI mode;;KARMA: General scheme;;Making KARMA Adaptive;;Experiments;;Outlines;;3D instructed-delay with continuous target-totarget reaching;;3D instructed-delay with continuous target-totarget reaching ;;Arm Control;;Real Time tracking of hand movements by KARMA;;bbci09_vaadia_alpa_Page_61;;bbci09_vaadia_alpa_Page_62;;Adaptivity model is helpful in tracking;;Adaptive Models are Useful for These Brains;;Brain Control – Reaching Targets in 3-D;;First days of BMI adaptation;;Switching from Arm control to Brain Control is fast!;;Adaptive model performs better in Brain control;;Learning novel visuomotor task using a BMI;;Target Rotation Task;;Learning anew in BMI - Target Rotation Task;;Gradual emergence of Population responses;;Reach and Rotate;;Summary and conclusions;;More investment in funds and manpower will put us on the yellow brick road;;Acknowledgments;;bbci09_vaadia_alpa_Page_77;;bbci09_vaadia_alpa_Page_78;;bbci09_vaadia_alpa_Page_79;;bbci09_vaadia_alpa_Page_80;;bbci09_vaadia_alpa_Page_81;;bbci09_vaadia_alpa_Page_82;;bbci09_vaadia_alpa_Page_83;;bbci09_vaadia_alpa_Page_84;;bbci09_vaadia_alpa_Page_85;;bbci09_vaadia_alpa_Page_86'
9317,'tutorial','en',8954,'2009-07-08','2009-08-10','Theory and Application of Electrocorticographic (ECoG) Signals in Humans','Brain-computer interfaces (BCIs) convert brain signals into outputs that communicate a user\'s intent. BCIs can be used by people to communicate and interact with their environment. However, the prevailing non-invasive and invasive sensor methods have important limitations. Electrocorticographic (ECoG) recordings from the surface of the brain could be a robust and high-fidelity alternative to existing sensor methods. This tutorial will provide an overview of the history of ECoG recordings; describe the types of signals present in ECoG and their relationship to signals detected using EEG and intracortical microelectrodes; and finally give examples of successful use of these signals in real time for BCI purposes and also for diagnosis.','Theory and Application of Electrocorticographic (ECoG) Signals in Humans;;Electrocorticographic Signals (ECoG) in Humans (1);;Electrocorticographic Signals (ECoG) in Humans (2);;Different BCI Signal Modalities;;Electrocorticography (ECoG);;Electrocorticographic Signals (ECoG) in Humans;;Quote;;Quote;;Quote;;Quote;;More Recently ... (1);;More Recently ... (2);;More Recently ... (3);;More Recently ... (4);;More Recently ... (5);;More Recently ... (6);;Electrocorticographic Signals (ECoG) in Humans;;Mu/Beta and Gamma (1);;Mu/Beta and Gamma (2);;Mu/Beta and Gamma (3);;Mu/Beta and Gamma (4);;The Local Motor Potential (LMP);;Electrocorticographic Signals (ECoG) in Humans;;Relationship with General Movement Parameters: Motor Homunculus;;Relationship of ECoG with Hand/Tongue Movements (1);;Relationship of ECoG with Hand/Tongue Movements (2);;Relationship of Gamma With Speech Function (1);;Relationship of Gamma With Speech Function (2);;Relationship of Gamma With Electrical Stimulation;;Relationship of ECoG with Multi-Unit Activity (in rats);;Relationship of Gamma with fMRI;;Relationship of ECoG with Details of Movements: Decoding of Function;;Decoding Direction of Hand Movements;;Tuning to Direction of Hand Movements (1);;Tuning to Direction of Hand Movements (2);;Spatio-Temporal Gamma Activity Related to Hand Movements;;Spatio-Temporal Gamma Activity Related to Hand Movements (2);;Decoding Hand Position;;Decoding Hand Movements;;Decoding Finger Flexion;;Response to Thumb Movement;;Response to Index Finger Movement;;Classification of Individual Fingers in 5 Subjects;;Decoding Thumb Flexion (1);;Decoding Thumb Flexion (2);;Decoding Vowels and Consonants;;Electrocorticographic Signals (ECoG) in Humans;;Associating Brain Activity with Cursor Movement;;One-Dimensional BCI Control (1);;One-Dimensional BCI Control (2);;bbci09_schalk_taaoe_Page_51;;Brain Control with Imagined Movements;;Two-Dimensional BCI Control;;bbci09_schalk_taaoe_Page_54;;Triggering Action with the Brain: Clint Eastwood, 1982;;bbci09_schalk_taaoe_Page_56;;Triggering Action with the Brain: Brunner, Ritaccio, Schalk, 2009;;bbci09_schalk_taaoe_Page_58;;Using Imagined Vowels for Silent Communication;;One more thing ... (2);;One more thing ... (1);;bbci09_schalk_taaoe_Page_62;;bbci09_schalk_taaoe_Page_63;;Waiting to start ...;;Electrocorticographic Signals (ECoG) in Humans;;Functional Mapping;;Real-Time Mapping Example #1;;Real-Time Mapping Example #2;;bbci09_schalk_taaoe_Page_69;;Real-Time Mapping Example #3 (1);;Real-Time Mapping Example #3 (2);;Real-Time Mapping Example #3 (3);;Real-Time Mapping Example #3 (4);;Real-Time Mapping Example #3 (5);;Electrocorticographic Signals (ECoG) in Humans;;Question 1: What is Gamma?;;Question 2: What is the LMP? (1);;Question 2: What is the LMP? (2);;Question (Set) 3: What is the best ...;;Electrocorticographic Signals (ECoG) in Humans;;Current μECoG;;Next Generation μECoG;;Different Design ...;;What does all this mean?;;The Communication Problem;;Req. 1: Better Access to Brain Signals (1);;Req. 1: Better Access to Brain Signals (2);;Req. 2: Better Interpretation (1);;Req. 2: Better Interpretation (2);;The Communication Problem Solved;;Quote;;Quote;;Conclusions;;5th BCI2000 Workshop;;Credits'
9318,'lecture','en',8954,'2009-07-09','2009-08-10','What\'s the Plan? - Movement-Goal Representations in the Frontoparietal Reach Network','When planning goal-directed arm movements the sensorimotor system needs to integrate the current behavioral context with given spatial constraints to define and maintain motor-goals. We are interested in how this integration is achieved within the sensorimotor network. Specifically we tested the respective roles of the dorsal premotor cortex (PMd) and the parietal reach region (PRR) in defining and planning context-specific reach goals.','What\'s the plan? - Movement-goal representations in the frontoparietal reach network;;BCI;;Simultaneous multi-channel intracortical recordings in areas PMd and PRR;;Space-context integration for reaching – Where, when and how?;;Cortical encoding of arm movement plans (1);;Cortical encoding of arm movement plans (2);;Identifying movement plans: Step 1: Sustained activity during instructed delay;;Goal-directed movement planning;;Identifying movement plans: Step 2: Motor-goal selectivity;;PRR encodes motor-goal location during the planning phase of an arm movement;;Never trust any motor goal under 200ms?;;Space-context integration – The partial pre-cuing experiment;;Congruent (PRO) motor goals are faster especially if context is known in advance;;Motor goals are earlier in PMd than in PRR but only for inferred (ANTI) reaches;;Context representation is more prevalent in PMd than PRR;;Motor goals are earlier in PMd than in PRR independent of the pre-cuing condition;;Motor goal latencies PRR and PMd;;Limited generalization of motor-goal decoding;;All motor goals are equal?;;Contextual gain modulations of motor-goal representations – examples;;Contextual gain and selectivity modulations similarity between model and neural data;;Strength and bias of contextual motor-goal modulations PRR vs. PMd;;Conclusion - Motor-goal encoding in PRR and PMd;;Implications for BCI design;;Acknowledgements;;bbci09_gail_wtpm_Page_26;;bbci09_gail_wtpm_Page_27;;bbci09_gail_wtpm_Page_28;;bbci09_gail_wtpm_Page_29;;bbci09_gail_wtpm_Page_30;;bbci09_gail_wtpm_Page_31'
9319,'lecture','en',8954,'2009-07-09','2009-08-10','Brain-Machine Interfaces Based on Neuronal Ensemble Recordings ','Brain-machine interfaces (BMIs) have experienced an explosive development during the last decade. Current state of the art BMIs convert neuronal ensemble activity recorded in nonhuman primates or human subjects into reaching and grasping movements performed by artificial actuators. BMIs that enact movements of lower extremeties are less explored. Additionally, most BMI implementations do not have somatosensory feedback from the actuator. I will review our recent experiments in which we (i) extracted bipedal locomotion patterns from monkey cortical activity and (ii) used spatiotemporal patterns of intracortical microstimulation to deliver information back to the brain. These results bring us closer to building clinical neuroprosthetic devices for restoration of both sensory and motor functions in paralyzed people.','BRAIN-MACHINE INTERFACES BASED ON NEURONAL ENSEMBLE RECORDINGS;;Encoding (microstimulation) (1);;Encoding (microstimulation) (2);;Brain-Machine Interfaces;;Macaque Monkey Brain;;Rhesus Monkey and Owl Monkey Brain;;Cortical Hierarchy according to Fuster (2001);;Cortical Neurons Are Directionally Tuned;;Frontal Cortex Neurons Modulate Firing During Movement Preparation and Execution;;Multielectrode Implant (1);;Multielectrode Implant (2);;Example implants (1);;Example implants (2);;Decoding with linear model;;Real-time predictions of hand position;;Prediction of Multiple Motor Variables;;Reach and grasp task;;Real-Time Predictions;;Kalman filter in BMI design;;N-th order unscented Kalman filter (1);;N-th order unscented Kalman filter (2);;N-th order unscented Kalman filter (3);;Timing Experiment (1);;Timing Experiment (2);;Prediction of Time;;Decoding Representation of Time;;Monkey Locomotion (1);;Monkey Locomotion (2);;Leg Representation (1);;Leg Representation (2);;Decoding of multiple locomotion parameters (1);;Decoding of multiple locomotion parameters (2);;Decoding of multiple locomotion parameters (3);;Prediction of Locomotion;;Humanoid Robot at ATR, Kyoto, Japan Driven by Monkey Neural Activity (In Real Time!) (1);;Humanoid Robot at ATR, Kyoto, Japan Driven by Monkey Neural Activity (In Real Time!) (2);;Encoding (microstimulation);;Stimulating electrodes;;Microstimulation patterns;;Initial training;;Psychometric curve;;Reversal task;;Discrimination of temporal patterns;;Discrimination of spatiotemporal patterns;;Recordings during microstimulation;;Microstimulation in Rhesus Monkeys (1);;Microstimulation in Rhesus Monkeys (2);;Microstimulation in Rhesus Monkeys (3);;Microstimulation in Rhesus Monkeys (4);;Learning with Vibratory Cue;;Learning with Microstimulation Cue;;Bidirectional BMI;;Owl monkey reaching experiment;;Perspectives;;Acknowledgements'
9320,'lecture','en',8954,'2009-07-09','2009-08-10','Plasticity at the Brain-Computer Interface','Next generation recurrent Brain-Computer Interfaces will not only extract signals from cortical activity but also deliver feedback to the nervous system via electrical stimulation. For example, stimulation of cervical spinal segments can produce functional arm and hand movements such as reaching and grasping. We are developing new technologies including chronic electrodes and implantable electronic circuitry to control stimulation from cortical recordings, constituting an artificial corticospinal connection which could replace injured motor pathways. I will present evidence that the motor system can readily acquire the novel neuromotor transformations required to incorporate these connections into motor system function. In separate experiments we have shown that operation of artificial connections can potentiate new motor pathways via activity-dependent plasticity mechanisms. Together, these results suggest that recurrent BCIs have application not only as prostheses to replace function, but also as tools for manipulating plastic reorganisation to restore nervous system function following injury.','Plasticity at the Brain-Computer Interface;;Classes of Brain-Machine Interface;;A Recurrent BCI for Spinal Cord Injury;;Cervical intraspinal microstimulation (cISMS) (1);;Cervical intraspinal microstimulation (cISMS) (2);;cISMS – Effect of stimulus intensity;;cISMS – Effect of stimulus frequency;;Modeling spinal input-output transformations (1);;Modeling spinal input-output transformations (2);;cISMS – Documenting motor output;;Sinusoidal grip force produced by cISMS;;‘Twin peaks’;;Sinusoidal arm movements produced by cISMS;;Two channel cISMS – Reach and grasp;;Towards a chronic cISMS implant – flexible electrodes: (1);;Towards a chronic cISMS implant – flexible electrodes: (2);;A Recurrent BCI for Spinal Cord Injury;;Two approaches to Brain-Computer Interfaces…;;Myoelectric control of a computer cursor (1);;Myoelectric control of a computer cursor (2);;Myoelectric control of a computer cursor (3);;Learning unnatural motor patterns;;Tuning functions for distal and proximal muscles;;Correlations between muscles during MCI learning;;Examples of successful human-device interfaces:;;Neural control of FES (1);;Neural control of FES (2);;A Recurrent BCI for Spinal Cord Injury;;Activity-dependent plasticity and R-BCIs;;The Neurochip: a recurrent Brain-Computer Interface;;Neural and EMG recording with a Neurochip;;Various time-scales of Neurochip recording;;Long-term motor plasticity induced by a cortical R-BCI (1);;Long-term motor plasticity induced by a cortical R-BCI (2);;Conclusions;;A dual mechanism for motor rehabilitation with R-BCIs?;;Acknowledgements:;;bbci09_jackson_patb_Page_38;;bbci09_jackson_patb_Page_39;;bbci09_jackson_patb_Page_40;;bbci09_jackson_patb_Page_41'
9321,'lecture','en',8954,'2009-07-09','2009-08-10','BCI in Paralysis: An Unfulfilled Promise','EEG and ECoG (Electrocorticogram) can be used successfully to initiate direct brain communication with locked-in patients but fail in completely locked-in patients. Possible reasons are explained and some new solutions with first data presented. In chronic stroke the author\'s team together with L. Cohen\'s group at NIH have shown motor restoration of paralysed hand in chronic stroke without residual movement using non-invasive MEG/BCI. However generalization from the BCI-clinic to the social reality was poor. A new strategy for invasive and non-invasive BCI in chronic stroke is demonstrated and first data presented.','The longer a blind lives the more he sees.;;Aknowledgements;;Biofeedback of Slow Potentials ;;slow cortical potentials;;A Brain-Computer-Interface for ADHD;;Near Infrared Spectroscopy- BCI in Attention Deficit Disorder;;Patient 1;;Patient 2;;Patient 3;;Example - different tasks;;Detection of Cognition;;Probabilities of cortical responses as a function of the complexity of stimulation (1);;Probabilities of cortical responses as a function of the complexity of stimulation (2);;Probabilities of cortical responses as a function of the complexity of stimulation (3);;Quote;;Patient communicating (1);;Patient communicating (2);;Patient communicating (3);;Levels of impairment and BCI-control (1);;Levels of impairment and BCI-control (2);;Classification of brain activity during imagery (1);;Classification of brain activity during imagery (2);;George (with patient‘s permission);;Completely locked-in patient GR with 120 electrode grid implanted êpidurally left fronto-central cortex;;Neill Miller;;Dworkin&Miller ,Behav.Neurosc(1986);;Quote;;Quality of life in ALS-patients;;Quality of life– patients and the bias of significant others;;Mean scores of depression;;Subjective responses to emotional slides;;ALS-patients minus healthy participants;;ALS-patients minus healthy participants (2);;The Training Paradigm;;MEG-BCI training in chronic stroke (1);;MEG-BCI training in chronic stroke (2);;MEG-BCI training in chronic stroke (3);;MEG-BCI training in chronic stroke (4);;Quote;;fMRI-BCI system;;Rückmeldung der Hirnaktivität [Training];;Operant Conditioning of BOLD;;Learning of right inferior frontal gyrus activation (1);;Learning of right inferior frontal gyrus activation (2);;SPM analysis of subject FM, showing the contrast up-regulation vs baseline during an early and a late session.;;Emotional Face Recognition after 42 sessions of insula up-training in schizophrenia;;Acquisition CS+/CS-;;Aggressionsstudie: Bestrafung;;Guilt in low versus high psychopathy trait;;Near Infrared Spectroscopy (NIRS) for Operant Training of Cerebral Oxygenation ;;Emotional response;;Control Groups;;Psychopaths - Linear increase of activation over time in the left insula;;Functional connectivity changes due to training;;Quote;;bbci09_birbaumer_bip_Page_056;;bbci09_birbaumer_bip_Page_057;;bbci09_birbaumer_bip_Page_058;;bbci09_birbaumer_bip_Page_059;;bbci09_birbaumer_bip_Page_060;;bbci09_birbaumer_bip_Page_061;;bbci09_birbaumer_bip_Page_062;;bbci09_birbaumer_bip_Page_063;;bbci09_birbaumer_bip_Page_064;;bbci09_birbaumer_bip_Page_065;;bbci09_birbaumer_bip_Page_066;;bbci09_birbaumer_bip_Page_067;;bbci09_birbaumer_bip_Page_068;;bbci09_birbaumer_bip_Page_069;;bbci09_birbaumer_bip_Page_070;;bbci09_birbaumer_bip_Page_071;;bbci09_birbaumer_bip_Page_072;;bbci09_birbaumer_bip_Page_073;;bbci09_birbaumer_bip_Page_074;;bbci09_birbaumer_bip_Page_075;;bbci09_birbaumer_bip_Page_076;;bbci09_birbaumer_bip_Page_077;;bbci09_birbaumer_bip_Page_078;;bbci09_birbaumer_bip_Page_079;;bbci09_birbaumer_bip_Page_080;;bbci09_birbaumer_bip_Page_081;;bbci09_birbaumer_bip_Page_082;;bbci09_birbaumer_bip_Page_083;;bbci09_birbaumer_bip_Page_084;;bbci09_birbaumer_bip_Page_085;;bbci09_birbaumer_bip_Page_086;;bbci09_birbaumer_bip_Page_087;;bbci09_birbaumer_bip_Page_088;;bbci09_birbaumer_bip_Page_089;;bbci09_birbaumer_bip_Page_090;;bbci09_birbaumer_bip_Page_091;;bbci09_birbaumer_bip_Page_092;;bbci09_birbaumer_bip_Page_093;;bbci09_birbaumer_bip_Page_094;;bbci09_birbaumer_bip_Page_095;;bbci09_birbaumer_bip_Page_096;;bbci09_birbaumer_bip_Page_097;;bbci09_birbaumer_bip_Page_098;;bbci09_birbaumer_bip_Page_099;;bbci09_birbaumer_bip_Page_100;;bbci09_birbaumer_bip_Page_101;;bbci09_birbaumer_bip_Page_102;;bbci09_birbaumer_bip_Page_103;;bbci09_birbaumer_bip_Page_104;;bbci09_birbaumer_bip_Page_105;;bbci09_birbaumer_bip_Page_106;;bbci09_birbaumer_bip_Page_107;;bbci09_birbaumer_bip_Page_108;;bbci09_birbaumer_bip_Page_109'
9322,'lecture','en',8954,'2009-07-09','2009-08-10','The Hybrid BCI','There are several different BCI approaches, which may or may not depend on external stimulation. Slow cortical potential (SCP)-, event-related desynchronisation (ERD)- and sensorimotor rhythm (SMR)-BCIs do not require external stimulation, while P300-BCIs and steady state visual evoked potential (SSVEP)-BCIs do. Dependent means in this respect that the user has to focus attention and/or gaze to flickering/flashing lights or and can therefore not completely freely decide to perform an action. Each type of BCI system has advantages and disadvantages. SSVEP-BCIs need minimal training time and can achieve a high information transfer rate (ITR), but have a relatively high false positive rate during rest. In contrast, an asynchronous brain switch based on the post-imagery beta ERS has a low ITR, but can be set up quickly and easily with a low false position rate (Pfurtscheller and Solis-Escalante, Clin. Neurophysio. 2009). It is therefore a challenge to use the advantages of different BCI systems and create a “hybrid” BCI system by switching e.g. a battery of flickering lights (SSVEP-BCI) on or off by using a brain switch (ERD-BCI). Another type of “hybrid” BCI can analyse motor imagery related EEG changes and SSVEP amplitudes simultaneously. It was shown recently that such a “hybrid” strategy results in a better classification accuracy relative to either an ERD or SSVEP classification alone (Allison et al submitted 2009).',NULL
9323,'lecture','en',8954,'2009-07-09','2009-08-10','Feedback-Regulated Mental Imagery in BCI Applications: Using Non-Invasive EEG and NIRS Signals','An important issue of brain-computer interface (BCI) development is to detect changes in brain signals that are related to specific intentions or thought processes. For example, mental motor imagery modulates the sensorimotor brain activity, and the detected changes can be used to operate a computer-controlled device. Clinical applications of this technology include the restoration of movement, such as control of grasping with the help of a neuroprosthesis, in severely paralyzed individuals. The motor imagery based BCI training may further be useful as a complementary therapeutic tool to facilitate functional recovery after stroke. To date, the majority of BCI systems rely on EEG recordings. However, near-infrared spectroscopy (NIRS) has recently attracted attention of BCI researchers due to its noninvasiveness, portability, short preparation time, and relatively low cost. In this talk I will shortly introduce the NIRS technique for BCI development and present data on how characteristic hemodynamic responses during motor imagery can be modulated by real-time NIRS feedback. Based on recent results I will finally discuss how simultaneous NIRS and EEG recordings might combine advantages of both approaches.','Feedback-regulated mental imagery in BCI applications: using non-invasive EEG and NIRS signals;;Rehabilitation with BCI-Systems;;Voluntary Movment and ERD/ERS;;Motor Imagery as Mental Strategy;;Graz-BCI: ERD/S Classification;;BCIs for People with Motor Disabilities;;Motor Restoration;;BCI Control of Neuroprosthesis (1);;BCI Control of Neuroprosthesis (2);;Foot Motor Imagery in Tetraplegic Patient (1);;Foot Motor Imagery in Tetraplegic Patient (2);;Foot Motor Imagery in Tetraplegic Patient (3);;Impact of Visual Feedback;;BCI Feedback Study: Grasping Hand;;BCI Feedback Study: Abstract vs. Realistic;;Motor Recovery;;BCI-based stroke therapy;;ERD/S Patterns in Stroke Patients (1);;ERD/S Patterns in Stroke Patients (2);;ERD/S Patterns in Stroke Patients (3);;ERD/S Patterns during passive movement (1);;ERD/S Patterns during passive movement (2);;ERD/S Patterns during passive movement (3);;ERD/S Patterns during passive movement (4);;ERD/S Patterns during passive movement (5);;ERD/S Patterns during passive movement (6);;Use of NIRS signals?;;Near-Infrared Spectroscopy (NIRS) (1);;Near-Infrared Spectroscopy (NIRS) (2);;Correlation between NIRS and fMRI Signals;;NIRS Probe-Set;;Motor Execution;;Motor Execution (ME) vs. Motor Imagery (MI) (1);;Motor Execution (ME) vs. Motor Imagery (MI) (2);;NIRS Feedback-System;;NIRS Feedback: Oxy-Hb increase (1);;NIRS Feedback: Oxy-Hb increase (2);;NIRS Feedback: Oxy-Hb Left-right Asymmetry (1);;NIRS Feedback: Oxy-Hb Left-right Asymmetry (2);;NIRS Feedback: Oxy-Hb Left-right Asymmetry (3);;Combined EEG/NIRS recording (1);;Combined EEG/NIRS recording (2);;Feedback;;Motor Imagery - Session 1 (1);;Motor Imagery - Session 1 (2);;Session 1;;rCBF/PET & Sensorimotor Rhythms;;Take home message ...;;Graz-BCI Research Team;;Acknowledgements'
9324,'lecture','en',8954,'2009-07-09','2009-08-10','EEG‐Based Brain‐Computer Interface for Communication and Control: Independent Home Use','People affected by severe motor disorders such as amyotrophic lateral sclerosis (ALS), brainstem stroke, cerebral palsy, and spinal cord injury need alternative methods for communication and control. They may not be able to use even the most basic conventional assistive technologies, which all rely in one way or another on muscles. Studies from this and other laboratories have shown that humans, including those with severe motor disabilities, can learn to control sensorimotor rhythms and other features of scalp‐recorded electroencephalographic (EEG) activity and that they can use this control to select letters or icons, or move a cursor in up to three dimensions. Such multidimensional control could be used to control a prosthesis or a robotic arm. Currently, we are showing that people with ALS can use EEG‐based brain‐computer interfaces (BCIs) for communication and control independently in their homes.',NULL
9325,'lecture','en',8954,'2009-07-09','2009-08-10','Tackling Increasing Opthalmologic Problems in Patients with a New Auditory Multi-Class BCI Paradigm','Most P300 BCI approaches use the visual modality for stimulation and feedback. Due to increasing sight deterioration, this might not be the preferable choice for ALS patients in late stages. To tackle this general problem, a multi-class brain-computer interface paradigm is proposed that uses fast spatially distributed auditory cues for ERP paradigms.','New Auditory Multiclass Paradigm for Brain-Computer Interfaces;;Outline of Talk;;Event Related Potentials (ERP) (1);;Event Related Potentials (ERP) (2);;Why ERPs for BCI?;;What Factors have Influence on ERP? (1);;What Factors have Influence on ERP? (2);;What Factors have Influence on ERP? (3);;Detection of ERPs;;BCI Paradigms based on VEP (1);;BCI Paradigms based on VEP (2);;Minor Impaired ALS Patients and ERPs (1);;Minor Impaired ALS Patients and ERPs (2);;Minor Impaired ALS Patients: P300 and Age;;Major Impaired ALS Patients and VEP (1);;Major Impaired ALS Patients and VEP (2);;Major Impaired ALS Patients and VEP (3);;Auditory Evoked Potentials (AEP);;Spatially Coded AEP (1);;Spatially Coded AEP (2);;Results I: Perception of Directional Cues;;Results II: Physiological Responses (1);;Results II: Physiological Responses (2);;Results III: Directional Cues Useful?;;Results IV: How Quick Is Quick Enough? (1);;Results IV: How Quick Is Quick Enough? (2);;Results IV: How Quick Is Quick Enough? (3);;Results IV: How Quick Is Quick Enough? (4);;Next Steps;;Support for Your AEP Experiments;;Summary;;More “aha!“ effects?;;Thanks to:'
9328,'lecture','en',8954,'2009-07-10','2009-08-10','A Robust Spelling Device for Locked-In Patients Based on Real-Time fMRI','Several medical conditions (e.g., brain injury, stroke, progressive neurological diseases) can lead to complete paralysis while largely preserving sensory and cognitive functions and associated brain activation. We investigated whether healthy subjects are able to \"write\" solely on the basis of voluntary control of the fMRI (BOLD) signal. Using a guided display technique, we show that subjects can learn in less than half an hour to produce reliably any letter of the alphabet in a single trial. To achieve this performance, subjects use three mental strategies to modulate spatio-temporal properties of the fMRI signal in three different brain areas. While the transmitted information (BOLD time courses from regions-of-interest) has been initially decoded offline by human raters, we have recently implemented a fully automatized real-time \"brain reading\" technique.The developed paradigm and decoding technique might be applied in locked-in patients to let them communicate their wishes and thoughts reliably without extensive pre-training.','A Robust Spelling Device for Locked- In Patients based on Real-Time fMRI;;Overview;;Real-Time fMRI (1);;Real-Time fMRI (2);;Real-time Statistics – Design Matrix;;Standard GLM Analysis;;Recursive Least Squares;;Real-Time fMRI;;A demonstration;;Real-Time fMRI Neurofeedback (1);;Real-Time fMRI Neurofeedback (2);;FMRI Neurofeedback - First experiment;;FMRI neurofeedback - Differential modulation of two brain regions;;Overview of fMRI Neurofeedback Studies;;Potential Clinical Implications;;Learning from a Meditation Expert;;Training Effects in Beginners;;Synchro-Scanning and Neurofeedback;;BOLD Brain Pong - Experimental Logic;;Subject Pretraining of Graded Control;;Pretraining of Graded Control - Results ;;Scanning Two Brains Simultaneously;;Interactive Neurofeedback - Experimental Setup;;Graded Control and Brain Pong Results – Example game (real-time movie);;BOLD Brain Pong - Results;;Brain Computer Interfaces (BCIs);;“Brain Writing” Brain Computer Interface Sorger et al (submitted) (1);;“Brain Writing” Brain Computer Interface Sorger et al (submitted) (2);;“Brain Writing” Brain Computer Interface Sorger et al (submitted) (3);;“Brain Writing” Brain Computer Interface Sorger et al (submitted) (4);;“Brain Writing” Brain Computer Interface Sorger et al (submitted) (5);;“Brain Writing” Brain Computer Interface Sorger et al (submitted) ();;Easy-to-use instructive display;;“Brain Writing” – Guided Display Sorger et al (submitted);;“Brain Writing” Brain Computer Interface Sorger et al (submitted) (6);;“Brain Writing” fMRI Brain Computer Interface Sorger et al (submitted) (1);;“Brain Writing” fMRI Brain Computer Interface Sorger et al (submitted) (2);;“Brain Writing” fMRI Brain Computer Interface Sorger et al (submitted) (3);;Word encoding and automated letter decoding;;“BOLD” Conversations Sorger et al (submitted);;Discussion;;Discussion and Future Work Comparison with best EEG-based systems;;Discussion and Future - Work Why not using more “direct” task, e.g. letter imagery, and MVPA? (1);;Discussion and Future Work - Why not using more “direct” task, e.g. letter imagery, and MVPA? (2);;Discussion and Future Work - Intact visual attention/fixation not required'
9330,'lecture','en',8954,'2009-07-10','2009-08-10','Modeling fMRI Dynamics','Functional MRI modeling is challenged by long-range coupling, non-linearity, and lack of detailed physiological information. I will review our progress in modeling the spatio-temporal dynamics of fMRI including hemodynamic deconvolution, blind deconvolution, and brain state decoding based on spatio-temporal kernel methods.','Modeling fMRI Dynamics;;OUTLINE;;fMRI;;BOLD fMRI: Is hemodynamicde-convolution feasible?;;BOLD hemodynamics R-Bayesmodel selection;;Multivariate neuroimaging models (1);;Multivariate neuroimaging models (2);;Generalizability;;Bias-variance trade-off as function of PCA dimension;;Learning curves for multivariate brain state decoding;;Visualization of brain state decoder representation;;…hints from asymptotic theory;;The sensitivity map;;NPAIRS: Reproducibility of parameters;;Reproducibility of internal representations;;Unsupervised learning: Factor analysis generative model;;Factor models;;Matrix factorization: SVD/PCA, NMF, Clustering;;ICA: Assume S(k,t)’s statistically independent;;Challenges for the linear factor model;;fMRI: Delayed activation in visual cortex;;Instantaneous mixing: Components1,2 (30%+30% of variance);;Instantaneous mixing cross correlation between components;;Convolutive mixing (60% of total variance);;Data representedas multiway arrays;;ERPWAVELAB;;Generalizable supervised models;;Visualization of SVM learning from fMRI;;Visualization of kernel machine internal representations;;The sensitivity map;;Sensitivity maps for non-linear kernel regression;;Initial dip data: Visual stimulus (TR 0.33s) (1);;Initial dip data: Visual stimulus (TR 0.33s) (2);;Conclusion;;Acknowledgments'
9332,'lecture','en',8954,'2009-07-10','2009-08-10','Bernstein Focus: Neurotechnology Berlin','The Bernstein Focus: Neurotechnology Berlin (BFNT-B) posits that neuroscientific results can be exploited for developing robust ‘real-world’ applications that have a major potential for (also non-medical) industry. Similar to the new paradigm of medical research ‘from bench to bedside and back’, the center brings together a multidisciplinary faculty with the aim of directly applying insights from basic neuroscience to relevant applications (‘from bench to desktop and back’). The major aim of the BFNT-B is to foster novel noninvasive ‘brain reading’ techniques to enhance man-machine interactions. Their contributions will be evaluated, e.g. in the future-oriented field of usability studies for telecommunications systems and services, or driver-assisted measures for vehicle safety.','Bernstein Focus: Neurotechnology Berlin (BFNT-B) Applications to Quality and Usability Measurement;;Motivation;;Quality - Involved perception and judgment processes.;;Quality - Auditory speech transmission qualitymeasurement.;;Quality - Taxonomy of quality aspects. (1);;Quality - Taxonomy of quality aspects. (2);;Quality - Measuring and predicting speech transmission quality.;;Quality - Measuring and predicting interactive system usability.;;Quality and Usability Prediction - Approach.;;Quality and Usability Prediction - Speech transmission quality. (2);;Quality and Usability Prediction - Speech transmission quality. (1);;Quality and Usability Evaluation - Current work involving neurotechnology.;;Quality and Usability Evaluation - Open issues for neurotechnology.;;Thank you for your attention.'
9333,'lecture','en',8954,'2009-07-10','2009-08-10','Bernstein Focus: Neurotechnology Freiburg','In spite of considerable progress towards prosthetic devices controlled by neuronal signals, brain-machine interfaces and other neurotechnological devices, however, user-friendly, neurotechnical devices for everyday use remain a vision of the future, with numerous fundamental biological, technical, computational, clinical, and ethical problems still to be solved. The aim of the BCNT-FT consortium is the development of bidirectional hybrid neurotechnical devices for human usage. This will be implemented in three research clusters, each consisting of projects organized around a common goal: to understand the principles, to advance technology, and to explore and extend clinical applications. Each project addresses issues central to neurotechnology, from basic questions on decoding neuronal signals, interfacing biological neuronal networks to technical devices, actuators and real-time feedback systems, via the stable recording and interpretation of neuronal signals, to the clinical testing and application of new technologies. Research in the BCNT-FT will be supported by a matching, interdisciplinary training program for neurotechnology. In collaboration with industrial, applied and clinical partners neuroprosthetical devices for biomedical application will be developed.',NULL
9340,'opening','sl',8651,'2009-06-05','2009-10-26','Uvodni govor organizatorja ',NULL,NULL
9341,'opening','sl',8651,'2009-06-04','2009-10-26','Predstavitev Odseka za prenos znanja v IT',NULL,NULL
9342,'tutorial','sl',8651,'2009-06-05','2009-10-26','OpenID, OAuth in Najdi.si Prijava – kako v aplikacijo vgraditi prijavo z enim klikom','Uporabniki so naveličani vnašanja osebnih podatkov v vsako spletišče posebej, a obenem vseeno željni naprednih storitev, ki jih spletišča ponujajo prijavljenim uporabnikom. Odprti standard OpenID omogoča, da uporabnik za prijavo uporabi digitalno identiteto, ki jo ima shranjeno pri izbranem ponudniku. Komplementarno, odprti standard OAuth omogoča časovno in vsebinsko omejeno posredovanje osebnih podatkov med spletišči, ki je v celoti pod nadzorom uporabnika. Na delavnici bomo predstavili uporabljene tehnologije in naredili praktični primer uporabe OpenID in OAuth, ter predstavili storitev Najdi.si Prijava, ki temelji na teh standardih.',NULL
9488,'lecture','en',8831,'2009-06-23','2009-09-24','Everithing will be on machines',NULL,NULL
9489,'lecture','en',8831,'2009-06-23','2009-09-24','Presentation of V-Lab',NULL,'INTEROP-VLab;;I-VLab: the results of several years of EI development;;Enterprise Interoperability definition;;The originality of INTEROP-VLab approach;;Missions;;INTEROP-VLab Member Poles;;Structure of INTEROP-VLab;;Who can become partner of INTEROP-VLab?;;The Scientific Activities;;The Education and Standardisation Activities;;Services and tools proposed to partners;;Services proposed around the I-V KMap;;The e-Learning Platform;;Research Project Service;;How to join INTEROP-VLab?;;Programme;;Programme 2'
9490,'lecture','en',8831,'2009-06-23','2009-09-24','Business Cases for Enterprise Interoperability - The Andalusian Aeronautics Business Case',NULL,'Business Cases for Enterprise Interoperability;;The AS-IS scenario. Cluster Introduction - 1 ;;The AS-IS scenario. Cluster Introduction - 2;;The AS-IS scenario. VO formation phase;;The AS-IS scenario. VO operation phase - 1;;The AS-IS scenario. VO operation phase - 2;;The AS-IS scenario. VO operation phase - 3;;The AS-IS scenario. VO operation phase - 4;;The To-BE scenario. VO formation phase ;;The To-BE scenario. VO operation phase - 1;;The COIN EI/EC Solutions -1 ;;The COIN EI/EC Solutions - 2;;The COIN EI/EC Solutions - 3;;The COIN expected benefits;;Overcoming the Capital Sins;;Thanks for your attention'
9491,'lecture','en',8831,'2009-06-23','2009-09-24','Coin',NULL,NULL
9492,'lecture','en',8831,'2009-06-23','2009-09-24','eBIZ-TCF: An Initiative to Improve eAdoption in European Textile/Clothing and Footwear Industry ',NULL,'eBIZ-TCF: An Initiative Improve eAdoption in European Textile/Clothing and Footwear Industry;;eBIZ-TCF At glance;;Ultimate Objective;;Project Partners;;Project Methodology;;Analysis: Level of eBusiness Adoption - 1 ;;Analysis: Level of eBusiness Adoption - 2;;Analysis: Obsticles to eBusiness Adoption in TCF sectors ;;Project Methodology;;Objectives of the architecture;;Business level: Standards specifications;;Architecture: methodology;;Architecture: business level;;Downstream: standards;;T / C Upstream;;Footwear Upstream;;Definition of the reference product classification;;Project Methodology;;What are the pilots;;Pilots, the biginning...;;...PILOTS, today;;Key Pilot Actors;;Pilots 1st phase: Overview;;Pilots 1st phase: Results - 1 ;;Pilots 1st phase: Results - 2;;Pilots 2nd phase: Overview;;Pilots: Some conclusions;;Further Information'
9493,'debate','en',8831,'2009-06-23','2009-09-24','Debate on Business Cases for Enterprise Interoperability',NULL,'ice09_debate_qa_Page_1;;ice09_debate_qa_Page_2;;EIBC Workshop: Sins - 1'
9494,'lecture','en',8831,'2009-06-23','2009-09-24','Business Cases for Enterprise Interoperability Collaborative Demand Capacity Planning (CDCP)',NULL,'Business Cases for Enterprise Interoperability Collaborative Demand Capacity Planning (CDCP);;Overview;;ITA - Information Technology for Automotive;;ITA Projects;;Changes on the Automotive Market;;CDCP Project / 1; Problems & Challenges;;CDCP Project / 2; Goals;;CDCP Project / 3; Solution Approach;;CDCP Implementation;;Synergy among ITA and COIN;;Overcoming of COIN Capital Sins / 1;;Overcoming of COIN Capital Sins / 2;;Conclusions;;Thank you for your attention!'
9495,'lecture','en',8831,'2009-06-23','2009-09-24','iSURF – Piacenza Knitwear Business Case ',NULL,'iSURF – Piacenza Knitwear Business Case ;;General overview - 1;;iSURF project;;General overview - 2 ;;Areas for RFID implementation;;RFID in the Supply Chain;;RFID in the SC - Applications -1 ;;RFID in the SC - Applications - 2;;RFID in the SC - Applications - 3;;Piacenza SC CPFR Process;;General overview - 3;;Benefit Analysis;;Benefit Analysis Overview;;Clothing Retail Benefit Application Scenario - Information exchange between retail and production;;Clothing Retail Benefit RF-ID Application Scenario Evaluation;;Retail Benefits Information exchange and interoperability ;;Retail Benefits; Applications;;Retail Benefits; Impact and exploitation ;;Clothing production; Conclusions;;Open Issues;;General overview - 4;;Cost-Benefit Analysis - Basic Issues;;Cost-Benefits Analysis - Conclusions;;Thank you!'
9496,'lecture','en',8831,'2009-06-23','2009-09-24','Collaboration and Interoperability in Production Management of Ship-Building Industry',NULL,'Collaboration and Interoperability in Production Management of Ship-Building Industry;;Outline;;Ship-Building Enterprise;;Ship-Building Processes;;Characteristics of Ship-Building Industry;;Physical View of ship-building;;Typical interoperability problems in ship-building industry - 1 ;;Typical interoperability problems in ship-building industry - 2;;Requirements of Collaboration and Interoperability in Ship-Building;;Typical interoperability problems in ship-building industry - 3 ;;Collaborative Production Management for Ship-Building -1;;Collaborative Production Management for Ship-Building -2;;Model-driven Collaboration and Interoperability;;Model-Driven Interoperability;;CIM Model;;PIM Model;;PSM model;;Model-Driven Software Generation;;Collaborative Resource Planning ;;Case study: HUANGHAI Ship-Building Co. Ltd in China ;;CORP for HUANGHAI SHIP-BUILDING Co. LTD;;Production Planning;;Co-ordination management;;Benefits of the Ship-building Co.;;Thank you! Dank!'
9497,'lecture','en',8831,'2009-06-23','2009-09-24','The eGov Financial Reporting Business Case',NULL,NULL
9498,'opening','en',8831,'2009-06-24','2009-09-24','Welcome to the COIN4LL Workshop - \"Unleashing Open Innovation with Enterprise Collaboration & Interoperability Services, the Living Lab Way\"',NULL,'Welcome to COIN4LL Workshop;;Objectives of the Workshop;;Workshop Programme'
9499,'lecture','en',8831,'2009-06-24','2009-09-24','Unleashing Open Innovation potential in Living Labs by Enterprise Interoperability and Collaboration Services: the COIN project',NULL,'Unleashing Open Innovation potential in Living Labs by Enterprise Interoperability and Collaboration Services: the COIN project;;Agenda;;The COIN Vision & Motto;;The COIN Integrated Project;;The COIN Consortium & Funnel Model;;The COIN Metaphore;;COIN Architecture;;COIN EC: state-of-the-art;;COIN EC for Open Innovation;;COIN EC: the IKE model;;COIN Value: state-of-the-art;;COIN Value for Open Innovation;;COIN Value: the TAP model;;COIN Market: starting point;;Digital Business Ecosystems;;Professional Services;;Social Services;;COIN Market: future outlook;;COIN 4 Living Labs;;Living Labs 4 COIN'
9500,'lecture','en',8831,'2009-06-24','2009-09-24',' Living Labs in Open Innovation Functional Regions ',NULL,' Living Labs in Open Innovation Functional Regions ;;Background and motivation;;Open Innovation Functional Regions and Living Labs;;Living Labs and User Driven Open Innovation;;User-driven Open Innovation: Functional Region scenario;;Action space for Living Labs along the technology adoption cycle;;LLAB Innovation Vortex for Reality Breeding: From Promising Ideas to solve user needs to validated opportunities for the ICT service market;;Functional Region: Motivations;;129 ENoLL Members including 10 outside EU;;Building the foundations of ENoLL Open Innovation System;;Open System of Living Labs Communities;;Challenges / opportunities'
9501,'lecture','en',8831,'2009-06-24','2009-09-24','Living Lab salud and alucia',NULL,'Presentation;;IAVANTE Foundation - 1;;IAVANTE Foundation - 2;;Facility - 1;;Facility - 2 ;;IAVANTE Foundation - 3;;www.informarseessalud.org;;www.saludinnova.com;;www.portaleir.es;;Virtual Simulated Patient;;What is Living Lab Andalusia Health?;;Objectives of Living Lab Andalusia Health;;Who are the members?;;What do the members provide?;;Main fields of development;;Structure and Organisation;;Working groups;;Presence in Europe;;http://livinglab.iavante.es;;For more information...'
9502,'lecture','en',8831,'2009-06-24','2009-09-24','Methodologies for Engaging Users into Research & Innovation: The Living Lab way as an Open Innovation Ecosystem',NULL,'Methodologies for Engaging Users into Research & Innovation: The Living Lab way as an Open Innovation Ecosystem;;User/Citizen Centric Open Innovation;;User Innovation: Engaging users into the Innovation process - 1;;User Innovation: Engaging users into the Innovation process - 2;;User Centred Design;;UCD Stages;;Contextual Design Process;;Experience Design;;The Crowdsourcing Process (Web2.0, Mass Collaboration);;The Wisdom of Crowds;;The Living Lab Approach;;Examples of User Experience Prototyping Environment;;Examples of User Experience in their Natural Environment;;Living Labs & Open Innovation: How it works?;;Examples of Collaboration Services;;References'
9503,'lecture','en',8831,'2009-06-24','2009-09-24','COIN Collaborative Product Development Services',NULL,'COIN4Llabs COIN Collaborative Product Development Services;;The COIN EI/EC Solutions - Baseline Services;;The COIN EI/EC Solutions - Innovative Services;;Collaborative - Product Development Services - COIN C-PD services in PLM Lifecycle - 1;;Collaborative - Product Development Services - COIN C-PD services in PLM Lifecycle - 2;;Collaborative - Product Development Services - Semantic c-PD web services - 1;;Collaborative - Product Development Services - Semantic c-PD web services - 2;;Collaborative - Product Development Services - Semantic c-PD web services - 3 ;;Collaborative - Product Development Services - Advanced semantic c-PD web services - 1;;Collaborative - Product Development Services - Advanced semantic c-PD web services - 2;;Collaborative - Product Development Services - Collaborative 3D designer web service - 1;;Collaborative - Product Development Services - Collaborative 3D designer web service - 2;;Collaborative - Product Development Services - Advanced Visualization web services;;Collaborative - Product Development Services - Semantic Document Management web services - 1;;Collaborative - Product Development Services - Semantic Document Management web services - 2;;Thanks for your attention'
9504,'lecture','en',8831,'2009-06-22','2009-09-24','EI Science Base initiative: a state-of-play from the Commission',NULL,'Towards an Enterprise Interoperability Science Base?;;Vision of our Research Domain (Future Internet Enterprise Systems);;History of the initiative;;Why this is initiative?;;Why a Science Foundation?;;EISB Current approach;;Current Plan;;Precautionary principle;;Why a Science Foundation for EI?'
9505,'lecture','en',8831,'2009-06-22','2009-09-24','Task Forceon Enterprise Interoperability Science Base',NULL,'Task Force on Enterprise Interoperability Science Base;;Relationship with EC EISB Task Force and Forum;;INTEROP-VLab EISB Task Force Roles'
9506,'lecture','en',8831,'2009-06-22','2009-09-24','On the Scientific Basis of Enterprise Interoperability',NULL,'On the Scientific Basis of Enterprise Interoperability;;Evolution of human knowledge: from Science to Engineering;;Model as the key product of Science;;GMT - General Model Theory;;On the benefits of Science Base;;On EISB Benefits (2);;On EISB Benefits (3);;Science Base for Enterprise Interop;;Levels of Enterprise Interoperability;;A Synoptic view;;A layered design framework;;An example;;Conclusions'
9507,'lecture','en',8831,'2009-06-22','2009-09-24','Towards Semantic Interoperability in an Evolving Environment',NULL,'Towards Semantic Interoperability in an Evolving Environment;;... et respice finem;;Requirements for Interoperability Support;;Distributed Information Systems;;Sub-Problem exchange of documents;;Evolution an different levels;;Possible solution 1;;Possible solution 2: Proposed architecture;;Scientific Basis for Evolvable Interoperability;;Need for (semi-)automatic adoption;;Conclusion:;;Possible Solution 1'
9508,'lecture','en',8831,'2009-06-22','2009-09-24','Dealing with Interoperability:An Agent-Oriented Perspective',NULL,'Dealing with Interoperability: An Agent-Oriented Perspective;;Designing Service-Oriented Architectures;;Semantic Services vs. MDA/MDD;;Interactions in SOA;;FIPA Specifications for Agent Communication;;A FIPA and WS-Addressing Mapping;;Transformation of SOA into a Message-Oriented Architecture;;Semantics of Basic Communicative Acts;;Process Alignment;;Proposal for Research Topics'
9509,'debate','en',8831,'2009-06-24','2009-09-24','Living Labs solutions debate',NULL,NULL
9510,'lecture','en',8831,'2009-06-22','2009-09-24','System Theory to support Enterprise Interoperability Science Base ',NULL,'System Theory to support Enterprise Interoperability Science Base;;Introduction;;Contribution to Science Base in EI;;Why non-interoperability? (on Natural Science);;A Framework for solving EI problems;;System Theory (on Artificial Science);;System of Systems;;Contribution of System Theory;;Application: ATHENA project;;GRAI Modellin Process (Global view);;GRAI Process modellin (detailed view);;GRAI decision model;;Conclusions'
9511,'lecture','en',8831,'2009-06-22','2009-09-24','Towards EI as a science: Considerations and points of view',NULL,'Towards EI as a science: Considerations and points of view;;GRIS Group for Research in Interoperability of Systems;;Enterprise Interoperability;;Science and Engineering;;What is EI today? What about tommorrow?;;EI and interoperability in other domains;;EI and Complex Systems;;System\'s dynamics (non linear behaviour);;Dynamics bahaviour;;Theory for knowledge interoperability* - 1 ;;Mazimation of transfer;;Maximization of recoverability;;Theory for knowledge interoperability* - 2;;Challenge: Move from Complexity to Understandibility by KI;;Current situation and the IQ;;Do we really need EI science? Advantages? Risk?;;Towards EI as science: Considerations and points of view'
9512,'debate','en',8831,'2009-06-23','2009-09-24','Breeding Business Success - West midlawos collaborative commerce marketplace',NULL,NULL
9533,'lecture','en',9019,'2009-07-21','2009-08-21','Multi-Strategy Trading Utilizing Market Regimes','This video considers the problem of dynamically allocating capital to a portfolio of trading strategies.\nThe allocation should be robust, and the capital allocated to a trading strategy should reflect\nthe confidence in the expected profit that the strategy will make in current market conditions.\nGood trading strategies exploit recurring market dynamics that can be more prevalent in some time\nperiods than in others. Indeed, the concept of regimes is fundamental to financial markets, and much\nresearch has focused on the detection of regime shifts. In this paper, we consider a regime as defined\nby a set of trading strategies that exhibit similar performance in a given time period.\nWe consider different parameterizations of the same strategy as distinct in our ground set of strategies.\nThe trading problem is to pick a distribution over the ground set that will achieve good performance\nin the current time period. That we typically choose a distribution of support greater than\none reflects uncertainty on many levels, and allows diversification of risk and return drivers.\nWe provide a simple algorithm that empirically picks distributions that often approximate the performance\nof an oracle that picks the best trading strategy in each period from the ground set. To\nthis end, we explicitly define regimes as subsets of strategies. An initial phase is to rule out a large\nnumber of regimes as irrelevant to counter the combinatorial explosion of dealing with subsets.\nIn the training phase of our algorithm, we pick random time windows and learn two functions: the\nfirst, classifyMarket, is for (probabilistic) regime classification and takes as input the market data\nand produces a distribution over regimes; the second, stFuncDist, produces for each regime a distribution\nover strategies, where strategies believed to be good in that regime are assigned higher\nprobability. The main tools we use are Monte Carlo permutation tests and incremental re-weighting\nof probabilities. In the trading phase we use a standard “walk-forward” approach. In the in-sample\nperiod we use the trading results for regime classification, and in the out-of-sample period we allocate\ncapital according to the combination classifyMarket determined from the in-sample period and\nthe current stFuncDist. This is a simple algorithm, but an empirically successful one - an indication\nof which we report. The approach bears some similarity to Sequential Monte Carlo methods [3] in\nthat it sequentially re-weights hypotheses (in our case, regarding suitability of strategies).\nIn the final section, we discuss an approach to modelling the time evolution of strategy fitnesses\nwith a view towards characterizing regimes. This could be used to guide our choice of in-sample\nof out-of-sample periods in the existing setup. We present preliminary results in this direction. In\ncurrent work, we are trying to extend the basic algorithm in such a way that we can more directly\nmake use of the Sequential Monte Carlo method, such as particle filter based estimation of strategy\nfitness that might parsimoniously accomplish what is done above with permutation tests.','Multi-Strategy Trading Utilizing Market Regimes;;The Portfolio Allocation Problem (1);;The Portfolio Allocation Problem (2);;The Portfolio Allocation Problem (3);;The Portfolio Allocation Problem (4);;The Portfolio Allocation Problem (5);;Model-free\" Portfolio Allocation (1);;Model-free\" Portfolio Allocation (2);;Model-free\" Portfolio Allocation (3);;Model-free\" Portfolio Allocation (4);;Utilizing Market Context (1);;Utilizing Market Context (2);;Utilizing Market Context (3);;Utilizing Market Context (4);;Utilizing Market Context (5);;Utilizing Market Context (6);;Portfolio Allocation - Our Approach (1);;Portfolio Allocation - Our Approach (2);;Portfolio Allocation - Our Approach (3);;Portfolio Allocation - Our Approach (4);;Portfolio Allocation - Our Approach (5);;Portfolio Allocation - Our Approach (6);;Our Approach - Two Major Concepts (1);;amlcf09_ramamoorthy_mstumr_01_Page_24;;amlcf09_ramamoorthy_mstumr_01_Page_25;;amlcf09_ramamoorthy_mstumr_01_Page_26;;Our Approach - Two Major Concepts (2);;amlcf09_ramamoorthy_mstumr_01_Page_28;;On Trading Strategies (1);;On Trading Strategies (2);;On Trading Strategies (3);;amlcf09_ramamoorthy_mstumr_01_Page_32;;On Trading Strategies (1);;On Trading Strategies (2);;Portfolio Allocation Algorithm: A Template (1);;Portfolio Allocation Algorithm: A Template (2);;Portfolio Allocation Algorithm: A Template (3);;Simplest Instantiation: Trade with Best In-Sample Strategy (1);;Simplest Instantiation: Trade with Best In-Sample Strategy (2);;Simplest Instantiation: Trade with Best In-Sample Strategy (3);;Performance: Trading with Best In-Sample Strategy;;Observations: Trading with Best In-Sample Strategy;;Another Simple Instantiation: k-NN (1);;Another Simple Instantiation: k-NN (2);;Regimes - Layered Graph of Strategies (1);;Regimes - Layered Graph of Strategies (2);;Regimes - Layered Graph of Strategies (3);;Regimes - Layered Graph of Strategies (4);;Regimes - Layered Graph of Strategies (5);;Regimes - Layered Graph of Strategies (6);;Regimes - Layered Graph of Strategies (7);;Regimes - Layered Graph of Strategies (8);;Regimes - Layered Graph of Strategies (9);;amlcf09_ramamoorthy_mstumr_01_Page_54;;amlcf09_ramamoorthy_mstumr_01_Page_55;;amlcf09_ramamoorthy_mstumr_01_Page_56;;amlcf09_ramamoorthy_mstumr_01_Page_57;;amlcf09_ramamoorthy_mstumr_01_Page_58;;Algorithm: REgime Detection and STrategy OPtimization (1);;Algorithm: REgime Detection and STrategy OPtimization (2);;Algorithm: REgime Detection and STrategy OPtimization (3);;Algorithm: REgime Detection and STrategy OPtimization (4);;Performance of RED-STOP Algorithm (1);;Performance of RED-STOP Algorithm (2);;amlcf09_ramamoorthy_mstumr_01_Page_65;;amlcf09_ramamoorthy_mstumr_01_Page_66;;amlcf09_ramamoorthy_mstumr_01_Page_67;;amlcf09_ramamoorthy_mstumr_01_Page_68;;amlcf09_ramamoorthy_mstumr_01_Page_69;;Discussion (1);;Discussion (2);;Discussion (3);;Conclusions (1);;Conclusions (2);;Conclusions (3);;Conclusions (4);;Conclusions (5);;Conclusions (6);;Conclusions (7);;Conclusions (8);;Conclusions (9);;Conclusions (10)'
9534,'lecture','en',9019,'2009-07-20','2009-08-21','The More Rating: New Model -a comparative analysis of different companies from different countries-\"','This video discusses a specific model for assessing credit risk of Industrial\ncompanies by using financial statement data and industry-specific information.\nIn particular, the model permits each enterprise to associate a fundamental credit\nrating giving an indication of the creditworthiness of industrial companies.',NULL
9537,'lecture','en',9019,'2009-07-20','2009-08-21','Dynamic Portfolio Management with Transaction Costs','We develop a recurrent reinforcement learning (RRL) system that directly induces\nportfolio management policies from time series of asset prices and indicators,\nwhile accounting for transaction costs. The RRL approach learns a direct mapping\nfrom indicator series to portfolio weights, bypassing the need to explicitly\nmodel the time series of price returns. The resulting policies dynamically optimize\nthe portfolio Sharpe ratio, while incorporating changing conditions and transaction\ncosts. A key problem with many portfolio optimization methods, including\nMarkowitz, is discovering ”corner solutions” with weight concentrated on just a\nfew assets. In a dynamic context, naive portfolio algorithms can exhibit switching\nbehavior, particularly when transaction costs are ignored. In this work, we extend\nthe RRL approach to produce better diversified portfolios and smoother asset\nallocations over time. The solutions we propose are to include realistic transaction\ncosts and to shrink portfolio weights toward the prior portfolio. The methods\nare assessed on a global asset allocation problem consisting of the Pacific, North\nAmerica and Europe MSCI International Equity Indices.','Dynamic portfolio management with transaction costs;;Objectives and methodology;;Dynamic portfolio management;;Experiments;;Time series of asset prices;;Time series of returns;;Initial portfolio;;Passive management: Market capitalization;;Active management (no transaction costs);;Portfolio value (without transaction costs);;Portfolio value (with transaction costs);;Recurrent RL architecture (without transaction costs);;Recurrent RL architecture (with transaction costs);;RRL architecture (without transaction costs);;RRL architecture (with transaction costs);;Measures of performance: Portfolio value;;Measures of risk;;Balancing risk and performance: Sharpe ratio;;Exponential moving average Sharpe ratio;;Differential Sharpe ratio;;Maximizing the Differential Sharpe ratio;;Learning protocol;;Results (without costs);;Results (with costs);;Conclusions (I);;Conclusions (II)'
9538,'invited talk','en',9019,'2009-07-20','2009-08-21','Modelling decimalisation in the Nasdaq stockmarket',NULL,'Agent-Based Modeling of the Nasdaq Stock Market and Predicting the Impact of Rule Changes;;Problem Statement;;Goals;;Problem Architecture;;Model Implementation;;Philosophical Observations;;Agent Details;;Simulation Basics;;Investor – Market Maker Interaction and Parasitism;;Model Structure;;Model Features;;Model Calibration;;Questions Investigated;;Tick size effects;;Tick Size Effects, Many Parasites;;Fat Tail Results;;Original Gaussian Distribution;;Fat Tails in Simulated Average Price Dynamics;;Time Correlations and Fat Tails;;Why Fat Tails in the Simulation?;;Spread Clustering (1);;Spread Clustering (2);;Importance of Spread Clustering;;Learning in the Simulation;;Phase Transitions;;Summary of Findings;;Comparisons with Data;;Comparisons with Data (Cont.);;Nasdaq Book;;Longer-Term Effects;;Future Directions;;Summary and Conclusions'
9540,'lecture','en',9019,'2009-07-20','2009-08-21','The Effect of Reinforcement Learning Agents in Double-Auction Markets','Several time series models such as ARCH and GARCH have been developed to forecast volatility\nusing asset returns data. However, these methods ignore one key source of market volatility: financial\nnews. Similarly, asset pricing models often describe the arrival of novel information by a jump\nprocess, but the characteristics of the underlying jump process are only coarsely, if at all, related to\nthe underlying news source. Our objective in this paper is to show that recent advances in statistical\nlearning allow a much more refined analysis of the impact of news on asset prices.\nIn this paper, we demonstrate that information from press releases can be used to predict intraday\nabnormal returns with relatively high accuracy. We form a text classification problem where\npress releases are labeled positive if the absolute return jumps at some (fixed) time after the news\nis made public. First, abnormal returns are predicted using support vector machines in similar fashion\nto [1]. Given a press release, we predict whether or not an abnormal return will occur in the\nnext 10, 20, ..., 250 minutes using either text or past absolute returns. Our experiments analyze predictability\nat many horizons and demonstrate significant initial intraday predictability that decreases\nthroughout the trading day. Second, we optimally combine text information with asset price time\nseries to significantly enhance classification performance using multiple kernel learning (MKL).We\nuse an analytic center cutting planemethod (ACCPM) to solve the resultingMKL problem. ACCPM\nis particularly efficient on problems where the objective function and gradient are hard to evaluate\nbut whose feasible set is simple enough so that analytic centers can be computed efficiently. Furthermore,\nbecause it does not suffer from conditioning issues, ACCPM can achieve higher precision\ntargets than other first-order methods.',NULL
9541,'invited talk','en',9019,'2009-07-21','2009-08-21','Machine Learning Based Prediction in Financial Markets','Forecasting models generally do a very poor job in predicting future returns in financial markets which\nare characterized by high levels of noise. It is commonly known that predictions of typical autoregressive\ntime series forecasting models, for example, are usually very conservative – meaning close to the mean –\nbecause of the inherent difficulty of making accurate forecasts. This situation is particularly discouraging\nsince it is the large future values that we especially care about predicting accurately. Machine learning\nmethods provide a potential solution to this problem by providing multiple models that each of which\nmakes forecasts of different magnitudes. The obvious problem with this approach is overfitting,\nespecially if the learner has no constraints on how complex its models can be. In this talk, I present the\ntradeoffs between increased the model complexity and forecast accuracy based on a mix of trading results\nand current research.',NULL
9542,'lecture','en',9019,'2009-07-21','2009-08-21','Modelling Financial Time Series using Grammatical Evolution','The traditional models of price, and its statistical signatures are often based on\nlimiting assumptions, such as linearity. Moreover, the model developer is faced\nwith the model selection problem, and model uncertainty. In this paper we introduce\na method based on Grammatical Evolution (GE) to evolve models for\npredicting financial returns, and we examine the profitability of these models. Our\nempirical analysis demonstrates that for some securities our method is able to produce\nmodels of return that are lead to more profitable trading compared with an\nAutoregressive model picked using Aikake Information Criterion (AIC), under the\nassumption of frictionless markets.','Modelling Financial Time series using Grammatical Evolution;;Motivation;;Framework (1);;Framework (2);;Framework (3);;Data (1);;Data (2);;Data (3);;Data (4);;Elitist;;GE Elitist Vs Buy & Hold, and AR Model;;Conclusion & Future Work'
9544,'lecture','en',9019,'2009-07-21','2009-08-21','Modeling Dependence in Financial Data with Semiparametric Archimedean Copulas','Copulas are useful tools for the construction of multivariate models because they\nallow to link univariate marginals into a joint model with arbitrary dependence\nstructure. While non-parametric copula models can have poor generalization performance,\nstandard parametric copulas often lack expressive capacity to capture\nthe dependencies present in financial data. In this work, we propose a novel\nsemiparametric bivariate Archimedean copula model that is expressed in terms\nof a latent function. This latent function is approximated using a basis of natural\nsplines and the model parameters are selected by maximum penalized likelihood.\nExperiments on financial data are used to evaluate the accuracy of the proposed\nestimator with respect to other benchmark methods: Two flexible estimators of\nArchimedean copulas previously introduced in the literature, two approaches for\ncopula estimation that allow for more general dependencies and three parametric\ncopulas models. The proposed semiparametric copula model has excellent in and\nout-of-sample performance, which makes it a useful tool for modeling multivariate\nfinancial data.','Modeling Dependence in Financial Data with Semiparametric Archimedean Copulas;;Outline (1);;Outline (2);;Copulas and Computational Finance;;Definition of a copula function;;Eliminating the marginals;;Eliminating the marginals (continued);;Some bivariate copula functions;;Some bivariate copula densities;;Parametric, non-parametric and semiparametric copulas;;Outline (3);;Bivariate Archimedean copulas;;Parameterizations of Bivariate Archimedean copulas;;Some plots of g for parametric Archimedean copulas;;periments with financial data Modeling g;;Estimation of g;;Outline (4);;The data;;Modeling the marginal distributions;;Benchmark copula estimation methods;;Experimental protocol;;Average log-likelihood for each method on each problem;;Some copula density estimates;;Summary;;Thanks!'
9548,'invited talk','en',9019,'2009-07-21','2009-08-21','Empirical Portfolio Selection','Dark pools are a relatively recent type of equities exchange in which\ntransparency is deliberately limited in order to minimize the market\nimpact of large-volume trades. The success and proliferation of dark \npools has also led to a challenging and interesting problem in\nalgorithmic trading --- namely, optimizing the distribution of a large \ntrade over multiple competing dark pools. In this work we formalize\nthis as a problem of multi-venue exploration from censored data, and\nprovide a provably efficient and near-optimal algorithm for its solution.\nThis algorithm and its analysis has much in common with well-studied\nalgorithms for exploration-exploitation in reinforcement learning, and\nis evaluated on dark pool execution data from a large brokerage.\n','Empirical portfolio selections;;Portfolio selections (1);;Portfolio selections (2);;Portfolio selections (3);;Portfolio selections (4);;Portfolio selections (5);;Portfolio selections (6);;Growth rate (1);;Growth rate (2);;Growth rate (3);;Growth rate (4);;Growth rate (5);;Static portfolio selection: single period investment (1);;Static portfolio selection: single period investment (2);;Static portfolio selection: single period investment (3);;Static portfolio selection: single period investment (4);;Static portfolio selection: single period investment (5);;Static portfolio selection: single period investment (6);;Static portfolio selection: single period investment (7);;Dynamic portfolio selection: multi-period investment (1);;Dynamic portfolio selection: multi-period investment (2);;Dynamic portfolio selection: multi-period investment (3);;Dynamic portfolio selection: multi-period investment (4);;Dynamic portfolio selection: multi-period investment (5);;Dynamic portfolio selection: multi-period investment (6);;Dynamic portfolio selection: multi-period investment (7);;Dynamic portfolio selection: multi-period investment (8);;Dynamic portfolio selection: multi-period investment (9);;Dynamic portfolio selection: multi-period investment (10);;Dynamic portfolio selection: multi-period investment (11);;Dynamic portfolio selection: multi-period investment (12);;log-optimum portfolio (1);;log-optimum portfolio (2);;log-optimum portfolio (3);;log-optimum portfolio (4);;History (1);;History (2);;History (3);;History (4);;History (5);;History (6);;History (7);;History (8);;Dynamic portfolio selection: general case (1);;Dynamic portfolio selection: general case (2);;Dynamic portfolio selection: general case (3);;Dynamic portfolio selection: general case (4);;Dynamic portfolio selection: general case (5);;Dynamic portfolio selection: general case (6);;log-optimum portfolio (5);;log-optimum portfolio (6);;Optimality (1);;Optimality (2);;Proof (1);;Proof (2);;Proof (3);;Universally consistent portfolio;;Empirical portfolio selection (1);;Empirical portfolio selection (2);;Empirical portfolio selection (3);;Empirical portfolio selection (4);;Empirical portfolio selection (5);;Empirical portfolio selection (6);;Empirical portfolio selection (7);;Empirical portfolio selection (8);;Empirical portfolio selection (9);;Empirical portfolio selection (10);;Empirical portfolio selection (11);;Regression function (1);;Regression function (2);;Regression function (3);;Regression function (4);;Regression function (5);;Regression function (6);;Regression function (7);;Regression function (8);;Correspondence (1);;Correspondence (2);;Correspondence (3);;Kernel-based portfolio selection (1);;Kernel-based portfolio selection (2);;amlcf09_gyorfi_eps_01_Page_082;;Combining elementary portfolios (1);;Combining elementary portfolios (2);;Combining elementary portfolios (3);;Exponential weighing (1);;Exponential weighing (2);;Exponential weighing (3);;Exponential weighing (4);;Exponential weighing (5);;Exponential weighing (6);;Exponential weighing (7);;Exponential weighing (8);;Exponential weighing (9);;Exponential weighing (10);;Exponential weighing (11);;Theorem;;Proof (1);;Proof (2);;Proof (3);;Proof (4);;Proof (5);;Proof (6);;Proof (7);;Proof (8);;Proof (9);;Semi-log-optimal portfolio (1);;Semi-log-optimal portfolio (2);;Semi-log-optimal portfolio (3);;Semi-log-optimal portfolio (4);;Semi-log-optimal portfolio (5);;Conditions of the model;;NYSE data sets (1);;NYSE data sets (2);;Experiments on average annual yields (AAY) (1);;Experiments on average annual yields (AAY) (2);;Experiments on average annual yields (AAY) (3);;Experiments on average annual yields (AAY) (4);;The average annual yields of the individual experts, for the 19 large assets'
9549,'lecture','en',9019,'2009-07-21','2009-08-21','Dynamic Asset Allocation for Bivariate Enhanced Index Tracking using Sparse PLS','Index tracking is a popular portfolio management strategy which involves creating a portfolio whose\nreturns track very closely those achieved by a benchmark index. There are two interconnected problems\nassociated with index tracking: asset selection and asset allocation. Asset selection involves\nselecting a subset of p out of n available assets, whereas asset allocation involves investing a proportion\nof the total available capital in each one of the p assets with the objective of reproducing the\nperformance of the index. The capital invested in asset i is in proportion i of the total capital so that\nPp\ni=1 i = 1. These portfolio weights are generally estimated by minimzing the tracking error, that\nis the error between the index returns yt and the portfolio returns ˆy, given by T−1PT\nt=1(yt − ˆyt)2.\nFollowing this setting, the problem of asset allocation becomes a standard regression problem with\nthe portfolio weights being the parameters to be estimated.\nIn the literature, only a few attempts have been made to tackle both the asset selection and allocation\nproblems at the same time; for instance, [8] use a quadratic programming approach and the method\nin [3] is based on genetic algorithms. Our interest lies in taking a unified approach which simultaneously\nselects a subset of assets in the available basket and minimizes the tracking error. We take a\nregularized regression approach. In a full index replication scenario, asset selection can be thought\nof as assigning certain assets a zero weight, so that those assets are not included in the portfolio,\nwhereas the selected one should be able to reproduce the index. These ideas have recently been\nexploited in the context of minimum variance portfolios and L1-penalized least squares have been\nproved to be a promising method for creating robust portfolios [4]; see also the related work by [5].\nWe extend on these ideas in three main ways. Firstly, we consider a multivariate version of the index\ntracking problem, where the selected portfolio is expected to reproduce the performance of multiple\nindices. Secondly, we are interested in enhanced versions of the indices to be tracked so that the\nportfolio is also expected to overperform each index by a given annual percentage return (say, plus\n15%). Thirdly, we propose a methodology that works well in real-time and is fully adaptive, in the\nsense that both the asset allocation and optimization solutions can be updated in a recursive manner,\nkeeping the number of computations low, every time new data points are made available. This\nlast feature makes the methodology more robust against non-stationarities presented in the data and\nyelds superior tracking results, before transaction costs.','Dynamic Asset Allocation for Bivariate Enhanced Index Tracking using Sparse PLS;;Index Tracking;;The Problem;;Singular Value Decomposition (SVD);;Principal Components Analysis (PCA);;Partial Least Squares Regression (PLS);;PLS;;LASSO (Tibshirani, 1996);;Regularized SVD;;Sparse PLS;;Solving PLS online;;Incremental Sparse PLS (iS-PLS);;Adaptive Forgetting;;Simulation Results (1);;Simulation Results (2);;Simulation Results (3);;Simulation Results (4);;Application to Bivariate Index Tracking (1);;Application to Bivariate Index Tracking (2);;Application to Bivariate Index Tracking (3);;Summary;;Limitations and Future Work;;References'
9551,'invited talk','en',9019,'2009-07-21','2009-08-21','Are markets efficient? A view from micro-structural data','Efficient market theory posits that market prices reflect at any instant of time the fundamental value of assets, and can only change because of unpredictable news or other information items that affect this fundamental value. If true, well, systematic quantitative strategies should not work. But of course this picture cannot strictly hold – for one thing someone should process information and push the price towards its putative true value. There should be at least some kind of tatonnement and arbitrage opportunities at high frequencies. In order to dissect these possible mispricing mechanisms and to devise profitable high frequency trading and execution models, the detailed study of order flow and order books has become mandatory. \n\nMuch as in physics, where the detailed understanding of the microscopic world provides invaluable insight on macroscopic phenomena, we believe that a consistent picture of the microstructure mechanisms will help put in perspective some of the traditional questions about markets and prices, such as: “Are prices in equilibrium?”, “What is the information content of these prices?”, or “Why is the volatility so high?”. It will also allow one to optimize execution costs, which for large AUMs is mostly due to impact.\n\nEmpirical data reveals an unexpectedly subtle price formation mechanism. Order flow turns out to be a highly persistent, long memory process, both in sign and volume. This reflects the fact that even on very liquid markets, the revealed liquidity is in fact extremely small (typically 0.001% of the market cap of a stock). Large orders to buy or sell can only be traded incrementally, over periods of time as long as months. Hence prices cannot be instantaneously in equilibrium, and cannot instantaneously reflect all available information. There is nearly always a substantial offset between latent offer and latent demand that only slowly gets incorporated in prices. \n\nMaintaining compatibility with market efficiency has profound consequences on price formation, on the dynamics of liquidity, and on the nature of impact. On anonymous, electronic markets, there cannot be any distinction between “informed” trades and “uninformed” trades. The average impact of all trades must be the same, which means that impact must have a mechanical origin: if everything is otherwise held constant, the appearance of an extra buyer (seller) must on average move the price up (down).\n\n\nA body of theory that makes detailed quantitative predictions about the volume and lag dependence of market impact, the bid-ask spread, order book dynamics,\nand volatility has been recently put forth [1,2,3,4]. This framework allows one to make quantitative models of execution costs in terms of a time dependent (non-local) friction kernel. \n\nIt also suggests a novel interpretation of financial information. The theory of rational expectations and efficient markets has increasingly emphasized information and belittled the role of supply and demand, in contradiction with the intuition of traders and of the layman. Our recent work on the role of news on price jumps [5] also shows that information in the traditional sense is not the main driver of market volatility. Rather, we highlight the role of fluctuations in supply and demand, which may or may not be exogenous, and may or may not be informed – it does not really matter. Attempts to estimate ex-post the fraction of truly informed trades actually leads to very small numbers, at least judged on a short time basis, meaning that the concept of informed trades is not very useful to understand what is going on in markets at high frequencies. But still, prices manage to be almost perfectly unpredictable, even on very short time scales. The conclusion is that any useful notion of information must be internal to the market: trades, order flow, cancellations are information, whatever the final cause of these events may be.\n',NULL
9553,'lecture','en',9019,'2009-07-20','2009-08-21','Predicting Abnormal Returns From News Using Text Classification',NULL,'Predicting Abnormal Returns From News Using Text Classification;;A Market Classification Problem;;Experimental Setup;;Data;;Text classification in finance;;Support Vector Machines;;Performance Measures;;Predicting Abnormal Returns (75% with only SVM);;Strategy: Hedged Covered Call Options;;Predicting Daily Abnormal Returns;;Kernel Optimization (1);;Kernel Optimization (2);;Analytic Center Cutting Plane Method;;Algorithm 1 Analytic center cutting plane method;;How do these algorithms compare against each other?;;Kernel Optimization - Improvements? (75% Threshold);;Final Remarks Further Directions'
9554,'lecture','en',9019,'2009-07-21','2009-08-21','Modeling the S&P 500 Index using the Kalman Filter and the LagLasso','This video introduces a method to predict upward and downward monthly variations\nof the S&P 500 index by using a pool of macro-economic and financial\nexplicative variables. The method is based on the combination of a denoising\nstep, performed by Kalman filtering, with a variable selection step, performed\nby a Lasso-type procedure. In particular, we propose an implementation of the\nLasso method called LagLasso which includes selection of lags for individual factors.\nWe provide promising backtesting results of the prediction model based on a\nnaive trading rule.',NULL
9579,'invited talk','en',9515,'2009-08-03','2009-08-07','QCA and fuzzy sets','This course examines the family of \'configurational comparative methods\' (CCM). First, the course spells out the fundamental concepts that underlie the configurational comparative approach. In the framework of the general literature on comparative empirical social research, participants are made familiar with issues such as concept formation, truth tables, basic Boolean algebra, ideal types, and property spaces. Then participants are trained to use the most widely used of the CCM so far: dichotomous Qualitative Comparative Analysis (csQCA). The practical steps and best practices of csQCA (including software use: TOSMANA and fs/QCA) are taught: first the basic procedures, then various refinements. The course is concluded with an overview of linked developments such as fuzzy set QCA (fsQCA) and multi-value QCA (mvQCA) and the combination of QCA with other methods. Real-life, published applications are used throughout the course; participants are also encouraged to bring their own data, if available. Some basic quantitative or qualitative methodological training is probably useful to get more out of the course, but participants with little methodological training should find no major obstacles to follow the course. Above all, participants should be motivated to engage in rigorous comparative analysis.',NULL
9580,'invited talk','en',9515,'2009-08-03','2009-08-07','Multiple regression analysis','The course starts with a discussion of the logic of the multivariate regression model and the central assumptions underlying the ordinary least squares approach. Then it proceeds with testing for the adequacy of the assumptions and suitable corrections and extensions to the estimation techniques in the context of cross-sectional data. Particular emphasis will be laid on multicollinearity and heteroskedasticity. The second part of the course focuses on functional form. Models that are nonlinear in variables but linear in parameters, dummy variables, and interaction terms will be covered. In the third part, various topics arising with special data are covered. Firstly, the analysis of binary dependent variables is introduced. Secondly, problems involved with the analysis of longitudinal data, i.e. time series and panel data, are discussed, with special emphasis on autocorrelation. The course assumes proficiency with descriptive and inferential statistics at the level of test theory and bivariate regression analysis. ',NULL
9581,'invited talk','en',9515,'2009-08-03','2009-08-07','Mixed methods research','This interactive course provides new and seasoned researchers with a framework in a step-by-step manner for using quantitative and qualitative research approaches within the same study. The instructor will provide many published examples and illustrate how to conduct mixed methods research using both statistical software such as SPSS and qualitative software such as QDA Miner. Participants will be able to understand the historical underpinnings of mixed methods research, define and explain mixed methods research in its current form, describe the major steps in the mixed methods research process, identify goals and objectives for mixed methods research studies, identify mixed methods techniques for conducting literature reviews, identify the rationale and purpose for mixing quantitative and qualitative approaches, design mixed methods research questions, describe the role of sampling in the mixed methods research process, compare and contrast several mixed methods research designs, describe several ways of collecting data in mixed methods research studies, conduct mixed methods data analyses, link research questions to mixed methods data analysis techniques, identify how to make quality meta-inferences, explain the major legitimation types in mixed methods research, and understand issues and standards involved in conducting, reporting, and publishing mixed methods research. ',NULL
9582,'invited talk','en',9515,'2009-08-04','2009-08-07','Creative Environment and Young Researchers Performance: The Keys to PhD Students Success','The results of the study (also conducted by Hajdeja Iglič, Franc Mali, Uroš Matelič\nand Petra Ziherl) presented in this lecture confirm other empirical results obtained by\nsociological research on the activities of research groups (e.g., Hemlin, Allwood in Martin\n2004): creativity or research productivity of young researchers is strongly influenced by intrasocial\nfactors such as autonomy, flexibility, cooperation, etc. More precisely, this study\nconfirms that, at the micro level, the relationships among the researchers, especially between\nthe young researcher and his/her mentor, play an important role for the young researcher\'s\nscientific performance. This is especially true in the phase of the socialisation and\nprofessionalisation of young scientists (during the Ph.D. research).',NULL
9583,'debate','en',9515,'2009-08-04','2009-08-07','‘Creative Environment and Young Researchers’ Performance: The Keys to PhD','After the lecture and a reaction from the discussant, an open debate will be held with the\naudience, both on substantive and methodological issues.',NULL
9586,'tutorial','en',NULL,'2009-08-18','2009-08-24','Computer Verified Exact Analysis','This tutorial will illustrate how to use the Coq proof assistant to implement effective and provably correct computation for analysis. Coq provides a dependently typed functional programming language that allows users to specify both programs and formal proofs.\n\nWe will introduce dependent type theory and show how it can be used to develop both mathematics and programming. We will show how to use dependent type theory to implement constructive analysis. Specifically we will cover how to implement effective real numbers and effective integration.\n\nThis work will be done using the Coq proof assistant. The tutorial will cover how to use the Coq proof assistant. Attendees are encouraged to download and install Coq 8.2 from http://coq.inria.fr/download and also download and make the full system of C-CoRN from http://c-corn.cs.ru.nl/download.html beforehand.','Tutorial: Computer veried implementation of analysis;;Meeting in Nijmegen;;Outline;;Two motivations;;Computing with real numbers - 1;;Computing with real numbers - 2;;Computing with real numbers - 3;;Computing with real numbers - 4;;Computing with real numbers - 5;;Computing with real numbers - 6;;Exact analysis;;Computational framework;;Motivation - 1;;Motivation - 2;;Motivation - 3;;Motivation - 4;;Motivation - 5;;Proof assistant - 1;;Proof assistant - 2;;Proof assistants - 1;;Proof assistants - 2;;Proof assistants - 3;;Proof assistants - 4;;Proof assistants - 5;;Proof assistants - 6;;Motivation - 6;;Types - 1;;Types - 2;;Types - 3;;Types - 4;;Curry-Howard-deBruijn isomorphism;;Computational framework;;Reals - 1;;Constructive logic - 1;;Constructive logic - 2;;Reals - 2;;Reals - 3;;Reals - 4;;Functional programming - 1;;Functional programming - 2;;Functional programming - 3;;Monads - 1;;Monads - 2;;Monads - 3;;Monads in Haskell - 1;;Monads in Haskell - 2;;Monads in Haskell - 3;;Monads in Haskell - 4;;Monads in Haskell - 5;;Monads in Haskell - 6;;Monads - 4;;Monads - 5;;O\'Connor completion monad - 1;;O\'Connor completion monad - 2;;Motivation - 7;;Motivation - 8;;Brief history of Bishop program in type theory;;Real world programs - 1;;Real world programs - 2;;Real world programs - 3;;References;;Constructive mathematics - 1;;Constructive mathematics - 2;;Constructive mathematics - 3;;Outline;;Step functions;;Step functions are inductive;;Step Functions form a monad - 1;;Step Functions form a monad - 2 ;;Step Functions form a monad - 3;;Applicative functors (McBride/Paterson);;Lifting relations - 1;;Lifting relations - 2;;Lifting relations - 3;;Two metric spaces of Step functions - 1;;Two metric spaces of Step functions - 2;;Two metric spaces of Step functions - 3;;Bounded Functions and Integrable Functions;;Dening integration - 1;;Dening integration - 2;;Dening integration - 3;;Dening integration - 4;;Dening integration - 5;;Dening integration - 6;;Dening integration - 7;;Correctness - 1;;Correctness - 2;;Correctness - 3;;Correctness - 4;;Implementation - 1;;Implementation - 2;;Implementation - 3;;Implementation - 4;;Lifting theorems - 1;;Lifting theorems - 2;;Lifting theorems - 3;;Lifting theorems - 4;;Lifting theorems - 5;;Reflection on Bishop\'s program - 1;;Reflection on Bishop\'s program - 2;;Reflection on Bishop\'s program - 3;;Reflection on Bishop\'s program - 4;;Reflection on Bishop\'s program - 5;;Conclusion;;References;;Tutorial: Computer Verified Implementation of Analysis;;A Metric on List of Points;;Find Closest Green Points;;Pick the Longest One;;This is not Symmetric;;Take the Longest One;;Metric Space of Finite Sets;;Compact Sets;;Provably Correct Graph;;Riemann Hypothesis - 1;;Riemann Hypothesis - 2;;Filled Julia Sets - 1;;Filled Julia Sets - 2;;Filled Julia Sets - 3;;Further Reading;;Demo - 1;;Demo - 2;;Demo - 3;;Demo - 4;;Demo - 5;;Demo - 6;;Demo - 7;;Demo - 8;;Demo - 9;;Demo - 10;;Demo - 11;;Demo - 12;;Demo - 13;;Demo - 14;;Demo - 15;;Demo - 16;;Demo - 17;;Demo - 18;;Demo - 19;;Demo - 20;;Demo - 21;;Demo - 22;;Demo - 23;;Demo - 24;;Demo - 25;;Demo - 26;;Demo - 27;;Demo - 28;;Demo - 29;;Demo - 30;;Demo - 31;;Demo - 32;;Demo - 33;;Demo - 34;;Demo - 35;;Demo - 36;;Demo - 37;;Demo - 38;;Demo - 39;;Demo - 40;;Demo - 41;;Demo - 42;;Demo - 43;;Demo - 44;;Demo - 45;;Demo - 46;;Demo - 47;;Demo - 48;;Demo - 49;;Demo - 50;;Demo - 51;;Demo - 52;;Demo - 53;;Demo - 54;;Demo - 55;;Demo - 56;;Demo - 57;;Demo - 58;;Demo - 59;;Demo - 60;;Demo - 61;;Demo - 62;;Demo - 63;;Demo - 64;;Demo - 65;;Demo - 66;;Demo - 67;;Demo - 68;;Demo - 69;;Demo - 70;;Demo - 71;;Demo - 72;;Demo - 73;;Demo - 74;;Demo - 75;;Demo - 76;;Demo - 77;;Demo - 78;;Demo - 79;;Demo - 80;;Demo - 81;;Demo - 82;;Demo - 83;;Demo - 84;;Demo - 85;;Demo - 86;;Demo - 87;;Demo - 88;;Demo - 89;;Demo - 90;;Demo - 91;;Demo - 92;;Demo - 93;;Demo - 94;;Demo - 95;;Demo - 96;;Demo - 97;;Demo - 98;;Demo - 99;;Demo - 100;;Demo - 101;;Demo - 102;;Demo - 103;;Demo - 104;;Demo - 105;;Demo - 106;;Demo - 107;;Demo - 108;;Demo - 109;;Demo - 110;;Demo - 111;;Demo - 112;;Demo - 113;;Demo - 114;;Demo - 115;;Demo - 116;;Demo - 117;;Demo - 118;;Demo - 119;;Demo - 120;;Demo - 121'
9596,'promotional video','en',9595,'2009-08-25','2009-08-25','WSA award ',NULL,NULL
9648,'lecture','sl',NULL,'2009-09-14','2009-09-17','Možgani - Od Elektrike do Spomina','Električna aktivnost živčnih celic predstavlja enega osnovnih mehanizmov delovanja možganov, ki posredujejo različne duševne procese (npr. zaznavanje, spomin, čustvovanje, odločanje). Beležimo in preučujemo jo lahko s pomočjo metode elektroencefalografije (EEG). Sodobni pogled na delovanje možganov pravi, da posamezno funkcijo posredujejo prostorsko ločeni možganski centri, ki pa delujejo sočasno. Na kakšen način je torej usklajeno njihovo delovanje? Predstavljena bo novejša metoda EEG-koherence za preučevanje tovrstne komunikacije v možganih, na primeru procesov spomina.',NULL
9651,'interview','sl',9650,'2005-12-09','2010-01-13','Institut za narodnostna vprašanja',NULL,NULL
9652,'interview','sl',9650,'2006-01-06','2010-01-13','Rudisti',NULL,NULL
9654,'interview','sl',9650,'2006-01-20','2010-01-13','45 let Nacionalnega inštituta za biologijo ',NULL,NULL
9655,'interview','sl',9650,'2006-02-03','2010-01-13','Etimološki slovar slovenskega jezika',NULL,NULL
9656,'interview','sl',9650,'2006-02-17','2010-01-13','Almanach in slikarstvo konec 17. stol. na Kranjskem',NULL,NULL
9657,'interview','sl',9650,'2006-03-03','2010-01-13','Fakulteta za elektrotehniko med najboljšimi',NULL,NULL
9658,'interview','sl',9650,'2006-03-17','2010-01-13','Družinska medicina',NULL,NULL
9659,'interview','sl',9650,'2006-04-07','2010-01-13','Foresight - napovedovanje v znanosti',NULL,NULL
9660,'interview','sl',9650,'2006-04-21','2010-01-13','Arhiv družboslovnih podatkov ',NULL,NULL
9661,'interview','sl',9650,'2006-05-05','2010-01-13','Kemija bo rešila Prešerna',NULL,NULL
9662,'interview','sl',9650,'2006-05-19','2010-01-13','80 let akad. prof. dr. Janez Peklenika',NULL,NULL
9663,'opening','sl',9653,'2009-06-04','2009-09-15','Pozdravni Nagovor in Uvodne Besede',NULL,NULL
9664,'lecture','en',9653,'2009-06-04','2009-09-15','The Evolutions of Cybercrime: Is the Email of the Species still more Deadlier than the Mail?','This talk will discuss the implications of technology for criminal behaviour and its control. The first part will briefly outline how networked technology has transformed /is transforming crime, crime control, policing and surveillance. It will chart the development of cybercrime through three generational changes from discrete computers systems to dial-in modem access to broadband. It will then map out the significant transformations and the challenges they create, especially the need to deal with informationalized, networked and globalised small impact bulk victimisations that do not fall within the routine activities and experiences of criminal justice systems and the professionals who work within them. \n\nThe second part will explore recent developments in cybercrimes that are continuing to challenge criminal justice systems. For example, as dial in computer networking became common place during the late 1990s the practice of bulk spamming, through their content and also attachments, were arguably the most prevalent form of online victimisation. The prevalence of spamming proliferated dramatically from mid 2003 onwards following the advent of broadband and the growth of botnets (robot networks of remotely administered infected computers). However, in more recent years we have experienced the emergence of new forms of victimization online which are showing interesting and distinct signs of evolution from their predecessors. \n\nBotnets and the threats from spams remain prevalent, but the explosion in social networking sites has added potential opportunities for online victimisation. Not only are the there now many more opportunities for obtaining personal information about individuals who live out large parts of their lives online, but these social networks can also be exploited by socially engineering (persuading) participants to pass on information to the various nodes in their personal networks. These information flows can be used to perform more advanced forms of phishing expeditions. In deed, in the worst case scenario they can contribute to mass panics through the intentionally or accidental flow of misinformation. Not only is email being surpassed as the primary form of threat but it will be suggested in this talk that these new victimisations are potentially more invasive. \n\nThe third part of the talk will seek to identify some of the new developments in networked technology that could be used to initiate future online attacks in the future. These include ambient technologies, new generations of Radio Frequency Identity Tags, but also the impact of governmental and commercial policies which increase our reliance upon technology. Whilst some of these predictions may be speculative, one thing remains certain, cybercrime is not an absolute concept – it will not be eradicated, rather it is relative to online business and social opportunities and it is therefore a function of that opportunity. As a consequence cybercrime will never be eradicated; the best that we can hope to achieve is that it can be prevented through social information as quickly as potential exploits in operating and financial systems can be identified. To this end we need to develop new methodologies for understanding change as it happens and also to explore the various relationships between technology and law in the process of regulating harmful behaviour online.',NULL
9665,'lecture','sl',9653,'2009-06-04','2009-09-15','Krhkost Varnosti v Digitalnem Svetu - Praktični Primeri Kiberkriminala','Če so bili tim. hekerji včasih predvsem radovedni najstniki z razmeroma nedolžnimi motivi, kot npr. radovednost, samodokazovanje in zabava, je danes prevladujoč motiv kiberkriminalcev predvsem zaslužek. Napadi so zato bolj kompleksni, motivirani napadalci pa uporabljajo različne tehnike za prikrivanje svojih dejanj in svoje identitete.\n\nPo drugi strani pa rast interneta v zadnjih letih poteka predvsem na obrobju, med uporabniki, ki nimajo računalniško-varnostnih znanj. Dodatno težavo pogosto predstavlja tudi razmejitev med javnim in zasebnim na internetu, saj uporabniki pogosto težko presodijo kateri deli interneta so javni (in torej na njih ni pametno objavljati zaupnih informacij ali osebnih podatkov) in kateri deli niso. Nevešči uporabniki na robu omrežja so zato čedalje pogostejša, predvsem pa lahka tarča napadalcev.\n\nPrav tako praviloma ni mogoče ločiti “legitimne tehnologije” od tiste, ki je namenjena izključno izvajanju kiberkriminalnih dejanj. Orodje, ki je v rokah varnostnega inženirja uporabljeno z namenom zaščite informacijskih sistemov, je v rokah napadalca lahko uporabljeno kot pripomoček za vdor v informacijski sistem. Poleg tega je napad na informacijski sistem mogoče izvesti brez specializiranih programskih orodij – pogosto zadostuje že običajen spletni brskalnik. Preiskovanje kiberkriminalnih dejanj je zato težavno, saj praviloma zahteva poglobljeno razumevanje tehnologije in sodelovanje strokovnjakov, pogosto pa je potrebno tudi tesno mednarodno sodelovanje.\n\nNa predavanju bo predstavljenih nekaj primerov, ki nakazujejo kako kompleksni so lahko primeri kiberkriminala ter kako enostavno je lahko izvesti napad na informacijski sistem. Prikazani bodo konkretni primeri iskanja javno objavljenih občutljivih podatkov, primeri izvedbe napadov na slovenske spletne strani ter še nekatere druge oblike kiberkriminala.',NULL
9666,'interview','sl',9650,'2005-12-23','2010-01-13','Ob zaključku leta fizike',NULL,NULL
9667,'lecture','sl',9653,'2009-06-04','2009-09-15','Podatki o Prometu v Slovenski Zakonodaji in Ustavnosodni Praksi','Slovenska in evropska zakonodaja s področja elektronskih komunikacij razlikujeta med vsebino komunikacije in podatki o prometu. Razlikovanje je ključno pri postavitvi standardov za poseg v zasebnost komunikacij, saj je praviloma vsebina komunikacije varovana strožje od drugih podatkov o določeni komunikaciji, na primer o času in trajanju ter o telefonskih številkah klicočega in klicanega. Na ravni EU smo glede podatkov o prometu prišli celo tako daleč, da se morajo ti obvezno hraniti za potrebe (morebitnih) kazenskih postopkov. Po drugi strani pa se zdi, da gre precedenčna odločba Ustavnega sodišča Up-106/05 z dne 2.8.2008 o pridobivanju podatkov iz pomnilnika mobilnega telefona oziroma SIM kartice v drugo smer: zasebnost komunikacij je v naši Ustavi tako široka in pomembna pravica, da razlikovanje med podatki o prometu in samo vsebino komunikacij morda nima več pravega pomena. \n\nZbliževanje je z vidika človekovih pravic primerno izključno v duhu zviševanja standardov varstva. Široka obveznost hrambe podatkov o prometu, kot jo poznamo v EU in drugih jurisdikcijah, denimo v ZDA, je nedvomno pričela spodkopavati idejo, da je nadzor komunikacij mogoč le na podlagi konkretnega in predhodnega suma kaznivega dejanja. Tako bi denimo določbe o pretiranem času ali obsegu hrambe podatkov o prometu lahko dobile ustavnopravno dimenzijo posega v zasebnost komunikacij. Na 37. člen Ustave se torej moramo spomniti tudi takrat, ko gre za kakršnokoli obdelavo oziroma poseg v podatke o prometu; slednjih ustava ne izvzema iz varstva, kar je skladno tudi z odločbo Evropskega sodišča za človekove pravice v zadevi Malone v. Združeno kraljestvo. \n\nPostavljanje identičnih ustavnopravnih standardov za obe vrsti podatkov pa bi lahko postalo problematično, če bi šlo za zniževanje obstoječe ravni varstva. Tako bi denimo lahko prišli do zahteve po hrambi vsebin komunikacij na enak način kot podatkov o prometu. Evropsko sodišče, ki je sicer že zavrnilo tožbo zoper Direktivo 2006/24/ES o hrambi podatkov iz naslova pravne podlge, istega akta doslej ni presojalo z vidika varstva temeljnih pravic. Vendar pa ne moremo sklepati, da bi Evropsko sodišče sistem hrambe podatkov o prometu, ki je bil po njegovih lastnih ugotovitvah že pred uveljavitvijo navedene direktive uzakonjen v več evropskih državah, zlahka razglasilo za neskladnega z varstvom komunikacijske zasebnosti.\n\nKer torej glede na obstoječo evropsko in globalno klimo ni pričakovati, da bi se države odpovedale enostavnejšim postopkom nadzora nad podatki o prometu, bi bilo nujno, da navedeno razlikovanje v svojih bodočih odločbah vendarle prizna tudi slovensko ustavno sodišče. Dokler nas glede hrambe podatkov zavezuje (nadustavna) evropska zakonodaja, si težko domišljamo, da bi lahko oba režima popolnoma izenačili. Pri tem pa velja opozoriti, da se v slovenskem pravnem redu hkrati odvija divergenca, in sicer posegov v zasebnost med samo komunikacijo in po njej: tako predlog novele Zakona o kazenskem postopku (ZKP) ločeno od spremljanje komunikacij ureja preiskavo komunikacijskih in drugih elektronskih naprav, kamor štejeta tudi mobilni telefon in osebni računalnik. Pri posegih v zapise, ki jih hranijo navedene naprave, pa je predlagatelj sledil (konvergenčnim) napotkom Ustavnega sodišča ter izenačil podatke o prometu in vsebino, a hkrati zatovrstne posege uveljavil nekoliko nižje standarde od tistih, ki veljajo za posege med samo komunikacijo.\n\nIn še v razmislek: v sodobnih komunikacijskih omrežjih se inteligenca in spomin v veliki meri nahajata na obrobju, v terminalskih napravah; zato te postajajo pomemben vir najrazličnejših podatkov za potrebe kazenskega postopka, tako o vsebini kot o prometu. V tem smislu je odločba Up-106/05 vsaj implicitno tlakovala pot tudi za konvergenco 35. in 37. člena Ustave, kar se zdi še pomembnejši prispevek od zbliževanja statusa podatkov o prometu in vsebine komunikacij.',NULL
9668,'lecture','sl',9653,'2009-06-04','2009-09-15','Sodobne Informacijsko-Komunikacijske Tehnologije in Varstvo Osebnih Podatkov','V razvoju informacijske družbe smo s prehodom v 21. stoletje trčili ob nova razvojna, pravna in etična vprašanja. V začetnih fazah razvoja informacijske družbe smo bili predvsem osredotočeni na dileme glede regulacije trgov elektronskih komunikacij ter pospeševanja uporabe sodobnih informacijsko-komunikacijskih tehnologij. Če so bile digitalna ločnica, povečevanje deleža širokopasovnih povezav in spodbujanje projektov za nove e-vsebine teme, s katerimi smo se ukvarjali tedaj, smo v zadnjem desetletju trčili ob nekatere vidike razvoja informacijske družbe, ki terjajo nov premislek. V dobi vse-prisotnega računalništva in povezljivosti, konvergence medijev, spletnih družbenih omrežij in silovitega tehnološkega razvoja, so čedalje bolj pogosti primeri etično in pravno sporne uporabe sodobnih tehnologij, ki nudijo izjemne možnosti nadzora. Temeljna človekova pravica do (informacijske) zasebnosti je v tej dirki pogosto povožena, posameznik pa izgublja možnost varovanja meja svoje zasebnosti in postaja le subjekt nadzora – nadzorovan potrošnik, nadzorovan zaposleni, nadzorovan državljan, katerega pravica do svobodnega odločanja je reducirana na minimum. Skrajni čas je, da se kot družba vprašamo, kako daleč želimo iti v tehnološko podžgani želji po nadzoru, in ali želimo živeti v družbi nadzora ali družbi svobode. Prispevek odpira navedena vprašanja in poskuša najti odgovore, s katerimi lahko ponovno umirimo družbeni kompas. Ob zasebnosti prijazni uporabi tehnologije gresta lahko pravica do zasebnosti in pravica do varnosti z roko v roki v igri s pozitivno vsoto.',NULL
9669,'lecture','sl',9653,'2009-06-04','2009-09-15','Zasebnost na Delovnem Mestu - ZDA ali Evropa','Nadzor zaposlenih na delovnem mestu, predvsem nadzor njihovih elektronskih komunikacij v zadnjem času postaja vroča tema med zaposlovalci.\n\nRazlogi za nadzor so različni, večinoma pa podjetja želijo preprečiti odtekanje poslovnih skrivnosti, neprimerno obnašanje zaposlenih - predvsem zlorabo službenega časa in računalnika za neslužbene namene - ter zagotoviti varnost informacijske infrastrukture podjetja (zmanjšati število okužb z virusi in zlonamerno kodo, preprečiti vdore, itd.). Temu se pridružuje še agresivno oglaševanje izdelkov za nadzor komunikacijske infrastrukture s strani proizvajalcev in prodajalcev tovrstne opreme, nadzorna tehnologija pa je pogosto predstavljena kot magična paličica za rešitev vseh problemov v podjetju.\n\nOglaševalci nadzornih naprav pogosto navajajo “ameriški pristop” k nadzorovanju zaposlenih na delovnem mestu, ki temelji na dejstvu, da zaposleni na delovnem mestu uporablja opremo, ki je last delodajalca, v delovnem času pa je plačan s strani delodajalca, zato službenih komunikacijskih sredstev in službenega časa ne sme zlorabljati v zasebne namene.\n\nA zakonodaja v ZDA se na tem področju bistveno razlikuje od zakonodaje v Evropi. Evropsko pravo zaposlenega na delovnem mestu ne vidi zgolj kot samo delavca, pač pa predvsem kot človeško bitje oziroma posameznika s človekovimi pravicami.\n\nNa predavanju bo predstavljena problematika pravnega varstva zasebnosti na delovnem mestu ter dva konkretna slovenska primera nezakonitega nadzora elektronskih komunikacij zaposlenih na delovnem mestu. V prvem primeru je delodajalec zaradi spora z uslužbenko upraviteljem poštnega sistema v ustanovi naročil izvedbo prestrezanja njene odhodne in dohodne elektronske pošte. V drugem primeru pa je organizacija uvedla prestrezanje internetnih komunikacij vseh zaposlenih s pomočjo tehnologije Deep Packet Inspection z namenom zaščite integritete omrežja. Predstavljeni bodo tudi pravni vidiki obeh primerov nadzora.',NULL
9672,'lecture','en',9653,'2009-06-04','2009-09-15','Online Child Pornography: European and Hungarian Perspective',NULL,NULL
9675,'lecture','sl',9653,'2009-06-04','2009-09-15','Nigerijska Prevarantska Pisma','Marca 2009 je imelo Medmrežje več kot milijardo in pol virtualnih pebivalcev. Ta populacija je godna za izkoriščanje. Škoda, ki jo prevare v virtualni skupnosti povzročajo dosega več deset milijard dolarjev letno. Samo nigerijska prevarantska pisma (t.i. »419 pisma«) pošilja žrtvam približno 300.000 storilcev. 419 prevare sodijo med “sheme predhodnega plačila”, kjer v zameno za kasnejšo (fiktivno) veliko pridobitev žrtev najprej vloži nekaj svojih sredstev. Prevare tega tipa so se prvič pojavile v 16. stoletju v obliki “pisem španskega zapornika” – tarče so bili angleški aristokrati, ki so dobili pismo bogatega sonarodnjaka, ki naj bi bil zaprt v Španiji. Na prostost ga bodo spustili šele, ko bo plačal določeno vsoto, ki jo bo, takoj ko bo nazaj v rodni Angliji seveda povrnil z obrestmi. Naslove žrtev storilci pridobijo iz spletnih forumov, spletnih seznamov zaposlenih v podjetjih in t.i. \"sucker-lists“, kamor žrtev najhitreje pride tako, da odgovori na kako 419 pismo ali pa dejansko tudi nasede nanj. Ko je žrtev enkrat v sistemu, prične dobivati večje količine neželene pošte. Končnica nigerijskih prevar se ne zaključi nujno zgolj s finančno izgubo ali izgubo prostosti žrtve. Vsako leto je več deset žrtev nigerijskih prevarantskih pisem umorjenih.',NULL
9676,'lecture','sl',9653,'2009-06-04','2009-09-15','Jurisdikcija za Dejanja Kibernetske Kriminalitete','Kibernetska kriminaliteta je tipičen primer čezmejne kriminalitete. Kazniva dejanja, ki izkoriščajo možnosti, ki jih ponuja razvoj računalniške in IT tehnologije, imajo praviloma tudi mednarodni element. Kibernetska kriminaliteta je zato doživela precej buren odziv, ne le pri njenem dokazovanju, ampak že pri oblikovanju odločitev, ali in na kakšni podlagi jo preganjati. Za odziv na kibernetsko kriminaliteto je tipično dvoje: prvič, kazenskopravni sistemi so se oprli na ustaljena pravila o krajevni veljavnosti kazenskopravne zakonodaje,; in drugič, zaradi potrebe po hitrem odzivu, je bila uporaba teh načel zelo neuravnotežena.\nTo je v primerjalnopravni perspektivi pomenilo, da so države bodisi sprejemale nova pravila, ki so se naslanjala na že obstoječa pravila veljavnosti kazenskega zakona, in jih prilagajala kibernetski kriminaliteti, bodisi so obstoječa pravila razlagala preširoko. V obeh primeri je zaznati težnjo, da se zagotovi pregon domnevnih storilcev in hkrati zmanjša možnost izogibanju pregona. To je vodilo v nov problem, in sicer h konkurenci jurisdikcij, ki ustvarja nevarnosti večkratnega pregona za isto kaznivo dejanje. Tak učinek pa je vse prej kot zaželen, tako z vidika obdolžencev, kakor tudi z vidika stroškov, ki jih prinaša večkraten pregon teh kaznivih dejanj.\nKako uravnotežiti politiko pregona? Ponuja se več možnosti. Prvič, mogoče je ožje tolmačiti teritorialno načelo krajevne veljavnosti kazenskega zakona, zlasti v delu, ki se navezuje na nastanek prepovedane posledice na ozemlju države. Nekateri se zavzemajo za uporabo dodatnih kriterijev, ki naj utrdijo povezavo med dejanjem in posledico, ki je nastala na ozemlju države. Navezna okoliščina nastanka prepovedane posledice je bila zlasti v primerih t.i. content-related kaznivih dejanj, kjer so sodišča svojo pristojnost utemeljevala že z golo možnostjo priklica in ogleda prepovedanih vsebin.\nDruga možnost je izraziti procesne narave in se nanaša na ureditev mednarodne pravne pomoči v kazenskih zadevah. Taki procesni ukrepi sicer ne morejo preprečiti konkurenci jurisdikcij, lahko pa pomagajo zmanjšati negativne učinke in zagotovijo načine izbire države pregona. Tak pristop je ubrala Konvencija o kibernetski kriminaliteti.\n V slovenskem pravu je mogoče ugotoviti, da imamo tako materialnopravne kot tudi procesne mehanizme, ki naj preprečujejo ali vsaj olajšajo probleme z jurisdikcijo pri pregonu kaznivih dejanj kibernetske kriminalitete. Sem sodi predvsem omejevanje pravil krajevni veljavnosti kazenskega zakona s pravilom ne bis in idem ter instituta odstopa oziroma prevzema pregona.',NULL
9677,'lecture','sl',9653,'2009-06-04','2009-09-15','Posest kot Kaznivo Dejanje: Problem Otroške Pornografije','Posest – izvorno koncept civilnega prava  že dolgo zaposluje tudi kazenske pravnike. Tradicionalnemu vprašanju, pod katerimi pogoji je posest predmetov samo po sebi dopustno opredeliti kot kaznivo dejanje, so se pridružila nova. Kako daleč naj gre kazensko pravo pri preganjanju posesti otroške pornografije? Ali naj bo kazniva tudi posest podob imaginarnih oseb in odraslih oseb, ki skušajo dajati vtis, da so mladoletne? Kako pojem posesti sploh razumeti v kibernetskem prostoru? So podobe, do katerih dostopamo na svetovnem spletu, v naši posesti? Na navedena vprašanja skuša avtor odgovoriti teleološko, tj. izhajajoč iz namena kazenskopravnega odzivanju na področju otroške pornografije (ta namen vidi v prvi vrsti v varstvu mladoletnih oseb pred zlorabami pri izdelavi pornografskega gradiva). Pri tem ugotavlja, da novejši zakonodajni trendi v Evropi ta namen občasno spregledajo, pri čemer se zdi, da zakonodajalce bolj kot varstvo potencialnih mladoletnih oškodovancev vodi nekaj, kar bi lahko imenovali »moralna panika«.',NULL
9678,'lecture','sl',9653,'2009-06-04','2009-09-15','Steganografija – Prikirito Komuniciranje','Namen prispevka je pokazati, kako zahteven je problem skrivanja podatkov - steganografije in pokazati, kako težko je odkriti tovrstne komunikacije. \nSteganografija potencialno predstavlja velik problem, saj je način komuniciranja, ki se ga po pravilu ne da zaznati. Običajni načini, kako zakriti vsebino sporočil uporabljajo kriptografske postopke, kjer se osnovno sporočilo preoblikuje v obliko, ki nekomu, ki ne pozna načina preoblikovanja, ne pomeni ničesar. Vsebina ostane neznana, obstaja pa sled, ki potrjuje komunikacijo med vsaj dvema akterjema. Že sam obstoj komunikacije je včasih dovolj indikativen. \nPri steganograskih metodah pogosto ne moremo ugotoviti niti dejstva ali je do komunikacije sploh prišlo. Vsebina komunikacije je skrita v mnogih možnih oblikah, včasih na mestih, kjer bi najmanj pričakovali. Fenomen steganografije je poznan, vendar še vedno predstavlja enega redkih načinov komunikacij, ki se jih praktično ne da zaznati. \nPri forenzičnem pregledu računalnika tako lahko zasledimo nekaj sledi, ki nakazujejo uporabo steganografskih metod. Za uporabo steganografskih metod mora biti na računalniku pošiljatelja in prejemnika nameščena programska oprema, ki te procese preoblikovanja izvaja. \nUporaba teh orodij je zabeležena v t.im. log datotekah, kjer je možno odkriti tudi ali je bila morda datoteka s samim steganografskim orodjem izbrisana. \nV zakonodaji bo nujno vpeljati dva zelo različna pojma – prvi je skrivanje podatkov (steganografija), drugi pa preoblikovanje podatkov (kriptiranje).\n',NULL
9679,'lecture','sl',9653,'2009-06-04','2009-09-15','Zlorabe Elektronskega Bančništva - Potek Preiskave v Praksi','Z razvojem in širšo dostopnostjo interneta, osebnih računalnikov in njim sorodnih naprav so se ponudile priložnosti, ki so ustvarile povsem novo generacijo storilcev kaznivih dejanj. Njihovo znanje ter povezana kompleksnost načina storitve kaznivih dejanj so globalno presenetila preiskovalne organe. \n\nDanes se storilci kaznivih dejanj, povezanih z računalniško tehnologijo, že ločijo po posameznih skupinah oz. kriminalnih združbah. Te so lahko organizirane le za določene oblike dejanj (npr. industrijsko vohunjenje, zloraba plačilnih sistemov, zloraba plačilnih kartic, tatvine in zlorabe osebnih podatkov, lažna prodaja na internetu, igre na srečo ipd.). Kljub selitvi kaznivih dejanj na internet in računalnike pa motiv v glavnem ostaja isti - t.j. koristoljubje.\n\nMetode storilcev so vse bolj izpopolnjene, vse manj je naključnih poskusov, nekoga \"ujeti na limance« in vse več je usmerjenih napadov. Pri svojem delu najpogosteje uporabljajo osebne računalnike, prirejena in namensko izdelana programska orodja (kot pripomočke oz. orodja za izvršitev kaznivega dejanja) ter seveda najpomembnejše - svoje znanje. \n\n\nSamo kaznivo dejanje napada na informacijski sistem po 237. členu Kazenskega zakonika je zelo kompleksno. Predstavljeno kaznivo dejanje je sicer šolski primer kaznivega dejanja Neupravičenega vstopa v informacijski sistem (KZ-04), kljub temu pa je bilo ob preiskavi dejanje opredeljeno kot Velika tatvina po čl. 212 KZ. Vsako kaznivo dejanje \"kibernetske kriminalitete\" ima namreč svoje tehnične posebnosti, ki postopke na vseh nivojih običajno močno otežijo. Ravno zaradi tega je obravnavanje tovrstnih dejanj v predkazenskem in kazenskem postopku zelo zahtevno za vse sodelujoče, saj morajo imeti poleg pravnega tudi tehnično znanje.\n\n\nV letu 2006 smo na Policijski upravi Ljubljana prjeli večje število prijav zlorabe elektronskega bančništva, pri čemer so bila sredstva iz tekočih računov komintentov (brez njihove vednosti) prenešena na tuje račune. Predstavitev zajema prikaz poteka predkazenskega postopka s poudarkom na analizi pridobljenih digitalnih dokazov ter \"modusa operandi\" osumljenca.',NULL
9680,'lecture','sl',9653,'2009-06-04','2009-09-15','Pomen Forenzike Mobilnih Telefonov in Vloga Sodnega Izvedenca za Računalniško Forenziko v Kazenskih Postopkih','Računalniška forenzika, kakor jo popularno imenujemo, poleg forenzike vseh vrst računalnikov zajema tudi forenziko mobilnih telefonov in drugih prenosnih naprav, saj se tudi na njih nahaja množica uporabnih digitalnih dokazov. Digitalni dokazi so v sodnih postopkih uporabni le, če so vsi koraki v procesu narejeni na zakonit način, sicer o forenziki niti ne moremo govoriti.\n\nMobilni telefoni so že več kot dobro desetletje nekaj povsem običajnega in le redko kdo ga še nima. V mobilnem telefonu in drugih podobnih sodobnih napravah se nahaja veliko podatkov, ki so pomembni za kazenski postopek. Če jih naštejemo le nekaj: podatki o kontaktih, fotografije, video posnetki, koledarski vpisi, SMS, MMS, e-pošta, uporabniška imena in gesla. Poleg podatkov pa se v teh napravah nahajajo tudi dodatne spominske kartice, kjer se prav tako nahaja veliko prej omenjenih podatkov, in kartice SIM, ki omogočajo povezavo v omrežje mobilnega operaterja. Tudi na njih je veliko zanimivih podatkov med katerimi izstopajo kontakti, SMS sporočila, zadnje klicane številke …\n\nForenzični postopki za mobilne telefone in kartice SIM so v primerjavi z forenzičnimi postopki za računalnike in trde diske veliko bolj zahtevni, še zlasti to velja za zavarovanje izbrisanih podatkov.\n\nVsi forenzični in z njimi povezani postopki na splošno, ne samo za mobilne telefone, so za nestrokovnjake za področje informacijskih tehnologij večinoma zelo zahtevni. Pri razumevanju terminologije, opravljenih postopkov, pregledu pisne dokumentacije je vsem tem lahko v veliko pomoč sodni izvedenec za to področje. Sodni izvedenec lahko tudi pomaga pri pregledu in vrednotenju digitalnih dokazov, ustreznosti forenzičnih postopkov, pravilnosti zaključkov oziroma rezultatov forenzične preiskave, prav tako pa lahko delno ali v celoti ponovno izvede forenzični postopek in tako preveri, če so prvotno predstavljeni digitalni dokazi dejansko pravilni. V primeru, ko pa forenzični postopek še ni bil opravljen seveda lahko opravi tudi tega in tako ponovno olajša odločanje v kazenski zadevi. Ne nazadnje pa lahko sodni izvedenec vse ugotovitve v zvezi z digitalnimi dokazi nazorno prikaže in demonstrira s pomočjo računalnika in projektorja. Taki prikazi so običajno zelo koristni, saj povedo veliko več kot le besede.',NULL
9681,'lecture','sl',9653,'2009-06-04','2009-09-15','Digitalni Dokazi v Kazenskem Postopku: Primerjalno-Pravna Perspektiva','Izhodišče primerjalno-pravne perspektive je bodoča procesna ureditev zasega in preiskovanja elektronskih naprav in zavarovanja elektronskih dokazov v Republiki Sloveniji, kot je predvidena v noveli Zakona o kazenskem postopku (EVA: 2008-2011-0117; na dan 16.5.2009 ima ta predlog oznako ZKP-K), ki je v parlamentarnem postopku. S to novelo bosta v ZKP predvidoma vnesena obsežna 219.a in 223.a člen, ki bosta urejala pravila za posege v komunikacijsko in tudi v elektronsko zasebnost zaradi pridobivanja podatkov v elektronski obliki za potrebe kazenskega postopka.\n\nSlovenija se bo torej pridružila (manjšemu) krogu držav, ki posebej urejajo zaseg, preiskovanje in zavarovanje elektronskih dokazov za potrebe kazenskega postopka. Predlagani novi določbi ZKP je mogoče označiti za pomemben korak naprej na poti prilagajanja (kazensko)pravnega sistema dejstvu, da živimo v hitro razvijajoči se tehnološki dobi; kako se bodo v praksi obnesli mehanizmi za varovanje zasebnosti, pa bo pokazal čas.',NULL
9682,'lecture','sl',9653,'2009-06-04','2009-09-15','Zaključna Razprava, Ugotovitve in Sklep Konference',NULL,NULL
9684,'interview','sl',9650,'2006-06-02','2010-01-13','20 let mladih raziskovalcev',NULL,NULL
9685,'interview','sl',9650,'2006-06-16','2010-01-13','Novi spektrometer',NULL,NULL
9686,'interview','sl',9650,'2006-09-15','2010-01-13','Zoisova nagrajenca za leto 2006',NULL,NULL
9687,'interview','sl',9650,'2006-10-13','2010-01-13','Monografije Slovencev v tujini',NULL,NULL
9688,'interview','sl',9650,'2006-11-10','2010-01-13','Naj programi v letu 2005',NULL,NULL
9689,'interview','sl',9650,'2006-12-08','2010-01-13','Vrhunski dosežki (Zoisove nagrade) 2006',NULL,NULL
9690,'interview','sl',9650,'2007-01-05','2010-01-13','Pozitivna psihologija',NULL,NULL
9691,'interview','sl',9650,'2007-01-19','2010-01-13','Sinteza biologija - tekmovanja v ZDA',NULL,NULL
9692,'interview','sl',9650,'2007-02-02','2010-01-13','Intervju akad. prof. dr. Jože Toporišič',NULL,NULL
9693,'interview','sl',9650,'2007-02-16','2010-01-13','Muzikološki institut SAZU',NULL,NULL
9694,'interview','sl',9650,'2007-02-16','2010-01-13','Institut za matematiko, fiziko in mehaniko',NULL,NULL
9695,'interview','sl',9650,'2007-03-16','2010-01-13','VIII. Bled forum',NULL,NULL
9696,'interview','sl',9650,'2007-04-02','2010-01-13','Forenzika pri nas',NULL,NULL
9697,'interview','sl',9650,'2007-04-20','2010-01-13','Dva gozdarska projekta (Evr. 5 in 6. prog)',NULL,NULL
9698,'interview','sl',9650,'2007-04-20','2010-01-13','40 let revije Materiali in tehnologije',NULL,NULL
9699,'interview','sl',9650,'2007-05-18','2010-01-13','Virtualni studio SAZU',NULL,NULL
9700,'interview','sl',9650,'2007-06-01','2010-01-13','Intervju z akad. prof. dr. Francetom Bernikom',NULL,NULL
9701,'interview','sl',9650,'2007-06-15','2010-01-13','50 let revije Geologija',NULL,NULL
9724,'tutorial','sl',8651,'2009-06-05','2009-10-26','Varnost in PHP','Na koliko načinov lahko varnost strežnika in podatkov ogrozijo napadalci preko spleta? Na primerih si bomo pogledali, kako izgledajo SQL injection, XSS, CSRF, session hijacking/fixation in kako se pred takimi napadi pravilno zaščititi. Pisanje varne kode ni težko, vendar zahteva razumevanje in konsistenten pristop na vseh nivojih aplikacije.',NULL
9725,'lecture','sl',8651,'2009-06-05','2009-10-26','Kaj pa, če bi šel “na svoje”?','Razmišljanje o vprašanjih, kot npr.:\n\n  * Ali je bolje ostati v varnem zavetju službe, ali postati podjetnik?\n  * Kaj potrebujem, koliko me bo stalo, kje se lahko zalomi?\n  * Koliko drugih še to počne?\n  * Kako pa si naredim izračun?\n  * …',NULL
9726,'lecture','sl',8651,'2009-06-05','2009-10-26','PHP brez brskalnika','Ukazna lupina in razvijanje aplikacije zanjo ponuja možnosti, ki so za marsikateri problem primernejše kot bolj poznani pristop preko brskalnika. Predavanje vključuje predstavitev konkretnega problema, ki ga taka aplikacija učinkoviteje rešuje ter pregled dodatnih funkcionalnosti, ki so nam na voljo v okolju ukazne lupine.',NULL
9727,'tutorial','sl',8651,'2009-06-05','2009-10-26','Izdelava Facebook aplikacij in uporaba Facebook Connecta','Z več kot 260000 slovenskimi uporabniki in rastjo, okrog 30000 novih slovenskih uporabnikov na mesec, postajajo Facebook aplikacije in spletne strani, ki uporabljajo Facebook Connect, zanimive tako za nas razvijalce, kot za naročnike.\n\nUdeleženci interaktivne delavnice bodo spoznali kaj so FB API, FBML, XFBML, FQL, FBJS, in druge stvaritve razvijalcev Facebooka in kako lahko z pomočjo njihove tehnologije in orodij izkoristite svoje znanje PHP-ja za razvoj naslednje virusne aplikacije ali implementacijo Facebook Connecta na katerikoli spletni strani.',NULL
9728,'lecture','sl',8651,'2009-06-06','2009-10-26','10 koščkov kode, ki so mi olajšali življenje','Konferenca brez debate ne bi bila konferenca, zato bo MŠ prebil led in razvezal razvijalske jezike z 10 “snippeti” kode iz svojih spletnih aplikacij, ki so mu še posebej pri srcu.',NULL
9729,'lecture','sl',8651,'2009-06-06','2009-10-26','Keširanje dinamičnih vsebin','Spletne aplikacije se vsakodnevno srečujejo z navali obiskovalcev, ki vsi pričakujejo nizke odzivne čase. Vendar kako pohitriti aplikacijo ob takem številu dinamičnih elementov na tipični spletni strani? V tem predavanju si bomo ogledali načine hranjenja teh podatkov med aplikacijo in podatkovno bazo, primerjali tehnologije, ki so nam na voljo, in izbrali tisto pravo. A PHP je le del mozaika…',NULL
9730,'lecture','sl',8651,'2009-06-06','2009-10-26','PHP+Flash=RIA','Tudi vam krade živce prilagajanje spletnih strani, da delujejo in izgledajo enako v FireFoxu, Internet Explorerju 6 (7, 8..), Operi, itd.? Bi radi izdelalovali namizne aplikacije, ki so lahko obenem spletne in delujejo enako na vseh operacijskih sistemih (Windows, Linux, Mac OS X)? Včasih le orodje za izdelavo vektorskih animacij oz. nadležnih flash oglasov, sedaj pa rešitev vseh zgoraj naštetih težav, to je Adobe Flash.\n\nNa tem predavanju:\n\n  * boste ugotovili kako vse lahko uporabite Flash pri izdelavi svojih spletnih in namiznih aplikacij,\n  * videli kako poteka izdelava Flash aplikacij s pisanjem kode v Eclipsu oz. Flex Builderju,\n  * in se naučili več vrst komunikacije med Flashom in PHPjem -> XML, JSON, AMF (Zend_AMF), itd.',NULL
9731,'lecture','sl',8651,'2009-06-06','2009-10-26','Real-time web (Comet)','Začeli bomo s predstavitvijo tehnologije, kaj točno je “Comet”, kaj nam omogoča in kdo ga uporablja. Nato bomo prestavili nekaj implementacij strežnikov.\nNadaljevali z prikazom demo programa in prikazali integracijo v PHP jeziku. V povzetku pa bomo pogledali kaj se obeta v prihodnosti.',NULL
9732,'lecture','sl',8651,'2009-06-06','2009-10-26','Spletne aplikacije na namizju','Predstavitev prednosti in slabosti spletnega programiranja za namizje preko Adobe AIR ter prikaz razpona moznosti za spletne programerje. Kratek prikaz komponent potrebnih za izdelavo delujocega prototipa in predstavitevh tezav na katere lahko naleti programer vajen predvsem spletnega razvoja.',NULL
9733,'lecture','sl',8651,'2009-06-06','2009-10-26','CodeIgniter PHP Framework - kako v krajšem času narediti več','Kaj je framework ? Kaj je MVC ?\nZakaj izbrati CodeIgniter in ne kakšen drug PHP framework (CakePHP, Symfony ali Zend).\nKako nam trenutno eden izmed naj popularnejših framework-ov pomaga pri razvoju naprednih spletnih aplikacij in pisanju boljše kode ter nam omogoča, da v krajšem času naredimo več.',NULL
9735,'lecture','sl',8651,'2009-06-06','2009-10-26','Zaključni nagovor in podelitev nagrad',NULL,NULL
9794,'interview','sl',9650,'2008-03-21','2010-01-13','IX. Forum Bled',NULL,NULL
9795,'interview','sl',9650,'2008-05-02','2010-01-13','Krožišča',NULL,NULL
9796,'interview','sl',9650,'2008-05-16','2010-01-13','Telemedicina',NULL,NULL
9797,'interview','sl',9650,'2008-11-27','2010-01-13','Novi materiali',NULL,NULL
9798,'interview','sl',9650,'2008-03-26','2010-01-13','Jedrsko zlivanje ali fuzija',NULL,NULL
9799,'interview','sl',9650,'2008-02-01','2010-01-13','Intervju z akad. prof. dr. Janezom Orešnikom',NULL,NULL
9800,'interview','sl',9650,'2008-02-14','2010-01-13','Intervju z akad. prof. dr Jožetom Pirjevcem',NULL,NULL
9801,'interview','sl',9650,'2008-03-07','2010-01-13','Svetovni dan Zemlje',NULL,NULL
9802,'interview','sl',9650,'2008-09-18','2010-01-13','Elektronsko prijavljanje',NULL,NULL
9803,'interview','sl',9650,'2008-10-23','2010-01-13','Študentski roadster',NULL,NULL
9806,'interview','sl',9650,'2008-12-25','2010-01-13','Zoisova nagrajenca za leto 2008',NULL,NULL
9807,'interview','sl',9650,'2008-01-08','2010-01-13','Problematika promoviranja znanosti',NULL,NULL
9808,'interview','sl',9650,'2008-01-22','2010-01-13','Intervju akad. prof. dr. Robertom Blincem',NULL,NULL
9809,'interview','sl',9650,'2009-02-12','2009-10-05','Intervju akad. prof. dr. Ignacijem Vojetom',NULL,NULL
9810,'interview','sl',9650,'2009-02-24','2010-01-13','Dežela vmes (The land between)',NULL,NULL
9811,'interview','sl',9650,'2009-04-23','2010-01-13','Zdrava starost',NULL,NULL
9812,'interview','sl',9650,'2009-03-12','2010-01-13','Intervju s prof. dr.Dušanom Petračem',NULL,NULL
9813,'interview','sl',9650,'2009-04-09','2010-01-13','Utekočinjen les',NULL,NULL
9814,'interview','sl',9650,'2009-05-14','2010-01-13','Superprevodnost',NULL,NULL
9815,'interview','sl',9650,'2009-05-28','2010-01-13','Kriptografija, zaščita zasebnosti',NULL,NULL
9816,'interview','sl',9650,'2009-06-11','2010-01-13','Kriminologija na Slovenskem',NULL,NULL
9817,'interview','sl',9650,'2009-06-25','2010-01-13','Ohranjanje objektov v posebnih razmerah',NULL,NULL
9823,'opening','en',9601,'2009-09-07','2009-10-20','Opening and Awards Ceremony',NULL,'Opening session;;ECML PKDD in SecondLife;;Conference chairs -1;;Conference chairs -2;;Conference chairs -3;;Local Team;;Accepted papers - content;;Accepted Papers by Topic;;Previous editions ECML;;Topics over the last 3 years;;All registrations by country;;Registrations by zype: summary;;Registrations by type;;On-line proceedings by Springer -1;;On-line proceedings by Springer -2;;Sponsors;;Reviewing process;;Overview of submissions;;Reviwing process - hierachical;;Reviewing process - details -1;;Reviewing process - details -2;;Scientific program;;Schedule;;Author Analysis: Accepted papers;;Author Analysis: Acceptance Rate;;Author Analysis: Accepted by Region;;Author Analysis: Acceptance by Region;;Demos;;Invited Talks;;Best Papers: procedure;;The Best ECML Paper;;The Best PKDD Papers;;Best ECML Student Paper;;Best PKDD Student Paper;;Industrial Track;;Workshops: Monday;;Workshops: Friday;;Tutorials:. Monday;;Tutorials: Friday;;Discovery Challenge;;Challenge: Winners;;Video recording;;About videolectures.net;;Publicity;;Social Events;;Conference proceedings;;Thanks'
9824,'invited talk','en',9601,'2009-09-07','2009-10-08','Privacy in Web Search Query Log Mining','Web search engines have changed our lives - enabling instant access to information about subjects that are both deeply important to us, as well as passing whims. The search engines that provide answers to our search queries also log those queries, in order to improve their algorithms.\nAcademic research on search queries has shown that they can provide valuable information on diverse topics including word and phrase similarity, topical seasonality and may even have potential for sociology, as well as providing a barometer of the popularity of many subjects. At the same time, individuals are rightly concerned about what the consequences of accidental leaking or deliberate sharing of this information may mean for their privacy. In this talk I will cover the applications which have benefited from mining query logs, the risks that privacy can be breached by sharing query logs, and current algorithms for mining logs in a way to prevent privacy breaches.',NULL
9825,'invited talk','en',9601,'2009-09-08','2009-10-20','Theory-Practice Interplay in Machine Learning – Emerging Theoretical Challenges','Theoretical analysis has played a major role in some of the most prominent practical successes of statistical machine learning. However, mainstream machine learning theory assumes some strong simplifying assumptions which are often unrealistic. In the past decade, the practice of machine learning has led to the development of various heuristic paradigms that answer the needs of a vastly growing range of applications. Many useful such paradigms fall beyond the scope of the currently available analysis. Will theory play a similar pivotal role in the newly emerging sub areas of machine learning?\nIn this talk, I will survey some such application-motivated theoretical challenges. In particular, I will discuss recent developments in the theoretical analysis of semi-supervised learning, multi-task learning, “learning to learn”, privacy-preserving learning and more.','The Theory-Practice Interplay in Machine Learning;;Success and Limitations;;If it works, why bother with theory?;;The modeling of prior knowledge;;Common PK modeling frameworks;;Prior Knowledge as \'Meta-Bias\';;The theory-practice gap;;Negative results for SSL;;Another type of meta-bias;;Key component for theoretical analysis;;Transformation relatedness;;Evaluation of the Transformation;;A major common assumption;;Learning when training and Test distributions differ;;Main issue;;Evaluating the generalization bound;;The algorithmic conclusion;;Can the covariate shift assumption help?;;Major remaining open questions;;Summary;;Major challenge - clustering;;Questions that research of fundamentals of clustering should address;;Worthy challenge;;Characterizing Single Linkage clustering;;Characterization of Single Linkage;;Characterizing Linkage Based clusterings;;Properties of Linkage-Based clustering;;Characterizing Linkage-Based clusterings;;Note that the most of the fundamental questions remain open;;Some further important new research directions;;Another practice-driven challenge;;Demonstrating uselessness of the Covariate shift assumption -1;;Demonstrating uselessness of the Covariate shift assumption -2;;Conservative vs. Adaptive algorithms;;Demonstrating the failure of the AMM reweighting paradigm'
9826,'invited talk','en',9601,'2009-09-09','2009-10-20','Highly Multilingual News Analysis Applications','The publicly accessible Europe Media Monitor (EMM) family of applications (http://press.jrc.it/overview.html) gather and analyse an average of 80,000 to 100,000 online news articles per day in up to 43 languages. Through the extraction of meta-information in these articles, they provide an aggregated view of the news, they allow to monitor trends and to navigate the news over time and even across languages. EMM-NewsExplorer additionally collects historical information about persons and organisations from the multilingual news, generates co-occurrence and quotation-based social networks, and more. All EMM applications were entirely developed at, and are being maintained by, the European Commission’s Joint Research Centre (JRC) in Ispra, Italy.\n\nThe applications make combined use of a variety of text analysis tools, including clustering, multi-label document classification, named entity recognition, name variant matching across languages and writing systems, topic detection and tracking, event scenario template filling, and more. Due to the high number of languages covered, linguistics-poor methods were used for the development of these text mining components. See the site http://langtech.jrc.it/ for technical details and a list of publications.\n\nThe speaker will give an overview of the various applications and will then explain the workings of selected text analysis components.','Highly multilingual news monitoring applications;;Joint Research Centre - Who we are;;Agenda;;Media Monitoring – Users / Motivation;;European context – Motivation for multilinguality;;Multilinguality: complementary news coverage in various languages;;Language coverage of various media analysis tools (August 2009);;Agenda;;Europe Media Monitor (EMM) - News data;;EMM – NewsBrief (currently 50 languages);;NewsBrief: Live Cluster Map;;EMM-Labs: Real-time Cluster Network;;MedISys – Filtering and classification in up to 50 languages;;Aggregation of multilingual information;;Detection and visualisation of events (violence/disasters/humanitarian/…) - 1;;Detection and visualisation of events (violence/disasters/humanitarian/…) - 2;;NewsExplorer – Functionality;;NewsExplorer – Multilingual daily news overview;;NewsExplorer – Cross-lingual cluster linking;;NewsExplorer – Time line: biggest clusters per day;;NewsExplorer – Aggregation of clusters into longer ‘stories’;;NewsExplorer –Information about people collected from multiple languages and over time;;NewsExplorer – Relation exploration;;Text analysis tools integrated in NewsExplorer;;Agenda;;News clustering;;Clustering: Monolingual document representation;;Multi-monolingual news clustering;;Multilingual named entity recognition and variant mapping - 1;;Multilingual name recognition and variant mapping - 2;;Multilingual named entity recognition (NER) – brief overview;;Name Variants;;Name transliteration;;Name normalisation – Why? - 1;;Name normalisation – Why? - 2;;Name normalisation ~ 30 Rules;;Similarity measure for name merging;;Merging name variants – some results;;Person name recognition and variant merging – Result;;Social network extraction from multilingual news;;Social networks and relationship extraction;;Associated names: weighting formula;;Daily co-occurrence networks (reset every midnight);;Daily mixed-language co-occurrence networks (~100,000 links/day);;Daily co-occurrence networks: Edward Kennedy – Barack Obama;;Quotation network, built from multilingual quotations;;Quotation network: http://langtech.jrc.it/entities/socNet/quotes.html;;Multilingual quotation network (directed graph): sub-network;;Quotation network: another sub-network;;Quotation network: another sub-network;;Network of specific relationships (English only);;Cross-lingual Cluster Linking;;Approaches to cross-lingual document similarity calculation - 1;;Approaches to cross-lingual document similarity calculation - 2;;Approaches to cross-lingual document similarity calculation - 3;;NewsExplorer - Cross-lingual cluster linking;;Multilingual Geo-tagging;;Eurovoc subject domain categorisation;;Multi-label indexing with Eurovoc;;Assignment Result (Example);;Two freely available multilingual resources (22 languages);;NewsExplorer - Cross-lingual cluster linking;;Agenda;;Conclusion Ongoing work;;Summary;;Multilinguality: complementary news coverage in various languages;;Multilinguality: More information about relations between people;;Multilinguality: Gathering more information about people;;Ongoing work'
9827,'invited talk','en',9601,'2009-09-10','2009-10-20','The Growing Semantic Web ','From its beginnings in 2004, the data available on the web in Semantic Web formats has typically been both eclectic and relatively small, and closely linked the interests of particular researchers. In the past year, however, the quantity and scope of data published on the public semantic web has exploded, and the size of the semantic web is now measured in the billions of assertions. It is a significant and growing resource for applications which depend on web-based resources for some or all of their knowledge. With this massive increase in quantity and scope come many opportunities, as well as the usual issues of scale on the web: inconsistency, mapping problems, incompleteness and data variability. This talk will cover the history and current state of the Semantic Web and the Linked Data Cloud, describe some of the uses to which web-based semantic data is currently put, and discuss prospects for the ECML/PKDD community to leverage this growing web of data.','The Growing Semantic Web;;What is the Semantic Web?  4 Answers (1);;What is the Semantic Web?  4 Answers (2);;What is the Semantic Web?  4 Answers (3);;What is the Semantic Web?  4 Answers (4);;Talk Outline: The Growing Semantic Web (1);;Talk Outline: The Growing Semantic Web (2);;The Roots of the Semantic Web;;The Beginnings of the US Semantic Web: DARPA’s DAML Program;;What is RDF?;;What Does OWL Add?;;From XML to OWL ;;DAML Program Elements;;The Semantic Web in 2009 (1);;The Semantic Web in 2009 (2);;The Semantic Web in 2009 (3);;The Semantic Web in 2009 (4);;Completing The Semantic Web Picture;;Beyond RDF and OWL: 2009 Semantic Web Infrastructure;;State of Semantic Web Work in the US;;Semantic Web Work in the EU;;Talk Outline: The Growing Semantic Web;;Evolving Conceptions for the Semantic Web;;The Situation for Semantic Web and ML/DM in 2007;;Evolving Conceptions for the Semantic Web (Part 2);;What does this mean for ML/DM on the Semantic Web?;;Before we continue: 2 challenges about the Semantic Web;;Talk Outline: The Growing Semantic Web;;First Generation Semantic Web Applications;;Semantic Web in Search and Presentation;;Second Generation Semantic Web Applications;;Layers of Semantic Data in Strategic Enterprise IT;;Semantic Web in Strategic Enterprise IT;;Third Generation Semantic Web Applications;;Web Knowledge Bases: Metaweb and Freebase;;Semantic Blogger Support: Zemanta;;Third Generation Example: Semantic Wikis;;An Example of (Manually Annotated) Semantic Wiki;;Semantic MediaWiki and Rules;;More complex: National Cancer Institute (NCI) Thesaurus;;Using Semantic Web data from Wikis: Project Halo;;AURA – Automated User-centered Reasoning and Acquisition System;;Symbiosis Between Aura and Semantic Wikis;;Example: Wikipedia Article on Organelle;;Source Text of Article on Organelle in Semantic MediaWiki;;Fact Box With the Annotations in Semantic MediaWiki;;Ontology Browser for Biology Data in Semantic MediaWIki;;Aura/Semantic MediaWiki Use Case;;AURA User Searches for Information;;Aura User Notices Useful Information in Wiki;;Aura User Maps Wiki Knowledge into Aura KB (with FoaM proposals);;Wiki Knowledge Available in Aura for Question-Answering;;Talk Outline: The Growing Semantic Web;;Fourth Generation Semantic Web;;Fourth Generation Example: DBpedia;;DBpedia for Users;;Fourth Generation Example: Linked Open Data;;The Growing Web of Linked Data;;Topic Distribution in the March 2009 Linked Datasets;;Common Tag Specification;;Semantic Dynamism at Web Scale;;Fourth Generation Application: The Large Knowledge Collider (1);;Fourth Generation Application: The Large Knowledge Collider (2);;Fourth Generation Application: The Large Knowledge Collider (3);;Summing up: The Growing Semantic Web (1);;Summing up: The Growing Semantic Web (2);;Summing up: The Growing Semantic Web (3);;Thank you;;ecmlpkdd09_greaves_gsw_01_Page_69'
9828,'invited talk','en',9601,'2009-09-11','2009-10-20','Are We There Yet?','Statistical approaches to Artificial Intelligence are behind most success stories of the field in the past decade. The idea of generating non-trivial behaviour by analysing vast amounts of data has enabled recommendation systems, search engines, spam filters, optical character recognition, machine translation and speech recognition. As we celebrate the spectacular achievements of this line of research, we need to assess its full potential, its limitations and its position within the larger scheme of things. What are the next steps to take towards machine intelligence?','Video 1;;Are We There Yet?;;November 1958;;November 1958 (1);;November 1958 (2);;Contents;;Participants;;General Priciples;;Example: Methods of Artificial Intelligence and Heuristic Programming;;Example: Speech Recognition;;Learning in Machines;;Example: Learning Machines: Conditional Probability Machine;;Machine Intelligence, AD 1958;;How Much Have We Progressed?;;Machine Intelligence, AD 2009;;Machine Intelligence, AD 2009 (1);;Machine Intelligence, AD 2009 (2);;Machine Intelligence, AD 2009 (3);;An invited talk from the future;;Data-Driven Artificial Intelligence;;Low Level Processing;;Video 2;;Example: Viterbi Algorithm;;Example: Viterbi Algorithm (1);;Impact;;“Statistical Hacks”;;Optimisation and Statistics;;Optimisation and Statistics (1);;Searching under the Lamp-post;;What is the goal?;;Intelligent Behaviour;;Video 3;;Beyond Statistics;;Modelling Interaction;;Intelligent Behaviour as a Property of a System;;Stability, Robustness, Control;;Intelligent Behaviour is the Target;;Another Feature of AI research AD 2009;;Video 4;;Overcoming Babel;;AI 2009 –…;;AI 2009 – Things are moving…;;Back to the Future?;;The biggest question of all…;;Hvala lepa'
9974,'summary','en',9601,'2009-09-11','2009-10-21','Closing Ceremony',NULL,NULL
9981,'opening','en',9600,'2009-09-04','2009-10-20','Opening and Introduction',NULL,'1st ACTIVE Summer School;;The aim of the 1st ACTIVE Summer School;;Programme;;Speakers at the 1stACTIVE summer school;;Dinner'
9982,'lecture','en',9600,'2009-09-04','2009-10-20','Hands on Semantic Web',NULL,'Semantic Web;;Agenda;;Universal Access to All Knowledge;;Semantic Web Logo;;Semantic Web Scheme: Layers of the Semantic Web;;Data Interchange: RDF - in scheme;;Example;;Example (1);;Example (2);;Example (3);;RDF;;Data interchange: RDF - in scheme (1);;URIs / IRIs;;Example (4);;Example (5);;Example (6);;Example (7);;Example (8);;RDF (1);;Example (9);;Example (10);;RDF (2);;URI / IRI - in scheme;;SPARQL : RDF Query Language;;Example (11);;Query: SPARQL - in scheme;;RDF Schema;;Example (12);;Example (13);;RDF Schema (1);;Example (14);;Example (15);;Semantic Web - graph;;Semantic Web World - graph;;Universal Access to All Knowledge (1);;RDFS - in scheme;;Layers of the Semantic Web;;Ontology: OWL - in scheme;;Web Ontology Language OWL;;Ontologies;;OWL Variants;;OWL Classes;;OWL Classes (1);;OWL Classes (2);;OWL Properties;;OWL Properties (1);;OWL Properties (2);;OWL Individuals;;Remember: It\'s about semantics;;Semantic MediaWiki;;Wikis are great;;Wiki Clock;;Wikipedia;;Universal Access to All Knowledge (2);;What Wikipedia knows;;Full-text Search Example;;Wikipedia’s answer: lists;;List Example;;List Example (1);;List Example (2);;List Example (3);;List Example (4);;List Example (5);;List Example (6);;List Example (7);;List Example (8);;List of lists Example;;List of lists Example (1);;Ergo;;Computers are stupid;;What humans see;;What humans see (1);;What computers see;;What computers see (1);;Computers don‘t make connections;;Computers need our help;;Help Example;;Querying the wiki;;Result rendering;;Pie chart;;Bar chart;;Timeline;;Querying Example;;Querying Example (1);;Review process;;Semantic page Example;;Semantic page Example (1);;Semantic page Example (2);;Semantic page Example (3);;Semantic page Example (4);;WikiTaaable Architecture;;Semantic page Example (5);;Semantic page Example (6);;Semantic page Example (7);;External data reuse;;Python example;;SNPedia;;SNPedia (1);;Characteristics prediction contest;;Semantic MediaWiki (1);;Summary;;Questions?'
9983,'lecture','en',9600,'2009-09-04','2009-10-20','Artificial Business Intelligence: Scaling Beyond the Real World with Cyc and LarKC','In the last few years significant advancement has been achieved in semantic, knowledge and context technologies as well as in methods for knowledge management. These technologies are becoming especially effective when applied to the capture, formalization and automated reuse of knowledge. In particular, these techniques have been demonstrated by Cycorp in specific intelligence and medical domains. Equally, though they may be applied to problems of managing business complexity to provide ABI - Artificial Business Intelligence.\nThe explosion of availability of free and open information resources following the emergence of the Web2.0 paradigm has widened the prospects for constructing real Artificial Intelligence solutions that are able to learn, to reason and to speculate.\n\nIn my talk I\'ll discuss the general class of problems that should be solvable in the near term, in part by exploiting available knowledge, and in part by collaboration between people and machines. I\'ll show some examples of partial solutions, and describe in some detail the components of a more complete solution. The discussion will focus on the issue of scaling AI techniques up to real applications, both in terms of very large, inferentially sophisticated knowledges bases, like Cyc, and in terms of techniques for web scale inference - the goal of the FP7 LarKC project.','Thinking Big: Web Scale AI;;Human knowledge evolution;;Example;;Content adaptation: heart valve repair;;Content adaptation: coronary artery;;45th’s Space Wing Hurricane Preparedness;;The Cyc Analytic Environment;;Cyc Analytical Environment: Screenshot;;Example: Hamas Leader;;Example: Hamas Leader (1);;Example: Hamas Leader (2);;Example: Hamas Leader (3);;Example: Hamas Leader (4);;Example: Hamas Leader (5);;Knowledge for People;;Example: inCyc - Slovenia;;Logistics;;Logistics (1);;Detailed Representations;;Overwhelming Problems;;Cycorp Corporate Mission;;Use-case: City on-line;;Use case: Drug Discovery;;Medical Outcome Studies;;Wikipedia screenshot;;inCyc screenshot;;Elements of Scale;;Some aspects of Solutions;;General Knowledge about Various Domains;;Scecific segments;;Cyc KB Extended w/Domain Knowledge;;Cyc KB Extended w/Domain Knowledge (1);;Complex logics;;For Inference: Senses of ‘In’;;Senses of ‘In’;;Concepts are densely related;;Temporal Relations;;Lexical Entry Example: Eat;;Using representations: Noun Compounds;;Some Transportation Event Types;;Relating Events and Participants;;Specificity has its own problems;;Gulliver’s Travels in Basic English;;Existing Vocab.;;Content Understanding, Review, or Entry - CURE;;Low Barriers to (knowledge) Entry;;Low Barriers to (knowledge) Entry (1);;Low Barriers to (knowledge) Entry (2);;Low Barriers to (knowledge) Entry (3);;Low Barriers to (knowledge) Entry (4);;Low Barriers to (knowledge) Entry (5);;Low Barriers to (knowledge) Entry (6);;Low Barriers to (knowledge) Entry (7);;Low Barriers to (knowledge) Entry (8);;Low Barriers to (knowledge) Entry (9);;Low Barriers to (knowledge) Entry (10);;Low Barriers to (knowledge) Entry (11);;Low Barriers to (knowledge) Entry (12);;Knowledge Acquisition Goals;;Even Lower Barriers Learning Facts by Search;;Parsing Results;;Machine Reading: Term learning;;Machine Reading: Background;;Example: Machine Reading;;Machine Reading: Scaling up scope, detail, understanding;;Coming up;;TextPrism;;Personalized Information Feeds;;TextPrism: Improved Recall;;Improved Recall Examples;;TextPrism: Improved Precision;;Semantic Licensing Examples;;Semantic Licensing Examples (1);;More Precise Matches;;More Precise Matches (1);;Only Restaurants in Marseille;;More Precise Matches (2);;Example: More Precise Matches;;Scaling Beyond the Web with LarKC;;Scheme: Query;;Performance: Subtheory: disjointWith;;Inference is Fast & Trainable;;The Large Knowledge Collider;;Goals of LarKC;;Infinite scalability?;;Basic Operation Types;;Realising the Architecture;;LarKC Architecture;;What does a pipeline look like?;;What Does a Pipeline Look Like?;;What Does a Pipeline Look Like? (1);;What Does a Pipeline Look Like? (2);;What Does a Pipeline Look Like? (3);;Decider Using Plug-in Registry to Create Pipeline;;Platform and Plug-in APIs are useable;;Released System: larkc.eu;;Alpha Urban LarKC High Level Architecture;;Destination Selection Pipeline Urban Monuments;;Destination Selection Pipeline Events;;LarKC Experiment: MaRVIN;;Reinforcement Learning;;Other potential plug-ins;;Why would people (like you) want to use LarKC;;Links;;Research Cyc Licensees;;Research Cyc Licensees (1);;LarKC First Release;;The End.'
9984,'lecture','en',9600,'2009-09-04','2009-10-20','Link Mining','Statistical machine learning is in the midst of a \"relational revolution\". After many decades of focusing on independent and identically-distributed (iid) examples, researchers are now studying problems in which the examples are linked together into complex networks. These networks can be a simple as sequences and 2-D meshes (such as those arising in part-of-speech tagging and remote sensing) or as complex as the collaboration structures produced by knowledge workers performing a variety of tasks in different contexts within an enterprise. In this talk, I will give an overview of this newly emerging research, focusing specifically on link mining tasks and algorithms.','Link Mining - first;;Roadmap;;Link Mining;;Linked Data;;Sample Domains;;Link Mining Tasks;;Object Classification;;Object Type Prediction;;Link Type Classification;;Predicting Link Existence;;Link Cardinality Estimation I;;Link Cardinality Estimation II;;Entity Resolution;;Group Detection;;Subgraph Discovery;;Graph Alignment;;Link Mining Tasks;;Link Mining Challenges;;Logical vs. Statistical Dependence;;Model Search;;Feature Construction;;Aggregation;;Selection;;Individuals vs. Classes;;Instance-based Dependencies;;Class-based Dependencies;;Collective classification;;Collective Resolution;;Labeled & Unlabeled Data;;Link Prior Probability;;Closed World vs. Open World;;Link Mining Summary;;Some Link Mining Algorithms;;Collective Classification;;Traditional Classification;;Relational Classification (1);;Relational Classification (2);;Relational Classification (3);;The Problem;;Example: Linked Bibliographic Data;;Feature Construction;;Simple Aggregation;;Feature Construction;;Aggregate Features Used;;Formulation;;CC Inference Algorithms;;Local Classifiers Used in ICA;;ICA: Learning;;ICA: Inference (1);;ICA: Inference (2);;Experimental Evaluation;;Results on Real Data;;Effect of Structure;;Entity Resolution;;The Problem;;InfoVis Co-Author Network Fragment;;The Entity Resolution Problem;;Attribute-based Entity Resolution;;Roadmap: Relational Entity Resolution;;Relational Entity Resolution;;Relational Identification;;Relational Disambiguation;;Relational Constraints;;Collective Entity Resolution;;Entity Resolution with Relations;;Algorithms;;Example: CiteSeer;;Example: CiteSeer (1);;Relational Clustering (RC-ER);;Relational Clustering (RC-ER) (1);;Relational Clustering (RC-ER) (2);;Relational Clustering (RC-ER) (3);;Cut-based Formulation of RC-ER;;Objective Function;;Measures for Attribute Similarity;;Relational Similarity: Example 1;;Relational Similarity: Example 2;;Comparing Cluster Neighborhoods;;Relational Clustering Algorithm;;Probabilistic Model (LDA-ER);;Probabilistic Generative Model for Collective Entity Resolution;;Discovering Groups from Relations;;Latent Dirichlet Allocation ER ;;Generating References from Entities;;Approx. Inference Using Gibbs Sampling;;Faster Inference: Split-Merge Sampling;;Experimental Evaluation;;Evaluation Datasets;;Baselines;;ER over Entire Dataset;;ER over Entire Dataset (1);;Performance for Specific Names;;Trends in Synthetic Data;;Link Prediction;;Link Prediction: The Problem;;Links in Data Graph;;Links in Information Graph;;Predicting Relations;;Roadmap: Conclusion;;Putting Everything together….;;Learning and Inference Hard;;Caveat: Link Mining & Privacy;;Link Re-Identification;;Attribute disclosure in OSNs;;Conclusion;;Thanks!'
9985,'lecture','en',9600,'2009-09-04','2009-10-20','Text Mining and Light Weight Semantics',NULL,'Text Mining & Light Weight Semantics;;Outline;;Where Text related technologies fit in Gartner Hype Cycle 2008?;;Priority Matrix for Web and User Interaction Technologies 2008;;How technical research areas are approaching text and semantics?;;…some of the key issues from methodological side;;What are the key issues in today’s semantic technologies?;;Text & Semantic Analytics;;Broader context: Web Science;;How do we represent text?;;Levels of text representations;;What dimensions are in text analytics?;;How dimensions fit to research areas?;;Semantic Web Technology stack;;The Semantic Web in 2008;;The Semantic Web in 2008 (1);;The Semantic Web in 2008 (2);;The Semantic Web in 2008 (3);;The Semantic Web Picture;;The beautiful world of Web X.X;;The beautiful world of Web X.X versions (…a trial to put all of them on one slide);;Web 2.0 – is there any new quality?;;Web 2.0 – the current hype;;…scale and dynamics of Web 2.0 ;;Some demonstrations… …from light-weight to heavy-weight;;Modeling the data (learning discrimination models);;Modeling the data with Support Vector Machine (SVM);;Classification into large taxonomies;;DMoz (Open Directory Project);;Classification of a query into DMoz;;Classification of a document into DMoz;;Visual & Contextual Search;;Contextualized search;;Example: searching for “Jaguar”;;Context sensitive search with http://searchpoint.ijs.si;;Multilingual search;;Example;;Example of cross-lingual information retrieval on Reuters news corpus (using KCCA);;News reporting bias;;Detecting News Reporting Bias;;News Visualization;;Topic landscape of the query “Clinton” from Reuters news 1996-1997;;Visualization of social relationships between “Clinton” and other entities;;Topic Trends Tracking of the documents including “Clinton”;;WW2 query “Pearl Harbor” into NYTimes archive;;WW2 query “Belgrade” into NYTimes archive;;WW2 query “normandy” into NYTimes archive;;LiveNetLife;;LiveNetLife connects people on similar information;;LiveNetLife in ACTIVE;;LiveNetLife demonstration;;Knowledge based summarizaiton;;Summarization via semantic graphs;;Detailed Summarization Procedure;;Example of automatic summary;;Full document semantic graph;;Full document semantic graph (1);;Automatically generated summary;;More examples;;More examples (1);;Question Answering;;Asking a question in natural language;;…result set is set of mentions of potential answers;;Document browser with summarization;;Cyc Knowledge Base and Reasoning;;The Cyc Ontology;;Cyc’s front-end: “Cyc Analytic Environment” – querying (1/2);;Cyc’s front-end: “Cyc Analytic Environment” – justification;;Further references…;;References to some Text-Mining books;;Books on Semantic Technologies;;References to the main conferences;;Videos on Text and Semantic Technologies'
9986,'lecture','en',9600,'2009-09-05','2009-10-20','Informal Knowledge Processes: The Long Tail of Business Processes',NULL,'Informal Knowledge Processes;;Name;;European Microsoft Innovation Center;;EMIC;;EMIC != MSR;;Anatomy of the long tail;;Agenda;;I’m a Knowledge Worker!;;EXERCISE – before we start;;The Knowledge Worker;;Knowledge Worker Revisited;;ACTIVE’s Knowledge Worker;;The typical situation of a Knowledge Worker;;EXCERCISE;;The Long Tail …;;Rules of Business…;;Where is the knowlegde?;;Workflow;;Business Process;;Informal Knowledge Process;;Workflows, Business Processes, Informal Knowledge Process;;Business Processes & KPs;;Evolving Knowledge Processes;;Definition;;KP over time;;KP-Example: Prepare Presentation;;Motivation;;Knowledge Processes in ACTIVE;;TaskService/TaskBar Integration;;Task Management as a Web Service;;Task Execution (top-down);;KProcess Execution Level;;Metrics and Measures for KPs;;‚Inter‘ – action Matters;;Hot-dog theory;;Hot-dog theory (1);;Security-aware Knowledge Processes;;Security-aware Knowledge Processes (1);;Summary;;Enterprise 2.0;;References;;Q&A'
9987,'lecture','en',9600,'2009-09-05','2009-10-20','Lizzon: A Professional Messaging Utility for Distributing Relevant Information within Enterprise in Real-Time',NULL,'A professional messaging utility for distributing relevant information within enterprise in real-time.;;Agenda (1);;About the Project;;Team Lizzon;;Agenda (2);;Gartner‘s Hype Cycle for Emerging Technologies;;Microblogging Platforms;;Agenda (3);;Features;;Principles;;Key-Features - Advanced Resource Publishing;;Key-Features - Generic Tagging;;Key-Features - Knowledge Map;;Key-Features - Integrate with existing tools;;Features;;What can you do?;;Agenda (4);;Classification of enterprise tools;;Thank you for Lizzon-ing.;;Why not groups? – Status quo;;Why not groups? – Avoid detour;;Why not groups? – Subtopics;;How Hierarchies Work'
9988,'lecture','en',9600,'2009-09-05','2009-10-20','Taking Anysite.com to the Next Level with SEO, Web Analytics, Testing, Data Mining, Targeting, Forecasting and Web Personalization',NULL,'Taking Anysite.com To The Next Level;;Brief;;SEO: Search Engine Optimization;;Search drives about two thirds of non-direct traffic;;Very few searchers go beyond the first Search Engine Results Page;;SEO generates 200% to 400% more traffic;;SEO Best Practices: Determine Key Phrases;;SEO Best Practices: Most Important;;SEO Best Practices: Including Top Key Phrases;;SEO Best Practices: Links, SEM & WebPosition;;SEO Example: Bloomberg.com Article on Gold Futures;;SEO Example: Bloomberg.com Gold Futures Article Source Code;;SEO Example: Google Keyword Tool;;SEO Example: Google Keyword Tool Results;;SEO Example: Wordtracker Results;;SEO Example: Google Query For Gold Futures;;SEO Example: MarketWatch Gold Futures Search Result;;SEO Example: MarketWatch Gold Futures Search Result Source Code;;How do I convince 2500 reporters to write for Google?;;Web Analytics;;Web Analytics Application Report;;BBG Weekly Web Metrics Report Page 1;;BBG Weekly Web Metrics Report Page 2;;BBG Weekly Web Metrics Report Page 3;;BBG Weekly Web Metrics Report Page 4;;NYT Page Type Transition Probabilities;;NYT Times Topics Article Page Driver Analysis;;NYT Market Share of News Content Page Views by Page View Segment;;NYT Decay Rate Analysis: Overall WWW Results;;NYT Decay Rate Analysis: Overall Mobile Results;;Testing;;Page Testing: Making Improvement;;A/B;;MVT;;Bonferonni;;Bonferonni with Data Mining;;NYT Global Regilite Test;;NYT Sponsored Search Test;;NYT Sponsored Search Test;;NYT Archive Article Page Macro Deconstruction Test I Results;;NYT Archive Article Page Macro Deconstruction Test II Results;;Data Mining;;Data Mining: Finding Patterns;;NYT Visit Arrival Clusters;;News to Article Page Cluster Graph;;NYT Click Path Cluster Profiles;;Multi-Nav AP Page Type Transition Probabilities;;Designed Nav Page Type Transition Probabilities;;HP Squatter Page Type Transition Probabilities;;SF Nav Page Type Transition Probabilities;;HP-AP Nav Page Type Transition Probabilities;;Only Articles Nav Page Type Transition Probabilities;;Everything Nav Page Type Transition Probabilities;;HP Nav Page Type Transition Probabilities;;Click Path Segmentation Summary;;Cluster Cross Tab Analysis: Column Percents;;Boston DMA Reach;;Boston DMA Reach (1);;Boston DMA User Content Clusters at ABT;;Boston DMA User Content Clusters at BOS;;Boston DMA User Content Clusters at NYT;;Boston DMA Term by Site Odds;;Targeting;;Targeting: Taking Action;;Content Targeting: Recommendation Engines;;User Based Collaborative Filtering;;Item Based Collaborative Filtering;;An Item based Recommendation Engine Approach (Sarwar, et al);;An Item based Recommendation Engine Approach (Sarwar, et al) (1);;Item Similarity;;Ad Targeting: NYT CXOs Key Phrases;;CXO Key Phrase Results;;Bernoulli Naïve Bayes: Bayes Rule;;Bernoulli Naïve Bayes: Naïve Assumption;;Bernoulli Naïve Bayes: LLRs;;Gaussian Naïve Bayes: Intro;;Gaussian Naïve Bayes: Above Average TFIDF;;Gaussian Naïve Bayes: TFIDF Distribution;;Gaussian Naïve Bayes: Normal Approach;;Gaussian Naïve Bayes: Gaussian Approach;;Gaussian Naïve Bayes: Normal Approach;;Forecasting;;NYT Homepage Impressions Forecast Model;;How do I use Analytics to stop or minimize this?;;BBG Weekly Web Metrics Report Page 5;;BBG Forecasting Issue;;Web Personalization;;How do you make the news as compelling as this?;;Thank You'
9989,'lecture','en',9600,'2009-09-05','2009-10-20','Introduction to the ACTIVE Knowledge Workspace SDK','This session will provide a short introduction into the ACTIVE knowledge workspace with online demonstration of the basic Workspace features.\nWorkspace software architecture will be overviewed and then the ACTIVE Software Developer Kit will be presented. As an SDK usage example the scenario for developing an ACTIVated application will be explained.','Introduction to the ACTIVE Knowledge Workspace SDK ;;Agenda;;Introduction to the ACTIVE knowledge workspace (1);;Introduction to the ACTIVE knowledge workspace (2);;Workspace software architecture (1);;Workspace software architecture (2);;Workspace software architecture (3);;Workspace software architecture (4);;Online demonstration of basic Workspace features;;Overview of ACTIVE Software Developer Kit ;;Overview of ACTIVE Software Developer Kit (2)'
9990,'lecture','en',9600,'2009-09-05','2009-10-20','A Cabinet of Web 2.0 Scientific Curiositics',NULL,'A Cabinet of Web 2.0 Scientific Curiosities;;Some of the people involved;;Overview;;Publishing Industry facts & figures;;Publishing industry size;;Largest STM publishing companies;;Funding sources;;Costs of research;;Example (1);;Example (2);;(Some) Publishing Milestones;;Journal Evolution;;Example;;fass09_mulvany_cwsc_01_Page_014;;Going beyond journals;;2.0;;Web 1.0 & Web 2.0;;Google;;eBay;;Wal Mart;;Data;;explodingdog;;Stay Classy, SXSW: Building Respectful Software;;Scientists resist (1);;Scientists resist (2);;Some Issues Where Web 2.0 May Help in Science;;Framework (1);;fass09_mulvany_cwsc_01_Page_028;;Fire eagle;;100,000;;1.1 Billion > 129;;Naming;;Why is the issue of identity important, for reputation!;;1619 - 1677;;Impact Factor;;Example (1);;Example (2);;Example (3);;Example (4);;Example (5);;Example (6);;Example (7);;Main-path analysis and path-dependent transitions in HistCite™-based historiograms;;21 000;;Weaving in more value;;Example;;Framework (2);;Example;;Building a delivery infrastructure;;Example (1);;Example (2);;Example (3);;fass09_mulvany_cwsc_01_Page_053;;Example (4);;Nature chemistry;;Example (5);;Example (6);;Example (7);;Example (8);;Example (9);;Example (10);;Example (11);;Organise metadata;;Creating a central NPG database;;Example (12);;FlyBase;;WormBase;;Example (1);;Example (2);;Framework (3);;Getting Social;;arXiv;;NaturePrecedings;;Plos;;Connotea;;Example (1);;Example (2);;fass09_mulvany_cwsc_01_Page_078;;Example (3);;Example (4);;Example (5);;Example (6);;Example (7);;DRF;;Example (1);;Example (2);;Example (3);;Example (4);;Example (5);;Most read publication outlets;;Nature Network;;Example;;Nature Network Hubs;;Bringing things together;;Pg;;Blogged Articles;;Scintilla;;Friendfeed;;Google Wave;;streamosphere.nature.com;;Example (1);;Framework (5);;Citizen Science;;Seti@home;;The Sheep Market;;Cheap Sentiment Analysis;;Percent Tweets with Positive Sentiment;;Galaxy Zoo;;Example;;Framework (5);;Google Wave ;;Google Wave (1);;Example (1);;Example (2);;Google Wave;;fass09_mulvany_cwsc_01_Page_116;;Framework (7);;Opensource;;Visualisation;;Eigenfactor.org;;Example (1);;Example (2);;Example (3);;biological pathways;;The Future;;Final thoughts (1);;Final thoughts (2);;sci foo;;Resources;;Extra image Acknowledgements;;The End'
9991,'lecture','en',9600,'2009-09-06','2009-10-20','On Future Internet, Cloud Computing and Semantics - You Name It','This presentation will present various developments in the Internet of Services. Research in the Internet of Services is put in the context of ongoing research on the Future Internet. The role of semantics in this research domain will also be illustrated. In addition, this presentation will consider industry relevance by focusing on well-known business models based on Software-as-a-Service and Cloud Computing. A number of business strategies will be discussed as well. Some glimpses of future research will also be given.','On Future Internet, Cloud Computing, and Semantics– You name it;;Overview;;Future Internet - Today’s Internet (1);;Future Internet - Today’s Internet (2);;Future Internet - Today’s Internet (3);;Future Internet - Today’s Internet (4);;Future Internet - World Internet Penetration Ratesby Geographic Regions;;Future Internet - Current/emerging problems and opportunities;;Future Internet - What is it?;;Future Internet - Different perspectives and their danger;;Future Internet - What’s next? (1);;Future Internet - What’s next? (2);;Internet of Services - Vision;;Internet of Services - Vision (1);;Internet of Services - Cloud Computing – Everything old is new again?;;Internet of Services - Cloud Computing – Everything is renamed?;;Internet of Services - Cloud Computing – What is it? (1);;Internet of Services - Cloud Computing – What is it? (2);;Internet of Services - Cloud Computing – What is different?;;Internet of Services - Cloud Computing – Every cloud has a silver lining;;Internet of Services - Business Models: factors to consider (1/2);;Internet of Services - Business Models: factors to consider (2/2);;Internet of Services - Business Strategies (1/2);;Internet of Services - Business Strategies (2/2);;Internet of Services - Some issues for debate;;Internet of Services - Some issues for debate: SaaS, a silver bullet? (1);;Internet of Services - Some issues for debate: SaaS, a silver bullet? (2);;Internet of Services - Some issues for debate: Billions of services? ;;Internet of Services - Some issues for debate: independent thinking?;;Internet of Services - What’s next? (1);;Internet of Services - What’s next? (2);;Semantics - What Semantics?;;Semantics - SOA4All;;Semantics - SOA4All overall architecture;;Semantics - Marrying Ontology and Software Technology ;;Semantics - Service Web 3.0;;Semantics - EU semantics research: vision without execution? (1);;Semantics - EU semantics research: vision without execution? (2);;Semantics - What’s next?;;So?;;WP2009-10 - 7th Framework Programme (2007-2013);;WP2009-10  -  ICT WP2009-2010, ~2 B€ total;;WP2009-10  Challenge 1;;WP2009-10 - Internet of Services, Software and Virtualisation;;WP2009-10 - Objective 1.2, Problems and opportunities (1/2);;WP2009-10 - Objective 1.2, Problems and opportunities (2/2);;WP2009-10 - Objective 1.2, Expected Impact;;WP2009-10 - Current FP7 projects under Objective 1.2;;And now what?;;Conclusions;;Questions?;;For more information'
9992,'lecture','en',9600,'2009-09-06','2009-10-20','Semantic Technology in Business Systems: Status and Prospects',NULL,'Semantic Technology in Business Systems Status & Prospects;;Next Generation Web team;;Overview;;Today’s Web is…;;Semantic Web;;Ontologies;;Ontologies & Taxonomies;;Ontology of People and their Roles;;Why develop an ontology?;;Ontologies and Description Logic;;Which Semantic Web?;;Overview;;In three words;;In three words (1);;Words and meanings;;Semantic Annotation;;Semantic Browsing;;Semantic Browsing (1);;Precision in Semantic Web Search;;Semantic KM at BT;;Overview;;Information Integration;;Semantic Information Integration;;Semantic Data Integration - results;;Semantic VOIP management;;Research prototype developed;;Business Impact;;Overview;;Motivation/Vision;;Software to Serviceware;;Semantic Technology & Serviceware;;Semantic Service-oriented Architectures;;Semantic Serviceware;;BT Ribbit Acquisition;;Next Generation Soft Telco (SOA4ALL EU Project) Lowering the barrier to find and use services on the web;;Overview;;Semantic Business Intelligence;;Semantic BI;;Semantic Business Intelligence;;Semantic Business Intelligence (1);;Semantic BI – benefits;;SBI Demonstrator;;COGITO Monitor;;COGITO Monitor (1);;Overview;;Solution Design - Challenges;;Improving the Solutions Design process;;Semantic Wiki: Answering Questions;;Semantic Wiki: Reasoning & Maintenance;;Proposal: Smith and Williamson;;Proposal: Smith and Williamson (1);;Proposal: Smith and Williamson (2);;Proposes product BT Net Premium;;Proposal: Phoenix;;Benefits;;Overview;;BT Global Services;;Health IT is heterogeneous & distributed;;Pattern repeated in each health community;;Patient centric Health IT;;NHS Connecting for Health;;Tools for Healthcare IT Integration;;Patient centric Health IT;;Semantic Technology & Health;;SNOMED-CT & OWL;;Pure subsumption hierarchy;;Composite Concepts: Property based definitions;;Post coordination;;Semantic reasoning at point of care;;Example;;Example (1);;Example (2);;Example (3);;Example (4);;Example (5);;Semantic reasoning – example 2;;Progress in BT;;Overview;;Semantic Technology uptake;;Semantic Technology uptake (1);;A couple of (non-)controversies;;Semantic Technology uptake;;Thank you for your attention'
9993,'lecture','en',9600,'2009-09-06','2009-10-20','Trust and Reputation in eCommerce',NULL,'Trust, Reputation and eCommerce;;Research Labs - Areas of Work;;Research Labs - Areas of Work (1);;Topics;;Information Assymetry;;Criteria for a Lemon Market;;Examples;;Solutions to the Lemon Market;;Reputation;;Solutions to Online “Lemon” Markets;;Online vs Offline Markets;;Yamagishi Experiments;;Online Strangers and Trust;;eBay Feedback;;eBay Feedback (1);;eBay Feedback (2);;Feedback Profile;;Analysis of Feedback Text (Sundaresan et al 2007);;eBay Feedback – Rated Aspect Summary (Lu, Sundaresan, Zhang – 2009);;Expression/Sentiment;;Is Reputation Rewarded?;;Is Reputation Rewarded? (contd);;Do Sellers care about their feedback?;;So far…;;Trust;;Reputation;;Trust and Reputation;;Mathematical Equivalence Properties of Trust;;Trust ust Transitivity and Recommendation;;Trust and Security/Safety;;Recommender Systems;;Recommender vs Reputation Systems;;Combining Recommender and Reputation Systems;;Reputation System Implementation;;Reputation Computation Engines;;Rating Computation Engines (contd.);;Bayesian Systems - Contd.;;Discrete Trust Model;;Belief Systems;;Example;;Fuzzy Models;;Trust and Reputation Inference;;Reputation Weights;;Reputation Calculation;;Overlay Computation;;PowerTrust (Zhu, Hwang 2006);;PeerTrust (Liong, Xiu 2004);;SmallTrust (Sakurai Lab, Kyushu univ);;Flow Models;;Static Web (PageRank);;Static Web (HITS);;TrustRank(Gyongji ’04);;EigenTrust System (Kamvar et al);;EigenTrust;;EigenTrust (1);;Online Implementations: eCommerce;;Product Reviews;;Epinons Web of Trust;;Epinions Incentive System;;Bizrate;;Amazon;;Online Implementations: Discussion Space;;Digg;;Advogato;;The Reputation Market;;Reputation Market (contd);;Need for Negative Reputation and Complaints;;Multiple Identities: Sybil Attack on Reputation;;Cost of Attack on Reputation System;;Costs and Payoffs;;Trust and Distrust Propagation (Guha et al 2004);;Propagating both Trust and Distrust;;Reaching the Final Value;;Interpreting F;;Is Distrust Transitive?;;Qualifying Reputation Score;;Auroral Diagrams (Shen, Sundaresan 07);;Auroral Diagram: Arts and Craft;;Auroral Diagram: Collectibles;;Motivation for Dynamic Reputation (Shen, Sundaresan 07);;Trust in Different Categories;;Spread the reputation;;The Web;;eBay;;Dynamic Trust and Reputation (Sundaresan 06);;Dynamic Trust and Reputation;;Benefits of this approach;;ReputationRank (Shen, Sundaresan 07);;The Good, The Bad;;Other Advantages;;Impact of Reputation;;Object-level Trust and Reputation;;Transparent vs Opaque Reputation;;Reputation and Relevance Sort;;Identity;;Identity and Reputation Portability;;Tagging and Trust;;The New Phenomena;;Summary'
9994,'lecture','en',9600,'2009-09-06','2009-10-20','Research Directions in Enterprise Knowledge Management',NULL,'Research Directions in Enterprise Knowledge Management;;Enterprise Search Today;;Enterprise IR is different from Web IR;;Enterprise Tasks involve specialized business processes and roles;;Collaborative Document Development;;Example;;Areas of Improvement;;Areas of Improvement (1);;From monolithic documents to reusable pieces of information;;Motivating business task;;Entity Retrieval & Ranking;;Online experiments;;Document Chunking;;Enterprise Image Classification and Retrieval;;Overview of Approach;;Feature Extraction;;Task specific application;;3. Task specific application;;Areas of Improvement (2);;Context;;Context-sensitive ranking;;Contextual Access to Information;;Areas of Improvement (3);;Sample Proposal;;Sample Proposal (1);;Areas of Improvement (4);;Publishing Enterprise Content Today;;Encouraging Content Submission;;Some Metadata fields;;Ordering Sequential Prediction Tasks;;Distributed Active Learning;;Confidentiality Issues;;Summary;;Enterprise KM: A different perspective;;The Consumer’s Life;;The Consumer’s Life (1);;Work Life;;Work Life (1);;Personalized Knowledge Models;;MyKM;;Clothing Retailer;;Sporting Goods;;Sporting Goods (1);;Challenge: How do you describe these products?;;Extreme Case: eBay;;Having a product attribute database;;shupping;;What can businesses do with such enriched databases?;;Challenges;;Example;;Pre-Processing ;;Example (1);;Unsupervised Seed Augmentation;;Unsupervised Seed Generation;;Unsupervised Seed Generation (1);;Examples of extracted attribute-value;;Example (2);;Titles;;Descriptions;;Classification: Co-EM with Naïve Bayes;;Classification: Co-EM with Naïve Bayes (1);;Classification: Co-EM with Naïve Bayes (2);;Training View2 from View1;;Final Labels;;Example (3);;Active Learning;;Accenture;;Accenture (1);;Accenture (2);;Accenture (3);;Experimental Results;;Experimental Results (1);;Example (4);;Forming attribute-value pairs;;Examples;;Interesting Results;;Interesting Results (1);;Context-dependent extraction;;KL metric is useful in detecting confusable;;Summary;;Summary (1)'
9995,'lecture','en',9600,'2009-09-06','2009-10-20','The Intelligent Cargo Concept in the European Project EURIDICE',NULL,'The Intelligent Cargo Concept in the European Project EURIDICE;;Content;;The Project (WHY);;EURIDICE: European Inter-Disciplinary Research on Intelligent Cargo for Efficient, Safe and Environment-friendly Logistics;;The logistics industry;;ICT innovation for the logistics industry:EC ICT for Mobility Strategic Research Agenda;;EURIDICE approach vs. state-of-the-art;;EURIDICE Intelligent Cargo vision;;The Visionand Message;;ICT for goods mobility today:Cutting-edge technologies for top demanding customers;;What services are needed by the majority of logistic users and operators?;;Finding our own “elevator speech”;;1. The product;;The customers: Who cares about the cargo being intelligent? -> Who is target of our value proposition?;;Approach to the market;;Value proposition pitfalls ;;2. The customers;;3. The benefits;;Application ideas;;Disruptive innovation strategy:Aim at the largest pool of users -> remove barriers ;;The EURIDICE message;;Our market;;ICT for goods mobility tomorrow;;What is Intelligent Cargo (HOW);;What does “Intelligent Cargo” mean?;;Intelligent vs. “dumb” cargo, basic capabilities;;Intelligent vs. “dumb” cargo, specialized capabilities;;Intelligent Cargo in practice;;Pilot Scenarios;;Example: Scenario S7 Intelligent routing through cargo-infrastructure cooperation;;Example: Scenario S8 Automated clearance and billing of transiting goods;;EURIDICE architecture and components (WHAT);;EURIDICE vision translated into an architecture;;Internet of Cargo vs. Internet of Things;;Expected paradigm shift;;Cargo objects and logistics stakeholders;;Thing-to-thing vs. organization-to-organization ;;Any-to-any communication and data interchange ;;Event-triggered, decentralized decisions support ;;Architecture overview;;Intelligent Cargo & the Agent Paradigm -> WP13;;Cargo Intelligence solution;;Contact'
9996,'lecture','en',9600,'2009-09-06','2009-10-20','KM at the Customer Front-Line: The BT Case Study in ACTIVE',NULL,'KM at the customer front-line - The BT case study in ACTIVE;;Why case studies?;;KM at the customer front-line - a greenfield site;;Trialists;;How they work;;Understanding their needs;;Help with knowledge sharing;;Context switching;;Our solution – next 6 months;;Semantic MediaWiki;;MediaWiki;;Semantic MediaWiki (1);;A semantic view of London;;Querying the Semantic MediaWiki;;Semantic MediaWiki in BT case study;;Categories;;Proposal : Smith and Williamson;;Proposal : Smith and Williamson (1);;Proposal : Smith and Williamson (2);;Proposes product BT Net Premium;;Proposal: Phoenix;;ACTIVE Knowledge WorkSpace (AKWS);;Opening a file normally;;Opening a file from context;;Tagging in an application;;Sharing through tagging;;Sharing through context;;Context in email (mock-up);;Tagging a document (mock-up);;Searching;;Learning context and process;;TNT (Time-Network-Text) Architecture;;Intuition behind developed model;;Examples of Processes, Tasks, Contexts;;Validating the prototype;;Validating the prototype (1);;User assessment criteria;;Summing-up;;Other topics;;Thank you!'
10000,'opening','sl',9976,'2009-10-01','2009-11-09','Pozdravni nagovor / Opening speech',NULL,NULL
10001,'opening','en',9976,'2009-10-01','2009-11-09','Opening speech / Pozdravni nagovor',NULL,NULL
10003,'introduction','sl',9976,'2009-10-01','2009-11-09','Napovednik prvega sklopa: Nastanek in evolucija življenja / Introduction to the First Session: Origin and Evolution of Life',NULL,NULL
10005,'lecture','en',9976,'2009-10-01','2009-11-09','The Emergence of Life on Earth: Mystery or Scientific Problem? / Nastanek življenja na Zemlji: misterij ali znanstveni problem?','Until the end of the 19th century, the origin of life on Earth was explained either as the creative act of god or as the result of \"spontaneous generation\" – the repeated formation of complete organisms from inanimate matter. Only within an evolutionary conception, following Darwin\'s theory, could the origin of life on the ancient Earth begin to be studied scientifically. Scientists still didn\'t find an empirical answer to this difficult question and are divided on the nature of the first systems to emerge. They agree however that natural selection was actively involved in the process. They are also united in rejecting the creationistic claims and in supporting the naturalistic worldview.\n----\nIzvor življenja so vse do konca 19. stoletja razlagali ali kot božje stvarstvo ali kot rezultat\nspontanega nastanka, torej kot ponovni nastanek celotnih organizmov iz nežive snovi. Šele z\nevolucijskim konceptom, ki je sledil Darwinovi teoriji, so ga začeli preučevati znanstveno.\nRaziskovalci še vedno niso našli empiričnega odgovora na to težko vprašanje in se delijo glede na\nprepričanje o pojavu prvih sistemov. Kljub vsemu se strinjajo, da je bil naravni izbor aktivno vključen\nv ta proces. Enakega mnenja so tudi pri zavračanju kreacionističnih razlag in pri podpiranju\nnaturalističnega svetovnega nazora.','The Emergence of Life on Earth: Mystery or Scientific Problem?;;How did life emerge on the ancient earth?;;Traditional views on the origin of life - 1;;Traditional views on the origin of life - 2;;Darwin’s Tree of Life;;Last Universal Common Ancestor;;LUCA and the three domains of life: Eukaria, Archaea, Bacteria;;The emergence phase and the tree of life;;“In a warm little pond”;;A breakthrough of a previous impasse;;A new scientific field is born in the 1950s and 1960s;;Molecular biology reveals the interdependence among cellular components;;The Chicken and Egg Problem;;Two research camps attack the problem from different angles;;The emergence of life –the emergence of biological complexity;;A paradox?;;The debate between the camps;;The gene-first answer: the RNA-world theory - 1;;The gene-first answer: the RNA-world theory - 2;;The “metabolic” answer ;;A Metabolic Self-Replicating Ensemble;;Dilemma;;The logic of the arch and scaffold;;“How can you build any kind of arch gradually?;;The Scaffolding;;Creationism and Evolution;;Is the conflict empirical? Can one prove that life emerged naturally? - 1;;Example;;Is the conflict empirical? Can one prove that life emerged naturally? - 2;;What kinds of primitive systems could support natural selection?;;Examples of prebiotic factors that could have built the infrastructure for natural selection - 1;;Examples of prebiotic factors that could have built the infrastructure for natural selection - 2;;Prebiotic chemists;;Continuity and Novelty in the Emergence of Life;;The origin-of-life question was formulated in scientific termsfollowing the rise of molecular biology in the 1950s and ’60s;;bzid09_fry_nznz_01_Page_36;;Cairns-Smith\'s formulation of the conditions of evolution of \"things\" through natural selection;;Last Universal Common Ancestor: LUCA;;Science aims;;The starting point of the origin-of-life process;;Michael Behe’s definition of an “irreducibly complex system”;;Theoretical and empirical refutations of the notion of irreducible complexity;;How did life emerge according to ID?;;The argument from Design;;Is the “analogy method” a valid scientific method?;;What is “Theistic science”?;;Could natural selection have taken part in the emergence of life? - 1;;Could natural selection have taken part in the emergence of life? - 2;;Origin-Of-Life and the nature of science;;Schema;;Science ;;The ID argument begs the question'
10006,'lecture','en',9976,'2009-10-01','2009-11-09','The Major Transitions in Evolution / Veliki prehodi v evoluciji','Some major transitions in evolution (such as the origin of multicellular organisms or that of social animals) occurred a number of times, whereas others (the origin of the genetic code, or language) seem to have been unique events. One must be cautious with the word ‘unique’, however. Due to a lack of the ‘true’ phylogeny of all extinct and extant organisms, one can give it only an operational definition. If all the extant and fossil species, which possess traits arising from a particular transition, share a last common ancestor after that transition, then the transition is said to be unique. Obviously, it is quite possible that there had been independent “trials”, as it were, but we do not have comparative or fossil evidence for them.','The major transitions in evolution;;Units of evolution;;John Maynard Smith (1920-2004);;The major transitions (1995);;Recurrent themes in transitions;;Difficulty of a transition;;Difficult transitions are ‘unique’;;A crucial insight: Eigen’s paradox (1971);;Molecular hypercycle (Eigen, 1971);;Parasites in the hypercycle(JMS);;Gánti’s chemoton model (1974);;The latest edition: OUP 2003;;The stochastic corrector model for compartmentation;;Dynamics of the SC model;;Group selection of early replicators;;Egalitarian and fraternal major transitions (Queller,1997);;The simplest cells are bacterial;;The eukaryotic cell is very complex—too complex!;;LECA and phagocytosis;;Most forms of multicellularity result from fraternal transitions;;The royal chamber of a termite;;Division of labour;;Hamilton’s rule;;The origin of insect societies;;Why is often no way back? ;;Contingent irreversibility;;Central control;;What makes us human?;;Evolution OF the brain;;The coevolutionary wheel'
10008,'lecture','sl',9976,'2009-10-01','2009-11-09','Sodobni pogled na drevo življenja: Mikrobiologova zgodba / Contemporary View of a Tree of Life: The Microbiologist’s Tale','Mikroorganizmi so si kot taksonomska skupina dokaj pozno utrli pot do lastne veje na\nskupnem drevesu življenja. Dolgo so na tem drevesu prevladovali predstavniki velikih organizmov,\ntorej živali in rastlin. Danes pa moderne metode omogočajo hitro in zanesljivo pridobivanje informacij\no mikroorganizmih, ki bivajo na najrazličnejših koncih našega planeta, ne da bi jih morali zato osamiti\nin gojiti v laboratorijskih razmerah, celo videti nam jih ni več potrebno. Z metagenomskim\nsekvenciranjem izbranih delov mikrobnih genomov, največkrat so to geni za ribosomske molekule, so\nraziskovalci v zadnjem desetletju pokazali, da na našem planetu biva neprimerno večje število\nbakterijskih in arhejskih vrst kot pa vrst evkariontskih večceličarjev in da velja podobno tudi za\nnajvišje taksonomske kategorije, torej debla ali kraljestva. Univerzalno drevo življenja je torej precej\ndrugačno, kot smo si ga slikali doslej, in v njem popolnoma prevladujejo mikroskopski, v največjem\ndelu še (razen taksonomske informacije) popolnoma neznani organizmi. Velika bitja predstavljamo na\ntem drevesu le nekaj drobnih, skoraj zanemarljivih vej.\n----\nMicroorganisms have managed to push their way onto the universal tree of life fairly late. For a long time the representatives of large organisms, i.e. animals and plants were dominating the trees of life. However, modern methods have made possible a fast and reliable retrieval of information concerning microorganisms, inhabiting various parts of our planet, without the need for isolation and cultivation of these organisms in in vitro conditions. Moreover, we don\'t even need to observe them anymore. Using the metagenomic sequencing of chosen parts of the microbial genomes, these are mostly the ribosomal genes, the researchers showed us within the last decade, that substantially more bacterial and archaeal species live on our planet as eucaryotic metazoans and similar is true at the highest taxonomic levels, i.e. phyla and kingdoms. Universal tree of life appears thus quite different from the trees that we have been seeing till now and is apparently completely dominated by microscopical, in the largest part completely unknown, apart from the pure taxonomical information, organisms. Large organisms represent only few and minor branches on such a tree.','Sodobni pogled na drevo življenja: mikrobiologova zgodba;;A: drevo življenja, kot ga je narisal von Haeckel leta 1866 ;;Whitaker, 1969;;B: drevo življenja, kot je narisano v večini modernih bioloških in mikrobioloških visokošolskih učbenikov ;;Bacteria 1999;;Koncept vrste (species) in debla (phylum) v mikrobiologiji;;Primeri;;Število znanih in opisanih vrst živih bitij;;Culturability determined as a percentage of culturable bacteria in comparison with total cell counts;;Okolje;;Molekularni kronometri (markerji) v mikrobni taksonomiji;;Predlagani koncept prokariontske vrste (filofenetski koncept);;Bacterial community;;Environmental samples;;Microbial diversity in the deep sea and the underexplored ‘‘rare biosphere’’;;TRENDS in Mcrobiology;;iTOL drevo življenja;;Eukaryota;;Archaea;;Bacteria;;Nature Microbiology Reviews ;;An ecological and evolutionary perspective on human-microbe mutualism and disease'
10009,'lecture','sl',9976,'2009-10-01','2009-11-09','Sistematski pogled na biodiverziteto / A Systematic Perspective on Biodiversity','Prispevek obravnava biodiverziteto kot zgodovinski pojav in produkt evolucije. Zavzema se\nza dosledno filogenetsko obravnavo pestrosti življenja na Zemlji. Opozarja, da marsikje še vedno\nprevladuje pojmovanje življenja v obliki premočrtnega niza od primitivnih do bolj popolnih oblik, in\nda pravilnejša alternativa – evolucijska zgodovina kot razvejeno drevo – še ni dobila svojega mesta v\nbiološkem izobraževanju. Podane so osnove filogenetske sistematike in argumenti v prid uporabi\nnaravnih skupin pri pedagoški in znanstveni obravnavi biodiverzitete.\n----\nIn this paper, biodiversity is considered as a historical phenomenon and the result of evolutionary processes. It is argued that as such the diversity of life on Earth should always be analyzed in a consistently phylogenetic perspective. Further, the problem of persistent ladder-thinking in several biodiversity-related fields including biological education, is discussed. In order to facilitate tree-thinking, fundamentals of phylogenetic systematics are laid out. Based on examples from well-known taxonomic groups, the advantages of monophyletic over artificial groupings in both educational and scientific aspects of biodiversity are discussed.','Sistematski pogled na biodiverziteto;;Biološka sistematika, sistematska biologija - 1;;Biološka sistematika, sistematska biologija - 2;;Umetni sistemi prikrojijo resničnost v skladu s sistematikovimi predstavami;;Hierarhična, drevesasto razvejena oblika odnosov med vrstami (skupinami živih bitij) je že dolgo znana;;Willi Hennig (1950);;Filogenetsko drevo - 1;;Filogenetsko drevo - 2;;Predstava o napredovanju po evolucijski lestvi trdovratno vztraja - 1;;Predstava o napredovanju po evolucijski lestvi trdovratno vztraja - 2;;Lestvičasto pojmovanje evolucije vodi do nenaravnih skupin;;Monofiletske (= naravne) skupine vključujejo skupnega prednika in vse njegove potomce - 1;;Monofiletske (= naravne) skupine vključujejo skupnega prednika in vse njegove potomce - 2;;Filogenetski sistem namesto arbitrarnih lestvic sestavljajo realni sestrski odnosi med neposrednimi potomci skupnega prednika - 1;;Filogenetski sistem namesto arbitrarnih lestvic sestavljajo realni sestrski odnosi med neposrednimi potomci skupnega prednika - 2;;Pomen naravnega sistema za razumevanje evolucije in biodiverzitete - 1;;Pomen naravnega sistema za razumevanje evolucije in biodiverzitete - 2;;Pomen naravnega sistema za razumevanje evolucije in biodiverzitete - 3;;Pomen naravnega sistema za razumevanje evolucije in biodiverzitete - 4;;Pomen naravnega sistema za razumevanje evolucije in biodiverzitete - 5;;Katera je predniška? - 1;;Katera je predniška? - 2;;Katera je predniška? - 3'
10010,'lecture','en',9976,'2009-10-01','2009-11-09','The Gene in Context: from Developmental Plasticity to Plastic Heredity / Gen v kontekstu: od razvojne plastičnosti do plastičnega dedovanja','The gene-centered view, according to which genes are the most important determinants of development, the sole stuff of biological heredity, and the guide for the understanding of all aspects of evolution, has dominated biological thinking for the last 50 years. This view is now changing. In this lecture I point to the perils of “genetic astrology” – predicting the future and analyzing personality on the basis of DNA sequencing. I present a developmental approach to biology and evolution which stresses the importance of phenotypic plasticity and which incorporates epigenetic inheritance. This approach points to the many sources of developmental and hereditary variations, answers some of the puzzles that the gene-centered approach failed to solve, and leads to a more satisfying and fertile biological outlook and research.\n----\nZadnjih petdeset let v biološkem razmišljanju prevladuje genocentričen pogled, po katerem\nso geni najpomembnejši dejavnik, ki vpliva na ontogenetski razvoj organizmov, edina osnova za\nbiološko dedovanje in vodilo za razumevanje vseh vidikov evolucije. Ta pogled se v zadnjem času\nspreminja. V tem prispevku bom izpostavila nevarnosti \"genetske astrologije\", ki napoveduje\nprihodnost in analizira osebnost na podlagi zaporedja DNA. Predstavila bom razvojni pogled na\nbiologijo in evolucijo, ki poudarja pomen fenotipske plastičnosti in vključuje epigenetsko dedovanje.\nTak pristop pokaže na mnogo vzrokov za ontogenetske in dedne raznolikosti, odgovori na nekatere\nuganke, ki jih genocentrični pogled ne reši, in obeta zadovoljivejše in plodnejše raziskovanje v\nprihodnosti biologije.','The gene in context: from developmental plasticity to plastic heredity;;Thanks;;James Watson 1989;;Medicus;;Genes;;DNA;;It’s All In Your GENES!!!!!! - 1;;It’s All In Your GENES - 2;;Dionne Quintuplets;;Type 1 diabetes;;Epigenetics;;Waddington’s epigenetic landscape;;Interactions among genes are not always linear;;Genetic correlation study;;Diabetes type II;;Goldstein, NEJM 2009;;Phenotypic plasticity Plasticity:;;Predator-induced Polyphenism;;Genetically identical mice;;Epigenetic inheritance;;Epigenetic inheritance: broad and narrow conceptions;;Five mothers;;Inputs to development and heredity: The five (potential) mothers;;Epigenetic Cellular Inheritance Systems;;Chromatin variations;;Replication of two DNA methylation patterns;;Epigenetic Processes: involved in the regulation of genes;;Monozygotic (Discordant) Twins;;EPIGENETIC DIFFERENCES ARISE IN MZ TWINS;;Linaria;;Genetically identical Ay/a mice;;They Are What She Ate;;FETAL ORIGINS OF ADULT-ONSET DISEASES;;Germline transmission of injected endocrine disruptors;;Seminiferous tubules from control rat (A) and rat whose grandfather was exposed in utero to vinclozolin;;Cases of trans-generational epigenetic inheritance;;Body-to-body routes of transmission;;Soma-to-soma Transmission: Maternal behaviour in the rat;;Putative promoter sites of genomic GR;;Graphs;;Comparison of the total number of genes significantly induced or repressed and the degree of overlap among these groups of genes in different experiments;;So where is “It” (you)??;;Questions???'
10011,'lecture','en',9976,'2009-10-01','2009-11-09','Cooperation – A Successful Principle in the Living World / Sodelovanje med organizmi kot princip v živih sistemih','Iz današnjega zornega kota lahko rečemo, da nobena žival ne preživi brez posebnih sodelujočih\npartnerjev. V nekaterih primerih so taka sodelovanja celo spremenila Zemljo in prinesla nove\npokrajine. Torej niso bile vpletene samo populacije in vrste, temveč veliko večji sistemi, biocenoze,\nekosistemi in pokrajine, vključno z obsežnimi območji oceanskega dna.\nNadalje, sodelovanje omogoča tudi prebavo. To sodelovanje je posebno izrazito pri termitih, ki jih\nnaseljujejo enocelični bičkarji, ki se nahajajo v posebnem delu črevesja. Ti bičkarji v sodelovanju z\nbakterijami omogočajo razgradnjo lignina. Če umrejo bičkarji, tudi termiti ne preživijo. Podobno\nprežvekovalci razgrajujejo celulozo v hrani. Migetalkarji, ki živijo v njihovih želodcih, omogočajo – s\npomočjo bakterij – prebavljivost hrane. Danes je splošno znano, da v prehranjevalnem traktu človeka\nživi več prokariontov, kot je vseh celic v telesu. Lahko bi našteli še veliko podobnih primerov.\nSklenemo lahko, da vse živali za prebavlajnje potrebujejo prisotnost in sodelovanje drugih\norganizmov v njihovih prebavilih.\nV mnogih primerih sodelovanje vodi v čisto nov razvoj. Najbolj prepričljiv primer so lišaji, ki so\nsestavljeni iz gliv in enoceličnih alg ali cianobakterij. Lišaji živijo skoraj v vseh kopenskih\nekosistemih, vključno z Antarktiko, uspevajo na morski obali, lahko so tudi vodni.\nRaznolikost današnjih cvetnic ne bi bila mogoča brez oprašitve, posebno z žuželkami kot tudi s ptiči\nin sesalci. Cvet in opraševalec sta šla skozi dolgo skupno evolucijo. Veliko cvetov potrebuje zelo\nposebne opraševalce. Če teh opraševalcev ni, lahko rastline izumrejo.\nPrenos (transport) je še en primer za obsežno sodelovanje. Mrtva telesa in iztrebki se morajo razkrojiti, do končnega produkta, ki so minerali, tako da ekosistemi ostanejo nepoškodovani. Mrtva telesa in iztrebki privlačijo mnogo žuželk, ki imajo druge pomembne organizme, ki so nujno potrebni za razkroj, obenem pa jih pripeljejo do naslednjega izvora hrane. Hrošči prenašajo gliste in pršice kot tudi bakterije in tako omogočajo zaprtje biokemijskega kroga .\nNa koncu pa še podmena: Nobena žival, vključno z današnjim človekom, ni sposobna preživeti brez\nmedvrstnega sodelovanja. Če je le-to v kritičnem stanju, se vsi lahko soočimo z globalnimi okoljskimi\nproblemi.','Cooperation: A successful principle in the living world;;COOPERATION CREATES REEFS, SEDIMENTS AND MOUNTAIN RANGES;;Palao archipelag;;Corals;;A single coral;;Several corals;;Corals fuze;;Corals grow;;Globe;;Sediments;;Sediments;;Beauty of Alps;;Spunges;;Egipt;;Superorganism;;Portugese ;;Ernst Hecker;;COOPERATION STRENGTHENS DEFENSIVE FORCES;;Spunges;;Search for vicinity;;Free water;;Crab;;COOPERATION CONSERVES INTEGRITY;;Cleaning fish - 1;;Cleaning fish - 2;;Cleaning fish - 3;;Cleaning fish - 4;;Cleaning;;Cleaning ;;Cleaner vs. imitator;;Cleaning fish;;Cleaning fish;;NO COOPERATION - NO DIGESTION;;Termites;;bzid09_storch_smo_01_Page_35;;bzid09_storch_smo_01_Page_36;;Termit inside;;LICHENS - 1;;LICHENS - 2;;LICHENS - 3;;LICHEN inside;;COOPERATION CREATES BIODIVERSITY;;Cooperation of animals with plants;;Pollinate grains;;Pollinate IV;;Humming bee;;Birds in Europe;;Plants from Australia;;Australian plants;;Birds;;COOPERATION MAKES TRANSPORT POSSIBLE;;Feces;;Corps;;Food dung beetle;;Dung beetle carying food'
10012,'lecture','sl',9976,'2009-10-01','2009-11-09','Vrsta / Species',NULL,'VRSTA;;Muzejski biolog;;Vrsta je v biologiji ...;;Agapow P-M. 2005;;Karl Linne;;Tipološki koncept;;Charles Darwin in Alfred R. Wallace;;Filetska speciacija - 1;;Filetska speciacija - 2;;Filetska speciacija - 3;;Filetska speciacija - 4;;Biološka vrsta;;Vrsta je kolektivna kategorija;;Simpatrija - 1;;Simpatrija - 2;;Parapatrija;;Vlažno Suho;;Koncepti;;Dve novi vrsti;;de Queiroz (2007);;Konceptualno;;Genetski koncept vrste;;Do genetske izolacije pride ...;;Genetska variabilnost;;Mus macedonis skupina - 1;;Mus macedonis skupina - 2;;Bayesian consensus tree;;Apodemus (cyt. b);;Apodemus vrste;;Število vrst - 1;;Število vrst - 2;;Število vrst - 3;;Število vrst - 4;;Jaccard\'s Coefficient Similarity;;Hvala'
10013,'lecture','sl',9976,'2009-10-01','2009-11-09','Vloga vrst v ekosistemskih procesih / Function of Species in Ecosystem Function','Raziskave delovanja ekosistemov potekajo predvsem iz dveh izhodišč - holističnem in\nredukcionističnem. Bistvo izhodišča holističnega pristopa je v združevanju žive komponente v trofične\nnivoje ter s tem zanemari vlogo posamezne vrste. Z izkanjem funkcije biodiverzitete pa prihaja v\nospredje redukcionističen pristop, saj je zaradi informacijskih razlik med posameznimi vrstami –\npopulacijami jasno, da je funkcija v ekosistemu vrstno specifična. Prav zaradi informacijske bogate\nkomponente v dobro razvitih ekosistemih je jasno, da ekosistemi niso preprosti fizikalno-kemijski\nsistemi ampak imajo številne lasnosti in zakonitosti, ki izhajajo iz življenja. Vlogo vrst-populacij tako\nlahko prepoznamo v nekaj osnovnih funkcijskih tipih: \n- so nosilci procesov kroženja snovi in pretoka energije, \n- vzdržujejo eksergijo, \n- sodelujejo pri oblikovanju življenskega prostora in pogojev v njemu,\n- oblikujejo medvrstna in znotrajvrstna razmerja. \nMed- in znotrajvrstna razmerja so kompleksna in imajo tako kratkoročen vpliv na stanje ekosistema kakor tudi dolgoročno vplivajo tako na razvoj populacij (strukturno, količinsko tudi genetsko), ter na različne ekosistemske procese. Seveda posredno tako vplivajo tudi na stanje in značilnosti celotne Biosfere oz. Zemlje kot biogenega planeta. Prav koevolucijski mehanizmi ter razvoj populacij v odvisnosti od abiogene komponente življenskega prostora vodijo v razvoj kompleksnih biodiverzitetno bogatih združb, ki zagotavljajo stabilnost in optimalno funkcionalnost ekosistemov.\n----\nResearches of ecosystem functioning have generally two approaches – holistic and reductionistic. The principle of holistic approach is association of live components in trophic levels and ignoring the role of single species. With searching for biodiversity function, the reductionistic approach is becoming more and more important, since because of information differences among individual species or populations, it is clear that their function in ecosystem is species specific. Because of rich information component in well developed ecosystems it is obvious that ecosystems are not simple physically-chemical systems, but have numerous characteristics and principles originating from life. The role of species or populations can be recognised in some basic functional types: they are the carriers of substance circulation and energy flow processes, they maintain exergy, they take part in formatting the living space and conditions in it, and they form interspecies and intraspecies relations. Inter- and intraspecies relations are complex and have short-term influence on ecosystem state as well as long-term influence on population development (structurally, quantitatively and genetically) and different ecosystem processes. Of course they also indirectly influence the state and characteristics of the whole biosphere or Earth as a biogenic planet. Just co-evolution mechanisms and population development in dependence of abiogenic component of living space lead to development of complex communities that enable stability and optimal functioning of ecosystems.','Vloga vrst v ekosistemskih procesih;;Uvod;;Združba je subjekt življenja!;;Naravne združbe kot osnova naravnih ekosistemov;;Ekosistemski procesi;;Ekološke šole proučevanja ekosistemov;;Pretok energije in kroženje snovi;;Navadni jelen –Evropska srna;;Fosfor, kalij, dušik;;Formativno oblikovanje življenjskega prostora;;Kdo zna in lahko to počne namesto njega?;;Medvrstne interakcije;;volk -ris;;Plenjenje jelenjadi;;Interakcije, ki sooblikujejo genski sklad, sodelujejo pri evoluciji (oblikujejo koevolucijo);;Razvoj združbe –povečevanje funkcionalne biodiverzitete;;Zaključki;;Hvala za pozornost!'
10014,'lecture','en',9976,'2009-10-01','2009-11-09','Evolution and How Microbes See It / Evolucija z vidika mikrobov','With the beginning of life under early Earth condition the microorganisms developed metabolic pathways for energy regeneration and carbon assimilation. Due to stepwise improvements new developments were introduced resulting finally in microbial life forms of today, more or less stable geochemical cycles and a remarkable changed world. For humankind a very minor fraction of today’s microorganisms can cause medical problems. Most of them are essential members of the ecosystem World and for human beings directly or indirectly of great importance. Nevertheless, there are several new habitats introduced by us which are invaded by them and where they cause major problems.\n----\nZ začetkom življenja, v pogojih na zgodnji Zemlji, so mikroorganizmi razvili metabolne\npoti za pridobivanje energije in asimilacijo ogljika. S postopnimi izboljšavami so razvijali nove\nlastnosti, čemur so sledili razmah mikrobnih oblik življenja, kot ga poznamo danes, bolj ali manj\nstabilni geokemični cikli in močno spremenjen svet. Za zdravje človeštva je nevaren le zelo majhen\ndel današnjih mikroorganizmov. Večina jih je pomembnih gradnikov svtovnega ekosistema in so\nneposredno ali posredno izjemno pomembni za človeka. Ne nazadnje, naselili so nekatera nova\nprebivališča, ki smo jih razvili mi, in tam lahko povzročajo resne težave','Evolution and how microbes see it ;;Free Hanseatic City of Bremen;;Bremen Institute for Materials Testing - 1;;Bremen Institute for Materials Testing - 2;;Service and Research Topics;;Microorganisms (MO);;Phylogenetic Tree of Life;;Early earth conditions;;Early pathways;;Problems;;Hyperthermophile biofilms and mats;;Scheme: timescale;;SPP 1144;;What still needs to be done, how and when?;;Next steps I:;;Anoxygenic photosynthetic mats;;Microorganisms of the sulfur cycle: sulfate-reducing prokaryotes (SRP) and sulfur-oxidizing prokaryotes (SOP);;Next steps II:;;Oxygenic photosythetic mats and stromatolites;;Interaction of organism all over the world;;Open ocean situation;;What you should know about MO part I;;What you should know about MO part II;;Where can you find microorganisms (MO) and why are they so successful?;;Why are surfaces attractive for MO?;;MO in space station;;Tested materials;;Surfaces;;Formation of biofilm;;MIC by sulfate-reducing bacteria (SRB);;Example;;Traditional model: corrosion in the absence of oxygen;;Traditional model;;Direct mechanism: removal of hydrogen;;Indirect mechanism: attack by sulfide produced by SRB;;New corrosive sulfate-reducing bacterium „Desulfobacterium corrodens“;;New results;;Fluorescence-labeled bacteria cells on metal surfaces;;Fungi in an anodizing bath;;Fungi in a metalworking fluid system - 1;;Plastic materials;;Important:;;Examples: fungi;;Example: bacteria;;Thank you very much for your attention!'
10015,'panel','sl',9976,'2009-10-01','2009-11-09','Prva okrogla miza / First Round-Table Discussion',NULL,NULL
10016,'lecture','sl',9976,'2009-10-01','2009-11-09','Nagovor / Honorary Speech',NULL,NULL
10017,'lecture','sl',9976,'2009-10-01','2009-11-09','Ali Kosovir obstaja? / Do Kosovirs Exist?','Kosovirji živijo v Kosoviriji. Delimo jih na radovedne in neradovedne. Imajo črn kožuh, ki se odlikuje po izredni mehkosti. Krasi jih dolg, košat rep, ki se navadno končuje v okroglast čop. V gobčku ima kosovir šestnajst ostrih zob, s katerimi razkosava paradižnike, ki so glavna kosovirska hrana.\n\nKosovirji so večinoma ljubke in družabne živali, ne smemo pa jih dražiti ali celo prehitro zbujati iz spanja. Takrat pobesnijo, praskajo in glasno vreščijo ter kosovikajo. Izjema so neradovedni kosovirji, ki pa so manj razširjeni. Obe vrsti prebivata v žlicah, na katerih rastejo paradižniki. Z žlicami se tudi premikajo po zraku. ','Svetlana Makarovič: Ali kosovir obstaja? / Do kosovirs exist?'
10018,'introduction','sl',9976,'2009-10-02','2009-11-09','Napovednik tretjega sklopa: Biodiverziteta in trajnostni razvoj / Introduction to the Third Session: Biodiversity and Sustainable Development',NULL,NULL
10019,'lecture','sl',9976,'2009-10-02','2009-11-09','O umetni biotski pestrosti človeške vrste – etični pomisleki / On Man-Made Biodiversity of the Human Species – Ethical Objections','Znanost je dala ljudem v roke nove možnosti. Genska tehnologija omogoča spreminjanje genoma.\nPosebno v rastlinskem svetu je prišla že precej daleč. Gensko spremenjeni organizmi paradoksno niso\npovečali biotske pestrosti, ampak so jo zmanjšali. Tehnologijo so zlorabile multinacionale družbe;\npred seboj imamo strašljivi zgled Monsanta, ki s svojo mednarodno \'policijo\' nadzira, izkorišča in\nbrezdušno izsiljuje armade kmetov po večjem delu sveta, mnoge ekonomsko uniči in spreminja v\nnovodobne sužnje.\nLe malo manj oporečno je kloniranje. Lani se je Evropska skupina za etiko v znanosti in novih\ntehnologijah, svetovalni organ Evropske komisije, izrekla proti kloniranju živali za hrano. Sklep večje\nštudije in potem priporočila je bil, da ljudje ocenjujejo tako početje kot nenaravno in etično\nnesprejemljivo. Poleg tega zanj ni dokazljive potrebe. Povsem nesprejemljivo pa je večini laične\njavnosti kloniranje ljudi za razplod, nekaterim pa tudi za namene raziskav. To je prepovedal posebni\nprotokol k Oviedski konvenciji – o varstvu človekovih pravic in dostojanstva človeškega bitja v zvezi\nz uporabo biologije in medicine.\nOviedska konvencija prepoveduje tudi posege v genom, ki bi imeli za cilj \'žlahtnjenje\' človeka oz.\nnjegovih telesnih in duševnih sposobnosti. Celo ko gre za medicinske razloge, na primer zdravljenje\nali preprečevanje dednih bolezni, bi bil poseg upravičen samo takrat, ko njegov cilj ni povzročiti\nspremembe na genomu potomcev. Forum nacionalnih etičnih svetov Evropske unije je izrazil zelo\nzadržano stališče tudi do drugih postopkov s področja biotehnologije ali farmakologije, ki bi imeli za\ncilj izboljševanje sposobnosti posameznikov ali krojenje njihovih lastnosti po lastnih željah ali\nzahtevah drugih. Vendar je tu etična meja včasih zabrisana in med razlogi proti takim ravnanjem niso\nveč zmeraj v ospredju pravice prizadetega posameznika, ampak tudi načelo enake dostopnosti do\ndobrin, do katerih so upravičeni tudi drugi.\nTako se poleg nove biologije in medicine utegne poroditi tudi nova etika. Če bo nekoč dobila\nodločilno besedo, bo spremenila nekatere temelje sedanje civilizacije.\n----\nRecent developments in the biological sciences have offered new possibilities, among them genetic engineering. Genetically modified plants and animals have become a reality, although all ethical issues have not been resolved. \nEven more serious ethical objections have been raised against attempting genetic modifications of human beings. Since recently, a lot of experimental work is being done with embryos which are hybrids between man and different animals, particularly in the UK, after having been authorized by the new legislation. Even before, a number of different human-animal mixtures have been proposed and many have actually been successfully produced. Allowing such beings to be born and mature, as recommended by some utilitarian ethicists would open difficult ethical and legal dilemmas. The Scottish Council on Human Bioethics has called for a European ethical debate, but so far this has not been considered. \nHuman-animal hybrids and chimeras, produced for industrial and military purposes, as well as for pleasure would change some of the foundations of our present societies.',NULL
10020,'lecture','en',9976,'2009-10-02','2009-11-09','Urban Ecology - Why Is It an Increasingly Important Topic? / Urbana ekologija – zakaj se njen pomen povečuje?','Land-use changes due rapidly increasing urbanization pose major threat on ecosystems and their functions worldwide. By the end of this decade, more than half of the world human population will be living in cities and other urbanized areas. Human-induced habitats, loss and fragmentation of the landscape as well as accumulation of trace gases and other pollutants serve as the best-known examples of negative impacts of dense human population on the surrounding environment. Land-use changes can be seen analogous to soil use, as well-developed old soils are replaced by functionally altered soils or even by completely new substrates, called “made lands”. Such conversion of land and soils to urban use is likely to translate into changes in soil biota, thereby distorting life-supporting ecosystem services, such as decomposition of organic matter, cycling of nutrients and detoxification of harmful substances. Urban soils are traditionally described as being highly artificial and disturbed, although soils in urban parks and gardens can share many features typical to agricultural, even natural soils. One of the key factors distinguishing urban soils from natural soils is their high spatial heterogeneity in the various ecological patterns and processes. This high heterogeneity manifests as parks, cemeteries, vacant lots, streams and lakes, gardens and yards, campus areas, golf courses, bridges, air ports and landfills. These habitats are highly dynamic, influenced by both biophysical and ecological drivers on the one hand and social and economic drivers on the other. Active management of green spaces is vital but seldom sufficient, there is also a need to protect, restore and manage surrounding ecosystems in order to maintain ecosystem services of value for human well-being and build resilience in the urban landscape. \nRecent climate models predict precipitation to increase under various climatic conditions, especially in heavily urbanized areas. Combined with increasing proportion of sealed, impermeable surfaces in urban settings, the growing trend of rain events are likely to cause anomalies in hydrological cycles. A typical example of it is the increased quantity and worsened quality of urban runoff waters (“street waters”). In this presentation urban runoff waters will be dealt as an indicator of the ecological health of urbanized habitats. Furthermore, the typicalities of urban vs. natural ecosystems are compared and some examples of the ongoing urban ecological studies in Finland will be presented.\n----\nZaradi hitro naraščajoče urbanizacije prihaja do sprememb v rabi zemljišč, kar predstavlja\npomembno grožnjo ekosistemom in njihovemu delovanju širom po svetu. Do konca tega desetletja bo\nveč kot polovica svetovne populacije živela v mestih in drugih urbaniziranih območjih. Habitati, ki jih\nspreminja človek, izguba in fragmentacija pokrajine kot tudi sproščanje plinov v sledovih in drugih\nonesnaževalcev služijo kot najbolj znani primeri negativnih vplivov goste človeške populacije na\nokolje. Spremembe v rabi zemljišč lahko gledamo kot izrabo tal, ko se dobro razvita stara prst\nnadomešča s funkcionalno spremenjeno prstjo ali celo s povsem novim substratom, tako imenovano\n\"umetno zemljo\". Takšno spreminjanje zemljišč za potrebe urbane uporabe najverjetneje vodi v\nspremembe v življenju v prsti in tako poruši življenjske podporne mehanizme ekosistema, kot so\nrazgradnja organskih snovi, kroženje hranil in razstrupljanje škodljivih snovi. Zemljo v urbanih\nobmočjih po navadi opisujejo kot umetno in močno prizadeto, vendar pa je prst v mestnih parkih in\nvrtovih lahko zelo podobna kmetijski ali celo naravni prsti. Eden glavnih dejavnikov, po katerih se\nzemlja v mestih loči od tiste v naravi zunaj mest, je velika prostorska heterogenost različnih ekoloških\nvzorcev in procesov. Visoko heterogenost kažejo okolja kot so parki, pokopališča, gradbišča, potoki in\njezera, vrtovi in dvorišča, univerzitetna naselja, igrišča za golf, mostovi, letališča in smetišča. Ti\nhabitati so zelo dinamični, nanje po eni strani vplivajo biofizikalni in ekološki dejavniki, po drugi\nstrani pa socialne in ekonomske težnje. Aktivno upravljanje zelenih prostorov je zelo pomembno,\nvendar redko zadostuje; treba je ščititi, obnavljati in upravljati tudi okolišnje ekosisteme, zato da se\nvzdržujejo podporne storitve v ekosistemih, ki so pomembne za blagostanje ljudi in omogočajo\nprožnost urbane krajine.\nZadnji klimatski modeli napovedujejo povečanje količine padavin v različnih klimatskih pogojih, še\nposebno v močno urbaniziranih območjih. V povezavi z vedno večjim deležem zatesnjenih,\nneprepustnih površin v urbanih okoljih je zelo verjetno, da bo naraščajoči trend dežja povzročil\nanomalije v hidroloških ciklih. Tipični primer tega je povečana količina in poslabšana kakovost\nurbanih površinsko odtekajočih voda (\"ulične vode\"). V tej predstavitvi bodo urbane odtočne vode\nuporabljene kot kazalnik ekološkega zdravja urbanih življenjskih okolij. Nadalje bodo predstavljeni\nprimerjava značilnosti urbanih in naravnih ekosistemov ter nekaj primerov potekajočih urbanih\nekoloških študij na Finskem.','URBAN ECOLOGY: Why is it an increasingly important topic?;;OUTLINE;;1: URBANISATION – some background;;World Population Growth;;CONSEQUENCES OF URBANISATION;;2) WHAT IS Urban ecology?;;Session III topic:;;Biodiversity and urbanisation: general trends;;National Urban Park Stockholm, Sweden;;Urban ecosystems and biodiversity;;3) A holistic, ecosystem approach in urban ecology(ecologyOF cities;;Peculiarities of urban ”eco”systems: A) Trophic pyramide upside-down in cities;;B) Loose material cycles in cities;;Due to the converted trophic pyramide and loose material cycles urban systems are inefficient in processing matter;;CRUCIAL ECOSYSTEM SERVICES IN CITIES;;4: URBAN SOILSAND ECOSYSTEM SERVICES-;;PIVOTAL role of SOILS;;WHAT ARE THE CRUCIAL SOILSERVICES in CITIES??;;Consequences of urbanisation: sealed, impermeable surfaces;;Permeability of soil surface;;Catchment areas in the city of Lahti - 1;;Catchment areas in the city of Lahti - 2;;STORM EVENT 15.6.09 Lahti;;5. Restoring urban ecosystem services –an impossible task?;;Can one solve urban-induced problemsthrough soil restoration?;;Three scientists and anurban dump yard (to test the theory);;Plants modify the soil (biota and structure), and this process is plant-trait dependent;;A field experiment (2004 –2007) was established to study above-belowground linkages and effects on nutrient cycling;;Soil animals can ”detect” plant influence;;Relative proportion of fungi and bacteria underneath the plants;;Urban soil can be manipulated ecologically;;The Urban Future?;;NASA satellite image: light in the night y. 2100;;bzid09_setala_ueko_01_Page_34;;Social, economic variables'
10021,'lecture','sl',9976,'2009-10-02','2009-11-09','Zasvojenost z gospodarsko rastjo na planetu z omejenimi naravnimi viri / Addiction with Economic Growth on the Planet with Limited Natural Resources','Moderne družbe so po dveh stoletjih izjemnega razvoja zasvojene z gospodarsko rastjo, ki\nnaj bi bila zaradi tehnološkega napredka in prevlade storitev nad proizvodnjo materialnih dobrin\nbrezmejna. Njen “znanstveni” temelj je produkcijska funkcija; gospodarsko rast pa naj bi ustvarjala\npredvsem skupna faktorska produktivnost, ki naj bi jo zagotovila vlaganja v raziskave in razvoj.\nEU je zasvojenost z rastjo strnila v lizbonsko strategijo, na pol poti priznala njen neuspeh in “staro”\nstrategijo zamenjala s »prenovljeno«; ta se je usmerila predvsem v zagotavljanje gospodarske rasti in\ndelovnih mest. Toda tudi »prenovljena« je temeljila na leporečju in ustvarjanju institucij.\nGospodarska kriza je dokončno razkrila, da je šlo za iluzije, da gospodarsko rast tudi na kratek rok\nomejuje povpraševanje in da je temeljni problem razvitega sveta ustvariti dovolj dela in ne dovolj\ndobrin. Tehnološke spremembe, ki izrivajo delo iz proizvodnje materialnih dobrin, sicer posredno\nomogočajo povečevanje zaposlenosti v storitvenih dejavnostih, vendar globalizacija, ki je tudi\nglobalizacija tržnega fundamentalizma, te možnosti zmanjšuje, saj dejavnosti z visoko dodano\nvrednostjo hitro pretvarja v dejavnosti z nizko. Gospodarska kriza bo nedvomno spremenila svet; vsaj\nzačasno z opustitvijo doslej veljavnih paradigem tržnega fundamentalizma na globalni ravni in z\nnjegovo nadomestitvijo z mnogo bolj lokalnimi politikami agregatnega povpraševanja, ki jih je\nmogoče usmeriti v novi »zeleni New Deal«.\n----\nAfter two centuries of extremely rapid development modern societies have become obsessed with economic growth. It is taken as limitless due to technological change and prevalence of services over production of goods. The “scientific” pillar of it is production function; growth is to be achieved by increases of total factor productivity secured by investments in research and development. \nIn 2000, EU condensed the obsession with growth in the Lisbon strategy. It admitted in 2004 that it failed, and, in 2005, replaced the “old” strategy with the “renewed” one; economic growth and job creation were in the core of it. The paths to the new goals did not seem to be assured; also the “renewed” strategy relied on empty talks and creation of new institutions. \nWorld economic crisis has finally and definitely shown that the strategy was illusion, that economic growth is in the short run limited by demand rather than by supply, and that the core problem of modern societies is creation of enough jobs and not creation of enough goods. Technological changes which are mainly labor saving, indirectly enable creation of new jobs in the service sectors; it is but countered by globalization of market fundamentalism which swiftly turns high value added sectors of economic activity into low value added sectors. World economic crisis will change the world; at least by temporary abandonment of global market fundamentalism with much more local policies of aggregate demand creation which could be directed towards a “Green New Deal”.','ZASVOJENOST Z GOSPODARSKO RASTJO NA PLANETU Z OMEJENIMI NARAVNIMI VIRI;;POVZETEK;;VIRI SODOBNE GOSPODARSKE RASTI;;SODOBNA GOSPODARSKA RAST;;GDP/PREBIVALCA (po kupni moči iz1990);;GDP/prebivalca $ kupna moč 1990;;GOSPODARSKI RAZVOJ V SVETU;;PRISPEVEK TEHNOLOŠKEGA NAPREDKA;;EMPIRIČNE OCENE;;LIZBONSKA STRATEGIJA;;GOSPODARSKA RAST V STARIH IN NOVIH ČLANICAH EU;;THE ROOTS OF THE CRISIS 1 (J.Huffschmid);;THE ROOTS OF THE CRISIS 2 (J. Huffschmid);;KAZINO KAPITALIZEM;;FINANČNI KAPITALIZEM (J.Huffschmid);;GLOBALIZACIJA “CASINO” KAPITALIZMA;;KAJ NAREDITI?'
10022,'lecture','en',9976,'2009-10-02','2009-11-09','The Young Charles Darwin - Student, Naturalist and Gardener / Mladi Charles Darwin – študent, naravoslovec in vrtnar','Charles Darwin was one of the most important scientists who ever lived. He was born in 1809 (200 years ago) in Shrewsbury, Shropshire, England. He was fortunate to have a wealthy father who was a doctor and be part of an intelligent and educated family. He lived in a large house called ‘The Mount’ with servants and a large garden, on the edge of the town and open countryside. He had developed a strong interest in natural history before he attended his first school at the age of eight, having been taught previously by his mother, brother and sisters. Many poor children of his age never had the opportunity to attend school. However, he was unfortunate because his mother died soon after he started at day school. He was sent to Shrewsbury Grammar School as a boarder for seven years where he studied Latin and Greek but little that interested him. Science was not taught in schools at that time but Charles developed his knowledge by collecting natural history specimens and helping his older brother with Chemistry experiments at home. He was not an exceptional child at school but his father taught him about observation, recording and analysis of information in the garden and surgery, assisting with his patients and diagnosing illnesses. This prepared him for Edinburgh University where he studied to become a doctor but he ‘dropped out’ because he did not like operations or dissections and was sent to Cambridge University to train for The Church (to become a priest). However, both in Edinburgh and Cambridge he disliked lectures, preferring to read about the subjects in books and spent most of his time having a good time with his friends and collecting beetles. However, he worked hard enough to pass examinations and achieved a good Bachelor of Arts Degree as a first step to becoming a clergyman. That career path was cut short because he had impressed influential professors and lecturers who admired his scientific prowess at a time when the study of natural history (studying the wonders of God’s Creation) was considered an appropriate pastime for a clergyman! He was recommended for the role of ship’s naturalist on the survey ship ‘The Beagle’ because of his natural history skills and because he was ‘a gentleman’ of the right social background to be the captain’s companion. His self-motivated study of plants, animals and rocks commenced as a child in Shrewsbury and encouraged at last by perceptive teachers, propelled him into a new direction. However, his five year voyage on The Beagle around the world and his subsequent life of research would have been impossible if his father had not supported him financially and later, when he married, invested a large sum of money, the income from which supported his research, wife and family. He had been raised in a one-parent family and did not do well at school where his interests were dismissed as a waste of time. However, he had the support of his family and eventually, at university, found the support of teachers who recognised his potential. \n----\nCharles Darwin je bil eden najpomembnejših znanstvenikov naše zgodovine! Rodil se je leta\n1809 (pred 200 leti), v Shrewsburyju, v okraju Shropshire, v Angliji. Dobro popotnico so mu\npredstavljali premožen oče, po poklicu zdravnik, ter izobražena in razgledana družina. Živeli so na\nobrobju mesta, v veliki hiši, imenovani »The Mount« (Gora) s služabniki in velikim vrtom.\nNaravoslovje je Charlesa začelo zanimati, že ko so ga poučevali mati, brat in sestre, še preden je pri\nosmih letih začel obiskovati v šolo. Mnogi revnejši otroci tedaj do šolanja sploh niso prišli. A tudi\nmalemu Charlesu ni bilo lahko, saj mu je že kmalu po vstopu v šolo umrla mati. Sedem let je prebil na\ngimnaziji v Shrewsburyju, kjer je bival v internatu. Tam se je učil latinščino in grščino, a ga to ni\npreveč zanimalo. Naravoslovnih predmetov tedaj v šolah niso poučevali, a Charles je svoje\nnaravoslovno znanje razvijal sam, med drugim tudi s tem, ko je doma starejšemu bratu pomagal pri\nkemijskih poizkusih. V šoli ni bil izjemen učenec, a ga je oče na domačem vrtu ter v ordinaciji pri\nkirurških operacijah in diagnosticiranju bolezni učil opazovati, beležiti in analizirati podatke. Tako se\nje pripravil na študij medicine na Edinburški univerzi. Ker pa ni maral operacij in seciranja, študija ni\ndokončal. Poizkusil je še v Cambridgeu, s študijem teologije. Tako kot v Edinburgu je tudi tu ugotovil,\nda ga zelo odbijajo vsa predavanja, in je raje študiral iz knjig, veliko časa pa posvetil tudi zabavi s\nprijatelji in zbiranju hroščev. Kljub vsemu je uspešno opravil izpite in bil na pravi poti do\nduhovniškega poklica. Na vplivne profesorje je s svojim naravoslovnim znanjem naredil močan vtis,\nin to v času, ko je veljalo naravoslovje (ali »preučevanje čudes božjega stvarjenja«) za primerno\nprostočasno dejavnost duhovnikov. Njegova nesojena duhovniška kariera je bila prekinjena, ko so ga,\nzaradi naravoslovnega znanja in ker je izhajal iz »primerne« družine, predlagali za »ladijskega\nnaravoslovca« in kapitanovega spremljevalca na raziskovalni ladji Beagle. Vztrajno samostojno\nproučevanje rastlin, živali in kamnin, začeto v otroštvu in nazadnje vzpodbujeno s strani dojemljivih\nučiteljev, ga je pognalo v novo smer. Vendar njegovo petletno potovanje z ladjo Beagle okoli sveta in\nnjegovo kasnejše raziskovalno delo ne bi bila možna brez očetove izdatne finančne pomoči. Tudi po\nCharlesovi poroki je oče vložil veliko denarja v investicije, s prihodki katerih je Charles plačeval svoje\nraziskovalno delo in vzdrževal družino. Odrasel je v enostarševski družini, v šolah, kjer so njegovo\nzanimanje za naravoslovje označili za izgubo časa, pa ni bil preveč uspešen. Kljub temu je vselej imel\npodporo družine in kasneje na univerzi vendarle našel tudi razumevanje in podporo učiteljev, ki so\nprepoznali njegove zmožnosti.','The Young Charles Darwin - student, naturalist and gardener;;Biography;;Shrewsbury;;Erasmus Darwin;;Shrewsbury was a prosperous market town in the late 18th century;;The cradle of the Industrial Revolution was a few miles away in Coalbrookdale. Here it is in 1777.;;Dr Robert Darwin married his cousin Susannah Wedgwood in 1796;;Charles was one of 6 children:;;Charles was born at The Mount on 12th February 1809;;‘The Mount’, was north of the old town;;As the name ‘The Mount’ suggests, the house was built on high ground overlooking the River Severn, This was drawn in about 1842;;‘The Mount’ was a large house with about 3 hectares of garden;;The garden at the Mount was planted with native and exotic trees, shrubs and other plants by Robert Darwin;;The surviving part of the garden still contains trees, shrubs and other plants planted by the Darwin Family including;;Cucumber Tree Magnolia acuminata;;Fruits of the ‘Cucumber Tree’ at The Mount;;Mulberry Morus nigraat The Mount;;Taxus baccata‘Dovastoni’ at The Mount;;Charles and the rest of his family were keen gardeners.;;Lachenalia aloides;;The Darwin Perennial Garden Diary - 1;;The Darwin Perennial Garden Diary - 2;;Charles had been christened at St. Chad’s Church (Anglican) ...;;... but Charles and his mother attended the Unitarian Church;;Charles attended the Rev. Case’s School on Claremont Hill from 1817-1818.;;His mother;;Susannah kept doves in the garden at The Mount;;“born a naturalist”;;These are the fields near his home where he played and studied natural history;;One little event ...;;His older sisters ...;;Charles was generally known as ‘Bobby’ ...;;Charles attended Shrewsbury Grammar School 1818-1825;;The exterior of Shrewsbury School in Charles Darwin’s time;;The school-room of the school in Charles Darwin’s time;;The library of the school in Charles Darwin’s time;;The chapel of the school in Charles Darwin’s time;;Charles did not enjoy most of his lessons at school ...;;The Headmaster’s House in Charles Darwin’s time;;Charles thought that, at the time when he left school, ...;;Charles went to Edinburgh University in 1826 at the age of 17 years to become a doctor like his father and grandfather;;Caroline missed him when he went to university;;During his time in Edinburgh ...;;Charles leaves Edinburgh for Cambridge;;Charles went to Christ’s College, University of Cambridge in 1828 as preparation to become a priest in the Church of England;;Charles rather liked the idea of life as a country clergyman;;However, while he was at Cambridge University he was more interested in beetles than what he was expected to learn!;;He was supported in his beetle studies in Cambridge by his more knowledgeable second cousin, William Darwin Fox.;;In a letter from Charles ...;;Charles made his own original natural history observations in Cambridge ...;;Charles already had some interest in Geology;;In the summer of 1831, Charles accompanied Professor Adam Sedgwick ...;;When he returned from Wales ...;;Josiah Wedgwood II;;The voyage lasted from 1831 to 1836 when Charles returned to Shrewsbury;;Charles and his family kept in touch with each other by letter during the voyage but he sometimes missed his home …;;In September 1833, Charles wrote to his sister Caroline from Buenos Ayres:;;The conservatory that opened off the Morning Room ...;;The conservatory greenhouse opened off the Morning Room which was a grand room with ornate columns;;Pineapples in the hothouse at The Mount;;‘Going Bananas’ in the hot house at The Mount;;In October 1832, Catherine wrote:;;Formation of a museum in Shrewsbury;;One of the many herbarium specimens donated to the new museum in 1835 by William Allport Leighton;;Robert Darwin had paid his son an allowance ...;;Charles married his cousin Emma Wedgwood ;;At first they lived in London ...;;Charles and Emma had ten children;;Charles was productive in many ways!;;Charles Darwin spent many years studying fertilization in Orchids;;Studies - 1 ;;Studies - 2;;For more information about Shrewsbury and the Darwins see www.darwincountry.org;;Read more about the Darwins in Shrewsbury and their garden at www.peterboyd.com'
10023,'lecture','sl',9976,'2009-10-02','2009-11-09','Razvoj biološke misli / Development of Biological Thought','Kot vsaka znanost tudi biologija pozna razvoj svoje teoretične misli. Ta se je začela že v\nantiki, mnogo pred nastankom biologije, in je že od takrat razpeta na dva zelo različna pogleda:\nredukcionistilčnega (Demokrit) in organicističnega (Aristotel). Skozi novi vek sta se oba pogleda na\nživljenje nenehno prepletala, s tem da je v enem obdobju prevladoval eden, v naslednjem pa drugi.\nBiologija, kakršna je danes, ni samo rezultat empiričnih raziskav, temveč tudi tega zgodovinskega\nprepletanja svoje misli. V sodobnem času je močno utrjen redukcionizem, ki pa ga postopoma vse bolj\n»ogroža« bogat razvoj – tako teoretičen kot empiričen – na organicistični strani.\n----\nAs any science biology demonstrates the development of its theoretical thought. It began in Antiquity, long before the foundation of biology as a distinctive science and included two very different views: reductionist (Democritus) and organicist (Aristotle). Throughout the new age these two views constantly interweaved; at one time one was in power, at the next time the other. Biology as known today is not only the result of its positive empirical development, but also of the historical development of its own theoretical perception of life. In contemporary times reductionism is very much in power, yet it is progressively “endangered” by the steady empirical as well as theoretical growth of organicistic biology.','RAZVOJ BIOLOŠKE MISLI ;;Uvod;;Uvod (2);;Rojstvo biološke misli: antika;;Razvoj po srednjem veku: renesansa;;Razvoj po srednjem veku: začetek novega veka - 1;;Razvoj po srednjem veku: začetek novega veka - 2;;Razvoj v novem veku: Lamarckov organicizem - 1;;Razvoj v novem veku: Lamarckov organicizem - 2;;Ponovni vzpon redukcionizma;;Sodobna biološka misel;;Zaključek'
10024,'lecture','sl',9976,'2009-10-02','2009-11-09','Razvoj kulture v naravoslovju in družboslovju – je to eno in isto in kaj, če ni? / The Evolution of Culture in Natural and Social Sciences: Is It the Same Thing, and What if It Isn\'t?','Spoznanje, da kulturno vedenje ni značilno le za našo vrsto, zahteva sodelovanje med\nbiologijo in družbenimi vedami. Razlogi, zakaj ni bolj razvito, so povezani s tematiko sámo.\nEvolucijska biologija zahteva perspektivo, v kateri se kulturno vedenje razvije kot specifična\nprilagoditev. Vedenjski ekologi na terenu pa si prizadevajo razločiti kulturno vedenje od togo okoljsko\nin gensko določenega. Zato zahtevajo širšo definicijo kulture od tiste, ki so jo prevzeli od\ndružboslovja. Hkrati je raziskovanje izumrlih človeških prednikov in sorodnikov pretežno motivirano\ns prepoznavanjem človeških kulturnih vzorcev. V besedilu poskušam utečene prakse postaviti pod\nvprašaj. Ker kultura ni več operativen znanstveni koncept v družboslovju, se zavzemam za\nsodelovanje med naravoslovjem ter družboslovjem in humanistiko, kjer je biološka problematika jasno\nločena od humanističnih podmen.\n----\nEver since it was discovered that Homo sapiens is not the only species behaving culturally, a growth of collaboration between biology and social sciences and humanities could be expected. But it has not happened. The reasons have to do with the topic itself. Evolutionary biology demands a research perspective where culture is viewed as a special kind of adaptation. Behavioral ecologists, on the other hand, try to unravel cultural behavior from environmentally and genetically fixed behavioral patterns. They feel they need a broader definition of culture from the one taken over from social sciences and humanities. At the same time the research of the remains of our extinct ancestors and relatives is still motivated by the wish to recognize distinctly human behavioral patterns. These practices are being questioned in the text. As culture ceased functioning as an operative concept in social sciences and humanities, it is argued that the collaboration between natural sciences and social sciences with humanities would be better if problems of biology would be held distinct from humanist presuppostions.','RAZVOJ KULTURE V NARAVOSLOVJU IN DRUŽBOSLOVJU: JE TO ENO IN ISTO, IN KAJ, ČE NI?;;Uvod;;Tabela 1: kulturne inovacije pred Homo sapiensom;;Tabela 2: oblike specifično človeškega kulturnega vedenja;;Prepoznavanje človeškosti kot orientacija raziskovanja; Podmeni: antropocentrizem, antropomorfizem;;Primer: orodja iz kamene dobe;;Možne funkcije kamnitih orodij - 1;;Možne funkcije kamnitih orodij - 2;;Možne funkcije kamnitih orodij - 3;;Možne funkcije kamnitih orodij - 4;;Definicija kulture;;Tabela 3: pogoji, ki jih mora izpolnjevati kulturno vedenje v kulturni antropologiji (Kroeber 1928) na zgledu šimpanzov v divjini (McGrew 2004);;Kulturna primatologija;;Primati;;Primer kopja;;Sklep??'
10025,'lecture','sl',9976,'2009-10-02','2009-11-09','Politične odločitve in spreminjanje vrednot za zagotavljanje trajnostnega razvoja / Political Decisions and Changing Values to Support Sustainable Development',NULL,NULL
10026,'lecture','en',9976,'2009-10-02','2009-11-09','Biological Education for the 21st Century: Educating the Next Generation for Tomorrow’s Society / Biološka izobrazba za 21. stoletje: Izobraževanje nove generacije za družbo prihodnosti','Against the background of a changing world and major developments in biological sciences, this paper addresses two overarching questions: What can biological education contribute to the general education of young people in 21st Century? and How might we approach biological education in order to meet the future demands of society? It argues that, by teaching about and through biology, we can contribute to the general education of young people enabling them to become successful learners, confident individuals and responsible citizens. Furthermore it outlines some principles to guide the development of the biology curriculum, emphasises the importance of young peoples’ own ideas in teaching and learning and highlights the key role of formative assessment. In considering biological education for 21st Century the paper emphasises: the need for different sectors (government, education, science and industry) to work together, the need to develop creative approaches to pedagogy and, importantly, the need to hold high expectations for quality and achievement.\n----\nOb spreminjajočem se svetu in velikem napredku biološke znanosti si v članku zastavljam\nkrovni vprašanji: Kaj lahko biološko izobraževanje prispeva k splošni izobrazbi mladih v 21. stoletju?\nin Kako naj zasnujemo biološko izobraževanje, da bo ustrezalo prihodnjim potrebam družbe? S\npoučevanjem o biologiji in skozi biologijo lahko prispevamo k splošni izobrazbi mladih, da se bodo\nuspešno učili ter postali samozavestne osebe in odgovorni državljani. Poleg tega predstavljam nekatere\nsmernice za razvoj učnih načrtov za biologijo, pomen lastnih predstav mladih pri poučevanju in učenju\nter ključno vlogo sprotnega preverjanja znanja. Za biološko izobraževanje v 21. stoletju so pomembni\nsodelovanje med različnimi sektorji (vlado, izobraževanjem, znanostjo in industrijo), razvoj\nustvarjalnih pristopov k pedagogiki ter visoka pričakovanja o kakovosti in dosežkih učencev.','Biological education for the 21st century: educating the next generation for tomorrow’s society;;EDUCATING THE NEXT GENERATION: stimulating interest, curiosity and challenge;;Two questions:;;Major challenges in the world today - 1;;Major challenges in the world today - 2;;Teachingabout biology andthrough biology;;Question 2:;;Meeting future demands of society;;Two key principles;;Young people should be able to: - 1;;Young people should be able to: - 2;;Biological knowledge:;;More Biological knowledge:;;Importance of children’s ideas;;What do you think happens to the food inside your body? - 1;;What do you think happens to the food inside your body? - 2;;What do you think happens to the food inside your body? - 3;;Developing children’s ideas - 1;;Developing children’s ideas - 2;;Going beyond the classroom: Darwin inspired activities;;Assessing student progress;;Looking forward - 1;;Looking forward - 2;;Engaging learners: at the heart of what we do'
10027,'lecture','sl',9976,'2009-10-02','2009-11-09','Evolucija kot osrednji koncept pri pouku biologije / Evolution as the Central Concept in Biology Education','Evolucija ima osrednje mesto v sodobni biološki znanosti, saj predstavlja ključ za\nrazumevanje delovanja živih sistemov. Evolucija pridobiva osrednje mesto tudi pri pouku biologije\nkot koncept, ki razumevanje različnih tem biologije povezuje v celoto. Pri pouku lahko uporabimo\ngalapaške želve kot primer, ki prikazuje osrednji pomen evolucije za razumevanje biologije. Na\nrazličnih Galapaških otokih živijo različne podvrste galapaške želve. O njih je pisal že Charles\nDarwin, zato imajo v biologiji zgodovinski pomen, podobno kot »Darwinovi« ščinkavci. Sodobni\nznanstveniki preučujejo sorodstvena razmerja med podvrstami galapaških želv s pomočjo genetskih\nanaliz. Povezavo med galapaškimi želvami in galapaškimi kaktusi lahko predstavimo kot primer\nkoevolucije. Galapaške želve imajo fiziološke prilagoditve, ki jim omogočajo preživetje v zelo sušnih\nrazmerah. Galapaške želve tudi dobro prikazujejo posledice človekovih posegov v ekosisteme, saj je\nčlovek želve na eni strani množično pobijal za prehrano, na drugi strani pa tudi dodatno ogrozil njihov\nobstoj z vnosom novih vrst na otoke.\n----\nIn modern life science, evolution is the key to understanding living systems. Gradually, evolution is gaining a more central position also in biological education, as the concept that links different topics in biology into a network of knowledge. To illustrate this principle, the Galápagos tortoise can be used in biology lessons as a case study. Different subspecies of the Galápagos tortoise live on different Galápagos islands. Although »Darwin\'s« finches are more widely known, Charles Darwin also wrote about the Galápagos tortoises, hence they are important for the history of biology. Modern scientists study evolutionary relationships among the subspecies of the Galápagos tortoise using genetic analysis. In addition, the relationship between Galápagos tortoise and the Opuntia cacti is an example of coevolution. The Galápagos tortoise has physiological adaptations for survival in extremely dry conditions. Finally, the case of the Galápagos tortoise demonstrates the influence of human activities on ecosystems. Populations of the tortoise fell dramatically because of hunting and the introduction of predators and grazers by humans since the seventeenth century.','Evolucija kot osrednji koncept pri pouku biologije;;Anna Zeligowski: Evolution 4;;2009 Darwinovo leto;;Celostna biologija: Izhodišča za poučevanje biologije na vseh stopnjah izobraževanja;;Evolucija;;Evolucija evolucije v naši osnovni šoli;;Učbenik za 8. razred: 1965 - 1;;Učbenik za 8. razred: 1965 - 2;;Učbenik za 8. razred: 1972 - 1;;Učbenik za 8. razred: 1972 - 2;;Učbenik za 8. razred:1972 - 3;;Učbenik za 8. razred: 1972 - 4;;Učbenik za 8. razred: 1987 - 1;;Učbenik za 8. razred: 1987 - 2;;Učbenik za 8. razred: 1987 - 3;;1998 UN za devetletko;;Učni načrti za devetletko (1998) - 1;;Učni načrti za devetletko (1998) - 2;;Učni načrti za devetletko (1998) - 3;;Učni načrti za devetletko (1998) - 4;;Učni načrti za devetletko (1998) - 5;;Kaj se leta 2009 učijo učenci v slovenskih osnovnih šolah?;;2008 Posodobljeni UN;;Osnovna šola(6. do 9. razred): Posodobljeni UN;;Darwinovo leto 2009: Evolucija se NI VRNILA v osnovno šolo.;;Evolucija v gimnaziji;;Gimnazija: Posodobljeni UN (obvezni program:3 leta, 210 ur);;Anna Zeligowski: Darwin 1;;black box;;Anna Zeligowski: Darwin 2;;Evolucija kot povezovalni biološki koncept v šoli – primer: “Darwinove” želve;;Darwinovo potovanje;;“Darwinovi” ščinkavci;;“Darwinove” želve;;galapaška želva - 1;;galapaška želva - 2;;Evolucijsko drevo želv;;kaktus opuncija;;Koevolucija;;Henslow 1837: opis nove vrste opuncije;;Vpliv človeka na ekosisteme;;Evolucija;;Kakšna oblika oklepa je evolucijsko izvorna?;;Darwinova “dediščina”?;;Dolgoživost?;;V šoli približno 20-30 let zaostanka za znanostjo?;;Že leta 1982 v srednji šoli'
10028,'lecture','sl',9976,'2009-10-02','2009-11-09','Koevolucija – medvrstni odnosi kot gonilo evolucijskega razvoja naravnih združb / Coevolution – Interspecific Interactions as a Driving Force of Natural Assemblages Evolution','Koevolucija je vzajemno evolucijsko spreminjanje sobivajočih vrst v združbi, ki so povezane z\nmedvrstnimi odnosi, in je proces, ki ga poganja naravni izbor. Čeprav evolucijo usmerjajo tako\nabiotski kot biotski dejavniki okolja, se je izkazalo, da je koevolucija, ki zajema biotski del\ndejavnikov, najpomembnejši ekološki in genetski proces, ki oblikuje biodiverziteto Zemlje. Gre torej\nza neprestano tekmovanje vrst v združbi, ki se morajo prilagajati abiotskim in predvsem biotskim\nspremembam v okolju. Tiste, ki v tej tekmi zaostanejo, preprosto izumrejo, saj pri izrabi okoljskih\nvirov niso več kos tistim vrstam, ki so si z evolucijskimi prilagoditvami pridobile prednost. Van Valen\nje ob tem pokazal, da je to izumiranje stalno oziroma da imajo za izumrtje enake možnosti vse vrste v\nzdružbi ne glede na njihovo evolucijsko starost. Proces koevolucije je tesno povezan z medvrstnimi\nodnosi. Vrsta, ki si, denimo, z neko uspešno mutacijo pridobi prednost pred drugimi vrstami v združbi,\nsi uspe prisvojiti večji delež okoljskih virov. Pri tem se lahko njena populacija poveča, zaradi\nnegativnih vplivov pa s tem ogrozi preživetje drugih vrst v združbi, ki so z njo tako ali drugače\npovezane. Da bi preživele, se morajo sobivajoče vrste med evolucijskim razvojem skozi naravni izbor\nprilagoditi nastalim razmeram in nadoknaditi zaostanek.','Zgodba o Alice v čudežni deželi;;pravilo Rdeče kraljice;;KOEVOLUCIJA medvrstni odnosi kot gonilo evolucijskega razvojanaravnih združb;;Življenjske združbe in medvrstni odnosi;;Koevolucija sobivajočih vrst;;Medvrstni odnosi in koevolucija;;Koevolucija med plenilcem in plenom;;Koevolucijska speciacija pod vplivom plenilstva;;Koevolucija med zajedavcem in gostiteljem;;Koevolucija med zajedavcem in gostiteljem;;Koevolucija in mutualizem;;Koevolucija med tekmujočimi vrstami (kompeticija) - 1;;Koevolucija med tekmujočimi vrstami (kompeticija) - 2;;Razmik znaka (character displacement);;Zaključek;;HVALA ZA POZORNOST!'
10029,'panel','sl',9976,'2009-10-02','2009-11-09','Druga okrogla miza / Second Round-Table Discussion ',NULL,NULL
10030,'summary','sl',9976,'2009-10-02','2009-11-09','Zaključek / Closing',NULL,NULL
10031,'interview','sl',9650,'2007-12-12','2010-01-13','Zoisova nagrajenca 2007',NULL,NULL
10032,'lecture','sl',9650,'2008-01-04','2010-01-14','40 let Inštituta za raziskovanje krasa',NULL,NULL
10033,'lecture','sl',9650,'2008-01-18','2010-01-14','ARRS v Evropski znan. fundaciji (ESF)',NULL,NULL
10034,'interview','sl',9650,'2007-09-21','2010-01-13','Rekultivacija na Kitajskem',NULL,NULL
10035,'interview','sl',9650,'2007-10-19','2010-01-13','60 let Biotehnične fakultete, Univerze v Ljubljana',NULL,NULL
10036,'lecture','sl',9650,'2007-11-16','2010-05-06','70 let revije Proteus',NULL,NULL
10052,'lecture','sl',9976,'2009-10-01','2009-11-09','Otvoritveni govor častnega pokrovitelja posveta / Opening Speech of the Honorary Patron of the Conference',NULL,NULL
10096,'lecture','en',10095,'2009-09-11','2009-10-30','Crime, Conflict and the Racialization of Criminal Law','The scars from riots in 47 American cities in the late 1960s remain visible today not only\nin the physical landscape of a few stubbornly poor cities, but in a philosophy and jurisprudence\nof criminal law that has instantiated the disparate fates of racial minorities\nin the criminal justice system. The riots took place in the midst of profound social and\neconomic restructuring of the nation’s cities, and at the outset of an epidemic of rising\nrates of crime and disorder that framed both a new political order and a profound\ntransformation of American criminal law and criminal procedure. Within the decade, a\npolitical and legal mobilization – fueled by racial and cultural conflict – led to an abrupt\nreversal in the substance and philosophy of criminal law. The ceding of rights to criminal\ndefendants and the increasing regulation of police in the early 1960s gave way through\na series of cascading court decisions and new laws to a punitive regime that, over three\ndecades, has expanded the authority of police, curtailed the procedural rights of criminal\ndefendants, and supported policies that have sustained a widening racial gap in\nincarceration. A new body of criminal laws, though facially race-neutral, have had profound\nracial consequences that are durable and sustainable even in a low crime era. Part\nI of this paper discusses the antecedents, contexts and dynamics of this turn in criminal\nlaw, focusing on the racial dynamics that exploded in a wave of riots. Part II examines\nthe development of the new legal order, analyzing the reversal in law through a series of\ncourt decisions over two decades. Part III examines how the use of race-neutral laws to\nachieve crime control in the absence of complementary models of social regulation has\nproduced disparate racial impacts that have become endogenous to the political order.\nPart IV discusses the challenges to legal and institutional reform to restore racial equality\nin criminal justice. The American experience is a cautionary tale of the limits and dangers\nof criminal law to manage diversity and social conflict.',NULL
10097,'lecture','en',10095,'2009-09-10','2009-10-30','Slovenia: Crime Policy in Time of Change','Traditionally Slovenia had a comparatively low level of violent and organized crime and\ncomparatively low imprisonment rate. In addition, it successfully resisted to punitiveness\nin all its aspects, starting on the level of prescribed sentences and incarceration\nrates. Recently, however, we can witness several new developments in its crime policy.\nFirst, we can observe the growing interest of populist politics in the crime policy issues.\nThe fear of and the fight against crime has risen higher among the priorities of the elections\ncampaigns and every day politics. Connected to that, the potential of academia\nand research institutions to influence crime policy decision making has been declining,\nas has been notably demonstrated in the haste passing of the new Criminal Code in\n2008. Finally, as the EU is becoming more and more interested in harmonizing criminal\nlaw and crime policy, the extending criminal law powers of the EU erode Slovenia’s sovereignty\nin this respect. In my presentation I will discuss the relevance of these developments\nfor the future.',NULL
10098,'lecture','en',10095,'2009-09-11','2009-10-30','Redeeming Redemption as a Criminological Concept','In the past two decades, the science of criminology has focused considerable attention\non the topic of desistance from crime or how and why individuals active in crime “go\nstraight.” This research has been instrumental in the design and assessment of strategies\nfor reducing recidivism through resettlement or reintegration support. Criminologists,\nhowever, have had little to say about the issue of “redemption” or what it should require\nfor individuals to be officially forgiven of their crimes and have their “good names” restored.\nIn this talk, I will outline the need for a discussion of secular redemption in society\nand discuss the implications of criminological research in this regard.',NULL
10099,'lecture','en',10095,'2009-09-10','2009-10-30','Slovenian Criminology: Its Beginnings, Development and State of the Art','The early beginnings of the literature on Slovenian Criminology go back to the early\n1920s when Fran Milčinski, a judge with enough literary talent to depict complex issues\nof law and crime, published the first Slovenian novel on juvenile delinquency. In\nthe 1930s, Aleksander Vasiljevič Maklecov, a Russian criminal lawyer and refugee from\nRussia, joined the Faculty of Law in Ljubljana and became well known for his reflections\nupon several criminological issues and problems, of which many are still topical\ntoday: alcohol abuse and juvenile delinquency prevention, women and crime, crime\nin newspapers, etc. He is also the author of the first Slovenian textbook on criminology,\n‘Introduction to criminology’, (1948). In 1950, the Secretariat of the Internal Affairs,\nhaving established a research unit to study crime and delinquency, started publishing\n‘Criminal Investigation Topics’, a professional journal to gradually evolve into ‘Journal of\nCriminal Investigation and Criminology’, now an SSCI journal. In addition, there are two\nmore recent journals dealing with criminological topics: ‘Social Education’ and ‘Journal\nof Criminal Justice and Security’. The Institute of Criminology was established in 1954,\nand its first director was Hinko Lučovnik. The first research project, finished in 1957, has\nso far been followed by more than 150 research projects. The most fertile development\nera of the Institute’s (positivistic) research endeavours was that under Katja Vodopivec,\nMaklecov’s PhD graduate (1943) and the second director of the Institute. She established\nSlovenian criminology as a science on equal footing with other disciplines and headed\na huge number of research projects. Her successors, as directors of the Institute, were\nJanez Pečar, Alenka Šelih and Matjaž Jager. In addition to the Institute of Criminology,\nother institutions have developed in this field of expertise, studying crime, delinquency,\nsafety and security issues and other crime related problems (Social Education Depart72\nment at the Faculty of Education, UL; Faculty of Law, UM, and Faculty of Criminal Justice\nand Security, UM). Slovenian criminology developed in several stages making significant\ncontributions and enjoying international recognition. The leading perspectives on this\ndiscussion relate to crime control and prevention, the impact of Slovenian criminological\nthought on policy making, international projects, publications, as well as contributions\nto global criminology.',NULL
10100,'lecture','en',10095,'2009-09-11','2009-10-30','Caught between crime control and human rights?','The fall of the Berlin wall in November 1989 has not brought the “end of history” but\nthe beginning of a new era of instability, uncertainty and conflict. One of the outputs\nof the opening of the borders in Europe has been the rapid increase of trafficking in human\nbeings in the 1990s, coupled with the rise of research on the phenomenon of human\ntrafficking. Despite all research done it remains very difficult to get a good grip on\nthe phenomenon. Albrecht, using a variety of sources, mentions estimates of between\n200,000–500,000 women who are trafficked to Western Europe for the purpose of prostitution\non an annual basis, many of them coming from the former socialist countries of\nCentral and Eastern Europe. Since the 1990s as well the issue of trafficking has become\nthe object of systems of crime control worldwide, both through criminal legislation and\ncriminal justice system enforcement. Both national states and international organisations\nhave adopted a variety of legal instruments that make trafficking a criminal offence\nand have reinforced the investigation and the prosecution of such offences. Enforcement,\nhowever, remains a problem in most countries, partly because of the close relationship\nwith organised crime, partly because victims are not always willing to testify out\nof fear for revenge. At the same time it is interesting to note a shift from conceiving human\ntrafficking as a law enforcement problem relating to offenders to understanding it\nas a serious violation of human rights and putting the emphasis on the human dignity of\nthe victims. This shift has also facilitated the development of protection mechanisms for\nvictims, including access to justice for them, which at the same time may strengthen the\nmodel of law enforcement. In this contribution I will focus both on the phenomenon of\ntrafficking, its antecedents and its manifestations, as well as on the policies designed to\ncombat trafficking. In doing so, I will also highlight fundamental conceptual paradigms\nused to view the phenomenon, such as ‘moral panics’ (Cohen), left realism (Young et al.)\nand crime and human rights (Parmentier and Weitekamp).',NULL
10101,'lecture','en',10095,'2009-09-12','2009-10-30','Smuggling and Trafficking of Human Beings in the Balkan Area','The paper intends to give and overview and critical analyses of causes and recent trends\nin smuggling and trafficking of human beings in the Balkan area, as well as of criminal\npolicies and mechanisms for protection of victims. First, the problems related to definitions\nand distinction between smuggling and trafficking will be analysed in relation to\ngeographical position of Balkan, and attention will be drown to the scarce serious academic\nresearch in this field, as well as to overall low quality of data about victims, perpetrators\nand policies. Then, main contributing factors and recent trends will be explored,\nsuggesting large parts of population being involved in smuggling and trafficking “business”,\nwhile large portions of victims are invisible and stay out of any support system.\nParticular attention will be paid to both victims and perpetrators coming from marginalised\ngroups, as well as to victims who are invisible because they do not fit widespread stereotypes about victims (illegal migrants, men, sexual workers, street children, children\nused by organised crime for guiding victims etc.). Criminal policies and mechanisms for\nprotection of victims will then be analysed in relation to the role and social position of\nperpetrators, and socio-economic status, social visibility and stereotypes related to both\nvictims and perpetrators. I will argue that, in spite of obvious positive developments\nrecent years, comprehensive and holistic approach to smuggling and trafficking in human\nbeings, which goes beyond stigmatization, “otherness” and social exclusion, is not\nestablished neither in Balkan, nor in Western countries. In the concluding part, the paper\nwill suggest possible directions toward policy which would be oriented toward prevention\nand social inclusion of both victims and perpetrators, with more victims assisted\nand human rights of both protected.',NULL
10102,'lecture','en',10095,'2009-09-11','2009-10-30','Crime and Globalisation','Post-industrial societies are facing changes in the way people internalize social norms,\nwhat they feel guilty about, when they experience shame and how they perceive punishment.\nIdentification with traditional authorities which have in the past transmitted\nsocial norms has been declining for some time. Individualism has been pushed to its\nlimits. And transgression of norms which comes from global capital, international financial\ninstitution and state governments has often been cherished as a matter of progress.\nUnder the veil of ideology of perpetual economic growth on the societal level and advancement\nof self-fulfilment on the individual level, the definition of what counts as\ntransgression has been globally altered. Redefinition of what counts as a limit, what is\nthe nature of the prohibition and what are publicly acceptable forms of remorse as well\nas individually experienced anxieties in regard to prohibitions also underwent a change.\nFeeling of guilt and shame often accompanies individual’s striving towards creating an\nimage of perfect life and not so much transgression of moral rules and the legal order. In\nthis context the definition of crime has radically changed, too. How can criminology respond\nto these changes? As an interdisciplinary discipline it needs to in a new way assess\nthe way malaise of the civilization affects the malaise of the individual and vice versa. In\ntrying to understand this connection, some lessons from contemporary psychoanalytic\nknowledge might be of help, especially the reasoning that utilitarianism ultimately failed in its perception that people work towards advancement of their well being and minimalization\nof pain. Current economic crisis, for example, cannot be explained through\nthis framework – rather we need to look at it through the prism of an enjoyment in selfdestruction\nwhich has always been the hidden underside of progress.',NULL
10103,'lecture','en',10095,'2009-09-11','2009-10-30','Crime Policy between Effective Crime Control and Human Rights Protection','Crime policy has been facing the dilemma of whether human rights standards should\nbe upheld or the effectiveness strengthened for quite some time. For the Central and\nEast European countries this dilemma is of particular importance because human rights\nhave been the motivating factor in the processes of the 1990ies democratization. Social\nchanges that occurred after the 1990ies have coincided with an ongoing change in crime\npolicy in the “free world”: the liberal and humane crime policy has been slowly replaced\nby just desert, law and order and other more punitive policies in this field. Crime policy\ndevelopments in the last decade, especially after 9/11, have been especially oriented\ntowards achieving greater effectiveness – also at the cost of human rights. Crime policies\nin different European countries have adopted measures that either diminished human\nrights standards; in some cases, zone of criminality has been extended beyond criminal\noffences; in others, law enforcements measures can be applied to persons very remotely\nconnected or not connected at all to the criminal offence. Policies and measures, clearly\ndisregarding human rights standards, have been taken by legislative as well as executive\nauthorities at the European as well as at national levels. The economic crisis may be the\ntesting point for future orientation of crime policy: is it going into a fully punitive direction,\nor may it be oriented towards its earlier goals – effectiveness by respecting human\nrights standards – in new ways?',NULL
10105,'lecture','en',9818,'2009-09-28','2009-12-03','What Are Patterns?','**//Disclaimer:// Videolectures.Net emphasises that the audio quality of this video could not be improved,\ndue to poor audio quality conditions provided in the lecture auditorium.**','WELCOME to Pula;;aop09_cristianini_wap_01_Page_02;;Who Needs Patterns?;;Picture 1;;Picture 2;;Picture 3;;Patterns on the map 1;;Patterns on the map 2;;Pattern: Alignments of Points;;Leylines 1;;Leylines 2;;Leylines 3;;Leylines 4;;Knockraheen;;A Rich Leyline;;A Rich Leyline patterns;;Leylines 5;;Patterns on the map 3;;Patterns on the map 4;;Visit the West of England;;Alignments of Random Points;;What is a Pattern?;;Pattern Discovery 1;;Pattern Discovery 2;;Finding Patterns;;Data;;Patterns;;Null Model;;Strength of a Pattern;;Predictive vs. Significant;;General Pattern Finding;;Why Patterns?;;Patterns and Intelligence;;NORD;;Periodic Table of the Elements;;Time Series Analysis;;Data - social network;;DNA Analysis;;Why Patterns?;;The Big Picture;;The Search Problem;;aop09_cristianini_wap_01_Page_42;;aop09_cristianini_wap_01_Page_43;;aop09_cristianini_wap_01_Page_44;;aop09_cristianini_wap_01_Page_45;;aop09_cristianini_wap_01_Page_46;;aop09_cristianini_wap_01_Page_47;;aop09_cristianini_wap_01_Page_48;;aop09_cristianini_wap_01_Page_49;;aop09_cristianini_wap_01_Page_50;;aop09_cristianini_wap_01_Page_51;;aop09_cristianini_wap_01_Page_52'
10106,'lecture','en',9818,'2009-09-28','2009-12-03','Pattern Analysis and Scientific Method, Privacy and Intelligent Machines','**//Disclaimer:// Videolectures.Net emphasises that the audio quality of this video could not be improved,\ndue to poor audio quality conditions provided in the lecture auditorium.**','aop09_cristianini_paasm_Page_001;;aop09_cristianini_paasm_Page_002;;aop09_cristianini_paasm_Page_003;;aop09_cristianini_paasm_Page_004;;aop09_cristianini_paasm_Page_005;;aop09_cristianini_paasm_Page_006;;aop09_cristianini_paasm_Page_007;;aop09_cristianini_paasm_Page_008;;aop09_cristianini_paasm_Page_009;;aop09_cristianini_paasm_Page_010;;aop09_cristianini_paasm_Page_011;;aop09_cristianini_paasm_Page_012;;aop09_cristianini_paasm_Page_013;;aop09_cristianini_paasm_Page_014;;aop09_cristianini_paasm_Page_015;;aop09_cristianini_paasm_Page_016;;aop09_cristianini_paasm_Page_017;;aop09_cristianini_paasm_Page_018;;aop09_cristianini_paasm_Page_019;;aop09_cristianini_paasm_Page_020;;aop09_cristianini_paasm_Page_021;;aop09_cristianini_paasm_Page_022;;aop09_cristianini_paasm_Page_023;;aop09_cristianini_paasm_Page_024;;aop09_cristianini_paasm_Page_025;;aop09_cristianini_paasm_Page_026;;aop09_cristianini_paasm_Page_027;;aop09_cristianini_paasm_Page_028;;aop09_cristianini_paasm_Page_029;;aop09_cristianini_paasm_Page_030;;aop09_cristianini_paasm_Page_031;;aop09_cristianini_paasm_Page_032;;aop09_cristianini_paasm_Page_033;;aop09_cristianini_paasm_Page_034;;aop09_cristianini_paasm_Page_035;;Patterns in Data and Scientific Method;;Venice 1609 (1) ;;Venice 1609 (2);;Discovery;;Implications;;The Scientific Method;;Publication;;A Revolution under way;;SEQUENCING;;LHC;;Astronomy;;Chemiistry;;A Google DATACENTER;;Many Google DATACENTERs;;The “Industrial Revolution”;;Implications;;Pattern Analysis 1;;Closing the Loop (1);;Closing the Loop (2);;Readability;;Pattern Analysis 2;;Science;;Social Sciences;;News Patterns 1;;News Patterns 2;;News Patterns 3;;News Patterns 4;;News Patterns 5;;Found In Translation 1;;Found In Translation 2;;Meme timelines;;Detecting changes;; Pope-ularity 1;; Pope-ularity 2;;Newspaper analizis;;Newspaper analizis (networks and informations);;Data Driven Artificial Intelligence Creating Intelligent Behaviour by Exploiting Patterns in Data;;General overview 1;;General overview 2;;Translator;;Selecting Ads for Web;;Selecting Ads;;November 1958 (1);;November 1958 (2);;1958 (research);;Contents;;Participants;;First session;;Methods of Artificial Intelligence and Heuristic Programming;;Example Speech Recognition;;Frank Rosenblatt;;Example Learning Machines Conditional Probability Machine;;Machine Intelllliigence, AD 1958;;How Much Have We Progressed?;;Machine Intelligence, AD 2009;;Amozon example (1);;Amozon example (2);;aop09_cristianini_paasm_Page_093;;An invited tallk from the future;;Data-Driven Artificial Intelligence;;Low Level Processing;;Example: Viterbi Allgorithm;;Errror bounds of convolutional codes (missing slide);;Impact;;“Statiistiicall Hacks”;;Optimisation and Statistics;;Patterns in Personal Data;;The Privacy Delusion;;Informatiion Society;;A Trail in Transaction Space;;Web Logs 1;;Web Logs 2;;The AOL Case;;THE AOL CASE STUDY == Search activity of User 98280 (1);;THE AOL CASE STUDY == Search activity of User 98280 (2);;THE AOL CASE STUDY == Search activity of User 98280 (3);;THE AOL CASE STUDY == Search activity of User 98280 (4);;THE AOL CASE STUDY == Search activity of User 98280 (5);;Google, and data integration combining queries, position, email content, background information;;Inferences: prediction by segmentation (double-click, post-code, credit scoring, …);;BS1 5TX;;Behavioural Segmentation;;Inference;;Consumer response;;Political Profilling;;From wired magazine;;Computer Voyeur;;Automating Usage;;Automatic Targeting;;Tomorrow’’s World;;THE END'
10107,'lecture','en',9818,'2009-09-28','2009-12-03','Patterns in Vector Spaces',NULL,'Patterns in vector spaces;;Overview -1;;Overview -2;;Overview -3;;Overview -4;;Overview -5;;Overview -6;;Overview -7;;Overview -8;;Overview -9;;Overview -10;;Outline -1;;Outline -2;;Linear techniques for pattern analysis;;Least Squares Problems;;Linear Regression -1;;Linear Regression -2;;Linear Regression -3;;Linear Regression -4;;Least Squares Regression -1;;Least Squares Regression -2;;Ridge Regression -1;;Ridge Regression -2;;Ridge Regression -3;;Classification;;Fisher\'s Discriminant Analysis-1;;Fisher\'s Discriminant Analysis-2;;Eigenvalue Problems -1;;Eigenvalue Problems -2;;Eigenvalue Problems -3;;Principal Component Analysis -1;;Principal Component Analysis -2;;Principal Component Analysis -3;;Principal Component Analysis -4;;Principal Component Analysis -5;;Principal Component Analysis -6;;Principal Component Analysis -7;;Relations between datasets -1;;Relations between datasets -2;;PCA on coupled data -1;;PCA on coupled data -2;;Partial least squares -1;;Partial least squares -2;;Canonical Correlation Analysis -1;;Canonical Correlation Analysis -2;;Summarizing -1;;Summarizing -2;;Regulated CCA -1;;Regulated CCA -2;;R-CCA and FDA;;Relation between multiple sources;;Multiway CCA -1;;Multiway CCA -2;;Summarizing -3;;Convex Optimization;;Classification;;Fisher\'s Discriminant Analysis;;Support Vector Machines -1;;Support Vector Machines -2;;Support Vector Machines -3;;Support Vector Machines -4;;Support Vector Machines -5;;Support Vector Machines -6;;Support Vector Machines -7;;SVM in practice -1;;SVM in practice -2;;Multiclass SVM -1;;Multiclass SVM -2;;Multiclass SVM -3;;Support Vector Machines -8;;Loss functions -1;;Loss functions -2;;Support Vector Machines -9;;Support Vector Machines -10;;Stacking;;Kernel methods;;Support Vector Machines -11;;Support Vector Machines -12;;Support Vector Machines -13;;Kernels -1;;Kernels -2;;Kernels -3;;Constructing Kernels -1;;Constructing Kernels -2;;Applications -1;;Applications -2;;Applications -3;;Applications -4;;Which kernel? -1;;Which kernel? -2;;Learning the kernel -1;;Learning the kernel -2;;Kernel combination -1;;Kernel combination -2;;SVM - Summarizing -1;;SVM - Summarizing -2;;SVM - Summarizing -3;;KRR, KPCA, KCCA;;Kernel RR;;Kernel PCA;;Kernel CCA;;KCCA -1;;KCCA -2;;Kernel methods - Summarizing;;Learning in Structured Output Spaces;;Learning in structured output -1;;Learning in structured output -2;;Learning in structured output -3;;Learning in structured output -4;;Learning in structured output -5;;Learning in structured output -6;;Learning in structured output -7;;Learning in structured output -8;;Learning in structured output -9;;Learning in structured output -10;;Learning in structured output -11;;Learning in structured output -12;;Encoding -1;;Encoding -2;;Encoding -3;;Encoding -4;;Encoding -5;;SODA -1;;SODA -2;;SODA -3;;SODA -4;;SODA -5;;Loss in structured output learning;;SVMISO -1;;SVMISO -2;;SVMISO -3;;SVMISO -4;;Applications -1;;Applications -2;;Summarizing -4;;Summarizing -5;;Thank you;;Picture'
10108,'lecture','en',9818,'2009-09-29','2009-12-03','Frequent Pattern Mining',NULL,'Frequent Pattern Mining;;Bart Goethals;;What this talk is about;;Pattern mining;;Outline -1;;Back in 1993...;;Applications -1;;Applications -2;;Formally;;Problem -1;;Example -1;;How?;;How to find all frequent itemsets -1;;How to find all frequent itemsets -2;;Apriori -1;;Apriori -2;;Example -2;;Level - wise search;;The Apriori Algorithm;;Candidate Generation;;Example run;;Apriori\'s main problem;;Optimizations;;Current Research;;What if DB fits in memory?;;Eclat: tidlist;;Eclat: tidlist example;;Eclat: algorithm;;Divide and conquer;;Eclat: algorithm;;FP - growth -1;;FP - growth -2;;Apriori vs. Eclat vs. FP - growth;;Some FIMI results;;Picture -1;;Picture -2;;Some FIMI conclusion;;Extensions -1;;Extensions -2;;Outline -2;;Complex Patterns;;Sequences;;Patterns in Sequences;;Episode mining -1;;Episode mining -2;;Episode mining -3;;Example -3;;Problem -2;;Graphs;;Patterns and Rules over Graphs;;Relational Databases;;Patterns in RDBs -1;;Patterns in RDBs -2;;Pattern Mining in general;;Solution;;Other constraints or interestingness;;Picture -2;;Motivation -1;;Motivation -2;;Tiles -1;;Tiles -2;;Tile Mining;;Picture -3;;Picture -4;;Picture -5;;Picture -6;;Picture -7;;Picture -8;;Picture -9;;Can we efficiently find them?;;The LTM algorithm;;The bound;;The Dynamics;;Thank you;;The end'
10109,'lecture','en',9818,'2009-09-29','2009-12-03','Analysis of Patterns',NULL,'Analysis of Patterns;;Outline;;Why Pattern Discovery?;;Avalibility of huge datasets;;Pattern Matching vs Pattern Discovery -1;;Pattern Matching vs Pattern Discovery -2;;Association Patterns -1;;Association Patterns -2;;Association Patterns -3;;Association Patterns -4;;Association Patterns -5;;Frequent Set Mining -1;;Frequent Set Mining -2;;Frequent Set Mining -3;;Frequent Set Mining -4;;Frequent Set Mining -5;;Frequent Set Mining -6;;Frequent Set Mining -7;;Frequent Set Mining -8;;Frequent Set Mining -9;;Frequent Set Mining -10;;Association Rules Mining -1;;Association Rules Mining -2;;Association Rules Mining -3;;Association Rules Mining -4;;Association Rules Mining -5;;Sequential Patterns;;Sequences -1;;Sequences -2;;Sequences -3;;Sequences -4;;Sequences -5;;Sequences -6;;Sequences -7;;Sequences -8;;Sequences -9;;Sequences -10;;Sequences -11;;Sequences -12;;Languages -1;;Languages -2;;Languages -3;;Languages -4;;Languages -5;;Languages -6;;Languages -7;;Languages -8;;Languages -9;;Languages -10;;Languages -11;;Languages -12;;Languages -13;;Languages -14;;Languages -15;;Languages -16;;Languages -17;;Languages -18;;Languages -19;;Going further ...;;Analysis of Patterns - Discovering events in text streams;;Acknowledgements;;News mining;;Memes -1;;Memes -2;;Memes -3;;Memes -4;;Memes -5;;The Pattern Discovery Task -1;;The Pattern Discovery Task -2;;Suffix trees/arrays -1;;Suffix trees/arrays -2;;Suffix trees/arrays -3;;Suffix trees/arrays -4;;Definitions -1;;Definitions -2;;Definitions -3;;Definitions -4;;Definitions -5;;Definitions -6;;Definitions -7;;Definitions -8;;Definitions -9;;Definitions -10;;Definitions -11;;Definitions -12;;Definitions -13;;Construction -1;;Construction -2;;Construction -3;;Construction -4;;Construction -5;;Construction -6;;Construction -7;;Construction -8;;Construction -9;;Construction -10;;Construction -11;;Construction -12;;Construction -13;;Construction -14;;Properties -1;;Properties -2;;Properties -3;;Properties -4;;Annotations -1;;Annotations -2;;First applications -1;;First applications -2;;Definitions -1;;Definitions -2;;Computing p-values -1;;Computing p-values -2;;Computing p-values -3;;Computing p-values -4;;Computing p-values -5;;Experimental results -1;;Experimental results -2;;Going further ...'
10110,'lecture','en',9818,'2009-09-29','2009-12-03','Three Hours on Multiple Classififier Systems','Motivations and basic concepts Motivations\nof multiple classifier systems. The “worst” case and “best” case motivations.\nPractical and theoretical motivations. Basic concepts. Architectures for\nmultiple classifier systems. Ensemble types, combiner types. The concept of\nclassifier “diversity”. The design cycle of a multiple classifier system.\n\nCreating multiple classifiers Systematic\nmethods for creating classifier ensembles. Methods\nbased on training data manipulation: data splitting methods, Bagging and\nBoosting. Methods\nbased on input and output feature manipulation: feature selection, the Random\nSubspace method, noise injection, and error-correcting codes.\n\nCombining multiple classifiers Methods\nfor combining multiple classifiers at the “abstract” level (voting methods, the\nBehaviour Knowledge Space method, etc.) Methods\nfor combining multiple classifiers at the “rank” level (the Borda count method,\netc.) Methods\nfor combining multiple classifiers at the “measurement” level (linear\ncombiners, the product rule, etc.) Basic\nconcepts on dynamic classifier selection methods.','Three Hours on Multiple Classifier Systems -1;;Terminology -1;;Terminology -2;;Tutorial Aims and Outline ;;Part 1;;The traditional approach to Pattern Classification;;The traditional approach: Small Sample Size Issue;;A practical example -1;;Multiple Classifier Fusion: Worst Case Motivation;;A practical example -2;;Theoretical support for the worst case motivation;;Multiple Classifier Fusion: Best Case Motivation;;Experimental evidences: Multimodal Biometrics;;Fusion of multiple classifiers: computional motivation;;Further Motivations for Multiple Classifiers;;Basic Architecture of a Multiple Classifier System;;MCS: Basic Concepts;;MCS Architectures/Topologies;;The Ensamble;;Fuser (\"combination\" rule);;Focus on Parallel Architecture;;Classifiers \"Diversity\" vs. Fuser Complexity;;Classifiers Diversity Measures: An Example;;Classifiers\' diversity is an elusive concept...;;Analogy between MCS and Single Classifier Design;;MCS Design;;A small homework....;;Question -1;;Three Hours on Multiple Classifier Systems -2;;Methods for creating classifier ensambles;;Methods for creating MCS;;Using problem and designer knowledge;;Injecting randomness;;Methods based on training data manipulation;;Bagging;;Bootstrap;;Bagging (Bootstrap AGGregatING);;Combining rules for Bagging;;Examples of bagging;;The right number of bagged classifiers -1;;The right number of bagged classifiers -2;;AdaBoost;;Basic Scheme of AdaBoost;;Methods based on Input Feature Manipulation;;The Random Subspace Methods;;RSM: multiple subspace generation;;Decision fusion with RSM;;RSM: Application to Decision Forests;;Some Remarks on RSM;;The concept of \"weak\" classifier;;Noise Injection;;The K-NN Direct Noise Injection;;Manipulating the Output Features;;ECOC: Basic Idea;;ECOC: An example of Decoding Matrix;;ECOC classification;;Question -2;;Three Hours on Multiple Classifier Systems -3;;Methods for combining multiple classifiers;;Methods for fusing multiple classifiers -1;;Methods for fusing multiple classifiers -2;;The Majority Voting Rule;;Majority Voting Rule;;Majority Voting Rule vs. Classifiers Dependency: An Example;;Rules based on the Bayes Approach;;Behaviour Knowledge Space (BKS);;BKS Small-Sample Size Drawback;;BKS Improvements -1;;BKS Improvements -2;;Remarks on Abstract Level Fusers;;Rank-level Fusion Methods;;The Borda Count Method: an example;;The Borda Count Method: an example;;Remarks on Rank level Methods;;Measurement-level Fusion Method;;Linear Combiners;;Bias/Variance Analysis in Linear Combiners -1;;Bias/Variance Analysis in Linear Combiners -2;;Bias/Variance Analysis in Linear Combiners -3;;Product and Order Statistics Fusers;;A Theoretical Framework;;Fusers with Weights;;\"Stacked\" Fusion;;Pros and Cons of the \"Stacked\" approach;;Classifier Selection -1;;Classifier Selection -2;;Classifier Selection -3;;Selection Condition: An Example;;Some remarks on classifier selection;;Final Remarks on Fixed vs. Trained Fusers;;MCS DESIGN -1;;MCS DESIGN -2;;MCS DESIGN -3;;Question -3;;The very last question...'
10111,'lecture','en',9818,'2009-10-01','2009-12-03','Statistical Significance and Stability Analysis for Patterns',NULL,'Statistical Aspects of Pattern Analysis;;Structure -1;;Aims;;Patterns: real or spurious -1;;Patterns: real or spurious -2;;Patterns: real or spurious -3;;Patterns: real or spurious -4;;Pattern analysis in science;;Significance vs stability -1;;Significance vs stability -2;;Theories of pattern analysis;;General statistical considerations;;Significance testing;;Spurious versus real patterns;;Summary -1;;Structure -2;;Significance testing -2;;Example of significance testing ;;Missouri example cont;;Significance level;;Pattern stability -1;;Pattern stability -2;;Misouri example;;Misouri stability;;Concentration inequalities;;Error ddistribution: dataset size: 342;;Concentrating inequalities cont.;;McDiarmid\'s inequality;;Using McDiarmid;;Application to Missouri;;Summary -3;;Structure -3;;Misouri revisited;;Multiple hypotheses;;In Picture;;Missouri;;Bonferroni correction;;Tandem repeats example -1;;Tandem repeats example -2;;Stratification;;Linking with algorithms;;Optimising the algorithm;;Structure -4;;Composite hypothesis testing;;Symetric Composite hypotheses;;Symetric hypothesis testing;;The DNA example;;Structure -5;;Multi-patterns for pattern stability;;Probability of being misled in classification;;finite or Countable function classes;;Finite or Countable function classes result;;Some comments on the result;;Statistical learning theory;;Structure -6;;Rademacher complexity;;Rademacher proof beginnings;;Deriving sample result;;Deriving sample result cont.;;Adding symmetrisation;;Main rademacher theorem;;Empirical Rademacher theorem;;Rademacher complexity;;Blank page;;SVM bound;;Kernel PCA;;Kernel PCA cont.;;Analysis of Kernel PCA;;Statistical analysis of PCA;;Outline of proof -1;;Outline of proof -2;;Feature space construction;;Feature space construction cont.;;Applying Rademacher complexity;;Applying Rademacher complexity cont;;Hypothesis testing using kernel spaces;;Composite hypothesis and permutation testing;;Bounding expected value;;Applying the test;;Conclusions;;aop09_taylor_ssasa_Page_01;;aop09_taylor_ssasa_Page_02;;aop09_taylor_ssasa_Page_03;;aop09_taylor_ssasa_Page_04;;aop09_taylor_ssasa_Page_05;;aop09_taylor_ssasa_Page_06;;aop09_taylor_ssasa_Page_07;;aop09_taylor_ssasa_Page_08;;aop09_taylor_ssasa_Page_09;;aop09_taylor_ssasa_Page_10;;aop09_taylor_ssasa_Page_11;;aop09_taylor_ssasa_Page_12;;aop09_taylor_ssasa_Page_13;;aop09_taylor_ssasa_Page_14;;aop09_taylor_ssasa_Page_16;;aop09_taylor_ssasa_Page_17;;aop09_taylor_ssasa_Page_18;;aop09_taylor_ssasa_Page_19;;aop09_taylor_ssasa_Page_20;;aop09_taylor_ssasa_Page_21;;aop09_taylor_ssasa_Page_22;;aop09_taylor_ssasa_Page_23;;aop09_taylor_ssasa_Page_24;;aop09_taylor_ssasa_Page_25;;aop09_taylor_ssasa_Page_26;;aop09_taylor_ssasa_Page_27;;aop09_taylor_ssasa_Page_28;;aop09_taylor_ssasa_Page_29;;aop09_taylor_ssasa_Page_30;;aop09_taylor_ssasa_Page_31;;aop09_taylor_ssasa_Page_32;;aop09_taylor_ssasa_Page_33;;aop09_taylor_ssasa_Page_34;;aop09_taylor_ssasa_Page_35;;aop09_taylor_ssasa_Page_36;;aop09_taylor_ssasa_Page_37;;aop09_taylor_ssasa_Page_38;;aop09_taylor_ssasa_Page_39;;aop09_taylor_ssasa_Page_40;;aop09_taylor_ssasa_Page_41;;aop09_taylor_ssasa_Page_42;;aop09_taylor_ssasa_Page_43;;aop09_taylor_ssasa_Page_44;;aop09_taylor_ssasa_Page_45;;aop09_taylor_ssasa_Page_46;;aop09_taylor_ssasa_Page_47;;aop09_taylor_ssasa_Page_48;;aop09_taylor_ssasa_Page_49;;aop09_taylor_ssasa_Page_50;;aop09_taylor_ssasa_Page_51;;aop09_taylor_ssasa_Page_52;;aop09_taylor_ssasa_Page_53;;aop09_taylor_ssasa_Page_54;;aop09_taylor_ssasa_Page_55;;aop09_taylor_ssasa_Page_56;;aop09_taylor_ssasa_Page_57;;aop09_taylor_ssasa_Page_58;;aop09_taylor_ssasa_Page_59;;aop09_taylor_ssasa_Page_60;;aop09_taylor_ssasa_Page_61;;aop09_taylor_ssasa_Page_62;;aop09_taylor_ssasa_Page_63;;aop09_taylor_ssasa_Page_64;;aop09_taylor_ssasa_Page_65;;aop09_taylor_ssasa_Page_66;;aop09_taylor_ssasa_Page_67;;aop09_taylor_ssasa_Page_68;;aop09_taylor_ssasa_Page_69;;aop09_taylor_ssasa_Page_70;;aop09_taylor_ssasa_Page_71;;aop09_taylor_ssasa_Page_72;;aop09_taylor_ssasa_Page_73;;aop09_taylor_ssasa_Page_74;;aop09_taylor_ssasa_Page_75;;aop09_taylor_ssasa_Page_76;;aop09_taylor_ssasa_Page_77;;aop09_taylor_ssasa_Page_78;;aop09_taylor_ssasa_Page_79;;aop09_taylor_ssasa_Page_80'
10112,'lecture','en',9818,'2009-10-01','2009-12-03','Pattern Analysis over Graphs, and Bioinformatics Applications','1. Classification and regression over graphs. Overview:\npositive definite graph kernels based on walk, subtrees etc.., as well\nas other non p.d. similarity functions (eg from graph matching) that\ncan be used to compare graphs and do classification/regression with\nkernel methods. Applications: QSAR in chemistry, image classification\n\n2. Detecting patterns in the context of regression or classification with a graph as prior knowledge over the features. \nOverview:\nin a classical regression/classification problem over high-dimensional\nvectors. Control the complexity, by using priors that can be derived\nfrom the graph over the vectors, and how they can be used as penalty\nfunctions for classification and regression. This will cover diffusion\nkernels and other kernels over graphs, fused lasso, structured group\nlasso. Application in bioinformatics.','Supervised classification for structured data: Applications in bio- and chemoinformatics;;Virtual screening for drug discovery;;Image retreval and classification;;Cancer diagnosis;;Cancer prognosis;;Pattern recognition, aka supervised classification -1;;Pattern recognition, aka supervised classification -2;;Pattern recognition, aka supervised classification -3;;Pattern recognition, aka supervised classification -4;;Pattern recognition, aka supervised classification -5;;Formalization;;Linear classifiers -1;;Linear classifiers -2;;Outline -1;;Outline -2;;Motivation -1;;The approach -1;;The approach -2;;The approach -3;;Example -1;;Challenge: which descriptors (patterns) ?;;Indexing by substructures;;Subgraphs;;Indexing by all subgraphs? -1;;Indexing by all subgraphs? -2;;Indexing by all subgraphs? -3;;Paths;;Indexing by all paths? -1;;Indexing by all paths? -2;;Indexing by all paths? -3;;Indexing by what?;;Example: Indexing by all shortest paths -1;;Example: Indexing by all shortest paths -2;;Example: Indexing by all subgfraphs up to k vertices -1;;Example: Indexing by all subgfraphs up to k vertices -2;;Summary -1;;Outline -3;;Outline -4;;Positive definite kernels;;The kernel trick;;Learning linear classifiers with kernels;;Making kernels;;Outline -5;;The idea -1;;The idea -2;;The idea -3;;Expressiveness vs Complexity -1;;Expressiveness vs Complexity -2;;Complexity of complete kernels -1;;Complexity of complete kernels -2;;Subgraph kernel;;Subgraph kernel complexity -1;;Subgraph kernel complexity -2;;Subgraph kernel complexity -3;;Path kernel -1;;Path kernel -2;;Summary -2;;Walks;;Walks / paths;;Walk kernel -1;;Walk kernel -2;;Walk kernel examples -1;;Walk kernel examples -2;;Walk kernel examples -3;;Computation of walk kernels;;Product graph;;Walk kernel and product graph -1;;Walk kernel and product graph -2;;Computation of the nth-order walk kernel;;Computation of random and geometric walk kernels;;Extensions 1: label enrichment;;Extension 2: Non-tottering walk kernel;;Computation of the non-tottering walk kernel;;Extension 3: Subtree kernels;;Example: Tree-like fragments of molecules;;Computation of the subtree kernel;;Application in chemoinformatics;;2D Subtree vs walk kernels;;Image classification;;Summary: graph kernels;;Outline -6;;Microarrays measure gene expression;;Cancer classification from microarray data;;Gene networks;;Gene networks and expression data;;An idea;;Graph Laplacian;;Fourier basis -1;;Fourier basis -2;;Fourier basis -3;;Smoothing operator -1;;Smoothing operator -2;;Smoothing operator -3;;Smoothing operator -4;;Supervised classification and regression;;Link with shrinkage estimator -1;;Link with shrinkage estimator -2;;Kernel methods;;Examples -3;;Examples -4;;Data;;Classification performance;;Classifier -1;;Classifier -2;;Summary -3;;Outline -5;;Linear classifiers -1;;Linear classifiers -2;;Example: Norm Constraints;;Example: Feature Selection;;Example: Sparsity inucing convex priors;;Why LASSO leads to sparse solutions;;Efficiency computation of the regularization path;;Incorporating prior knowledge;;Outline -6;;Motivation -4;;Boosting over subgraph indexation;;The DFS code tree;;Graph LASSO regularization path;;Summary -4;;Outline -7;;Chromosomic aberrations in cancer;;Comparative Genomic Hybridization;;Aggressive vs non-aggressive melanoma;;Classification of array CGH;;A penalty for CGH array classification;;Application: metastasis prognosis in melanoma;;Outline -8;;How to select jointly genes belonging to the same pathways?;;Selecting pre-defined groups of variables;;What if a gene belongs to several groups?;;Overlap norm;;A new norm;;Overlap and group unity balls;;Theoretical results -1;;Theoretical results -2;;Experiments;;Extension: Graph lasso;;Graph lasso vs kernel on graph;;Results;;Outline -9;;Conclusion'
10113,'lecture','en',9818,'2009-10-02','2009-12-03','Pattern Recognition in Computer Vision',NULL,'Pattern Recognition in Computer Vision;;Outline and Goals;;What is vision?;;What do we want?;;So what do humans care about?;;Verification: is that a bus?;;Detection: are there cars?;;Identification: is that a picture of Mao?;;Object categorization;;Scene and context categorization;;The Computer Vision Industry;;Pattern Recognition in Computer Vision;;\"Pattern Recognition\" aproach;;Why Computer Vision is so difficult?;;Sources of image variability -1;;Sources of image variability -2;;Sources of image variability -3;;Sources of image variability -4;;Sources of image variability -5;;Sources of image variability -6;;Sources of image variability -7;;Sources of image variability -8;;Sources of image variability -9;;Sources of image variability -10;;Recognition in Vision;;Bag of Words Model -1;;Bag of Words Model -2;;Object;;Picture -1;;Picture -2;;Bag of Visual Words;;Local Image feature;;Interest Points Descriptors -1;;Interest Points Descriptors -2;;Local Image feature: Texture;;Texture - Descriptions;;Creation of a Visual Vocabulary;;KMeans;;Randomized Decision Forests;;Image Representation;;Spatial Hierarchy Representation;;Visual Words Correlograms;;Picture -3;;The statistical Viewpoint -1;;The statistical Viewpoint -2;;Discriminative;;Generative;;Multi-Class Classification ;;Learning and Recognition of Categories;;Notation;;Naive Bayes Model -1;;Naive Bayes Model -2;;Naive Bayes vs SVM;;Probabilistic Latent semantic Analysis -1;;Probabilistic Latent semantic Analysis -2;;PLSA: Learning and Categorization;;Hybrid generative/discriminative approach -1;;Hybrid generative/discriminative approach -2;;Hybrid generative/discriminative approach -3;;Picture -4;;Examples of Application;;Scene Classification and Object Recognition;;Content Based Image Retrieval;;SEmantic Segmentation;;Action Recognition;;Medical Imaging;;Direct Marketing Learning;;Conclusion;;References and Further Readings -1;;References and Further Readings -2;;References and Further Readings -3;;Thank you'
10114,'lecture','en',9818,'2009-10-02','2009-12-03','Patterns: Significant vs. Accidental',NULL,'Patterns True vs. accidental;;Picture -1;;Picture -2;;Picture -3;;Picture -4;;Picture -5;;Picture -6;;Picture -7;;Picture -8;;Picture -9;;Picture -10;;Picture -11;;Picture -12;;Picture -13;;Picture -14;;Picture -15;;Picture -16;;Picture -17;;Picture -18;;Picture -19;;Picture -20;;Picture -21;;Benefits of detecting Patterns;;Periodic Table of the Elements -1;;Periodic Table of the Elements -2;;Periodic Table of the Elements -3;;Benefits of Detecting Patterns;;Patterns and Intelligence;;The instinct for Patterns;;Picture -22;;Picture -23;;Patterns and randomness -1;;Patterns and randomness -2;;Finding Patterns;;Patterns in Natural Phenomena;;Patterns in Collective Behaviour'
10115,'lecture','en',9818,'2009-10-02','2009-12-03','Patterns in Web Content',NULL,'Patterns in WEB Content;;Our Project -1;;Our Project -2;;Birth of the Meme;;Memes in Blogs;;Picture -1;;NY Times -1;;NY Times -2;;Patterns in Media Content -1;;Patterns in Media Content -2;;Picture -2;;Picture -3;;Picture -3;;Picture -4;;Picture -5;;Strange Life of Some Memes;;Operational Definitions;;Tracking Replied Text;;Picture -6;;Picture -7;;Picture -8;;Opportunities;;Grand Challenge;;Conclusion -1;;Conclusion -2'
10116,'lecture','en',9818,'2009-10-02','2009-12-03','Analysis of Patterns for Computer Security',NULL,NULL
10117,'lecture','en',9818,'2009-10-02','2009-12-03','Constraint Programming for Itemset Mining',NULL,'Constraint Programming for Itemset Mining -1;;Position in summer school;;Constraint Programming for Itemset Mining -2;;(frequent) Itemset mining -1;;Goal -1;;(frequent) Itemset mining -2;;Too many patterns;;Goal -2;;Constraint - based mining;;Constraint - based Itemset Mining -1;;Constraint - based Itemset Mining -2;;The need for a principled approach;;Constraint Programming for Itemset Mining -1;;Constraint programming -1;;How CP works;;A CP model;;The CP Search;;A CP search;;Constraint Programming for Itemset Mining -2;;Constraint Programming -2;;Itemset mining;;CP 4 IM -1;;CP 4 IM -2;;CP 4 IM -3;;Itemset Mining in CP;;The FIM_CP search -1;;The FIM_CP search -2;;The FIM_CP search -3;;The FIM_CP search -4;;The FIM_CP search -5;;The FIM_CP search -6;;The FIM_CP search -7;;FIM_CP model: expressive;;FIM_CP model: general;;FIM_CP model: flexible;;In short: FIM_CP;;Runtime behavior, unconstrained;;Runtime behavior, constrained;;Experiment conclusions -1;;Constraint Programming for Itemset Mining;;Correlated Itemset Mining -1;;Constraint-based mining;;Correlated Itemset Mining -2;;ROC analysis;;Measuring correlation;;Convex measures in CP;;Bound in PN-space;;Improved bound in PN-space;;Better bound in PN-space;;Branch and propagate CIMCP;;Correlation measures;;Experiments -1;;Experiments in CP -1;;Experiments -2;;Experiments in CP -2;;Experiment conclusion -2;;Parameter-free mining?;;Experiments convex hull;;Constraint programming for Itemset Mining -1;;Unrelated work;;Constraint programming for Itemset Mining -2;;Constraint programming for Itemset Mining -3;;Constraint programming for Itemset Mining -4;;Challenges;;Bigger picture;;Questions?'
10118,'interview','en',9818,'2009-10-02','2009-12-03','IFA for the Diagnosis of a Railway Infrastructure Device in a Semi-Supervised Learning',NULL,NULL
10729,'lecture','sl',10658,'2009-06-30','2009-12-01','Iz kakšnega testa so slovenski junaki','»Moje oči niso mrtev aparat; moje oči so pokoren organ moje duše – moje duše in njene lepote, njenega\nsočutja, njene ljubezni in njenega sovraštva ...« (Ivan Cankar, Človek, Vinjete, 1899.)\n\nPreštevanje telesnih delov v slovenski literaturi je razkrilo, da imajo največjo frekvenco leksemi roka, oko, glava, obraz,\nsrce. Pri poeziji so rangirani v zaporedju srce > roka > oko, pri prozi pa roka > oko > glava/obraz. Vsak avtor ima\nspecifično kombinacijo telesnih delov, kar bi lahko uporabili pri prepoznavanju avtorstva. Do neke mere so preference\npogojene tudi s spolom avtorja: pri moških je več obraza, pri ženskah pa več srca. Znotraj posameznega avtorskega opusa\nrazpored telesnih delov variira glede na žanr. Pri sodobnih avtorjih se na nižjih stopnicah lestvice pogostnosti namesto srca\nzačne pojavljati telo. Telesni izrazi so pogosto deli fraz, kadar pa se nanašajo na konkretne literarne osebe, so pogosto posrednik\nnjihovih čustev in misli oz. »izraz duše«.',NULL
10730,'lecture','sl',10658,'2009-06-30','2009-12-01',' Telo v slovenskih besedilih skozi tisočletje: od solznega telesa v Brižinskih spomenikih do Levstikove telovadbe','Predmet obravnave bo izrazna, slogovna in pomenska raznolikost, terminološka, frazeološka raba ter sopomenske zamenjave pojmovne skupine telesa in njegovih delov pri ljudeh in živalih v tisočletnem pisnem izročilu od Brižinskih spomenikov\n(972–1039), v različnih izbranih neumetnostnih besedilnih vrstah (predvsem v nabožni literaturi, prisegah, poljudnostrokovnih\nbesedilih, slovarskih delih), do konca 19. stoletja, ko dobimo tudi svojo telovadno terminologijo pod vplivom češke in je v\nSlovensko-nemški slovar (1894–1895) zajet največji izbor (okoli 30) tvorjenk s podstavo telo.',NULL
10731,'lecture','sl',10658,'2009-07-01','2009-12-01','Družbene podobe telesa v jeziku: lingvistično-medicinska razprava o metaforah in raku','Povezava med jezikom in delovanjem našega telesa je večja, kot se zdi. Večina vzročno-posledičnih povezav, ki jih\nizražamo z medicinskimi metaforami, ima tudi znanstveno razlago. Čeprav so metafore literarna izrazna sredstva, so pogoste\ntudi v medicini. Medicinske metafore izhajajo iz lastnosti človeškega telesa, saj svoje telo najbolj poznamo in ga\nnajbolj čutimo, pogoste pa so tudi v vsakdanjem govoru, in sicer ne samo ko govorimo o bolezni in zdravju. Razumevanje\npomena simboličnega izražanja lahko pomaga bolnikom soočati se z boleznijo, kot je rak, in jih osvoboditi stereotipov,\nkrivde in stigme, ki jo spremljajo.',NULL
10732,'lecture','sl',10658,'2009-07-01','2009-12-01','Podobe telesa kot podobe človeka – vprašanja identitete     (Telo v novejši slovenski avdiovizualni kulturi)','Članek kritično analizira najbolj izrazite primere obravnave razmerij človeka, podobe in telesa v novejši slovenski avdiovizualni\nkulturi, od anonimnih oglasov, fotografij Mirjane Rukavina, filma Kruh in mleko Jana Cvitkoviča, kratkih filmov Karpa\nGodine in glasbenih videov skupine Borghesia. Dela postavi v dialog s tezo o novi figuri človeškega filozofa Giorgia\nAgambena in zgodovinske spremenljivosti podobe človeka antropologa Hansa Beltinga.',NULL
10733,'lecture','sl',10658,'2009-07-02','2009-12-01','Semiotično in fenomenalno telo slovenskega gledališča','Prispevek se na podlagi raziskav Amelie Jones in Erike Fischer-Lichte ter ob izbranih primerih iz novejše zgodovine\ngledališča in uprizoritvenih praks (Dušan Jovanović, Bojan Jablanovec, Matjaž Zupančič in Sarah Kane) posveča razmišljanju\no telesu, ki se je tudi v slovenskem prostoru po performativnem obratu v šestdesetih letih 20 stoletja vzpostavilo kot\neden bistvenih dejavnikov sodobnega gledališča. Vzporedno s številnimi odmiki od dramskega k nedramskemu, neliterarnemu,\npostdramskemu se je odvila tudi serija preobratov k fizičnemu, k telesu scene in telesu na sceni. Vzpostavila se\nje posebna politika uprizarjanja, značilna za performativno kulturo, v kateri eno središčnih vlog igra prav živo telo na sceni\nin v avditoriju, razumljeno skozi posebno razmerje med sosubjekti, igralci in gledalci, ki si včasih celo izmenjajo vloge.',NULL
10734,'lecture','sl',10658,'2009-07-03','2009-12-01','Začutimo Slovenijo: Celodnevna ekskurzija na Kras in Obalo','Primorska je pokrajina v zahodnem delu Slovenije. Razprostira se od visokega Kaninskega pogorja na severu pa vse\ndo morja na jugu in je edina slovenska pokrajina, ki ima morje in gore, vinograde, gozdove in kraške jame. Primorska daje\nSloveniji sredozemski značaj in veljavo sredozemske države. Zaznamuje jo »terra rosa« ali rdeča zemlja, na kateri odlično\nuspeva vinska trta, primorski fenomen je tudi sunkovit veter, ki se imenuje burja, ter pokrajina Kras s slikovitimi vasicami in\nskrivnostnim podzemljem. Ob morju so biseri Piran, Izola, Koper in modernejši Portorož. Ozke uličice in mogočne cerkve\nso ujete med morje in kopno. Tukaj srečamo svet v malem, saj se v tem delu Slovenije radi ustavljajo popotniki z vseh koncev\nsveta.',NULL
10735,'lecture','sl',10658,'2009-07-06','2009-12-01','Hrana in žretje kot oblika razčlovečenja v slovenski dramatiki','Človek ne obstaja brez telesa, telo pa ne preživi brez hrane. Hrana ima poleg funkcije zadovoljevanja primarnih\nčlovekovih potreb v vsaki družbi in kulturi tudi številne simbolne pomene, gladovna stavka je znak političnega protesta, post\nočiščenja, tolaženje s hrano je znak čustvene stiske … Če je bil za pretekla obdobja značilen človekov strah pred lakoto,\nje za sodobnega strah pred požrešnostjo. V prispevku analiziramo različne pomene hrane/hranjena/žretja v treh slovenskih\ndramskih besedilih, to so Dogodek v mestu Gogi Slavka Gruma, Ljudožerci Gregorja Strniše in Žrelo Žanine Mirčevske.',NULL
10736,'lecture','sl',10658,'2009-07-06','2009-12-01','Motiv telesa v kratki sodobni pravljici Svetlane Makarovič','Za sodobno mladinsko književnost po letu 1970 je najbolj reprezentativna avtorica Svetlana Makarovič, ki v kratkih\nsodobnih pravljicah uporablja motiv personificiranega (Sapramiška), antropomorfiziranega (Pek Mišma) in zoomorfnega\n(Gospa Jazbečka) telesa. Uporablja različne motive telesa, npr. izmišljeno telo (Kosovirja, Ščeper, Mba), ki se upira konformizmu\nnajprej z videzom (Pasji in mačji), potem z drugačnostjo (Veveriček posebne sorte) ter na koncu s pluralizmom in\nstrpnostjo do različnih identitet (Ščeper in Mba). Avtorica posredno sporoča preko motiva telesa in telesnih tekočin, predvsem\nsolz (debele, grenke, pekoče; mačje, mišje, zajčkove). Le-te imajo funkcijo čarobnega rekvizita v kombinaciji z luninim\nžarkom (Lisjaček v Luninem gozdu), s čimer obravnava tematiko čustvenega opismenjevanja. Njene osebe izražajo\nnegativna čustva (Jedrt) in imajo težave pri izražanju pozitivnih čustev (Ščeper in Mba), kar avtorica prikazuje tenkočutno.',NULL
10737,'lecture','sl',10658,'2009-07-10','2009-12-01','Telo in čustva v slovenskih jezikovnih metaforah z vidika kognitivnega jezikoslovja','V prispevku je na osnovi slovenskega jezikovnega gradiva predstavljena t. i. ljudska, torej neznanstvena razlaga telesa\nin telesnega doživljanja čustev. Tekst obravnava tudi dojemanje telesa in čustev v nezahodnih kulturah, ki je predstavljeno v\njezikoslovnih in antropoloških razpravah ter primerjano s slovenskim oz. evropskim. Kljub temu da ljudje razpolagamo s približno\nenakimi telesi, o svojih čustvenih izkušnjah od kulture do kulture mislimo in govorimo z uporabo drugačnih metafor.',NULL
10738,'lecture','sl',10658,'2009-07-07','2009-12-01','Pomensko polje telo v slovenskih narečjih','V prispevku je predstavljeno narečno besedje, povezano s pomenskim poljem človeško telo, zbrano za Slovenski\nlingvistični atlas (SLA), katerega prvi zvezek se pripravlja na Inštitutu za slovenski jezik Frana Ramovša. Prikazana je\nproblematičnost in spremenljivost vprašalnice za SLA ter raznolikost gradiva, ki je bilo v zadnjih šestdesetih letih zbrano\nza ta projekt. Metoda jezikoslovne razčlembe gradiva in njegovega prikaza na jezikovni karti je ponazorjena z gradivom\nza vprašanje SLA V038 zanohtnica.',NULL
10739,'lecture','sl',10658,'2009-07-08','2009-12-01','Telo v slovenski likovni umetnosti','Likovna umetnost je v veliki meri umetnost telesa, saj so njeno poslanstvo podobe, ki jih najpogosteje zaznamuje prav\ntelo kot predmet ogledovanja in telo gledalca kot prostor ogledovanja. V slovenski likovni umetnosti (fotografija, kiparstvo\nin slikarstvo) se golo telo intenzivneje pojavlja šele v 20. stoletju. Podobe teles pri fotografih Avgustu Bertholdu, Marjanu\nPfeiferju, Miroslavu Zdovcu in Božidarju Dolencu so oblikovane kot valovanje linij in svetlo temnih niansiranj. V nasprotju s\nfotografijo se zdi kiparski medij pri likovnem obravnavanju telesa vizualno zahtevnejši. Kiparji Dragica Čadež, Polona\nDemšar, Drago Vit Rozman in Damijan Kracina ohranjajo voluminoznost teles in dodajajo velik pomen ambientalni vizualni\nmoči skulptur oziroma vmesnemu prostoru med figuro in njeno navidezno širitvijo v prostor. Slikarja Gorazd Satler in Samo\nsta ustvarila krčevite in ekspresivne telesne podobe. V razpotegnjenih, hitrih in stiliziranih potezah je črta nosilec vizualnega\nizraza in poudarjene dramatičnosti.',NULL
10740,'lecture','sl',10658,'2009-07-08','2009-12-01','Telo sodobnega plesa in njegov glas','Če telo sodobnega plesa analiziramo v razmerju do glasu, potem opazimo, da sodobni ples prekine prav s konvencijo\nmolčečega telesa, ki pleše tiho in brez glasu. Plesno telo 20. stoletja odkrije svoj notranji glas. Ta ni povezan samo s\ntem, da plesno telo spregovori, pač pa predvsem z avtonomnostjo plešočega telesa, z razbitjem estetske hierarhije gibanja\nin moči jezika nad telesom. Avtorica odkritje glasu poveže s primeri iz slovenskega sodobnega plesa.',NULL
10741,'lecture','sl',10658,'2009-07-09','2009-12-01','Podobe telesa v sedanji slovenski poeziji','Članek analizira in interpretira podobe telesa v izbranih pesniških zbirkah preteklega leta. Sedanjo slovensko poezijo\nustvarjajo izobraženi svetovljani, zato tudi pomen telesa vzpostavljajo na ozadju poljudnih strokovnih govoric in kodov drugih\numetnosti. V zapletenem pesniškem jeziku je mogoče razbrati konfliktno razmerje med posameznikovim samodoživljanjem,\nintimno izkušnjo in medijsko posredovanimi politično-propagandnimi sporočili, ki vso človeško resničnost reducirajo na\nnekaj družbeno koristnih funkcij. V etično in čustveno motiviranem vrednotenju, ironiji, groteski in potujitvi se razkrajajo fantazme:\nnamesto zapovedanega ideala o srečnem, zdravem, lepem, mladem telesu pesniki izpostavljajo bolečino razsute,\nizgubljene, samoodtujene, stigmatizirane, marginalizirane osebe, ki se bori za občutenje resničnosti lastnega bivanja.',NULL
10742,'lecture','sl',10658,'2009-07-09','2009-12-01','Zakaj je voditeljica v trenerki čisto druga oziroma ali (oblečeno) telo naredi čefurja?','V romanu Čefurji raus! (2008) Gorana Vojnovića (1980), ki tematizira življenje in položaj Neslovencev v slovenskem\nokolju, lahko telo opazujemo kot materialno in kot simbolično dejstvo; hkrati je povezano s tistim, kar fizično preživlja, s tistim,\nkar (in kako) govori, in s tistim, kar ima oblečeno in kako to nosi. To omogoča dinamiko, ki na osnovni, besedilni ravni\nvpisuje napetost med materialnim telesom in oblečenim telesom kot znakom ter telo ločuje na njegovo performativno in referenčno\nfunkcijo. Gre za prevladujoče vrednotenje človeka glede na to, kaj ima na sebi; kot so za čefurje stereotipno\nznačilna določena oblačila in modni dodatki, je za večinsko populacijo stereotipno značilna oblačilna urejenost. Po tem\n»načelu« je zasnovano presojanje in tako se ilustrirajo in konstruirajo diskurzi.',NULL
10743,'lecture','sl',10658,'2009-07-10','2009-12-01','Telo in strah pred nastopom','Strah pred nastopom je za mnoge javne govorce neprijeten, neizogiben mozaik čustvenih stanj, ki se začnejo z\nnaraščajočo tesnobo, nadaljujejo s histerijo izpostavitve, ko nadledvična žleza izbruha peklensko mešanico hormonov in\nki se marsikdaj končajo tragično, saj izpostavljeni govorec doživljenjsko trpi za sindromom popolnega zloma pred številnim\nobčinstvom. Pričujoči spis raziskuje vrste strahov, simptome, ki jih spremljajo, in zdravila, ki so na voljo za samoobvladovanje.\nRavno govorica telesa pa je za strahove in druge težave pri govorjenju in nastopanju najbolj ranljiva.',NULL
10783,'opening','en',10187,'2009-10-29','2009-11-24','Welcome and Introduction by Organizer and Partners',NULL,'ecitl09_schumacher_micelli_mazzarino_wio_01;;ecitl09_schumacher_micelli_mazzarino_wio_01'
10784,'lecture','en',10187,'2009-10-29','2009-11-24','Leveraging New Technologies for Process Flexibility in Logistics Service Providers',NULL,'Leveraging New Technologies for Process Flexibility in Logistics Service Providers;;The Management Model: A Prerequisite for Understanding;;The Problem;;Presentation Objectives;;Why is this Topic Important;;ecitl09_gulledge_lnt_01_Page_06;;Typical Enterprise Objectives(Using Product Lifecycle Management as an Example);;Other Examples of Business Process Oriented Solutions;;Composite Applications(Automating the Management Model);;Composite Applications;;The Composite Application Concept;;SystemsComposite Application Example: Unserviceable Reparable Processing;;Business Process Management;;Business and Technical BPM;;Joint Ownership of Requirements is Most Effective;;Total Business Process Integration (1);;Total Business Process Integration (2);;Vendor Responses;;ArchitecturesThe Vendors Converge on the Same Architecture;;ecitl09_gulledge_lnt_01_Page_20;;ecitl09_gulledge_lnt_01_Page_21;;ecitl09_gulledge_lnt_01_Page_22;;ecitl09_gulledge_lnt_01_Page_23;;ecitl09_gulledge_lnt_01_Page_24;;ecitl09_gulledge_lnt_01_Page_25;;ecitl09_gulledge_lnt_01_Page_26;;ecitl09_gulledge_lnt_01_Page_27;;Benefits of Architecture-driven SOA;;Conclusions;;ecitl09_gulledge_lnt_01_Page_30;;ecitl09_gulledge_lnt_01_Page_31;;ecitl09_gulledge_lnt_01_Page_32;;ecitl09_gulledge_lnt_01_Page_33;;ecitl09_gulledge_lnt_01_Page_34;;ecitl09_gulledge_lnt_01_Page_35;;ecitl09_gulledge_lnt_01_Page_36;;ecitl09_gulledge_lnt_01_Page_37;;ecitl09_gulledge_lnt_01_Page_38;;ecitl09_gulledge_lnt_01_Page_39;;ecitl09_gulledge_lnt_01_Page_40;;ecitl09_gulledge_lnt_01_Page_41;;ecitl09_gulledge_lnt_01_Page_42;;ecitl09_gulledge_lnt_01_Page_43;;ecitl09_gulledge_lnt_01_Page_44;;ecitl09_gulledge_lnt_01_Page_45;;ecitl09_gulledge_lnt_01_Page_46'
10785,'lecture','en',10187,'2009-10-29','2009-11-24','ICT - An Enabler for Efficient and Sustainable Transport Logistics',NULL,NULL
10786,'lecture','en',10187,'2009-10-29','2009-11-24','ICT Research to Support Freight and Logistics',NULL,'ICT research to support freight and logistics;;The political agenda for Europe;;Working in a globalised economy;;Working for a sustainable planet;;Can ICT help bridge the gap towards sustainable logistics ?;;How can ICT help with the greening of logistics?;;Eco-driving assistance;;Dynamic routing and route guidance;;Infrastructure access management;;Intelligent cargo;;Seamless and secure logistics;;Industry initiatives;;Synchronising joint and industrial research;;Thank you for your kind attention'
10787,'lecture','en',10187,'2009-10-29','2009-11-24','The Intelligent Cargo Concept in the European Project EURIDICE',NULL,'The Intelligent Cargo Concept in the European Project EURIDICE;;Content;;The logistics industry;;ICT for goods mobility today: Cutting-edge technologies for top demanding customers;;What services are needed by the majority of logistic users and operators?;;EURIDICE Intelligent Cargo vision;;From vision to adoption:Finding our own “elevator speech”;;1. The product;;The customers: Who cares about the cargo being intelligent? Who is target of our value proposition?;;ecitl09_paganelli_ic_01_Page_10;;2. The customers;;3. The benefits;;Disruptive innovation strategy:Aim at the largest pool of users remove barriers;;The EURIDICE message;;ICT for goods mobility tomorrow;;What does “Intelligent Cargo” mean?;;Intelligent vs. “dumb” cargo, basic capabilities;;Intelligent vs. “dumb” cargo, specialized capabilities ;;Intelligent Cargo in practice;;Expected paradigm shift;;Thing-to-thing vs. organization-to-organization;;Event-triggered, decentralized decisions support;;Pilot Scenarios;;Example: Scenario S1 Connected manufacturing and transport execution;;Example: Scenario S7 Intelligent routing through cargo-infrastructure cooperation;;Thank you for your attention'
10788,'lecture','en',10187,'2009-10-29','2009-11-24','Frameworks and Applications for Logistics ',NULL,'Frameworks & Applications for Logistics;;ecitl09_pedersen_fal_01_Page_02;;ecitl09_pedersen_fal_01_Page_03;;ecitl09_pedersen_fal_01_Page_04;;ecitl09_pedersen_fal_01_Page_05;;ecitl09_pedersen_fal_01_Page_06;;ecitl09_pedersen_fal_01_Page_07;;Implications;;Terminology Confusion;;ecitl09_pedersen_fal_01_Page_10;;ecitl09_pedersen_fal_01_Page_11;;Reference Model;;ecitl09_pedersen_fal_01_Page_13;;Efficient Cooperation Between Roles;;ecitl09_pedersen_fal_01_Page_15;;ecitl09_pedersen_fal_01_Page_16;;ecitl09_pedersen_fal_01_Page_17;;ecitl09_pedersen_fal_01_Page_18;;ecitl09_pedersen_fal_01_Page_19;;Planning;;ecitl09_pedersen_fal_01_Page_21;;ecitl09_pedersen_fal_01_Page_22;;ecitl09_pedersen_fal_01_Page_23;;ecitl09_pedersen_fal_01_Page_24;;RFID;;RFID Types;;ecitl09_pedersen_fal_01_Page_27;;ecitl09_pedersen_fal_01_Page_28;;ecitl09_pedersen_fal_01_Page_29;;ecitl09_pedersen_fal_01_Page_30;;Transport Execution Plan -TEP;;Goods Item Itinerary;;ecitl09_pedersen_fal_01_Page_33;;ecitl09_pedersen_fal_01_Page_34;;Goods Item Itinerary;;ecitl09_pedersen_fal_01_Page_36;;ecitl09_pedersen_fal_01_Page_37;;ecitl09_pedersen_fal_01_Page_38;;ecitl09_pedersen_fal_01_Page_39;;ecitl09_pedersen_fal_01_Page_40;;ecitl09_pedersen_fal_01_Page_41;;ecitl09_pedersen_fal_01_Page_42;;ecitl09_pedersen_fal_01_Page_43;;ecitl09_pedersen_fal_01_Page_44;;ecitl09_pedersen_fal_01_Page_45;;ecitl09_pedersen_fal_01_Page_46;;INTTRA –Representing UN EDIFACT Investments;;ecitl09_pedersen_fal_01_Page_48;;ecitl09_pedersen_fal_01_Page_49;;ecitl09_pedersen_fal_01_Page_50'
10789,'debate','en',10187,'2009-10-29','2009-11-24','Panel Discussion: Challenges Met in the Logistic Sector',NULL,'CHALLENGES MET IN THE LOGISTIC SECTOR;;The evolution of supply chains;;Supply Chain Visibility Definition ;;Supply Chain Visibility Empirical evidence (1);;Supply Chain Visibility Empirical evidence (2);;Supply Chain Visibility Questions / Open issues;;Supply Chain Integration and Collaboration Definition ;;Supply Chain Integration and Collaboration Empirical evidence (1);;Supply Chain Integration and Collaboration Empirical evidence (2);;Supply Chain Integration and Collaboration Empirical evidence (3);;Supply Chain Integration and Collaboration Questions / Open issues;;Wireless Supply Chain Definition ;;Wireless Supply Chain Empirical evidence (1);;Wireless Supply Chain Empirical evidence (2);;Wireless Supply Chain Questions / Open issues;;Panel discussion;;Questions / Open issues ;;ecitl09_perego_cml_01_Page_18'
10790,'lecture','en',10187,'2009-10-29','2009-11-24','Hardware and Related Software Technologies (Track and Trace, Monitoring, Data Aquisition)',NULL,'Technologies for T&T Solutions;;Summary ;;Components of a T&T Solution;;Automatic Identification;;Geographic Localization;;Communication;;Software;;Environmental Monitoring;;LocalIntellingence;;Container Total Control;;A complete view;;Case Histories: Driver + Trailer Tracking;;Case Histories–DHL (1) Smart Sensor;;Case Histories–DHL (2) Smart Truck;;Case Histories–Zenatek(1);;Case Histories–Zenatek(2);;Case Histories–Zenatek(3);;Case Histories–Zenatek(4)'
10791,'lecture','en',10187,'2009-10-29','2009-11-24','Frameworks for a Cargo Centric Approach',NULL,'Frameworks for a Cargo Centric Approach;;The basis for the work presented here;;Intermodality –why is it so hard?;;eFreight;;Requirements to a framework;;SMARTFREIGHT and Freightwise;;Framework content;;Reference Model (1);;Reference Model (2);;Reference Model (3);;Functional view;;Conclusions;;More information?'
10792,'lecture','en',10187,'2009-10-29','2009-11-24','The Unexploited Potential of Savings in the European Road Transport Industry',NULL,'Unexploited Savings Potential;;Cost Savings Potential;;1st „Victims“ of traditional „cost-cutting“: Stakeholders & Intelligence;;Real Cost Savings Potential;;Streamlining of Workflows, save 10-30%;;Train and reward your drivers, safe 15-30%;;Optimise your Sub-Contractors, save 10-20%;;Eliminate Errors by creating Transparancy;;How to proceed;;How can AIS help? (1);;How can AIS help? (2)'
10793,'lecture','en',10187,'2009-10-29','2009-11-24','Impact of Current and Future Technologies – Visions Beyond Existing',NULL,'intelligent cargo - The next revolution in logistics;;Past logistical revolutions (1);;Past logistical revolutions (2);;Past logistical revolutions;;Challenges;;Open Tracking and Tracing (1);;Open Tracking and Tracing (2);;From location-centric to product-centric systems;;Product flow-centric vs. Enterprise-centric systems;;Events&Queries include;;Upload;;Querying;;Challenge: Manage Semantics;;Semantical handshake;;Unit types may have properties;;Definition of new unit types by constraining properties;;Unit types have properties;;Definition by constraints;;Model driven application development;;The need for open T&T'
10794,'lecture','en',10187,'2009-10-30','2009-11-24','Results of the KOMODA Delphi Survey on e-Logistics',NULL,'E-Logistics Systems, Aplications, Functionalities and Awareness;;Objectives;;Methodology;;Why Delphi Study;;KOMODA Delphi Process;;Delphi studies response profile;;ecitl09_zunder_rkd_01_Page_07;;Definition;;Full agreement of Delphi panel;;Applicabilility of the definition of e Logistics;;Poor understanding;;Key Findings (1);;Key Findings (2);;Key Findings (3);;Thank You'
10796,'lecture','en',10187,'2009-10-30','2009-11-24','Impact Assessment Study on Intelligent Cargo',NULL,'Impact assessment studyon Intelligent Cargo;;Motivation (I);;Motivation (II);;Impact assessment study;;Intelligent Cargo;;Intelligent Cargo related projects (35);;Interviews (I);;Interviews (II);;Scenario building;;Realistic Scenario (RS);;Visionary Scenario (VS);;Assessment of impacts –Process;;Assessment of impacts – Results;;Target name;;INTERCARGONET migration path (I);;INTERCARGONET migration path (II);;INTERCARGONET migration path (III);;Conclusions;;Thank you !'
10801,'debate','en',10187,'2009-10-30','2009-11-24','Wrap Up of Parallel Sessions',NULL,NULL
10983,'best paper','sl',9976,'2009-10-01','2009-12-07','Podelitev priznanj dijakom / Awards',NULL,NULL
11099,'lecture','en',8831,'2009-06-22','2009-12-15','Furniture scenario - Delocalisation with production networks to countries with cheaper human efforts, or skill competencies',NULL,'Furniture scenario Delocalisation with production networks to countries with cheaper human efforts, or skill competencies;;Scenario;;Challenges for the scenario - 1;;Challenges for the scenario - 2;;Challenges for the scenario - 3;;Challenges for the scenario - 4;;Challenges for the scenario - 5;;Challenges for the scenario - 6;;Standards and the scenario - 1;;Standards and the scenario - 2;;Benefits;;Challenge - 1;;Challenge - 2;;Standards Implementation;;Using.... Model Morphisms;;And… MDA Methodology;;Transformation Framework;;Express2XMI mapping;;Express2Schematron;;Model Driven Approach;;Framework instantiation;;DWG to X3D Morphism (example);;Integration with industrial e-commerce tool;;Thankyou'
11141,'invited talk','en',11062,'2009-12-08','2010-01-25','Relative Entropy','An overview of relative entropy (aka Kulback-Leibler divergence, etc.) and its multiple appearances in information theory, probability, and statistics, including recent results by the speaker.','relative entropy;;definition;;alternative representation;;discrete case;;continuous case;;units - 1;;units - 2;;D(P//Q);;first appearance;;D(P//Q)+D(Q//P);;first definition - 1;;first definition - 2;;mutual information;;entropy;;conditional relative entropy;;mutual information - 1;;mutual information - 2;;gibbs inequality - 1;;gibbs inequality - 2;;processing reduces D(P//Q);;conditioning increases D(P//Q);;chain rule;;first definition;;differential entropy - 1;;differential entropy - 2;;differential entropy - 3;;differential entropy - 4;;nongaussianness;;maximum entropy: rationale;;monotonic decrease of nongaussianness;;memory;;variational representation;;parallelogram law;;pythagoras;;D(P//Q);;large deviations;;law of large numbers;;lossless data compression;;channel capacity;;estimation;;mmse estimation;;mmse estimator in AWGN - 1;;mmse estimator in AWGN - 2;;mmse estimator in AWGN - 3;;mmse notation;;mismatched estimation;;mismatched estimation: example: Q Gaussian;;relative entropy and mmse;;P=N(0,2) Q=N(0,0.1);;nips09_verdu_re_01_Page_50;;nips09_verdu_re_01_Page_51;;nips09_verdu_re_01_Page_52'
11142,'invited talk','en',11062,'2009-12-08','2010-01-20','Deep Learning with Multiplicative Interactions','Deep networks can be learned efficiently from unlabeled data. The layers of representation are learned one at a time using a simple learning module that has only one layer of latent variables. The values of the latent variables of one module form the data for training the next module. The most commonly used modules are Restricted Boltzmann Machines or autoencoders with a sparsity penalty on the hidden activities. Although deep networks have been quite successful for tasks such as object recognition, information retrieval, and modeling motion capture data, the simple learning modules do not have multiplicative interactions which are very useful for some types of data. The talk will show how a third-order energy function can be factorized to yield a simple learning module that retains advantageous properties of a Restricted Boltzmann Machine such as very simple exact inference and a very simple learning rule based on pair-wise statistics. The new module contains multiplicative interactions that are useful for a variety of unsupervised learning tasks. Researchers at the University of Toronto have been using this type of module to extract oriented energy from image patches and dense flow fields from image sequences. The new module can also be used to allow the style of a motion to blend auto regressive models of motion capture data. Finally, the new module can be used to combine an eye-position with a feature-vector to allow a system that has a variable resolution retina to integrate information about shape over many fixations.','Deep learning with multiplicative interactions;;Overview;;Restricted Boltzmann Machines;;The Energy of a joint configuration(ignoring terms to do with biases);;Using energies to define probabilities;;A picture of the maximum likelihood learning algorithm for an RBM ;;A quick way to learn an RBM;;Training a deep network(the main reason RBM’s are interesting);;Fine-tuning for discrimination;;Why unsupervised pre-training makes sense;;A neat application of deep learning;;One very deep belief net for phone recognition;;A simple real-valued visible unit;;The new idea;;Generating the parts of an object: why multiplicative interactions are useful ;;Generating the parts of an object ;;Towards a more powerful, multi-linear stackable learning module;;Higher order Boltzmann machines (Sejnowski, ~1986);;Using higher-order Boltzmann machines to model image transformations ;;Factoring three-way multiplicative interactions;;A picture of the rank 1 tensor contributed by factor f;;Inference with factored three-way multiplicative interactions;;Belief propagation;;Learning with factored three-way multiplicative interactions;;Showing what a factor learns by alternating between its pre- and post- fields;;The factor receptive fields, 1;;The factor receptive fields, 2;;The factor receptive fields (spirals), 1;;The factor receptive fields (spirals), 2;;How does it perceive two overlaid sparse dot patterns moving in different directions;;Time series models;;The conditional RBM model (a partially observed bipartite CRF);;Causal generation from a learned model;;Higher level models;;An application to modeling motion capture data;;Using a style variable to modulate the interactions   ;;Show demo’s of multiple styles of walking;;Modeling the covariance structure of a static image by using two copies of the image;;An advantage of modeling covariances between pixels rather than pixels;;Using linear filters to model the inverse covariance matrix of two pixel intensities;;Modulating the precision matrix by using additive contributions that can be switched off;;Using binary hidden units to remove violated smoothness constraints;;Inference with hidden units that represent active smoothness constraints;;Learning with an adaptive precision matrix;;Hybrid Monte Carlo;;mcRBM (mean and covariance RBM;;Receptive fields of the hidden units , 16x16;;Receptive fields of the hidden units, color blob;;Why is the map topographic?;;Multiple reconstructions from the same hidden state of a mcRBM;;Test examples from the CIFAR-10 dataset;;Application to the CIFAR-10 labeled subset of the TINY images dataset (Marc’Aurelio Ranzato);;How well does it discriminate?;;Percent correct on CIFAR-10 test data;;Summary;;THE END, Questions;;nips09_hinton_dlmi_01_Page_57;;nips09_hinton_dlmi_01_Page_58;;nips09_hinton_dlmi_01_Page_59;;nips09_hinton_dlmi_01_Page_60'
11143,'invited talk','en',11062,'2009-12-09','2010-01-19','The Rat Vibrissal Array as a Model Sensorimotor System','The rat whisker (vibrissal) system has neural processing pathways that are analogous to human tactile pathways through the spinal cord. Rats use rhythmic (5-25 Hz) movements of their whiskers to actually extract object features, including size, shape, orientation, and texture. In this talk, I will describe our efforts to characterize whisker mechanical properties and to determine the set of mechanical variables that could potentially be sensed by the rat. We have also developed a hardware array of artificial whiskers that makes use of these variables to successfully extract 3-dimensional object features. On the behavioral side, we have developed a laser light sheet to visualize whisker-object contact patterns during natural exploratory behavior and have used this technique to examine the relative roles of head and whisker movements in generating patterns of mechanosensory input across the array during natural exploratory sequences. Finally, we are developing a simulation environment that integrates our knowledge of whisker mechanics with our knowledge of head and whisker motion to enable the user to model the rat\'s interactions with various objects in the environment. Our goal is to predict the contact patterns – and resulting forces and moments – at each whisker base for a given exploratory sequence, and then to predict the resulting responses of trigeminal ganglion neurons.','The Rat Vibrissal Array as a Model Sensorimotor System;;SEnsory and Neural Systems Engineering;;Outline;;Sensory Perception;;Similarities between sensory pathways, Somatosensation;;Similarities between sensory pathways, Audition;;Similarities between sensory pathways, Vision;;SeNSE Laboratory: Active Sensing;;What is a “Model System?”;;Rats are “champions” at active touch;;Rats are “champions” at active touch (Missing video example);;Model System: the Rat Vibrissal Array;;The Vibrissal Array ;;Actuators and Sensors;;Rats as a “Model System” for Active Touch;;Outline, 2. Biomechanical experiments (quasi-static);;Sensory Coding;;Two approaches to studying whiskers;;Sensory Coding;;Passive vs. Active Whisker Movements;;Coordinates for 3-D feature extraction (1);; Coordinates for 3-D feature extraction (2);;Possible Mechanism for Radial Distance Extraction ;;A Simple Whisker Array (1);;A Simple Whisker Array (2);;Problem with the Array: Lateral Slip;;Problem of Unknown Friction;;Artificial Follicle;;Feature Extraction with 2D “Whisking”;;Sampling at different orientations (1);;Sampling at different orientations (2);;Whisker Sweep to Extract Contours (1);;Whisker Sweep to Extract Contours (2);;Numerical model to calculate components of moment;;Experimental Validation;;Experimental Validation (NOT simulation);;Tapping vs. Sweepin;;A “Koosh Ball” of whiskers for 3D feature extraction (1);;A “Koosh Ball” of whiskers for 3D feature extraction (2);;Summary and Some Predictions;;Sensory Coding;;Summary and Some Predictions;;State-Encoding Prediction;;Advantages of the state representation;;Re-analysis of data from Jones et al., Science, 2004;;State Encoding of Neural Data;;Outline, 3. New techniques to quantify behavior;;Laser Light Sheet;;(missing video example);;The image processing “Chute”;;Tracking the Eyes;;A battle not fought: Auto tracking the nose;;Measuring head movements in 3D;;Tracking Whiskers;;Identifying Whiskers;;The image processing “Chute”;;Preliminary Results;;Distribution of Head Orientations;;Spatiotemporal patterns of contact;;The order of contact;;Four different types of row-wise contact and detach sequences, Rostral to Caudal (RC);;Four different types of row-wise contact and detach sequences, Caudal to Rostral (CR);;Four different types of row-wise contact and detach sequences, Unordered (UO);;Four different types of row-wise contact and detach sequences, Simultaneous (SI);;Rats left side (missing video example);;Rats right side (missing video example) (1);;Rats right side (missing video example) (2);;Distribution of contact and detach sequence;;Global contact sequence measurements;;Initial Pattern Classification;;Initial Pattern Classification;;Velocities of whisker contacts;;Caudal whiskers move faster over object than rostral whiskers;;Global velocities: Whiskers within a row sweep along similar trajectories radiating from the nose;;Local velocities: Individual whiskers often move differently than neighbors within the global “slot”;;Local velocities: Individual whiskers travel in same direction as their nearest neighbors less than half of the time;;Summary;;Imposing the contact patterns on a “map of the rat”;;Video of the model rats dinamics and behaviour (missing video);;Video of the actual rat (missing video);;Outline,  4. Towards a full dynamic model of the whisker array;;Accurate Computation of Whisker Dynamics;;Newton-Euler Method to obtain equations of motion;;Example: summing forces using Newton-Euler;;Generalized Coordinates;;Lagrangian Method to obtain equations of motion (1);;Lagrangian Method to obtain equations of motion (2);;Summary so far;;Variational Integrator Approach (1);;Variational Integrator Approach (2);;Variational Integrator Approach (3);;Example of a whisker and a wall;;Example of a dinamic whisker (rat) and a wall (missing video);;First dinamic stimulation of the rat and the wall (missing video);;Future work: GUI to play back simulation and/or behavior;;Future work:  GUI to compare simulation and/or behavior;;Conclusions;;Acknowledgements;;Questions, Acknowledgements: Undergraduates'
11144,'invited talk','en',11062,'2009-12-09','2010-01-19','Learning and Inference in Low-Level Vision','Low level vision addresses the issues of labeling and organizing image pixels according to scene related properties - such as motion, contrast, depth and reﬂectance. I will describe our attempts to understand low-level vision in humans and machines as optimal inference given the statistics of the world. If time permits, I will discuss my favorite NIPS rejected papers.\nYair Weiss is an Associate Professor at the Hebrew University School of Computer Science and Engineering. He received his Ph.D. from MIT working with Ted Adelson on motion analysis and did postdoctoral work at UC Berkeley. Since 2005 he has been a fellow of the Canadian Institute for Advanced Research. With his students and colleagues he has co-authored award winning papers in NIPS (2002),ECCV (2006), UAI (2008) and CVPR (2009).\n\nSlide presentation contains animation videos which can be found at [[http://www.cs.huji.ac.il/~yweiss/movies.tar.gz]].','Learning and Inference in Low Level Vision;;Understanding Low-Level Vision in Human and Machine Perception;;Low-Level vs High Level Vision (missing video example) (1);;Low-Level vs High Level Vision (missing input example) (2);;Low-Level vs High Level Vision (missing picture example) (3);;Low-Level vs High Level Vision (missing input example) (4);;Low-Level vs High Level Vision (missing input example) (5);;Low-Level vs High Level Vision (missing input example) (6);;Outline;;Narrow vs Fat (missing picture);; Satellites (missing picture);; Distant Satellites (missing picture);; Competition (missing picture);;Layers (missing picture);;Motion Perception is ill-posed;;Energy Minimization Surprisingly Predictive;;Energy Minimization Predictions;;Energy Minimization Failures;;Layered Models (Wang and Adelson 93);;Energy Minimization and Layered Models (1);;Energy Minimization and Layered Models (2);;Layered Energy Minimization Models Predict Many Percepts;;Layered Models for Real Sequences ?;;Layered Models for Real Sequences;;Layered Models for Real Sequences;;The Dream part 1;;The Dream part 2;;How to get a Ph.D. in Mathematics (according to my brother) (1);;How to get a Ph.D. in Mathematics (according to my brother) (2);;How to get a Ph.D. in Mathematics (according to my brother) (3);;“Lemmas along the way” (1);;Global Optimization in Stereo Vision;;Stereo by Energy Minimization;;Local Optima in Stereo Vision;;Integer Programming formulation;;Linear Programming relaxation;;Off-the-shelf LP Solver?;;LP using Belief Propagation;;Global Optimality;;LP using Belief Propagation;;Global Optimality With Ties;;Global Optima in Stereo Vision;;“Lemmas along the way” (2);;Learning Energy Functions for Category-Specific Segmentation;;Energy Functions for Category-Specific Segmentation (1);;Energy Functions for Category-Specific Segmentation (2);;Constructing the Data Term (1);;Constructing the Data Term (2);;Constructing the Data Term (3);;Constructing the Data Term (4);;Constructing the Data Term (5);;Constructing the Data Term (6);;Learning Formulation (1);;Learning Formulation (2);;Feature Induction in CRFs;;Calculating Conditional Likelihood Exactly is Intractable;;Bounding log Z using Belief Propagation (1);;Bounding log Z using Belief Propagation (2);;Learning Results;;Test Set Results;;Lemmas along the way” (3);;The Dream ?;;The Dream part 2;;State of the Art (CVPR 2008) (1);;State of the Art (CVPR 2008) (2);;Outline;;Much Emphasis on Pairwise Discrete Energies;;Future Directions - Inference;;Much Emphasis On Train and Test Paradigm;;Future Directions - Learning;;Conclusions'
11145,'invited talk','en',11062,'2009-12-10','2010-01-19','Bayesian Analysis of Markov Chains ','Suppose we observe data and want to test if it comes from a Markov chain. If it does, we may want to estimate the transition operator. Working in a Bayesian way, we have to specify priors and compute posteriors. Interesting things happen if we want to put priors on reversible Markov chains. There are useful connections with reinforced random walk (work with Silke Rolles). On large-scale application to protein folding will be described. More generally, these problems arise in approximating a dynamical system by a Markov chain. For continuous state spaces, the usual conjugate prior analysis breaks down. Thesis work of Wai Liu (Stanford) gives useful families of priors where computations are \"easy.\" These seem to work well in test problems and can be proved consistent.','Bayesian analysis of Markov chains;;Motivation;;Owerview;;Classical Bayesian analysis;;de Fenettis theorem;;Conjugate priors;;I almost forgot;;But, PBLM;;A new story: Radom walk with reenforcement;;Same story for general graph;;Silke Rones;;Mixtures of conjugates;;formulas;;Higher order, reversible Markov chains;;Understanding these priors;;Infinitite graphs'
11147,'tutorial','en',11062,'2009-12-07','2010-01-19','Making Very Large-Scale Linear Algebraic Computations Possible Via Randomization','The demands on software for analyzing data are rapidly increasing as ever larger data sets are generated in medical imaging, in analyzing large networks such as the World Wide Web, in image and video processing, and in a range of other applications. To handle this avalanche of data, any software used must be able to fully exploit modern hardware characterized by multiple processors and capacious but slow memory. The evolution of computer architecture is currently forcing a shift in algorithm design away from the classical algorithms that were designed for single-processor computers with all the data available in Random Access Memory (RAM), towards algorithms that aggressively minimize communication costs. This tutorial will describe a set of recently developed techniques for standard linear algebraic computations (such as computing a partial singular value decomposition of a matrix) that are very well suited for implementation on multi-core or other parallel architectures, and for processing data stored on disk, or streamed. These techniques are based on the use of randomized sampling to reduce the effective dimensionality of the data. Remarkably, randomized sampling does not only loosen communication constraints, but does so while maintaining, or even improving, the accuracy and robustness of existing deterministic techniques.','Randomization: Making Very Large-Scale Linear Algebraic Computations Possible;;Goal;;The new methods -1;;The new methods -2;;The new methods -3;;Applications -1;;Caveats;;Applications -2;;Diffusion Geometry -1;;Diffusion Geometry -2;;Diffusion Geometry -3;;Example;;Picture -1;;Picture -2;;Solving the linear approximation problem;;Problem;;Question -1;;Question -2;;Question -3;;Existing techniques for handling very large matrices;;Goal (restated);;Related work;;Principal researchers on specific work reported;;How do you handle noise in the computation? -1;;How do you handle noise in the computation? -2;;Outline of the tutorial -1;;Review of the SVD;;The decay of the singular values -1;;The decay of the singular values -2;;The SVD;;Model problem -1;;Model problem -2;;Model problem -3;;Model problem -4;;Model problem -5;;Model problem -6;;Model problem -7;;Model problem -8;;Picture -3;;Golub-Businger algorithm;;Randomized method;;Theorem;;Proof;;Preview -1;;Preview -2;;Drawback;;Other randomized sampling strategies have been sugested;;Variations on the basic pattern;;Outline of the tutorial -2;;A single pass algorithm for a symmetric matrix;;A single pass algorithm, continued -1;;A single pass algorithm, continued -2;;Outline of the tutorial -3;;Finding \"spanning columns\" of a matrix -1;;Finding \"spanning columns\" of a matrix -2;;Finding \"spanning columns\" of a matrix -3;;Finding \"spanning columns\" of a matrix -4;;Finding \"spanning columns\" of a matrix -5;;Picture -4;;Picture -5;;Picture -6;;Picture -7;;Picture -8;;Picture -9;;Picture -10;;Picture -11;;Picture -12;;Factorization -1;;Factorization -2;;Clean up in the plethora of algorithms -1;;Clean up in the plethora of algorithms -2;;Clean up in the plethora of algorithms -3;;Stage A;;Outline of the tutorial -4;;We now consider the case where A takes the form:;;Problem, Observation, Remedy;;Primitive problem -1;;Picture -13;;Picture -14;;Primitive problem -2;;Primitive problem -3;;Picture -15;;Note;;Was this just a lucky realization?;;Picture -16;;Picture -17;;Important -1;;Picture -18;;Picture -19;;Let us apply the method to problems whose singular values do not decay rapidly;;Example -1;;Picture -20;;Example -2;;Picture -21;;Errors can be explained in detail by analysis;;Our set-up is:;;Theorem -1;;Theorem -2;;Observation -1;;Observation -2;;What about bounds on tail probabilities? -1;;What about bounds on tail probabilities? -2;;What about bounds on tail probabilities? -3;;Outline of the tutorial -5;;We are faced with a problem;;Algorithm;;Power method for improving accuracy;;Method;;Example -3;;Picture -22;;Example -4;;Picture -23;;Example -5;;Outline of the tutorial -6;;We have outstanding promise to deliver on;;Let us revisit the basic randomized scheme;;Let us change the random matrix ;;What is \"SRFT\"?;;The relative speed of three methods;;Picture -24;;Picture -25;;Notes ;;Other applications of \"structured\" random projections;;Outline of the tutorial -26;;Computing the SVC (or PCA) -1;;Computing the SVC (or PCA) -2;;Computing spanning rows;;Computing spanning rows and columns;;A one-pass algorithm for a symetric matrix;;A one-pass algorithm for a non-symetric matrix;;Miscellaneous remarks;;Connection to \" Johnson-Lindenstrauss theory\";;Bourgain embedding theorem;;The Johnson-Lindenstrauss lemma;;The randomized algorithm;;Observation -1;;Observation -2;;Observation -3;;Important -2;;Final remarks'
11148,'tutorial','en',11062,'2009-12-07','2010-01-19','Understanding Visual Scenes','One remarkable aspect of human vision is the ability to understand the meaning of a novel image or event quickly and effortlessly. Within a single glance, we can comprehend the semantic category of a place, its spatial layout as well as identify many of the objects that compose the scene. Approaching human abilities at scene understanding is a current challenge for computer vision systems. The field of scene understanding is multidisciplinary, involving a growing collection of works in computer vision, machine learning, cognitive psychology, and neuroscience. In this tutorial, we will focus on recent work on computer vision attempting to solve the tasks of scene recognition and classification, visual context representation, object recognition in context, drawing parallelism with work in psychology and neuroscience. Devising systems that solve scene and object recognition in an integrated fashion will lead towards more efficient and robust artificial visual understanding systems.','Understanding Visual Scenes;;Picture example;;Examples of the picture recognition;; Picture recognition: Labeling the objects on the picture;; Picture recognition: Global description of the scene;; Picture recognition: High level description of the scene;; Picture recognition: More structured interpetations of the scene;;Why do we care about recognition?;;The perception of function;;Direct perception;;Scenes, as objects, also have affordances;;The function of the scene;;Open space scene;;Direct perception;;Limitations of Direct Perception (1);;Limitations of Direct Perception (2);;Object detection and recognition, Short overview of current approaches;;Object recognition Is it really so hard? (1);;Object recognition Is it really so hard? (2);;So, let’s make the problem simpler: Block world;;Binford and generalized cylinders, Recognition by components;;Families of recognition algorithms;;The face age;;Face detection;;Haar-like filters and cascades;;Generic objects: Edge based descriptors;;Histograms of oriented gradients (1);;Histograms of oriented gradients (2);;Adding parts (1);;Adding parts (2);;Adding parts (3);;Evaluation of performance;;What object is detector trying to detect? (1);;What object is detector trying to detect? (2);;What object is detector trying to detect? (3);;Some symptoms of standard approaches;;nips09_torralba_uvs_01_Page_037;;Local information (picture example);;nips09_torralba_uvs_01_Page_039;;High resolution (picture example);;Scenes rule over objects;;Scene recognition The gist of the scene;;Mary Potter (1976);;Demo : Rapid image understanding;;Picture 1;;Picture 2;;Picture 3;;Picture 4;;Picture 5;;Picture 6;;Picture 7;;Picture 8;;Picture 9;;(Memorizing);;Memory Test;;Have you seen this picture ? (1);;No (1);;Have you seen this picture ? (2);;No (2);;Have you seen this picture ? (3);;No (3);;Have you seen this picture ? (4);;No (4);;Have you seen this picture ? (5);;Yes (1);;Have you seen this picture ? (6);;No (5);;You have seen these pictures, You were tested with these pictures;;The gist of the scene;;From objects to scenes;;What makes scenes different?, Different objects, different spatial layout;;Different objects, similar spatial layout;;Similar objects, different spatial layout (1);;Similar objects, different spatial layout (2);;Similar objects, and similar spatial layout;;What can be an alternative to objects? ;;Scene emergent features;;Examples of scene emergent features;;Ensemble statistics;;From scenes to objects;;How far can we go without objects?;;Global image descriptors (1);;Global image descriptors (2);;Gist descriptor;;Textons;;Bag of words & spatial pyramid matching;;The 15-scenes benchmark;;Scene recognition;;Large Scale Scene Recognition;;Indoor, Urban, Nature;;Performance with 400 categories;;Training images;;Training images, Correct classifications;;Training images, Correct classifications, Miss-classifications;;Example of three different scenes;;But they are all part of the same picture (1);;But they are all part of the same picture (2);;Scene detection;;Categories or a continuous space?;;Categories or a continuous space? (missing pictures of categories presentation);;Spatial envelope: a continuous space of scenes (1);;Spatial envelope: a continuous space of scenes (2);;Context for object recognition;;Who needs context anyway? We can recognize objects even out of context;;Look‐Alikes by Joan Steiner;;Why is context important?;;Objects and Scenes;;Global precedence;;Scene recognition without object recognition;;An integrated model of Scenes, Objects, and Parts;;Object retrieval: scene features vs. detector;;The layered structure of scenes;;Context driven object detection;;An integrated model of Scenes, Objects, and Parts (1);;An integrated model of Scenes, Objects, and Parts (2);;An integrated model of Scenes, Objects, and Parts (3);;An integrated model of Scenes, Objects, and Parts (4);;A car out of context …;;Modeling object co‐occurrences;; What are the hidden objects 1, 2? ;;What are the hidden objects?;;objects image;;Object model, Context model;;Full joint, Scene model, Approx. joint;;Office, street;;nips09_torralba_uvs_02_Page_09;;Pixel labeling using MRFs;;Object‐Object Relationships (1);;Object‐Object Relationships (2);;Object‐Object Relationships (3);;Object‐Object Relationships (4);;Objects in Context: Contextual Refinement;;Using stuff to find things;;What, where and who? Classifying events by scene and object recognition;;what who where;;Grammars;;Grammars for objects and scenes;;3D scenes;;We are wired for 3D;;We can not shut down 3D perception;;3D drives perception of important object attributes;;Manhattan World;;James Coughlan, lines;;Outliner detection;;Single view metrology;;3d Scene Context (1);;3d Scene Context (2);;Qualitative Results;;3D City Modeling using Cognitive Loops;;3D from pixel values;;Surface Estimation;;Object Support;;Qualitative 3D relationships;;Large databases, Algorithms that rely on millions of images;;Data;;The two extremes of learning;;Input image, Nearest neighbors;;The power of large collections;;Image completion;;im2gps;;im2gps , Hays & Efros. CVPR 2008;;Predicting events (1);;Predicting events (2);;Query;;Query, Retrieved video (1);;Query, Retrieved video, Synthesized video (1);;Query, Retrieved video (2);;Query, Synthesized video;;Query, Retrieved video, Synthesized video (2);;Databases and the powers of 10;;DATASETS AND powers of ten;;0 images;;10 0 images;;10 1 images (1);;10 1 images (2);;10 2-4 images;;The faces and cars scale, 10 2-4 images;;The PASCAL Visual Object Classes;;10 2-4 images;;10 5 images (1);;Caltech 101 and 256, 10 5 images;;Lotus Hill Research InsPtute image corpus;;LabelMe, 10 5 images;;Extreme labeling;;The other extreme of extreme labeling;;Creative testing;;Examples;;10 5 images (2);;Things start getting out of hand, 10 6-7 images;;Collecting big datasets, 10 6-7 images;;80.000.000 images, 10 6-7 images;;IMAFENT, 10 6-7 images;;Labeling for money;;1 cent Task: Label one object in this image;;1 cent Task: Label one object in this image;;Why people does this?;;10 6-7 images;;10 8-11 images;;Online companies, 10 8-11 images (1);;Online companies, 10 8-11 images (2);;Canonical Perspective;;3D object categorization;;Canonical Viewpoint, 10 8-11 images (1);;Canonical Viewpoint, 10 8-11 images (2);;10 >11 images;;Future work: Moving to more structureted interpretations of the scene'
11149,'tutorial','en',11062,'2009-12-07','2010-01-19','Model-Based Reinforcement Learning','In model-based reinforcement learning, an agent uses its experience to construct a representation of the control dynamics of its environment. It can then predict the outcome of its actions and make decisions that maximize its learning and task performance. This tutorial will survey work in this area with an emphasis on recent results. Topics will include: Efficient learning in the PAC-MDP formalism, Bayesian reinforcement learning, models and linear function approximation, recent advances in planning.','Model-Based Reinforcement Learning;;Topics;;Start With Game...;;Find The Ball: Elements of RL;;Problem To Solve;;Markov Decision Processes;;Find the Ball: MDP Version;;Families of RL Approaches;;Model-based RL Schematic;;PAC-MDP Reinforcement Learning;;Model-based Can Be PAC-MDP;;Model-driven Exploration;;3 Models for Learning Models;;KWIK-Rmax Proof;;KWIK Learn a Probability;;Other Things to KWIK Learn;;RMAX Speeds Learning;;Generalizing Transitions;;Continuous-state DBN;;World of Objects;;Comparing Taxi Results;;Pitfall!;;Structure Learning in DBNs;;Hidden-Bit Problem;;Hidden-bit Problem via KWIK;;Artificial Stock Example;;Many Learnable Problems;;Beyond Worst Case;;Bayes Optimal Exploration;;Concrete Example (1);;Concrete Example (2);;Representing Posteriors;;Bayes Optimal Plans;;Near Bayes Optimal Behavior;;Bayes Optimal Not PAC-MDP;;Inherent Conflict...;;PAC-MDP with Bayesian Priors;;BOSS: Algorithmic Approach;;BOSS in Structured Maze;;Computation Matters;;“Nesting” RL Approaches;;Function Approximation;;Example: Autonomous Flight;;Tricks and Treats;;Fitted Value Iteration;;UCT: Upper Conf. in Trees;;Linear Models;;Do Kids Explore Models?;;Do People Explore Models?;;Wrap-Up'
11150,'tutorial','en',11062,'2009-12-07','2010-01-19','Sparse Methods for Machine Learning: Theory and Algorithms','Regularization by the L1-norm has attracted a lot of interest in recent years in statistics, machine learning and signal processing. In the context of least-square linear regression, the problem is usually referred to as the Lasso or basis pursuit. Much of the early effort has been dedicated to algorithms to solve the optimization problem efficiently, either through first-order methods, or through homotopy methods that leads to the entire regularization path (i.e., the set of solutions for all values of the regularization parameters) at the cost of a single matrix inversion. A well-known property of the regularization by the L1-norm is the sparsity of the solutions, i.e., it leads to loading vectors with many zeros, and thus performs model selection on top of regularization. Recent works have looked precisely at the model consistency of the Lasso, i.e., if we know that the data were generated from a sparse loading vector, does the Lasso actually recover the sparsity pattern when the number of observations grows? Moreover, how many irrelevant variables could we consider while still being able to infer correctly the relevant ones? The objective of the tutorial is to give a unified overview of the recent contributions of sparse convex methods to machine learning, both in terms of theory and algorithms. The course will be divided in three parts: in the first part, the focus will be on the regular L1-norm and variable selection, introducing key algorithms and key theoretical results. Then, several more structured machine learning problems will be discussed, on vectors (second part) and matrices (third part), such as multi-task learning, sparse principal component analysis, multiple kernel learning and sparse coding.','Sparse methods for machine learning Theory and algorithms;;Supervised learning and regularization;;Regularizations (1);;Regularizations (2);;ℓ2 vs. ℓ1 - Gaussian hare vs. Laplacian tortoise;;Lasso - Two main recent theoretical results (1);;Lasso - Two main recent theoretical results (2);;Going beyond the Lasso (1);;Going beyond the Lasso (2);;Going beyond the Lasso (3);;Going beyond the Lasso (4);;Sparse methods for machine learning, Outline;;Why ℓ1-norm constraints leads to sparsity?;;ℓ1-norm regularization (linear setting);;A review of nonsmooth convex analysis and optimization;;Optimality conditions for smooth optimization Zero gradient (1);;Optimality conditions for smooth optimization Zero gradient (2);;Directional derivatives - convex functions on Rp;;Optimality conditions for convex functions;;Directional derivatives for ℓ1-norm regularization;;Optimality conditions for ℓ1-norm regularization;;First order methods for convex optimization on Rp, Smooth optimization;;First-order methods for convex optimization on Rp, Non smooth optimization;;Counter-example Coordinate descent for nonsmooth objectives;;Counter-example (Bertsekas, 1995) Steepest descent for nonsmooth objectives;;Sparsity-inducing norms Using the structure of the problem;;Cheap (and not dirty) algorithms for all losses (1);;Cheap (and not dirty) algorithms for all losses (2);;Cheap (and not dirty) algorithms for all losses (3);;Special case of square loss (1);;Special case of square loss (2);;Optimality conditions for the sign vector s (Lasso);;Homotopy methods for the square loss (Markowitz, 1956; Osborne et al., 2000; Efron et al., 2004);;Piecewise linear paths;;Algorithms for ℓ1-norms (square loss): Gaussian hare vs. Laplacian tortoise;;Additional methods - Softwares;;Sparse methods for machine learning, Outline;;Theoretical results - Square loss;;Model selection consistency (Lasso) (1);;Model selection consistency (Lasso) (2);;Model selection consistency (Lasso) (3);;Adaptive Lasso and concave penalization;;Bolasso (Bach, 2008a);;Model selection consistency of the Lasso/Bolasso;;High-dimensional inference, Going beyond exact support recovery;;High-dimensional inference, Variable selection without computational limits;;High-dimensional inference, Variable selection with orthogonal design (1);;High-dimensional inference, Variable selection with orthogonal design (2);;High-dimensional inference (Lasso);;Mutual incoherence (uniform low correlations);;Restricted eigenvalue conditions;;Checking sufficient conditions;;Sparse methods, Common extensions;;Relevance of theoretical results;;Alternative sparse methods, Greedy methods;;Alternative sparse methods, Bayesian methods;;Comparing Lasso and other strategies for linear regression;;Simulation results;;Summary, ℓ1-norm regularization;;Extensions;;Questions?;;Sparse methods for machine learning, Outline;;Penalization with grouped variables (Yuan and Lin, 2006);;Linear vs. non-linear methods ;;Kernel methods: regularization by ℓ2-norm;;Kernel methods: regularization by ℓ2-norm, Representer theorem;;Multiple kernel learning (MKL) (Lanckriet et al., 2004b; Bach et al., 2004a) (1);;Multiple kernel learning (MKL) (Lanckriet et al., 2004b; Bach et al., 2004a) (2);;Regularization for multiple features (1);;Regularization for multiple features (2);;General kernel learning;;Equivalence with kernel learning (Bach et al., 2004a);;Proof of equivalence;;Algorithms for the group Lasso / MKL;;Applications of multiple kernel learning (1);;Applications of multiple kernel learning (2);;Sparse methods for machine learning, Outline;;Lasso - Two main recent theoretical results (1);;Lasso - Two main recent theoretical results (2);;Lasso - Two main recent theoretical results (3);;Hierarchical kernel learning (Bach, 2008c);;Restricting the set of active kernels (1);;Restricting the set of active kernels (2);;DAG-adapted norm (Zhao & Yu, 2008) (1);;DAG-adapted norm (Zhao & Yu, 2008) (2);;Scaling between p, n and other graph-related quantities (1);;Scaling between p, n and other graph-related quantities (2);;Mean-square errors (regression);;Extensions to other kernels;;Grouped variables (1);;Grouped variables (2);;Structured Sparsity (Jenatton et al., 2009a);;Examples of set of groups G (1/3);;Examples of set of groups G (2/3);;Examples of set of groups G (3/3);;Relationship bewteen G and Zero Patterns (Jenatton, Audibert, and Bach, 2009a);;Overview of other work on structured sparsity;;Sparse methods for machine learning, Outline;;Learning on matrices - Collaborative Filtering (CF);;Learning on matrices - Multi-task learning;;Learning on matrices - Image denoising;;Two types of sparsity for matrices M ∈ Rn×p, I - Directly on the elements of M;;Two types of sparsity for matrices M ∈ Rn×p, II - Through a factorization of M = UV ⊤;;Structured matrix factorizations - Many instances;;Multi-task learning (1);;Multi-task learning (2);;Low-rank matrix factorizations, Trace norm (1);;Low-rank matrix factorizations Trace norm (2);;Results for the trace norm;;Spectral regularizations;;Sparse principal component analysis;;Sparse principal component analysis, Analysis view (1);;Sparse principal component analysis, Analysis view (2) ;;Sparse principal component analysis, Synthesis view (1);;Sparse principal component analysis Synthesis view (2);;Structured matrix factorizations;;Dictionary learning for image denoising (1);;Dictionary learning for image denoising (2);;Online optimization for dictionary learning;;nips09_bach_smm_Page_120;;Denoising result (Mairal, Bach, Ponce, Sapiro, and Zisserman, 2009c) (1);;Denoising result (Mairal, Bach, Ponce, Sapiro, and Zisserman, 2009c) (2);;What does the dictionary V look like?;;Inpainting a 12-Mpixel photograph (1);;Inpainting a 12-Mpixel photograph (2);;Inpainting a 12-Mpixel photograph (3);;Inpainting a 12-Mpixel photograph (4);;Alternative usages of dictionary learning;;Sparse Structured PCA (Jenatton, Obozinski, and Bach, 2009b);;Application to face databases (1/3);;Application to face databases (2/3) (1);;Application to face databases (2/3) (2);;Application to face databases (3/3);;Topic models and matrix factorization (1);;Topic models and matrix factorization (2);;Topic models and matrix factorization (3);;Sparsifying linear methods;;Sparse methods for matrices, Summary;;Sparse methods for machine learning, Outline;;Links with compressed sensing (Baraniuk, 2007; Cand`es and Wakin, 2008);;Why use sparse methods?;;Conclusion - Interesting questions/issues;;Hiring postdocs and PhD students;;nips09_bach_smm_Page_144;;nips09_bach_smm_Page_145;;nips09_bach_smm_Page_146;;nips09_bach_smm_Page_147;;nips09_bach_smm_Page_148;;nips09_bach_smm_Page_149;;nips09_bach_smm_Page_150;;nips09_bach_smm_Page_151;;nips09_bach_smm_Page_152;;nips09_bach_smm_Page_153;;nips09_bach_smm_Page_154;;nips09_bach_smm_Page_155'
11151,'tutorial','en',11062,'2009-12-07','2010-01-19','Deep Learning in Natural Language Processing','This tutorial will describe recent advances in deep learning techniques for Natural Language Processing (NLP). Traditional NLP approaches favour shallow systems, possibly cascaded, with adequate hand-crafted features. In constrast, we are interested in end-to-end architectures: these systems include several feature layers, with increasing abstraction at each layer. Compared to shallow systems, these feature layers are learnt for the task of interest, and do not require any engineering. We will show how neural networks are naturally well suited for end-to-end learning in NLP tasks. We will study multi-tasking different tasks, new semi-supervised learning techniques adapted to these deep architectures, and review end-to-end structured output learning. Finally, we will highlight how some of these advances can be applied to other fields of research, like computer vision, as well.','Deep Learning for Natural Language Processing;;Deep Learning for Natural Language Processing (Disclaimer);;A Brief History Of Machine Learning;;In the beginning: discovery of the Perceptron;;The Quest to Model Nonlinearities;;They Discovered Multi-Layered Perceptrons;;They were so excited they kept trying more and more things...;;And more and more things...;;Even though they hadn\'t reached the complexity of the only known intelligent thing in the universe (the brain);;They decided what they were doing was too complex..;;A new Perceptron network!;;Life was Convex;;Learning Representations;;Multi-tasking: sharing features;;Semi-supervised learning: Transductive SVM;;Feature Engineering;;Scalability;;IDEA! Rebrand Neural Nets\" - \"Deep Nets\";;Putting it all together;;This Talk: The Big Picture;;Part II: NLP Labeling;;Natural Language Processing Tasks;;NLP Benchmarks;;Complex Systems (1);;Complex Systems (2);;NLP: Large Scale Engineering (1);;NLP: Large Scale Engineering (2);;NLP: Large Scale Machine Learning;;Chapter II: The Networks;;Neural Networks;;Words into Vectors (1);;Words into Vectors (2);;Window Approach;;Sentence Approach (1);;Sentence Approach (2);;Training;;Word Tag Likelihood (WTL);;Sentence Tag Likelihood (STL) (1);;Sentence Tag Likelihood (STL) (2);;Sentence Tag Likelihood (STL) (3);;Supervised Benchmark Results;;Supervised Word Embeddings;;Chapter III: Lots Of Unlabeled Data;;Ranking Language Model;;Training Language Model;;Unsupervised Word Embeddings;;Semi-Supervised Benchmark Results;;Chapter IV: Multi-Task Learning;;Multi-Task Learning;;Multi-Task Learning Benchmark Results;;Chapter V: The Temptation;;Cascading Tasks;;Cascading Tasks Benchmark Results;;Variance;;Parsing;;SRL Benchmark Results With Parsing;;Engineering a Sweet Spot;;SENNA Speed;;SENNA Demo;;Conclusion;;Deep Learning for NLP: Parts 3 & 4;;Part 3: “Semantic Search”;;Document Ranking: Our Goal;;Basic Bag-o’-words;;Latent semantic indexing (LSI);;(Polynomial) Supervised Semantic Indexing (SSI );;SSI: why is this a good model?;;SSI: Why the Basic Model Sucks;;SSI Improved model: Low Rank W;;Neural Network Models for Retrieval;;Doc. Embedding for Polynomial Degree 3;;SSI: Training;;Prior Work: Summary of learning to Rank;;Experimental Comparison;;Experiments: Doc-Doc Ranking (D = 30000);;Experiments: Doc-Doc Ranking (D = 2.5M);;Experiments: Query-Document Ranking;;Experiments: Cross-Language Retrieval;;What’s Inside W?;;Summary;;Part 4: Situated Learning: Hidden Representations for Grounding Language;;Connecting NLP with a world: Why?;;Learning Speech in a Situated Environment?;;The Learning Signal : text adventure game;;The Concept Labeling Task;;Example of Concept Labeling;;nips09_collobert_weston_dlnl_Page_087;;Disambiguation Example;;Ambiguities we will handle;;Concept Labeling Is Challenging;;Learning Algorithm : Basic Argmax;;Simulation : algorithm;;Labeled Data generated by the Simulation;;Experimental Results using an SVM;;Neural Network Scoring Function;;Scoring Illustration (Step 0);;Scoring Illustration (Step 1);;Scoring Illustration (Step 2);;Scoring Illustration (Step 3);;Scoring Illustration (Step 4);;Scoring Illustration (Step 5);;Scoring Illustration (Step 6);;Scoring Illustration (Step 7);;Greedy “Order-free” Inference using LaSO;;Experimental Results;;Features Learnt By the Model;;Summary;;Final Conclusion;;nips09_collobert_weston_dlnl_Page_109;;nips09_collobert_weston_dlnl_Page_110;;nips09_collobert_weston_dlnl_Page_111;;nips09_collobert_weston_dlnl_Page_112;;nips09_collobert_weston_dlnl_Page_113'
11152,'tutorial','en',11062,'2009-12-07','2010-01-19','Sequential Monte-Carlo Methods','Over the last fifteen years, sequential Monte Carlo (SMC) methods gained popularity as powerful tools for solving intractable inference problems arising in the modelling of sequential data. Much effort was devoted to the development of SMC methods, known as particle filters (PFs), for estimating the filtering distribution of the latent variables in dynamic models. This line of research produced many algorithms, including auxiliary-variable PFs, marginal PFs, the resample-move algorithm and Rao-Blackwellised PFs. It also led to many applications in tracking, computer vision, robotics and econometrics. The theoretical properties of these methods were also studied extensively in this period. Although PFs occupied the center-stage, significant progress was also attained in the development of SMC methods for parameter estimation, online EM, particle smoothing and SMC techniques for control and planning. Various SMC algorithms were also designed to approximate sequences of unnormalized functions, thus allowing for the computation of eigen-pairs of large matrices and kernel operators. Recently, frameworks for building efficient high-dimensional proposal distributions for MCMC using SMC methods were proposed. These allow us to design effective MCMC algorithms in complex scenarios where standard strategies failed. Such methods have been demonstrated on a number of domains, including simulated tempering, Dirichlet process mixtures, nonlinear non-Gaussian state-space models, protein folding and stochastic differential equations. Finally, SMC methods were also generalized to carry out approximate inference in static models. This is typically done by constructing a sequence of probability distributions, which starts with an easy-to-sample-from distribution and which converges to the desired target distribution. These SMC methods have been successfully applied to notoriously hard problems, such as inference in Boltzmann machines, marginal parameter estimation and nonlinear Bayesian experimental design. In this tutorial, we will introduce the classical SMC methods and expose the audience to the new developments in the field.','Sequential Monte Carlo;;Tutorial overview;;Tutorial overview, Part I Arnaud – 50min, 20th century;;SMC in this community;;The 20th century - Tracking (1);;The 20th century - Tracking (2);;The 20th century – State estimation (1);;The 20th century – State estimation (2);;The 20th century – State estimation (3);;The 20th century – The birth;;Tutorial overview, Part I Arnaud – 50min;;Arnaud’s slides will go here;;Sequential Monte Carlo Methods;;State-Space Models (1);;State-Space Models (2);;State-Space Models (3);;Inference in State-Space Models (1);;Inference in State-Space Models (2);;Inference in State-Space Models (3);;Monte Carlo Methods (1);;Monte Carlo Methods (2);;Monte Carlo Methods (3);;Monte Carlo Methods (4);;Basics of Sequential Monte Carlo Methods (1);;Basics of Sequential Monte Carlo Methods (2);;Importance Sampling (1);;Importance Sampling (2);;Importance Sampling (3);;Resampling (1);;Resampling (2);;Resampling (3);;Bootstrap Filter (Gordon, Salmond & Smith, 1993) (1);;Bootstrap Filter (Gordon, Salmond & Smith, 1993) (2);;Bootstrap Filter (Gordon, Salmond & Smith, 1993) (3);;Bootstrap Filter (Gordon, Salmond & Smith, 1993) (3);;Bootstrap Filter (Gordon, Salmond & Smith, 1993) (4);;SMC Output (1);;SMC Output (2);;SMC Output (3);;SMC Output (4);;SMC on Path-Space - gures by Olivier Capp (1);;SMC on Path-Space - gures by Olivier Capp (2);;SMC on Path-Space - gures by Olivier Capp (3);;SMC on Path-Space - gures by Olivier Capp (4);;SMC on Path-Space - gures by Olivier Capp (5);;Illustration of the Degeneracy Problem;;Convergence Results (1);;Convergence Results (2);;Convergence Results (3);;Convergence Results (4);;Stronger Convergence Results (1);;Stronger Convergence Results (2);;Stronger Convergence Results (3);;Stronger Convergence Results (4);;Improving the Sampling Step (1);;Improving the Sampling Step (2);;Improving the Sampling Step (3);;Improving the Sampling Step (4);;Various standard improvements (1);;Various standard improvements (2);;Improving the Resampling Step (1);;Improving the Resampling Step (2);;Online Bayesian Parameter Estimation (1);;Online Bayesian Parameter Estimation (2);;Online Bayesian Parameter Estimation (3);;Cautionary Warning (1);;Cautionary Warning (2);;Cautionary Warning (3);;Cautionary Warning (4);;Example of SMC with MCMC for Parameter Estimation (1);;Example of SMC with MCMC for Parameter Estimation (2);;Example of SMC with MCMC for Parameter Estimation (3);;Illustration of the Degeneracy Problem;;O­ffline Bayesian Parameter Estimation (1);;O­ffline Bayesian Parameter Estimation (2);;O­ffline Bayesian Parameter Estimation (3);;Metropolis-Hastings (MH) Sampler (1);;Metropolis-Hastings (MH) Sampler (2);;Marginal Metropolis-Hastings Sampler (1);;Marginal Metropolis-Hastings Sampler (2);;Marginal Metropolis-Hastings Sampler (3);;Marginal Metropolis-Hastings Sampler (4);;Particle Marginal MH Sampler (1);;Particle Marginal MH Sampler (2);;Particle Marginal MH Sampler (3);;Validity of the Particle Marginal MH Sampler (1);;Validity of the Particle Marginal MH Sampler (2);;Validity of the Particle Marginal MH Sampler (3);;Validity of the Particle Marginal MH Sampler (4);;Inference for Stochastic Kinetic Models (1);;Inference for Stochastic Kinetic Models (2);;Inference for Stochastic Kinetic Models (3);;Experimental Results;;SMC Fixed-Lag Smoothing Approximation (1);;SMC Fixed-Lag Smoothing Approximation (2);;SMC Fixed-Lag Smoothing Approximation (3);;SMC Fixed-Lag Smoothing Approximation (4);;SMC Fixed-Lag Smoothing Approximation (5);;SMC Forward Filtering Backward Smoothing (1);;SMC Forward Filtering Backward Smoothing (2);;SMC Forward Filtering Backward Smoothing (3);;SMC Forward Filtering Backward Smoothing (4);;SMC Generalized Two-Filter Smoothing (1);;SMC Generalized Two-Filter Smoothing (2);;SMC Generalized Two-Filter Smoothing (3);;Convergence Results (1);;Convergence Results (2);;Convergence Results (3);;Experimental Results (1);;Experimental Results (2);;Experimental Results (3);;Empirical Variance for Standard vs FFBS Approximations;;Parameter Estimation using Gradient Ascent/EM (1);;Parameter Estimation using Gradient Ascent/EM (2);;Online Parameter Estimation using Gradient Ascent/EM (1);;Online Parameter Estimation using Gradient Ascent/EM (2);;Online Parameter Estimation using Gradient Ascent/EM (3);;Online Parameter Estimation using Gradient Ascent/EM (4);;Tutorial overview, Part II NdF – 45 min;;Sequential Monte Carlo (recap);;Sequences of distributions;;Importance weights;;SMC algorithm;;Example 1: Bayesian filtering (missing equations);;Example 2: Eigen-particles;;Quantum Monte Carlo;;Transfer matrices of Boltzmann Machines;;Power method (missing equations);;Particle power method;;Example 3: Particle diffusion (missing equations);;Example 3: Particle diffusion;;Example 4: SAWs;;Example 5: Stochastic control;;Particle smoothing can be used in the E step of the EM algorithm for MDPs;;Example 6: Dynamic Dirichlet processes;;SMC for static models;;Static SMC applications;;Static SMC derivation;;Static SMC algorithm;;Static SMC: Choice of L;;Example 1: Deep Boltzmann machines;;Some results for undirected graphs;;Example 2: ABC;;SMC samplers for ABC;;Final remarks;;nips09_doucet_freitas_smc_Page_146;;nips09_doucet_freitas_smc_Page_147;;nips09_doucet_freitas_smc_Page_148;;nips09_doucet_freitas_smc_Page_149;;nips09_doucet_freitas_smc_Page_150'
11179,'lecture','en',11140,'2009-12-10','2010-01-19','Towards Brain Computer Interfacing: Algorithms for on-line Differentiation of Neuroelectric Activities','Brain Computer Interfacing (BCI) aims at making use of brain signals\nfor e.g. the control of objects, spelling, gaming and so on. This talk\nwill first provide a brief overview of Brain Computer Interface\nfrom a machine learning and signal processing perspective. In\nparticular it shows the wealth, the complexity and the difficulties of\nthe data available, a truly enormous challenge: In real-time a\nmulti-variate very strongly noise contaminated data stream is to be\nprocessed and neuroelectric activities are to be accurately\ndifferentiated in real time.\n\nFinally, I report in more detail about the Berlin Brain Computer\n(BBCI) Interface that is based on EEG signals and take the audience\nall the way from the measured signal, the preprocessing and filtering,\nthe classification to the respective application. Â BCI as a new\nchannel for man-machine communication is discussed in a clinical\nsetting and for gaming.','Toward Brain Computer Interfacing;;NoninvasiveBrain-Computer Interface;;Brain Pong‘ with BBCI;;Noninvasive BCI: clinical applications;;EEG based noninvasive BCI;;The cerebral cocktail party problem;;Towards imaginations: Modulation of Brain Rhythms;;Variance I: Single-trial vs. Averaging;;Variance II: Session to Session Variability;;VarianceIII: intersubjectvariability [l vsr];;BCI withmachinelearning: training;;BBCI paradigms (1);;BBCI paradigms (2);;Playing with BCI: training session (20 min) (missing video);;Machine learning approach to BCI: infer prototypical pattern (missing video);;Common SpatialPattern Analysis;;CSP I;;CSP II;;Common Spatial Patterns for 2 classes;;right imagery (missing video example);; Distribution of EEG features;;BBCI Set-up;;BCI withmachinelearning: feedback;;Spelling with BBCI: a communicationforthedisabled I;;Spelling with BBCI: a communicationforthedisabled II;;Variance IV: covariate shift: from training to feedback;;Splitting intostationaryandnonstationarysubspace: SSA;;Splitting intostationaryandnonstationarysubspace: SSA II;;Towards Application: Predicting drowsiness;;Application: Cognitivew orkload and drowsyness assessment;;Real Man Machine Interaction;;Future issues: sensors;;picture 1;;Future Issues: Shifting distributions within experiment;;Conclusion;;Thanks to BBCI core team;;For BCI IV Competition see www.bbci.de;;MachineLearning open sourcesoftwareinitiative: MLOSS see'
11180,'lecture','en',11140,'2009-12-10','2010-01-19','Machine Learning for Brain-Computer Interfaces','Brain-computer interfaces (BCI) aim to be the ultimate in assistive technology: \ndecoding a user\'s intentions directly from brain signals without involving any \nmuscles or peripheral nerves. Thus, some classes of BCI potentially offer hope \nfor users with even the most extreme cases of paralysis, such as in late-stage \nAmyotrophic Lateral Sclerosis, where nothing else currently allows communication \nof any kind.  Other lines in BCI research aim to restore lost motor function in as \nnatural a way as possible, reconnecting and in some cases re-training motor-cortical \nareas to control prosthetic, or previously paretic, limbs. Research and development \nare progressing on both invasive and non-invasive fronts, although BCI has yet to \nmake a breakthrough to widespread clinical application.\n\nThe high-noise high-dimensional nature of brain-signals, particularly in non-invasive\napproaches and in patient populations, make robust decoding techniques a necessity. \nGenerally, the approach has been to use relatively simple feature extraction techniques, \nsuch as template matching and band-power estimation, coupled to simple linear classifiers. \nThis has led to a prevailing view among applied BCI researchers that (sophisticated) \nmachine-learning is irrelevant since \"it doesn\'t matter what classifier you use once you\'ve \ndone your preprocessing right and extracted the right features.\" I shall show a few examples \nof how this runs counter to both the empirical reality and the spirit of what needs to be done \nto bring BCI into clinical application. Along the way I\'ll highlight some of the interesting \nproblems that remain open for machine-learners.','Machine-Learning for Brain-Computer Interfaces;;BCI as a Potential Assistive Technology (1);;BCI as a Potential Assistive Technology (2);;BCI as a Potential Assistive Technology (3);;BCI as a Potential Assistive Technology (4);;BCI as a Potential Assistive Technology (5);;BCI as a Potential Assistive Technology (6);;BCI as a Potential Assistive Technology (7);;Problems with Clinical Deployment (1);;Problems with Clinical Deployment (2);;Problems with Clinical Deployment (3);;Problems with Clinical Deployment (4);;Problems with Clinical Deployment (5);;Problems with Clinical Deployment (6);;Problems with Clinical Deployment (7);;Problems with Clinical Deployment (8);;Measurement systems for BCI (1);;Measurement systems for BCI (2);;Measurement systems for BCI (3);;Measurement systems for BCI (4);;Measurement systems for BCI (5);;Induction (1);;Induction (2);;Induction - example (1);;Induction - example (2);;Induction - example (3);;Induction - example (4);;Induction - example (5);;Induction - example (6);;Induction (3);;Induction (4);;Induction (5);;Induction (6);;Induction (7);;Induction (8);;Event-Related Potentials (1);;Event-Related Potentials (2);;Event-Related Potentials (3);;Event-Related Potentials (4);;Event-Related Potentials (5);;Bandpower (1);;Bandpower (2);;Bandpower (3);;An Overfitting Nightmare? (1);;An Overfitting Nightmare? (2);;An Overfitting Nightmare? (3);;An Overfitting Nightmare? (4);;An Overfitting Nightmare? (5);;An Overfitting Nightmare? (6);;Source Separation (1);;Source Separation (2);;Source Separation (3);;Source Separation (4);;Cheap supervised rotation with CSP (1);;Cheap supervised rotation with CSP (2);;Cheap supervised rotation with CSP (3);;Cheap supervised rotation with CSP (4);;Cheap supervised rotation with CSP (5);;Cheap supervised rotation with CSP (6);;Cheap supervised rotation with CSP (7);;CSP: outlier- (artifact-) sensitivity (1);;CSP: outlier- (artifact-) sensitivity (2);;CSP: outlier- (artifact-) sensitivity (3);;CSP: outlier- (artifact-) sensitivity (4);;Slightly deeper learning? (1);;Slightly deeper learning? (2);;Slightly deeper learning? (3);;Slightly deeper learning? CSP + GPC (graphs) (1);;Slightly deeper learning? CSP + GPC (graphs) (2);;Slightly deeper learning? CSP + GPC (graphs) (3);;Deeper learning  more “hands-free” operation;;Deeper still? (1);;Deeper still? (2);;Deeper still? (3);;Deeper still? (4);;Deeper still? (5);;Deeper still? (6);;Deeper still? (7);;Low-rank Classification (1);;Low-rank Classification (2);;Low-rank Classification (3);;Low-rank Classification (4);;Low-rank Classification (5);;Low-rank Classification (6);;Example Sparsification Results (1);;Example Sparsification Results (2);;How Can Machine-Learners Help to Make BCI a Clinical Reality? (1);;How Can Machine-Learners Help to Make BCI a Clinical Reality? (2);;How Can Machine-Learners Help to Make BCI a Clinical Reality? (3);;How Can Machine-Learners Help to Make BCI a Clinical Reality? (4);;How Can Machine-Learners Help to Make BCI a Clinical Reality? (5);;How Can Machine-Learners Help to Make BCI a Clinical Reality? (6);;How Can Machine-Learners Help to Make BCI a Clinical Reality? (7)'
11181,'lecture','en',11140,'2009-12-10','2010-01-19','An Efficient P300-based Brain-Computer Interface with Minimal Calibration Time','Brain-Computer Interfaces (BCI) are communication systems that enable subjects to send commands\nto computers by using only their brain activity [1]. Most existing BCI are based on ElectroEncephaloGraphy\n(EEG) as the measure of brain activity [1]. So far, BCI have been proven to be\nvery promising communication and control tools for disabled people [1]. A promising brain signals\nused in the design of assistive BCI for disabled people is the P300, a positive waveform occuring\nroughly 300 ms after a rare and relevant stimulus [1, 2]. In order to use a P300-based BCI, subjects\nhave to focus their attention on a given stimulus randomly appearing among many others, each\nstimulus corresponding to a given command. The appearance of the desired stimulus being rare and\nrelevant, it is expected to trigger a P300 in the subject’s brain activity. As such, detecting the P300\nenables the system to identify the desired stimulus and hence the desired command. Interestingly\nenough, P300-based BCI have been successfully used to control a wheelchair (see, e.g., [3]) or to\nenable severely disabled users to spell words [2, 4].\n\nHowever, current P300-based BCI as well as other BCI systems still suffer from several limitations\nwhich prevent them from being widely used [1]. One of these limitations is that to use a BCI, many\nexamples of the subject’s EEG signals must be recorded in order to calibrate the BCI, which is\nunconvenient and time consuming. Moreover, this calibration process generally has to be repeated\nat regular intervals (e.g., from one day to the other) in order to accomodate sources of variations\nsuch as changes in electrode positions or changes in the subject’s mental state and fatigue level.\nTherefore, the calibration time should be maintained as brief as possible. Until now, reducing the\ncalibration time of P300-based BCI has been scarcely addressed by the literature. Exceptions are\nthe works of Li et al [5] and Lu et al [6]. Li et al suggested to use initially a BCI calibrated with\nfew training samples, and then to incrementally adapt this BCI online, thanks to semi-supervised\nlearning [5]. Lu et al proposed to use a subject-independent BCI, previously learnt from the data\nof many other subjects, also followed by online adaptation [6]. However, the main limitiation of\nthese two approaches is that such BCI would have initially poor detection performances, becoming\nefficient only after adaptation. An ideal P300-based BCI would have initially high performances,\neven if trained with very few examples. In this paper, we propose a new P300-based BCI design\nwhich can be trained using much fewer examples than current BCI designs, without sacrifying the\ndetection performances.','An Efficient P300-based Brain-Computer Interface with Minimal Calibration Time;;Introduction;;P300-based BCI;;limitation and objective;;State-of-the-art;;Our P300-based BCI design;;Feature Extraction with Canonical Correlation Analysis;;Regularized CCA;;Classification;;Evaluation;;Results - Standard BCI;;Results - PCA+LDA;;Results - RLDA;;Results - CCA + RLDA;;Results - Preposed design (RCCA + RLDA);;Conclusion;;Thank you for your attention!, Any question?;;nips09_lotte_epb_01_Page_18;;nips09_lotte_epb_01_Page_19'
11182,'lecture','en',11140,'2009-12-10','2010-01-19','Extracting Gait Spatiotemporal Properties from Parkinson\'s Disease Patients','The Parkinson’s disease (PD) is a frequent chronic progressive syndrome in the elderly population.\nCurrent available PD treatments either stimulate brain dopamine receptors or increase dopamine\nsynthesis. In the long-term, especially from the fifth year of disease on, onset of motor complications\nis often observed. Such motor complications arise as a consequence of a reduction in the duration\nof the effect of the medication. This motor complications affects spatiotemporal properties during\nthe gait of patients [8]. Length and speed of the steps change due to the effects known as dyskinesia\nand or akinesia, thus, and on-line measurement of these properties during gait may help to predict\nthese situations and therefore warn the patient (e.g., minimizing risk of falling) or a remote health\ncare system. Recently several approaches using inertial sensors have been developed with the aim\nof measure these types of gait properties [1, 2, 4, 5, 6]. The gait characteristics may be obtained\nusing gyroscopes tied at legs using a double inverted pendulum model [1, 5], nevertheless wearing\nthese devices on the legs during daily life activity seems a drawback, leaving the application scope\nof this method to clinical environments. In the case of accelerometers, they are usually positioned\nat the dorsal side of the trunk near the L3 region of the subject, since it is the CoM location. In this\nposition, 3D CoM acceleration, velocity and displacement can be estimated [2, 4]. However, to the\nbest of our knowledge, there is no a user-friendly wearable device/location, that patients may use\noutside the hospital. Here we propose a method, based on SVM-regression, to extract spatiotemporal\nproperties from accelerations obtained from a single accelerometer positioned at the lateral side of\nthe waist, with the advantage of being a wearable system the patients may use during their daily life,\nwithout danger of hurt or damaging the device.','Extracting Spatiotemporal Gait Properties fromParkinson\'s Disease Patients;;Motivation (1);;Motivation (2);;Outline;; Some related work;;2. Gait analysis (1);;2. Gait analysis (2);;2. Gait analysis (3);;2. Gait analysis (4);;2. Gait analysis (5);;3. Results;;4. Conclusions and future work;;Thank you for your attention'
11183,'lecture','en',11140,'2009-12-10','2010-01-19','Machine Learning Applied to Multi-Modal Interaction, Adaptive Interfaces and Ubiquitous Assistive Technologies','The presentation will describe the challenge of eInclusion in the technological design\nprocess, which impedes the complete integration of people with disabilities and elderly\nin Information Society. To face this challenge, the INREDIS project aims to face \nindividual needs of users instead of addressing the needs of the average user, by \nproposing basic technologies that enables the creation of personalized channels for\ncommunication and interaction with the technological environment. For this purpose, \nMachine Learning can help constructing effective methods to reflect user needs, \npreferences and expectations (and their evolution over time) on user interfaces,\nconsequently improving satisfaction and performance. In particular, academia and \nindustry within the INREDIS consortium explore together the potential of Machine \nLearning on multimodal services and ubiquitous assistive technologies, as well as \nadaptive user interfaces according to user and technological capabilities.','Machine learning applied to multi-modal interaction, adaptive interfaces and ubiquitous assistive technologies;;Technosite (who are we?…);;INREDIS project ;;Inredis arhitecture;;Accessibility and Machine Learning ;;Adaptive user interfaces and multimodal assistive technologies (1);;Adaptive user interfaces and multimodal assistive technologies (2);;Adaptive user interfaces (1);;Adaptive user interfaces (2);;Persistent user features: implicit interaction systems (1);; Persistent user features: implicit interaction systems (2);; Persistent user features: implicit interaction systems (3);; Persistent user features: implicit interaction systems (4);; Persistent user features: implicit interaction systems (5);; Persistent user features: implicit interaction systems (6);; Persistent user features: implicit interaction systems (7);;Non-persistent user features (1);;Non-persistent user features (2);;Non-persistent user features (3);;Non-persistent context features (1);;Non-persistent context features (2);;Non-persistent features - “non-persistent disabilities”;;Multimodal assistive technologies;;interoperability adaptability, multimodality, ubiquity  ;;Thank you for your attention'
11185,'lecture','en',11140,'2009-12-10','2010-01-19','Human-Centered Machine Learning in a Social Interaction Assistant for Individuals with Visual Impairments','Over the last couple of decades, the increasing focus on accessibility has resulted in the design and\ndevelopment of several assistive technologies to aid people with visual impairments in their daily\nactivities. Most of these devices have been centered on enhancing the interaction of a user who\nis blind or visually impaired with objects and environments, such as a computer monitor, personal\ndigital assistant, cellphone, road traffic, or a grocery store. Although these efforts are very essential\nfor the quality of life of these individuals, there is also a need (which has so far not been seriously\nconsidered) to enrich the interactions of individuals who are blind, with other individuals.\n\nNon-verbal cues (including prosody, elements of the physical environment, the appearance of communicators\nand physical movements) account for as much as 65% of the information communicated\nduring social interactions [1]. However, more than 1.1 million individuals in the US who are legally\nblind (and 37 million worldwide) have a limited experience of this fundamental privilege of social\ninteractions. These individuals continue to be faced with fundamental challenges in coping with\neveryday interactions in their social lives. The work described in this paper is based on the design\nand development of a Social Interaction Assistant that is intended to enrich the experience of social\ninteractions for individuals who are blind, by providing real-time access to information about\nindividuals and their surrounds. The realization of a Social Interaction Assistant device involves\nsolving several challenging problems in pattern analysis and machine intelligence such as person\nrecognition/tracking, head/body pose estimation, gesture recognition, expression recognition, etc on\na wearable real-time platform. A list of eight significant daily challenges faced by these individuals\nwas identified in our initial focus group studies conducted with 27 individuals who are blind or visually\nimpaired. Each of these problems raises unique machine learning challenges that need to\nbe addressed.','Human Centered Machine Learning in a Social Interaction Assistant for Individuals with Visual Impairments;;Outline;;Introduction – Human Centered Machine Learning;;Assistive Devices for the Visually Impaired;;Social Interaction;; Social Interaction for the blind;;“The Human-Machine System”;;Human-Centered Machine Learning;;Overview of the Social Interaction Assistant;;The Social Interaction Assistant (missing examples);;Examples of Human Centered Machine Learning;;Integrated Face Localization/Recognition (1);;Integrated Face Localization/Recognition (2);;User Conformal Confidence Measures;;Related Machine Learning Contributions;;Online Active Learning for Person Recognition;;Context Aware Batch Mode Active Learning;;Learning from Multiple Sources;;Thank You !!.., Questions ??..'
11186,'lecture','en',11140,'2009-12-10','2010-01-19','Toward Text-to-Picture Synthesis','It is estimated that more that 2 million people in the United States have significant communication\nimpairments that result in them relying on methods other than natural speech alone for communication\n[2]. One type of commonly used augmentative and alternative communication (AAC) system is\npictorial communication software such as SymWriter [8], which uses a lookup table to transliterate\neach word (or common phrase) in a sentence into an icon. This is an example of converting information\nbetween modalities. However, the resulting sequence of icons can be difficult to understand.\nWe have been developing general-purpose Text-to-Picture (TTP) synthesis algorithms [10, 5] to\nimprove understandability using machine learning techniques. Our goal is to help users with special\nneeds, such as the elderly or those with disabilities, to rapidly browse documents through pictorial\nsummaries (e.g., Figure 5). Our TTP system targets general English. This differs from other pictorial\nconversion systems that require hand-crafted narrative descriptions of a scene [1, 9], 3D models [3],\nor special domains [6]. Instead, we use a concatenative or “collage” approach. In this talk, we\ndiscuss how machine learning enables the key components of our TTP system.','Toward Text-to-Picture Synthesis;;Augmentative & Alternative Communication (AAC) (1);;Augmentative & Alternative Communication (AAC) (2);;Augmentative & Alternative Communication (AAC) (3);;Augmentative & Alternative Communication (AAC) (4);;Augmentative & Alternative Communication (AAC) (5);;Text-to-Picture Synthesis (1);;Text-to-Picture Synthesis (2);;Text-to-Picture Synthesis (3);;Text-to-Picture Synthesis (4);;Text-to-Picture Synthesis (5);;Text-to-Picture Synthesis (6);;Main TTP Components (1);;Main TTP Components (2);;Main TTP Components (3);;Main TTP Components (4);;Picture-Driven Keyphrase Extraction (1);;Picture-Driven Keyphrase Extraction (2);;Word Picturability Training Data (1);;Word Picturability Training Data (2);;Predicting Word Picturability (1);;Predicting Word Picturability (2);;Predicting Word Picturability (3);;Predicting Word Picturability (4);;Predicting Word Picturability (5);;Picturability Results;;Semantically Enhanced Layout (1);;Semantically Enhanced Layout (2);;Collecting ABC Pictures;;Layout Prediction using CRFs (1);;Layout Prediction using CRFs (2);;Layout Prediction using CRFs (3);;The Future;;Thank you, Any questions?'
11187,'lecture','en',11140,'2009-12-10','2010-01-19','Fast and Flexible Selection with a Single Switch','In single-switch communication, user input consists of repeated clicks, distinguished only by timing\ninformation; these clicks might be generated by pressing a button or blinking. For instance, the\nrange of movement of individuals with severe motor impairments may be limited to a single muscle.\nAlternatively, a crowded or jostled mobile technology user may be able to click precisely while\nother actions are difficult or sloppy. A single switch may also be useful when information conveyed,\nsuch as a PIN, is sensitive and hand location on a normal keyboard might betray this content. Our\nmethod, “Nomon” (e.g. Figure 1), expands the application scope of existing methods and facilitates\nfaster writing than the most common single-switch writing interface.\n\nExisting single-switch communication methods include scanning [1, 2] and One-Button Dasher [3,\n4]. (Morse Code, in contrast, requires either click duration information or multiple switches.) These\nmethods require options to be arranged in a particular configuration. By contrast, traditional operating\nsystems, web browsers, and free-form applications such as drawing place options at arbitrary\npoints on the screen. We seek a single-switch selection method that is not limited to certain forms of\noption placement. We want our method to work for any number of options; to be able to effectively\nreorder the set of selections without imposing additional cognitive load; and to allow the user to\nattend only to the desired target. Our method, Nomon, accomplishes these objectives. It can further\nautomatically adapt to individuals’ clicking abilities and incorporate prior beliefs about option\nselection frequency.\n\nTo test our method, we developed a writing application, the Nomon Keyboard (Figure 1), and compared\nits performance with a popular commercial scanning interface, The Grid 2 [5] (Figure 2). We\nexamined study participants’ writing speeds, error rates, and number of clicks made per character as\nwell as the subjective ratings of their experiences. We found that novice users wrote 35% faster with\nthe Nomon interface than with the scanning interface. An experienced user (author TB, with > 10\nhours practice) wrote at speeds of 9.3 words per minute with Nomon, using 1.2 clicks per character\nand making no errors in the final text.','Fast and flexible selectionwith a single switch;;Single-switch communication;;Nomon (1);;Nomon (2) (mising examples);;Tabele (mising examples);;Nomon operation (1);;Nomon operation (2);;Nomon operation (3);;Nomon operation (4);;Experiment (1);;Experiment (2);;Next;;Acknowledgments'
11188,'lecture','en',11140,'2009-12-10','2010-01-19','Data Mining Based User Modeling Systems for Web Personalization Applied to People with Disabilities','This position paper tackles the problem of automatic web personalization using machine learning\ntechniques to model the users\' behavior. The target population is people with physical, sensory or\ncognitive restrictions. In this paper we present our plans to study the possibility of creating user\nmodels using the information extracted from web navigation logs by means of data mining methods.\nWe discuss the expected advantages of adopting data mining to generate information about the user,\nin comparison with traditional methods.','Automatic cLasification dna PArallelism;;Schedule;;Objective;;The adaptive system can adapt the interaction to the concrete users;;Adaptive systems composed of profiles and stereotypes, ontologies  ;;General schema;;Manual option;;Automatic option, data mining ;;Automatic option, Different approaches;;Automatic option, unsupervised learning techniques ;;Automatic option, Meta-learning;;Automatic option, automatically generate profiles ;;Exploitation, shema;;Exploitation, Two main approaches to decide the profile: Explicit;;Exploitation, Two main approaches to decide the profile: Implicit;;Summary;;Thanks for your attention!!!'
11189,'lecture','en',11140,'2009-12-10','2010-01-19','Perspective on the Goals and Complexities of Inclusive Design','This presentation will discuss goals, methodology, and research for creating accessible user experiences in today\'s cutting-edge software technology. Using a framework for mapping user requirements to technology solutions, we will discuss the complex market for accessible technology and the opportunity for innovation in technology solutions. Demos will be given on new accessibility solutions in Windows and on the Internet. The presentation will highlight the complexities of the accessible technology space, with the hope of inspiring research and application of machine learning.','Perspective on the Goals and Complexities of Inclusive Design ;;Our Vision;;Agenda;;End-Users ;;Five Key Types of Disabilities ;; Customers have a Range of Accessibility Needs;;Matrix of User Needs (missing examples);;Opportunities to Apply Machine Learning;;User Scenarios (1);;User Scenarios (2) (missing example);;Improvements Needed;;AMP - Summary;;Opportunities;;Sources of Data (1);;Sources of Data (2);;Resources;;Resources (links);;nips09_zolyomi_perkins_pgc_01_Page_18'
11191,'lecture','en',11140,'2009-12-10','2010-01-19','Granger Causality and Dynamic Structural Systems','Using a generally applicable dynamic structural system of equations, we give natural definitions of direct and total structural causality applicable to both structural VARs and recursive structures representing time-series natural experiments. These concepts enable us to forge a previously missing link between Granger (G-) causality and structural causality by showing that, given a corresponding conditional form of exogeneity, G- causality holds if and only if a corresponding form of structural causality holds. Of importance for applications is the structural characterization of finite-order G-causality, which forms the basisfor most empirical work. We show that conditional exogeneity is necessary for valid structural inference and prove that in the absence of structural causality, conditional exogeneity is equivalent to G non-causality. We provide practical new G-causality and conditional exogeneity tests and describe their use in testing for structural causality.','Granger Causality and Dynamic Structural Systems;;Photo 1;;Photo 2;;Photo 3;;Photo 4;;Objective;;Outline;;Granger causality, a dynamic DGP and structural causality;;Granger causality;;Data generating process (DGP) (1);;Data generating process (DGP) (2);;Structural causality (1);;Structural causality (2);;Structural causality (3);;Granger causality and time-series natural experiments;;G-causality, conditional exogeneity, and direct causality (1);;G-causality, conditional exogeneity, and direct causality (2);;G-causality, conditional exogeneity, and direct causality (3);;Finite-order G-causality and Markov structures (1);;Finite-order G-causality and Markov structures (2);;Finite-order G-causality and Markov structures (3);;Finite-order G-causality and Markov structures (4);;Granger causality and structural VARs;;G-causality and structural VARs (1);;G-causality and structural VARs (2);;G-causality and structural VARs (3);;G-causality and structural VARs (4);;Testing finite-order Granger causality (1);;Testing finite-order Granger causality (2);;Conditional exogeneity;;The crucial role of conditional exogeneity;;Separability and finite-order conditional exogeneity;;An indirect test for structural causality;;Applications;;Economic announcements and stock returns (1);;Economic announcements and stock returns (2);;Economic announcements and stock returns (3);;Economic announcements and stock returns (4);;Conclusions'
11192,'lecture','en',11140,'2009-12-10','2010-01-19','Time Series Causality Inference Using the Phase Slope Index','A method recently introduced by Nolte et. al (Phys Rev Lett 100:23401, 2008) estimates the causal direction of interactions robustly with respect to instantaneous mixtures of independent sources with arbitrary spectral content, i.e. in observations which are dominated by non-white spatially correlated noise and in which dynamic structural interaction plays little part. The method, named Phase Slope Index (PSI), is unlikely to assign causality in the case of lack of dynamic interaction among time series, unlike Granger causality for linear systems. Results show that PSI does not yield false positives even in the case of nonlinear interactions. The meaning of instaneous noise mixtures in different data domains will be discussed in the context of correct correlation vs. causation inference, and the theoretical relationship of PSI to other time-series causality inference methods will be expanded upon.\n','Time series causality inference using the Phase Slope Index;;Introduction;;Outline;;DGP: Data Generating Process;;Stochastic DGP;;DGP equivalence;;DGP variations (1);;DGP variations (2);;DGP variations (3);;Structural / G - Causality (1);;Structural / G - Causality (2);;Structural / G - Causality (3);;Structural / G - Causality (4);;Structural / G - Causality (5);;Structural / G - Causality (6);;Structural / G - Causality (7);;Structural / G - Causality (8);;Phase slope index (1);;Phase slope index (2);;Phase slope index (3);;Phase slope index (4);;Phase slope index (5);;PSI: benchmark data;;G-Causality Results;;PSI Results;;Conclusions;;Acknowledgments'
11193,'lecture','en',11140,'2009-12-10','2010-01-19','Causality in Brain Connectivity Studies Using Functional Magnetic Resonance Imaging (fMRI) Data','This talk will discuss the application of Granger causality to fMRI data in the form of Granger causality mapping (GCM), which is used to explore directed influences between neuronal populations (effective connectivity) in fMRI data. The method does not rely on a priori specification of a model that contains pre-selected regions and connections between them. This distinguishes it from other fMRI effective connectivity approaches that aim at testing or contrasting specific hypotheses about neuronal interactions. Instead, GCM relies on the Granger causality concept to define the existence and direction of influence from temporal information in the data. The problems of limited temporal resolution in fMRI, and the hemodynamic source of the signal that makes direct interpretation of fMRI Granger causality as neuronal influence difficult, will be discussed. \n','Granger Causality in fMRI connectivity analysis;;Overview (1);;Integration and connectivity;;A problem for fMRI connectivity;;fMRI: The BOLD signal;;Overview (2);;Functional & Effective Connectivity;;Effective connectivity (1);;Effective connectivity (2);;Problem: spurious influence;;Overview (3);;Granger causality (G-causality);;Sampling & Hemodynamics;;Structural model for GC;;Granger causality mapping (GCM) (1);;Granger causality mapping (GCM) (2);;Overview (4);;Hemodynamics & GC (1);;Hemodynamics & GC (2);;Hemodynamic deconvolution (1);;Hemodynamic deconvolution (2);;Summary'
11194,'lecture','en',11140,'2009-12-10','2010-01-19','Graphical Causal Models for Time Series Econometrics: Some Recent Developments and Applications','Structural vector-autoregressive models are potentially very useful tools for guiding economic policy. I present a recently developed method to estimate and identify the causal structure underlying the data generating process. The method, which is based on graphical models, exploits conditional independence tests among estimated VAR residuals to infer the causal relationships among contemporaneous variables. I first show how this method works in the Gaussian linear setting. Then I present some developments for both the linear non-Gaussian and nonlinear settings.\n','Graphical Causal Models for Time Series Econometrics: Some Recent Developments and Applications;;Scope;;Overview (1);;Overview (2);;VAR vs. SVAR model (1);;VAR vs. SVAR model (2);;VAR vs. SVAR model (3);;VAR vs. SVAR model (4);;VAR vs. SVAR model (5);;VAR vs. SVAR model (6);;VAR vs. SVAR model (7);;VAR vs. SVAR model (8);;VAR vs. SVAR model (9);;VAR vs. SVAR model (10);;VAR vs. SVAR model (11);;Graphical models (1);;Graphical models (2);;Graphical models (3);;Graphical models (4);;Search algorithm (1);;Search algorithm (2);;Search algorithm (3);;Search algorithm (4);;Search algorithm (5);;Search algorithm (6);;GMs applied to SVAR (1);;GMs applied to SVAR (2);;GMs applied to SVAR (3);;Results (Moneta 2008) (1);;Results (Moneta 2008) (2);;Results (Moneta 2008) (3);;Impulse Response Analysis (1);;Impulse Response Analysis (2);;Impulse Response Analysis (3);;Impulse Response Analysis (4);;Impulse Response Analysis (5);;Impulse Response Analysis (6);;Extensions (1);;Extensions (2);;Nonparametric approach (1);;Nonparametric approach (2);;Nonparametric approach (3);;Causal search based on ICA (1);;Causal search based on ICA (2);;Causal search based on ICA (3);;Causal search based on ICA (4);;Causal search based on ICA (5);;Causal search based on ICA (6);;Empirical Application;;Structural coefficients one-lag model;;Structural coefficients two-lags model;;Conclusions (1);;Conclusions (2);;Conclusions (3);;Conclusions (4);;Conclusions (5);;Conclusions (6);;Thank you!;;References (1);;References (2)'
11195,'lecture','en',11140,'2009-12-10','2010-01-19','Open-Access Datasets for Time Series Causality Discovery Validation','The Causality Workbench project provides an environment to test causal discovery algorithms. Via a web portal (http://clopinet.com/causality), we provide a number of resources, including a repository of datasets, models, and software packages, and a virtual laboratory allowing users to benchmark causal discovery algorithms by performing virtual experiments to study artificial causal systems. We regularly organize competitions. Our repository already includes several time dependent datasets from a variety of domains: system biology, neurosciences, physics, manufacturing, and marketing. We will invite new contributions and present our plan for upcoming evaluations of causal models for time series applications. \n\n','Open-access datasets for time series causality discovery validation;;The challenges of causality discovery;;Causality and time;;Experimenting is needed…;;but...;;The Causality Workbench (1);;The Causality Workbench (2);;The Causality Workbench (3);;To benchmark algorithms, we built a …;;Models of systems;;What we can do for you;;Causation and Prediction challenge;;Pot-Luck challenge;;Other donated datasets;;Active Learning Challenge;;Next: Causality and Time Series'
11196,'lecture','en',11140,'2009-12-10','2010-01-19','Understanding Gene Regulatory Networks and Their Variations','A key biological question is to uncover the regulatory networks in a cellular system and to understand how this network varies across individuals, cell types, and environmental conditions. In this talk I will describe work that uses machine learning techniques to reconstruct gene regulatory networks from gene expression data. Specifically, we exploit novel forms of Bayesian regularized regression to enable transfer between multiple related learning problems, such as between different individuals or between different cell types. We demonstrate applications in two domains: understanding the effect of individual genetic variation on gene regulation and its effect on phenotypes including human disease; and understanding the regulatory mechanisms underling immune system cell differentiation.','Understanding Gene Regulation: From Networks to Mechanisms;;Gene Regulatory Networks;;;;Outline (1);;Regulatory Network I;;Regulatory Network II;;Module Networks*;;Regulation as Linear Regression;;L1 (Lasso) Regression;;L1/L2 (Elastic Net*) Regression;;Learning Regulatory Network;;Outline (2);;Genotype --> phenotype;;Genotype--> Regulation;;eQTL Data ;;Traditional Approach: Single Marker;;LirNet Regulatory network;;The Telomere Module;;Some Chromatin Modules;;Chromatin as Mechanism;;The Puf3 Module;;P-Bodies;;Microscopy experiment;;What Regulates the P-bodies?;;Outline (3);;Motivation;;Bayesian L1-Regularization;;Metaprior Model (Hierarchical Bayes);;Metaprior Method;;Transfer Learning;;Learned regulatory weights;;Statistical Evaluation;;Biological evaluation I;;Biological Evaluation II;;What Regulates the P-Bodies?;;Mkt1;;Predicting Causal Regulators;;Learning Regulatory Priors;;Outline;;Regulation --> Phenotype;;Transformation of FL to DLBCL;;Module Network for Transformation;;Example Module – Cell Cycle;;Key Modules in Transformation;;Transformation Network;;Predicting Survival;;Therapeutic Implications? (1);;Therapeutic Implications? (2);;Conclusion;;Future Directions;;Acknowledgements'
11197,'lecture','en',11140,'2009-12-10','2010-01-19','Time Varying Graphical Models: Reverse Engineering and Analyzing Rewiring Networks','A plausible representation of the relational information among entities in dynamic systems such as a social community or a living cell is a stochastic network that is topologically rewiring and semantically evolving over time. While there is a rich literature in modeling static or temporally invariant networks, until recently, little has been done toward modeling the dynamic processes underlying rewiring networks, and on recovering such networks when they are not observable. In this talk, I will present a new formalism for modeling network evolution over time based on time-evolving probabilistic graphical models, such as TV-GGM, TV-MRF, and TV-DBN, and several new algorithms for estimating the structure of such models underlying nonstationary time-series of nodal attributes. I will show some promising results on recovering the latent sequence of evolving social networks in the US Senate based it voting history, and the gene networks over more than 4000 genes during the life cycle of Drosophila melanogaster from microarray time course, at a time resolution only limited by sample frequency. I will also sketch some theoretical results on the asymptotic sparsistency of the proposed methods.','Time-varying network;;The regulatory machine of gene expression;;Gene regulatory network;;Regulation of cell;;Biological regulations;;Time-Varying Gene regulations;;The big-picture questions (1);;The big-picture questions (2);;Focus of this talk;;Outline, background;;Background: Structure Learning;;Graph regression (1);;Graph regression (2);;Graph regression (3);;Theoretical properties;;Our problem;;Challenge;;Reverse engineer temporal;;Challenges;;Modeling time-varying graphs;;Inference (0);;Problem;;Outline, Algorithms;;Two scenarios;;Inference I;;Problem formulation;;Algorithm - neighborhood;;Graph regression (1);;Synthetic data;;Structural consistency of KELLER ;;Theorem;;Inference II;;Temporally smoothed graph regression;;Coefficients;;nips09_xing_tvgmrearn_01_35;;Structural consistency;;KELLER and TESLA;;Outline, Empirical analysis;;Drosophila life cycle;;Dynamic Gene Interactions;;Static versus dynamic;;Stage-specific gene;;Gene interactions;;Transient subgraph;;Transcriptional factor cascade;;TF cascade (1);;TF cascade (2);;TF cascade (3);;TF cascade (4);;Transient group;;Network tomography;;Dynamic tomography;;example;;Mixed membership;;Mixed-membership simplex;;Elvolving networks;;Algorithm: Mean field;;Samsons Monk Network ;;Drosophila network: vectors;;Drosophila network: distribution of role-vectors;;Drosophila network: selected genes;;Discussion;;Aknowledgment'
11198,'lecture','en',11140,'2009-12-10','2010-01-19','Novel Applications of Computational Biology in Infectious Disease Interventions','Interventions in infectious diseases are increasingly relying on computational biology and genomic methods. Estimating changes in viral genetic diversity in a population could be a new potential method to evaluate vaccination strategies in populations. Transgenic mosquitoes immune to a pathogen are being developed to replace the native mosquito vector of a number of vector-borne diseases. High throughput methods are being used to elucidate mechanisms of immune memory with the promise of developing better vaccines. Large-scale computer simulation models are useful for exploring interventions and could benefit from input from network and graph theory. In this talk, we discuss a few novel applications of computational biology in understanding infectious diseases and interventions.','Simulations and Estimation for Pandemic Influenza A (H1N1) ;;Our Flu Research Group;;Large-Scale Influenza Simulations;;Background;;Influenza Virus;;The Flu Virus;;Influenza Type A Virus Classification;;Influenza Disease;;Basic Reproductive Number, R0;;Reproductive Number, R;;Spread within the US;;Components of the Simulator;;FluTE;;Community Structure and Social Contacts;;Mixing groups ;;Mixing group contact matrix ;;Mixing group contact matrix (cont’d);;nips09_halloran_nacbidi_01_Page_18;;Calibration for desired R0;;Travel ;;Current Research on Contact Structure ;;Influenza: TimeLines;;Intervention Strategies Pandemic Influenza A(H1N1) Vaccines;;Child First, Late December Peak;;Real-Time Vaccination Considerations;;Measures of Vaccine Efficacy (1);;Measures of Vaccine Efficacy (2);;Combined efficacy;;Tottal efficacy (graph);; VE Estimates from Influenza Challenge Studies ;;Absolute Efficacy of Life Influenza Vaccine (1);;Absolute Efficacy of Life Influenza Vaccine (2);;Estimated Influenza Vaccine Efficacies (%);;Vaccine efficacy over time;;Epidemic peak and vaccine supply;;Impact of vaccination, October peak, R =1.4 ;;Impact of vaccination October peak, R=1.2;;Impact of vaccination, November peak, R=1.2;;School opening dates predict the timing of H1N1 epidemics by state;;Google Flu Trends;;Google Flu Trends - US;;Graph: Washington, Louisiana;;DHHS regional map;;Google Flu Trends;;School opening dates by state;;School opening dates by state(data for 19 states + Washington DC);;Translating ILI data (regional baselines and school opening);;Elevated influenza activity correlated with school opening date;; Unmitigated epidemic scenarios;;Current Vaccine Supply, R = 1.3;;What to do now peak is over?;;Global Model: early version;;Global Model;;Summary;;Sciencexpress;;Design and Analysis of Vaccine Studies (book);;Summer institute in statistics and modeling in infectious diseases;;Thank you!'
11205,'lecture','en',11287,'2009-12-11','2010-01-19','Direct Maximization of Protein Identifications from Tandem Mass Spectra',NULL,'Identifying Proteins Directly from Tandem Mass Spectra.;;Mass Spectrometry in Proteomics;;Challanges in Proteomics Applications;;Tandem Mass Spectrometry - 1;;Tandem Mass Spectrometry - 2;;Data Analysis;;From Spectra to Proteins;;From PSMs to Proteins: Related Work - 1;;From PSMs to Proteins: Related Work - 2;;Contributions;;Notation;;Peptide-Spectrum Match (PSM) Score;;Peptide Score - 1;;Peptide Score - 2;;Setting up Classication Problem on Protein Level - 1;;Setting up Classication Problem on Protein Level - 2;;Algorithm;;Classication Results (ROC);;Independent Experimental Assays ;;Are the Identied Proteins Correct?;;Overlap between ProteinProphet and Barista;;Investigating the Nature of the Set Complements;;Optimization Options;;Protein and Peptide Level Optimizations are Cooperative;;Conclusions;;References ;;nipsworkshops09_spivak_dmpi_01_Page_27'
11206,'lecture','en',11287,'2009-12-11','2010-01-19','Exploiting Physico-Chemical Properties in String-Kernels',NULL,'Exploiting Physico‐Chemical Properties in String Kernels;;String Kernels - 1;;String Kernels - 2;;String Kernels - 3;;What’s in a Letter? - 1;;What’s in a Letter? - 2;;What’s in a Letter? - 3;;Nature vs. String Kernels - 1;;Nature vs. String Kernels - 2;;Nature vs. String Kernels - 3;;Nature vs. String Kernels - 4;;Position‐Independent String Kernels - 1;;Position‐Independent String Kernels - 2;;Position‐Dependent String Kernels;;Incorporation of Physico‐Chemical Properties - 1;;Incorporation of Physico‐Chemical Properties - 2;;Incorporation of Physico‐Chemical Properties - 3;;Kernels on Amino Acid Substrings - 1;;Kernels on Amino Acid Substrings - 2;;Putting It All Together - 1;;Putting It All Together - 2;;Putting It All Together - 3;;Alternative Proposal for Spectrum Kernel - 1;;Alternative Proposal for Spectrum Kernel - 2;;Alternative Proposal for Spectrum Kernel - 3;;Alternative Proposal for Spectrum Kernel - 4;;Alternative Proposal for Spectrum Kernel - 5;;Alternative Proposal for Spectrum Kernel - 6;;Experiments - 1;;Background;;Performance on IEDB Benchmark;;Learning Curve on HLA‐A*0201;;Experiments - 2;;Results - 1;;Results - 2;;Results - 3;;Summary'
11207,'lecture','en',11287,'2009-12-11','2010-01-19','A Bayesian Method for 3D Reconstruction of Macromolecular Structure Using Class Averages from Single Particle Electron Microscopy',NULL,'A Bayesian Method for 3D Reconstruction of Macromolecular Structure using Class Averages from Single Particle Electron Cryo-Microscopy.;;Protein Structure Determination;;Problem Description;;Electron Cryo-Microscopy;;Electron-Density Projections - 1;;Electron-Density Projections - 2;;Electron-Density Projections - 3;;Raw Data -GroEL;;Raw Data –ATP Synthase - 1;;Raw Data –ATP Synthase - 2;;Raw Data –ATP Synthase - 3;;Problem Description;;Complications;;3D Structure Inference Pipeline - 1;;3D Structure Inference Pipeline - 2;;3D Structure Inference Pipeline - 3;;Traditional Approaches;;Our Approach –Generative Model - 1;;Our Approach –Generative Model - 2;;Inferring 3D Structure;;Representing 3D Structure;;Probability of a Class Average - 1;;Probability of a Class Average - 2;;Probability of a Class Average - 3;;Probability of a Class Average - 4;;Probability of a Class Average - 5;;Probability of a Class Average - 6;;Probability of a Class Average - 7;;Inferring 3D Structure;;Deterministic Annealing for Parameter Search - 1;;Deterministic Annealing for Parameter Search - 2;;Datasets;;Results;;ATP Synthase;;Conclusions & Future Work;;Acknowledgements'
11208,'lecture','en',11287,'2009-12-11','2010-01-19','vbFRET: A Bayesian Approach to Single-Molecule Forster Resonance Energy Transfer Analysis',NULL,'Learning Rates and States from Biophysical Time Series: A Bayesian Approach to Model Selection and Single-Molecule FRET Data;;smFRET;;smFRET: exponential popularity;;Want to learn;;Rates from dwell-time histograms of Viterbi paths;;Model the time series as a HMM;;Previous solution: maximum likelihood;;Problems with ML;;Possible solutions;;Maximum Evidence;;vbFRET;;ME/ML illustration;;vbFRET validation - 1;;vbFRET validation - 2;;Experimental testing: the ribosome;;ME finds extra states;;Blur artifacts;;Experimental results;;Experimental conclusions;;Future work: hierarchical modeling;;hFRET vs vbFRET - 1;;hFRET vs vbFRET - 2;;Dkl of transition matrix;;Acknowledgements'
11209,'lecture','en',11287,'2009-12-11','2010-01-19','Leveraging Joint Test Status Distribution for an Optimal Significance Testing',NULL,'nipsworkshops09_eskin_ljts_01_Page_01;;nipsworkshops09_eskin_ljts_01_Page_02;;nipsworkshops09_eskin_ljts_01_Page_03;;nipsworkshops09_eskin_ljts_01_Page_04;;nipsworkshops09_eskin_ljts_01_Page_05;;nipsworkshops09_eskin_ljts_01_Page_06;;nipsworkshops09_eskin_ljts_01_Page_07;;nipsworkshops09_eskin_ljts_01_Page_08;;nipsworkshops09_eskin_ljts_01_Page_09;;nipsworkshops09_eskin_ljts_01_Page_10;;nipsworkshops09_eskin_ljts_01_Page_11;;nipsworkshops09_eskin_ljts_01_Page_12;;nipsworkshops09_eskin_ljts_01_Page_13;;nipsworkshops09_eskin_ljts_01_Page_14;;nipsworkshops09_eskin_ljts_01_Page_15;;nipsworkshops09_eskin_ljts_01_Page_16;;nipsworkshops09_eskin_ljts_01_Page_17;;nipsworkshops09_eskin_ljts_01_Page_18;;nipsworkshops09_eskin_ljts_01_Page_19;;nipsworkshops09_eskin_ljts_01_Page_20;;nipsworkshops09_eskin_ljts_01_Page_21;;nipsworkshops09_eskin_ljts_01_Page_22;;nipsworkshops09_eskin_ljts_01_Page_23;;nipsworkshops09_eskin_ljts_01_Page_24;;nipsworkshops09_eskin_ljts_01_Page_25;;nipsworkshops09_eskin_ljts_01_Page_26;;nipsworkshops09_eskin_ljts_01_Page_27;;nipsworkshops09_eskin_ljts_01_Page_28;;nipsworkshops09_eskin_ljts_01_Page_29;;nipsworkshops09_eskin_ljts_01_Page_30;;nipsworkshops09_eskin_ljts_01_Page_31;;nipsworkshops09_eskin_ljts_01_Page_32;;nipsworkshops09_eskin_ljts_01_Page_33;;nipsworkshops09_eskin_ljts_01_Page_34;;nipsworkshops09_eskin_ljts_01_Page_35;;nipsworkshops09_eskin_ljts_01_Page_36;;nipsworkshops09_eskin_ljts_01_Page_37;;nipsworkshops09_eskin_ljts_01_Page_38;;nipsworkshops09_eskin_ljts_01_Page_39;;nipsworkshops09_eskin_ljts_01_Page_40;;nipsworkshops09_eskin_ljts_01_Page_41;;nipsworkshops09_eskin_ljts_01_Page_42;;nipsworkshops09_eskin_ljts_01_Page_43;;nipsworkshops09_eskin_ljts_01_Page_44;;nipsworkshops09_eskin_ljts_01_Page_45;;nipsworkshops09_eskin_ljts_01_Page_46;;nipsworkshops09_eskin_ljts_01_Page_47;;nipsworkshops09_eskin_ljts_01_Page_48;;nipsworkshops09_eskin_ljts_01_Page_49;;nipsworkshops09_eskin_ljts_01_Page_50;;nipsworkshops09_eskin_ljts_01_Page_51;;nipsworkshops09_eskin_ljts_01_Page_52;;nipsworkshops09_eskin_ljts_01_Page_53;;nipsworkshops09_eskin_ljts_01_Page_54;;nipsworkshops09_eskin_ljts_01_Page_55;;nipsworkshops09_eskin_ljts_01_Page_56;;nipsworkshops09_eskin_ljts_01_Page_57;;nipsworkshops09_eskin_ljts_01_Page_58;;nipsworkshops09_eskin_ljts_01_Page_59;;nipsworkshops09_eskin_ljts_01_Page_60;;nipsworkshops09_eskin_ljts_01_Page_61;;nipsworkshops09_eskin_ljts_01_Page_62;;nipsworkshops09_eskin_ljts_01_Page_63;;nipsworkshops09_eskin_ljts_01_Page_64;;nipsworkshops09_eskin_ljts_01_Page_65;;nipsworkshops09_eskin_ljts_01_Page_66;;Leveraging joint test status distribution for an optimal significance testing;;Observation -1;;Observation -2;;Observation -3;;Observation -4;;Why do we care?;;Hot Off The Press;;Cross tissue eQTL Maps;;Proportion of Tissue Specific wQTLs;;Standard Method;;Lack of Powert in Standard Method;;Multiple Decision Discovery Procedure;;Relationship Between One Gene and One SNP;;Standard Likelihood Ratio Test;;Plotting the Statistics -1;;Plotting the Statistics -2;;Plotting the Statistics -3;;Plot of Statistics;;Liver Specific eQTL;;Kidney Specific eQTL;;Cross Tissue eQTL;;What about eQTL D?;;How Do We call eQTL D Significant Using Standars Methods? -1;;How Do We call eQTL D Significant Using Standars Methods? -2;;How Do We call eQTL D Significant Using Standars Methods? -3;;Intuition -1;;Intuition -2;;Multidimensional Discovery Procedure (MDDP) Statistic -1;;Multidimensional Discovery Procedure (MDDP) Statistic -2;;MDDP Statistic Properties;;Rejection Region of Meng et al. -1;;Rejection Region of Meng et al. -2;;Rejection Region of Meng et al. -3;;Rejection Region of Meng et al. -4;;What to estimate?;;Estimating the Priors;;Estimating The Joint Likelihoods;;Simulation Parameters;;Increased Power to Detect shared eQTLs in Simulation -1;;Increased Power to Detect shared eQTLs in Simulation -2;;Does Not Lose Power When eQTLs Are Not Shared;;EQTL Mapping -1;;EQTL Mapping -2;;EQTL Map;;Cis - regulatory Band;;Liver Test Dataset -1;;Liver Test Dataset -2;;Shared cis-eQTL Concordance to Original Liver Data -1;;Shared cis-eQTL Concordance to Original Liver Data -2;;Shared cis-eQTL Concordance to Original Liver Data -3;;Data Analysis Summary -1;;Data Analysis Summary -2;;Performance on Real Data -1;;Performance on Real Data -2;;Biological Questions;;Summary of Datasets;;What\'s the Distribution of cis-eQTLs?;;What About Replication Studies -1;;What About Replication Studies -2;;What About Replication Studies -3;;Distribution of cis-eQTLs;;Clusters of cis-eQTLs;;PANTHER Overlap Analysis -1;;PANTHER Overlap Analysis -2;;Section Summary & Other Applications;;Acknowledgements'
11210,'lecture','en',11287,'2009-12-11','2010-01-19','Statistical Methods for Ultra-Deep Pyrosequencing of Fast Evolving Viruses',NULL,'Statistical tools for ultra‐deep pyrosequencingof fast evolving viruses;;Motivation - 1;;Motivation - 2;;454 Pyrosequencing - 1;;454 Pyrosequencing - 2;;Detecting minor Hep‐B variants;;Sources of error;;Jargon;;Fitting the “noise”;;Overdispersion - 1;;Overdispersion - 2;;Some reads are terrible;;Indels accumulate along a read;;Some mismatches are common;;PCR simulation - 1;;PCR simulation - 2;;PCR simulation - 3;;Estimating the mismatch matrix - 1;;Estimating the mismatch matrix - 2;;Hypothesis testing - 1;;Hypothesis testing - 2;;Mixture model;;Compare to 95 Sanger limiting dilution sequences;;Conclusion;;Thanks'
11211,'lecture','en',11287,'2009-12-11','2010-01-19','A Machine Learning Pipeline for Phenotype Prediction from Genotype Data',NULL,'A Machine Learning Pipeline for Phenotype Prediction from Genotype Data;;General Framework -1;;General Framework -2;;Reference Data and Study;;Background -1;;Background -2;;Multivariate and ML approaches;;I1 - I2 Regularization -1;;I1 - I2 Regularization -2;;Data Analysis Protocol: overview;;Preprocessing;;L1L2 workflow;;Model selection;;Prediction accuracy;;Top-k Analysis;;Results: feature selection;;Conclusion;;Supplementary Material -1;;Supplementary Material -2;;Supplementary Material -3'
11212,'lecture','en',11287,'2009-12-11','2010-02-15','Association Mapping of Traits over Time Using Gaussian Processes',NULL,'Association mapping of time series of phenotypes using Gaussian Process;;Association studies -1;;Association studies -2;;Association studies -3;;Association studies -4;;Association studies -5;;Association studies -6;;Association studies -7;;Outline -1;;Outline -2;;Single regulator model -1;;Single regulator model -2;;Single regulator model -3;;Single regulator model -4;;Single regulator model -5;;Single regulator model -6;;Gaussian Process model -1;;Gaussian Process model -2;;Gaussian Process model -3;;Gaussian Process model -4;;Gaussian Process model -5;;Gaussian Process model -6;;Gaussian Process model -7;;Gaussian Process model -8;;Gaussian Process model -9;;Gaussian Process model -10;;Gaussian Process model -11;;Gaussian Process model -12;;Gaussian Process model -13;;Gaussian Process model -14;;Gaussian Process model -15;;Illustration of the model comparison -1;;Illustration of the model comparison -2;;Illustration of the model comparison -3;;Application to the differential gene expression;;Multiple regulators -1;;Multiple regulators -2;;Covariance function -1;;Covariance function -2;;\"Clustering\" property of the covariance function;;Feature selection -1;;Feature selection -2;;Feature selection -3;;Feature selection -4;;Feature selection -5;;Outline -3;;Simulation study;;Depression dataset -1;;Depression dataset -2;;Predictive power -1;;Predictive power -2;;Predictive power -3;;Predictive power -4;;Outline -4;;Conclusions and future work -1;;Conclusions and future work -2;;Conclusions and future work -3;;Backup slides;;Gaussian Process Model -1;;Gaussian Process Model -2;;Robustness With Respect to Outliers -1;;Robustness With Respect to Outliers -2;;Robustness With Respect to Outliers -3;;Smooth Time-local GPT woSample -1;;Smooth Time-local GPT woSample -2;;Smooth Time-local GPT woSample -3;;Kernel functions'
11213,'lecture','en',11287,'2009-12-11','2010-01-19','Learning Graphical Model Structure with Sparse Bayesian Factor Models and Process Priors',NULL,'Learning Graphical Model Structure with Sparse Bayesian Factor Models and Process Priors;;Goals ;;Challenges;;DAG representation of a d-dimensional data vectot Px;;Factor model;;Picture -1;;DAG;;Allowing for variabillity;;Latent factors;;The TP model;;Sparsity importance;;Sparsity priors;;Picture -2;;Picture -3;;Picture -4;;Picture -5;;Picture -6;;Picture -7;;Picture -8;;Picture -9;;Picture -10;;The joint probability for the factor model;;Bayesian sparse factor model -1;;Bayesian sparse factor model -2;;Bayesian sparse factor model -3;;Bayesian sparse factor model -4;;Bayesian sparse factor model -5;;Bayesian sparse factor model -6;;Bayesian sparse DAG -1;;Bayesian sparse DAG -2;;Bayesian sparse DAG -3;;Bayesian sparse DAG -4;;Bayesian sparse DAG -5;;Picture -11;;Picture -12;;Picture -13;;Picture -14;;Picture -15;;Picture -16;;Picture -17;;Usually factor model or DAG is assumed a-priori;;Artificial data;;Picture -18;;Temporal gene expression profiles;;Picture -19;;Picture -20;;Picture -21;;Summary;;References'
11214,'lecture','en',11287,'2009-12-11','2010-01-19','Scalable Hierarchical Multitask Learning in Sequence Biology',NULL,'Scalable hierarhical multitask learning in sequence biology;;Why multitask learning?;;Why Hierarchies?;;What problems could benefit from this?;;Formal Problem Definition;;Two ways of leveraging a given taxonomy;;Domain Adaptation by Regularization;;Hierarchical Top-Down Approach -1;;Hierarchical Top-Down Approach -2;;Pairwise Approach;;Multitask Kernel Approach;;Method Comparison;;Toy Data Generation;;Results Toy;;Application to splice-site recognition;;Results Splicing Data;;Summary and Discussion;;Acknowledgements ;;That\'s it'
11215,'lecture','en',11287,'2009-12-11','2010-01-19','Abstraction Augmented Markov Models',NULL,'Abstruction Augmented Markov Models;;Real World Applications;;Outline -1;;Outline -2;;Learning Probabilistic Models on Sequence Data;;Kth- Order Markov Models;;Outline -3;;Abstarction Augmented Markov Models;;Abstarction Hierarchies and m-Cuts;;Abstraction Augmented Markov Models;;Learning Abstarction Hierarchies -HAC;;Similarity Function for Merging Abstractions -JS;;Estimating AAMM Parameters;;Using AAMMs for Classification;;Outline -4;;Data sets;;AAMMs in a Supervised Setting -1;;AAMMs in a Supervised Setting -2;;AAMMs in a Semi-Supervised Setting -1;;AAMMs in a Semi-Supervised Setting -2;;Comparison of Algorithms for Learning AHs -1;;Comparison of Algorithms for Learning AHs -2;;Summary;;Feature Directions;;Thank you'
11268,'invited talk','en',11293,'2009-12-12','2010-01-19','Geostatistics for Gaussian Processes ','Gaussian process methodology has inspired a number of stimulating new ideas in the area of machine learning. Kriging has been introduced as a statistical interpolation method for the design of computer experiments twenty years ago. However, some aspects of the geostatistical methodology originally developed for natural resource estimation have been ignored when switching to this new context. This talk reviews concepts of geostatistics and in particular the estimation of components of spatial variation in the context of multiple correlated outputs.','Geostatistics for Gaussian processes;;Introduction;;Geostatistics and Gaussian processes;;Geostatistics -1;;Geostatistics -2;;Geostatistics: definition;;Stationarity;;Second-order stationary model;;Non-stationary model;;The variogram;;What is a variogram?;;Ordinary kriging;;Mobile phone exposure of children;;Phone position and child head;;SAR exposure;;Max SAR for different positions of phone;;Variogram;;Max SAR kriged map;;Prediction error -1;;Prediction error -2;;Geostatistical Model;;Linear model of coregialization;;Two linear models;;Linear Model of Coregionalization;;Coregionalization matrices;;LMC: intrinsic correlation;;Regionalized Multivariate Data Analysis;;Regionalized PCA?;;Multivariate Geostatistical filtering;;Modeling of spatial variability;;Geostatical filtering;;Zoom into corner;;Cokriging in NE corner;;Consequence;;Covariance structure;;Separable multivariate and spatial correlation;;Codispersion Coefficients;;Intrinsic Correlation;;Testing for Intrinsic Correlation;;Cross variogram;;Testing for Intrinsic Cerrelation;;Cokriging;;Ordinary cokriging;;Data configuration and neighborhood;;Data configurations;;Configuration -1;;Configuration -2;;Neighborhood -1;;Neighborhood -2;;Neighborhood -3;;Cokriging neighborhoods;;Conclusion -1;;Conclusion -2;;Acknowledgements;;References;;Appendix;;Geostatistical simulation;;Conditional Gaussian simulation;;Geostatisticiants do not use the gaussian covariance function;;Stable covariance functions;;Davis data set;;Stable covariance function -1;;Stable covariance function -2;;Conclusion'
11269,'invited talk','en',11293,'2009-12-12','2010-01-19','Gaussian Processes and Process Convolutions from a Bayesian Perspective',NULL,'Bayesian inference & process convolution models;;MOVING AVERAGE SPATIAL MODELS;;Kernel basis representation for spatial processes;;x and k(s) determine spatial processes;;Estimate z(s) by specifying kj(s) and estimating x;;Formulation for the 1-d example;;Posterior and full conditionals;;Gibbs sampler: intuition (1);;Gibbs sampler: intuition (2);;1-d example (1);;1-d example (2);;1-d example (3);;1-d example (4);;Basis representations for spatial processes z(s);;decomposition, basis, covariance;;How many basis kernels?;;Moving average specifications for spatial models z(s);;Uses;;Example: constructing 1-d models for z(s);;Kernes and include covariance functions;;MRF formulation for the 1-d example;;Posterior and full conditionals (MRF formulation);;1-d example - using MRF prior for x;;8 hour max for ozone on a summer day in the Eastern US;;A multiresolution spatial model formulation;;Multiresolution formulation and full conditionals;;Multiresolution model for 8 hour max ozone;;Basic binary classification example;;Constructing a binary spatial process z* (s)z(s);;Model Formulation;;Sampling the posterior via Metropolis;;Sampling from non-standard multivariate distributions;;Gibbs Sampling and Metropolis for a bivariate normal density;;Posterior realizations of z)(s) = I[z(s) > 0];;Posterior mean of z)(s) = I[z(s) > 0];;Application – locating archeological sites;;Posterior mean and realizations for z)(s) = I[z(s) > 0];;Bayesian formulation;;Posterior realizations of z under MRF and moving average priors;;nipsworkshops09_higdon_gppcbp_01_Page_40;;nipsworkshops09_higdon_gppcbp_01_Page_41;;A convolution-based approach for building non-stationary spatial models;;A convolution-based approach for building non-stationary spatial models;;Defining smoothly varying kernels via basis kernels (1);;Defining smoothly varying kernels via basis kernels (2);;An application to Piazza Road Superfund site;;MOVING AVERAGE/BASIS SPACE-TIME MODELS;;A convolution-based approach for building space-time models;;A Space-time model for ocean temperatures;;Knot locations and kernels;;Formulation for the ocean example;;Full conditionals for ocean formulation;;Posterior mean of the space-time temperature field;;Deviations from time-averaged mean temperature field;;Posterior probabilities of differing from time-averaged mean field;;Alternative approaches for building space-time models;;8 hour max for ozone over summer days in the Eastern US;;Temporally evolving latent x(s, t) process;;Formulation for temporally evolving z(s, t);;nipsworkshops09_higdon_gppcbp_01_Page_60;;nipsworkshops09_higdon_gppcbp_01_Page_61;;Posterior mean for first 9 days;;Posterior mean of selected xj’s;;References'
11270,'lecture','en',11293,'2009-12-12','2010-01-19','Prior Knowledge and Sparse Methods for Convolved Multiple Outputs Gaussian Processes','One approach to account for non-trivial correlations between outputs employs convolution processes. Under a latent function interpretation of the convolution transform it is possible to establish dependencies between output variables. Two important aspects in this framework are how can we introduce prior knowledge and how can we perform efficient inference. Relating the convolution operation with dynamical systems, we can specify richer covariance functions for multiple outputs. We also present different sparse approximations for dependent output Gaussian processes in the context of structured covariances. Joint work with Neil Lawrence, David Luengo and Michalis Titsias. ','Prior Knowledge and Sparse Methods for Convolved Multiple Outputs Gaussian Processes;;Contents;;Data driven paradigm;;Mechanistic models;;Hybrid systems;;Latent variable model: definition;;Latent variable model: alternative view;;Latent force model: mechanistic interpretation (1);;Latent force model: mechanistic interpretation (2), 1;;Latent force model: mechanistic interpretation (2), 2;;Latent force model: mechanistic interpretation (2), 3;;Latent force model: extension (1);;Latent force model: extension (2), 1;;Latent force model: extension (2), 2;;Latent force model: extension (2), 3;;Latent force model: properties;;Second Order Dynamical System;;Second Order Dynamical System: solution;;Second Order Dynamical System: covariance matrix;;Second Order Dynamical System: samples from GP, 1;;Second Order Dynamical System: samples from GP, 2;;Second Order Dynamical System: samples from GP, 3;;Second Order Dynamical System: samples from GP, 4;;Motion Capture Data (1);;Motion Capture Data (2);;Motion Capture Results;;Diffussion in the Swiss Jura,1;;Diffussion in the Swiss Jura, 2;;Diffussion in the Swiss Jura, 3;;Diffussion in the Swiss Jura, 4;;Diffusion equation;;Prediction of Metal Concentrations;;LFM in the context of convolution processes;;A pictorial representation, 1;;A pictorial representation, 2;;A pictorial representation, 2;;A pictorial representation, 3;;A pictorial representation, 4;;Covariance of the output functions.;;Likelihood of the full Gaussian process.;;Predictive distribution of the full Gaussian process.;;Conditional prior distribution., 1;;Conditional prior distribution., 2;;Conditional prior distribution., 3;;The conditional independence assumption I.;;The conditional independence assumption II., 1;;The conditional independence assumption II., 2;;Comparison of marginal likelihoods, 1;;Comparison of marginal likelihoods, 2;;Comparison of marginal likelihoods, 3;;Predictive distribution for the sparse approximation;;Remarks;;Additional conditional independencies, 1;;Additional conditional independencies, 2;;Additional conditional independencies, 3;;Comparison of marginal likelihoods, 1;;Comparison of marginal likelihoods, 2;;Comparison of marginal likelihoods, 3;;Comparison of marginal likelihoods, 4;;Comparison of marginal likelihoods, 5;;Comparison of marginal likelihoods, 6;;Computational requirements;;Deterministic approximation;;Examples;;Examples: Artificial data 1D;;Artificial example (cont.);;Predicting school examination scores;;Predicting school examination scores (cont.);;A dynamic model for transcription regulation;;A dynamic model for transcription regulation (cont.), 1;;A dynamic model for transcription regulation (cont.), 2;;A dynamic model for transcription regulation (cont.), 3;;A dynamic model for transcription regulation (cont.), 4;;Swiss Jura example revisited;;Conclusions;;Acknowledgments;;References I;;References II, Questions'
11271,'invited talk','en',11293,'2009-12-12','2010-01-19','Multi-Task Learning and Matrix Regularization','Multi-task learning extends the standard paradigm of supervised learning. In multi-task learning, samples for multiple related tasks are given and the goal is to learn a function for each task and also to generalize well (transfer learned knowledge) on new tasks. The applications of this paradigm are numerous and range from computer vision to collaborative filtering to bioinformatics while it also relates to vector valued problems, multiclass, multiview learning etc. I will present a framework for multi-task learning which is based on learning a common kernel for all tasks. I will also show how this formulation connects to the trace norm and group Lasso approaches. Moreover, the proposed optimization problem can be solved using an alternating minimization algorithm which is simple and efficient. It can also be \"kernelized\" by virtue of a multi-task representer theorem, which holds for a large family of matrix regularization problems and includes the classical representer theorem as a special case.','Multi-Task Learning and Matrix Regularization;;Outline;;Multi-Task Learning;;Transfer;;Multi-Task Applications;;Matrix Completion;;Related Problems;;Learning Multiple Tasks with a Common Kernel (1);;Learning Multiple Tasks with a Common Kernel (2);;Alternating Minimization Algorithm;;Alternating Minimization (contd.) (1);;Alternating Minimization (contd.) (2);;Trace Norm Regularization;;Trace Norm vs. Rank;;Machine Learning Interpretations;;“Rotation invariant” Group Lasso;;Experiment (Computer Survey) (1);;Experiment (Computer Survey) (2);;Generalizations: Spectral Regularization;;Generalizations: Learning Groups of Tasks;;Nonlinear Kernels;;Representer Theorems;;Representer Theorems (contd.) (1);;Representer Theorems (contd.) (2);;Multi-Task Representer Theorems;;Multi-Task Representer Theorems (contd.);;Implications;;Refinements of the MTL Representer Theorem;;Refinements of the MTL Representer Theorem (contd.) (1);;Refinements of the MTL Representer Theorem (contd.) (2);;Conclusion'
11272,'lecture','en',11293,'2009-12-12','2010-01-19','Learning Vector Fields with Spectral Filtering','We present a class of regularized kernel methods for vector valued learning, which are based on filtering the spectrum of the kernel matrix. The considered methods include Tikhonov regularization as a special case, as well as interesting alternatives such as vector valued extensions of L2 boosting. While preserving the good statistical properties of Tikhonov regularization, some of the new algorithms allows for a much faster implementation since they require only matrix vector multiplications. We discuss the computational complexity of the different methods, taking into account the regularization parameter choice step. The results of our analysis are supported by numerical experiments.','Spectral Filtering for MultiOutput Learning;;Plan;;Scalar Case;;Kernels and Regularization;;Kernel Design;;Multiple Outputs;;RKHS;;Which Kernels?;;Kernels and Regularizers;;Example: Mixed Effect;;Example: Clustering Outputs;;Example: Graph;;Inference and Computations;;Ill-posed Problems;;Regularization and Filtering (1);;Regularization and Filtering (2);;Classical Examples;;Other Examples;;Early Stopping;;Early stopping at work (1);;Early stopping at work (2);;Early stopping at work (3);;Early stopping at work (4);;Remarks;;Fast Solution for Tikhonov Regularization;;Vector fields;;Useful Kernels;;Numerical Results (1);;Numerical Results (2);;Some Theory: Random Operators;;Learning Rates;;Comments;;Vector Fields and Multi-tasks;;Different Regimes?;;Multiple Classes;;One Versus All;;Remarks;;nipsworkshops09_rosasco_lvfsf_01_Page_38;;nipsworkshops09_rosasco_lvfsf_01_Page_39'
11273,'invited talk','en',11293,'2009-12-12','2010-01-19','Borrowing Strength, Learning Vector Valued Functions and Supervised Dimension Reduction','We study the problem of supervised dimension reduction from the perspective of learning vector valued\nfunctions and multi-task or hierarchical modeling in ai regularization framework. An algorithm is specied\nand empirical results are provided. In the second part of the talk the same problem of supervised dimension\nreduction for a hierarchical model is revisted from a non-parametric Bayesian perspective.','Geometric perspectives for supervised dimension reduction (A Tale of Two Manifolds);;Information and sufficiency (1);;Information and sufficiency (2);;Regression (1);;Regression (2);;Dimension reduction (1);;Dimension reduction (2);;Supervised dimension reduction (SDR) (1);;Supervised dimension reduction (SDR) (2);;Visualization of SDR;;Linear projections capture nonlinear manifolds (1);;Linear projections capture nonlinear manifolds (2);;SDR model (1);;SDR model (2);;Gradients and outer products (1);;Gradients and outer products (2);;GOP captures the d.r. space (1);;GOP captures the d.r. space (2);;GOP captures the d.r. space (3);;Statistical interpretation (1);;Statistical interpretation (2);;Statistical interpretation (3);;Nonlinear case (1);;Nonlinear case (2);;Nonlinear case (3);;Nonlinear case (4);;Nonlinear case (5);;Nonlinear case (6);;Estimating the gradient (1);;Estimating the gradient (2);;Estimating the gradient (3);;Estimating the gradient (4);;Computational efficiency (1);;Computational efficiency (2);;Estimates on manifolds;;Convergence to gradient on manifold;;Multi-task learning (1);;Multi-task learning (2);;Multi-task gradient learning (1);;Multi-task gradient learning (2);;Multi-task gradient learning (3);;Multi-task gradient learning (4);;Principal components analysis (PCA) (1);;Principal components analysis (PCA) (2);;Probabilistic PCA (1);;Probabilistic PCA (2);;SDR model;;Principal fitted components (PFC) (1);;Principal fitted components (PFC) (2);;Principal fitted components (PFC) (3);;Mixture models and localization (1);;Mixture models and localization (2);;Mixture models and localization (3);;Model specification;;Dimension reduction space;;Sampling distribution;;Categorical response: modeling Gy (1);;Categorical response: modeling Gy (2);;Categorical response: modeling Gy (3);;Likelihood;;Posterior inference (1);;Posterior inference (2);;Posterior inference (3);;Posterior inference (4);;Markov chain Monte Carlo (1);;Markov chain Monte Carlo (2);;Markov chain Monte Carlo (3);;Sampling from the posterior (1);;Sampling from the posterior (2);;Gibbs sampling (1);;Gibbs sampling (2);;Gibbs sampling (3);;Gibbs sampling (4);;Posterior draws from the Grassmann manifold (1);;Posterior draws from the Grassmann manifold (2);;Posterior mean and variance (1);;Posterior mean and variance (2);;Posterior mean and variance (3);;Posterior mean and variance (4);;Distribution theory on Grassmann manifolds;;Swiss roll;;Pictures;;Metric;;Comparison of algorithms;;Posterior variance;;Error as a function of d;;Digits;;Two classification problems (1);;Two classification problems (2);;BMI;;3, 5, 8 Classification Problem (1);;3, 5, 8 Classification Problem (2);;Top features: 3 and 5 vs 8;;Top features: 3 vs 8;;Top features: 5 vs 8;;All ten digits;;Cancer classification;;Substructure captured;;Funding'
11274,'lecture','en',11294,'2009-12-12','2010-01-19','Approximate Inference in Natural Language Processing','I\'ll start out by presenting an idealized version of the natural language processing problem of parsing. I will brazenly suggest that most of NLP is reducible to variations on parsing problems. I\'ll show how dynamic programming solves the idealized version of the problem, both for calculating modes and marginals over parse trees, exploiting some key independence assumptions about the structure of natural language sentences. \n\nI will then discuss two approximate inference methods that let us build more powerful models of parsing. Neither comes with strong theoretical guarantees, but both are demonstrated to perform strongly in experiments on real NLP data. The first method builds on the dynamic programming representation, combining max-product and sum-product methods to produce, approximately, the k-best parses and a residual sum over the rest of the parses, useful when incorporating features that violate the usual independence assumptions. Experiments validate the approach with a discriminative model for machine translation. \n\nThe second method turns a parsing problem instance into a concise integer linear program. Approximate inference is then accomplished using well-known linear program relaxation. This is embedded in a new online learning algorithm that tries to penalize uninterpretable fractional solutions (and therefore inference cost at evaluation time). We show that this approach leads to state-of-the-art parsing performance on seven languages, with improved speed for both exact and approximate inference and no significant performance loss.','Approximate Inference in Natural Language Processing;;Requisite Joke -1;;Requisite Joke -2;;Talk Outline -1;;Natural Language Parsing;;Context-Free Dependency Parsing;;Parsing with CFGs;;Parsing and Inference -1;;Parsing and Inference -2;;Context-Free Dependency Parsing -1;;Context-Free Dependency Parsing -2;;Context-Free Dependency Parsing -3;;Context-Free Dependency Parsing -4;;Combining Items to Create Updates;;Context-Free Dependency Parsing -5;;Context-Free Dependency Parsing -6;;Context-Free Dependency Parsing -7;;Context-Free Dependency Parsing -8;;Context-Free Dependency Parsing -9;;Context-Free Dependency Parsing -10;;Context-Free Dependency Parsing -11;;Context-Free Dependency Parsing -12;;Context-Free Dependency Parsing -13;;Parsing and Supervised Learning;;Manual Parse ;;Automatic Parse;;What\'s the Trajectory;;NB;;Talk Outline -2;;Local and Non-Local Features -1;;Local and Non-Local Features -2;;Local and Non-Local Features -3;;Local and Non-Local Features -4;;Non-local Features and DP;;Combining items;;k-Best Combinators -1;;k-Best Combinators -2;;k-Best Combinators with Non-Local Features -1;;k-Best Combinators with Non-Local Features -2;;k-Best Combinators with Non-Local Features -3;;k-Best;;k-Best Combinations with \"Residuals\" -1;;k-Best Combinations with \"Residuals\" -2;;k-Best Combinations with \"Residuals\" -3;;k-Best Combinations with \"Residuals\" -4;;k-Best Combinations with \"Residuals\" -5;;k-Best Combinations with \"Residuals\" -6;;k-Best Combinations with \"Residuals\" -7;;k-Best Combinations with \"Residuals\" -8;;Formally;;Application to Machine Translation;;MT Performance;;MT Conclusion;;Talk Outline -3;;The \"Projectivity\" Constraint -1;;The \"Projectivity\" Constraint -2;;Nonprojective Parsing;;Concise ILP Formulation;;LP Relaxation;;Parsing;;Relaxation Gap -1;;Relaxation Gap -2;;Encouraging Integer Solutions;;Dependency Parsing;;Time Relaxation Gap;;Time Speed;;Example -1;;Example -2;;Conclusion;;Acknowledgments;;Publications'
11275,'lecture','en',11294,'2009-12-12','2010-01-19','Learning Deep Boltzmann Machines',NULL,'Learning Deep Boltzmann Machines;;Outline;;Boltzmann Machines;;Restricted Biltzmann Machines;;Boltzmann Machines: Learning;;Learning -1;;Learning -2;;Stochastic Approximation -1;;Stochastic Approximation -2;;Stochastic Approximation -3;;Variational Inference;;Learning BM\'s;;MNIST -1;;Deep Boltzmann Machines -1;;MNIST -2;;Learning DBM\'s;;An experiment;;Annealing;;Evaluating DBM\'s;;Benchmark experiment;;Gaussian-Bernoulli RBM\'s;;NORB data;;Deep Boltzmann Machines -2;;Model Samples;;Image Completion;;Dimensionality Reduction;;Thank you;;Deterministic Learning -1;;Deterministic Learning -2;;Deterministic vs. Stochastic;;DBM\'s vs. DBN\'s'
11276,'lecture','en',11294,'2009-12-12','2010-01-19','Joint Max Margin and Max Entropy Learning of Graphical Models','Inferring structured predictions based on correlated covariates remains a central problem in many fields, including NLP, computer vision, and computational biology. Popular paradigms for training structured input/output models include the maximum (conditional) likelihood estimation, which leads to the well-known CRF; and the max-margin learning, which leads to the structured SVM (a.k.a. M3N), each enjoys some advantages, as well as weaknesses. In this talk, I present a new general framework called Maximum Entropy Discrimination Markov Networks (MEDN), which integrates the margin-based and likelihood-based approaches and combines and extends their merits. This new learning paradigm naturally facilitates integration of the generative and discriminative principles under a unified framework, and the basic strategies can be generalized to learn arbitrary graphical models, such as the generative Bayesian networks or models with structured hidden variables. I will discuss a number of theoretical properties of this model, and show applications of MEDN to learning fully supervised structured i/o model, max-margin structured i/o models with hidden variables, and a max-margin LDA model for jointly discovering discriminative latent topic representations and predicting document label/score of text documents, with compelling performance in each case.','Joint Max Margin & Max Entropy Learning of Graphical Models;;Structured Inference Problem;;Classical Predictive Models;;Structured Prediction Models;;Example I: Image Segmentation;;Example II: Genome-Phenome association in complex diseases;;Structured Prediction Models;;Outline;;MLE versus max-margin learning;;Max-Margin Learning Paradigms;;Primal and Dual Problems of M3Ns;;MaxEnt Discrimination Markov Network;;Solution to MaxEnDNet;;Gaussian MaxEnDNet (reduction to M3N);;Three Advantages;;I: Generalization Guarantee;;II: Laplace MaxEnDNet (primal sparse M3N);;LapMEDN vs. L2 and L1 regularization;;Variational Learning of LapMEDN;;Experimental results on OCR datasets (1);;Experimental results on OCR datasets (2);;Feature Selection;;Sensitivity to Regularization Constants;;III: Latent Hierarchical MaxEnDNet;;Partially Observed MaxEnDNet (PoMEN);;Alternating Minimization Alg.;;Experimental Results;;Record-Level Evaluations;;Page-Level Evaluations;;VI: Max-Margin/Max Entropy Topic Model – MED-LDA;;LDA: a generative story for documents;;LDA: Latent Dirichlet Allocation;;Supervised Topic Model (sLDA);;The big picture;;MedLDA Regression Model;;MedLDA Classification Model;;Variational EM Alg.;;MedTM: a general framework;;Experiments;;Document Modeling;;Document Modeling (cont’);;Classification;;Regression;;Time Efficiency;;Summary;;nipsworkshops09_xing_jmmelgm_01 _Page_46;;nipsworkshops09_xing_jmmelgm_01 _Page_47;;nipsworkshops09_xing_jmmelgm_01 _Page_48'
11277,'lecture','en',11294,'2009-12-12','2010-01-19','Large-Scale Learning and Inference: What We Have Learned with Markov Logic Networks','Markov logic allows very large and rich graphical models to be compactly specified. Current learning and inference algorithms for Markov logic can routinely handle models with millions of variables, billions of features, thousands of latent variables, and strong dependencies. In this talk I will give an overview of the main ideas in these algorithms, including weighted satisfiability, MCMC with deterministic dependencies, lazy inference, lifted inference, relational cutting planes, scaled conjugate gradient, relational clustering and relational pathfinding. I will also discuss the lessons learned in developing successive generations of these algorithms and promising ideas for the next round of scaling up.','Large-Scale Learning and Inference: What We Have Learned withMarkov Logic Networks;;Markov Logic Networks;;MLN Algorithms:The First Three Generations;;Weighted Satisfiability;;Lazy Inference;;Cutting Plane Inference;;MC-SAT;;Lifted Inference;;Belief Propagation;;nipsworkshops09_domingos_lsliwwlmln_01_Page_10;;nipsworkshops09_domingos_lsliwwlmln_01_Page_11;;Forming the Lifted Network;;Weight Learning;;Weight Learning (contd.);;Structure Learning;;Clustering + Pathfinding;;MLNs: The Next Generation;;Resources'
11278,'lecture','en',11294,'2009-12-12','2010-01-19','Parameter Learning Using Approximate MAP Inference ','In recent years, machine learning has seen the development of a series of algorithms for parameter learning that avoid estimating the partition function and instead, rely on accurate approximate MAP inference. Within this framework, we consider two new topics. \n\nIn the first part, we discuss parameter learning in a semi-supervised scenario. Specifically, we focus on a region-based scene segmentation model that explains an image in terms of its underlying regions (a set of connected pixels that provide discriminative features) and their semantic labels (such as sky, grass or foreground). While it is easy to obtain (partial) ground-truth labeling for the pixels of a training image, it is not possible for a human annotator to provide us with the best set of regions (those that result in the most discriminative features). To address this issue, we develop a novel iterative MAP inference algorithm which selects the best subset of regions from a large dictionary using convex relaxations. We use our algorithm to \"complete\" the ground-truth labeling (i.e. infer the regions) which allows us to employ the highly successful max-margin training regime. We compare our approach with the state of the art methods and demonstrate significant improvements. \n\nIn the second part, we discuss a new learning framework for general log-linear models based on contrastive objectives. A contrastive objective considers a set of \"interesting\" assignments and attempts to push up the probability of the correct instantiation at the expense of the other interesting assignments. In contrast to our approach, related methods such as pseudo-likelihood and contrastive divergence compare the correct instantiation only to nearby instantiations, which can be problematic when there is a high-scoring instantiation far away from the correct one. We present some of the theoretical properties and practical advantages of our method, including the ability to learn a log-linear model using only (approximate) MAP inference. We the theoretical properties and practical advantages of our method, including the ability to learn a log-linear model using only (approximate) MAP inference. We also show results of applying our method to some simple synthetic examples, where it significantly outperforms pseudo-likelihood.','Parameter Learning with Approximate MAP Inference;;Non-local Contrastive Objectives;;Log-linear models;;Learning – Maximum Likelihood;;Approximate Learning;;Pseudo-likelihood;;Contrastive divergence;;Intuition;;But wait…;;Contrastive Objective;;Theoretical Result;;Corollary – Connected Values;;Pseudo-likelihood Coverage;;Non-Φ-representable Data;;Advantages;;Connections;;MAP-based Contrastive Objectives;;1-D Example;;Aside: Max-Margin Methods;;Cutting-plane algorithm;;Comparison to Cutting Planes;;Preliminary Experiments;;CRF Construction;;Experimental Setup;;Results (1);;Results (2) ;;Results (3);;Summary'
11279,'lecture','en',11294,'2009-12-12','2010-01-19','Training Structured Predictors for Novel Loss Functions','As a motivation we consider the PASCAL image segmentation challenge. Given an image and a target class, such as person, the challenge is to segment the image into regions occupied by objects in that class (person foreground) and regions not occupied by that class (non-person background). At the present state of the art the lowest pixel error rate is achieved by predicting all background. However, the challenge is evaluated with an intersection over union score with the property that the all-background prediction scores zero. This raises the question of how one incorporates a particular loss function into the training of a structured predictor. A standard approach is to incorporate the desired loss into the structured hinge loss and observe that, for any loss, the structured hinge loss is an upper bound on the desired loss. However, this upper bound is quite loose and it is far from clear that the structured hinge loss is an appropriate or useful way to handle the PASCAL evaluation measure. \n\nThis talk reviews various approaches to this problem and presents a new training algorithm we call the good-label-bad-label algorithm. We prove that in the data-rich regime the good-label-bad-label algorithm follows the gradient of the training loss assuming only that we can perform inference in the given graphical model. The algorithm is structurally similar to, but significantly different from, stochastic subgradient descent on the structured hinge loss (which does not follow the loss gradient). ','Direct Loss Minimization;;Perceptron-like Updates;;Direct Loss Update;;Direct Loss Theorem;;Proof Hint;;Approximate Inference and Hidden Information;;Experiments (Joseph Keshet);;Loss Functions;;Results;;Regularization;;Structured Hinge Generalizes Binary Hinge;;Hinge Loss upper Bounds L;;Margin Bounds;;Direct Optimization of the PAC-Bayes Bound;;Differentiating the PAC-Bayes bound'
11280,'lecture','en',11294,'2009-12-12','2010-01-14','Some Machine Learning Problems that We in the Computer Vision Community Would Like to See Solved','From a user\'s perspective, I\'ll describe what solutions I\'d like to see regarding the learning of large scale graphical models. Also, at a recent vision workshop, I asked (one by one) numerous leading researchers in computer vision what results they would like to see from computer scientists/machine learning folks. I\'ll present those responses.','Some machine learning problems that we in the computer vision community would like to see solved;;Outline;;Companies and applications;;Cognex;;Poseidon;;Saved by a computer lifeguard;;Mobil Eye;;Identix;;Microsoft;;What does work;;What doesn’t work;;Inferring latent variable structure;;Figure 1;;Figure 1: Shading & Paint;;Decompose the image into shading and reflectance components;;Finally, returning to our explanatory example…;;Clothing catalog image;;Original, Shape & Reflectance Images;;Separating a signal into separate statistical processes;;Separating sums of signals into statistically separate components;;Training Samples;;Dissection Results     ;;Need a good prior model for images;;Photo 1;;Photo 2;;Photo 3;;Image formation process;;Multiple possible solutions;;Natural image statistics;;Blury images have different statistics;;Parametric distribution;;Three sources of information;;Removing camera shake;;Close-up;;Evaluation results;;Image priors from Simoncelli lab ;;Priors in noise removal;;Problem: Statistical characterization of images;;Needs (In low-level vision);;Needs (In high-level vision);;Intra-class variation;;Object recognition issues;;Let’s go back in time…to the 1980’s;;What everyone looked like back then;;Features;;Recognizing planar objects using invariants;;Back to the present…;;SIFT vector formation;;Example;;Visual words;;Object recognition using visual words;;Many combinatorial matching problems to be solved for object recognition;;Problem: Category level recognition using visual words representation;;Photo: 2009 BIRS Workshop on Computer Vision and the Internet;;Photo: Rob Fergus, Lana Lazebnik & Rick Szeliski;;Nearest neighbor search in high dimensions;;Problem: Nearest neighbor search in high dimensions;;Photo: Shai Avidan;;Blind vision;;Problem: Develop secure multi-party techniques for vision algorithms;;Photo: Deva Ramanan;;Evaluate easily over a powerset of all segmentations;;Problem: Evaluate some segmentation-dependent function over (some approximation to) all possible segmentations;;Photo: Alyosha Efros;;Efros comments;;Photo: Pietro Perona;;Pietro Perona;;Photo: David Lowe;;David Lowe;;Needs;;End;;A computer graphics application of nearest-neighbor finding in high dimensions;;The image database;;Image representation;;Obtaining semantically coherent themes;;Basic camera motions ;;Scene matching with camera view transformations: Translation;;Scene matching with camera view transformations: Camera rotation;;More “infinite” images – camera translation;;Example 1: Hollywood;;Example 2;;Example 3: Windows XP Screensaver;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_083;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_084;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_085;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_086;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_087;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_088;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_089;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_090;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_091;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_092;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_093;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_094;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_095;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_096;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_097;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_098;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_099;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_100;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_101;;nipsworkshops09_freeman_smlptwcvcwlss_01_Page_102'
11281,'keynote','en',11295,'2009-12-12','2010-01-19','Covariate Shift by Kernel Mean Matching','Given sets of observations of training and test data, we consider the problem of re-weighting the training data such that its distribution more closely matches that of the test data. We achieve this goal by matching covariate distributions between training and test sets in a high dimensional feature space (specifically, a reproducing kernel Hilbert space). This approach does not require distribution estimation. Instead, the sample weights are obtained by a simple quadratic programming procedure.\nWe first describe how distributions may be mapped to reproducing kernel Hilbert spaces. Next, we review distances between such mappings, and describe conditions under which the feature space mappings are injective (and thus, distributions have a unique mapping). Finally, We demonstrate how a transfer learning algorithm can be obtained by reweighting the training points such that their feature mean matches that of the (unlabeled) test distribution. Our correction procedure yields its greatest and most consistent advantages when the learning algorithm returns a classifier/regressor that is \"simpler\" than the data might suggest. On the other hand, even an ideal sample reweighting may not be of practical benefit given a sufficiently powerful classifier (if available).','Kernel approaches to covariate shift;;Transfer learning and covariate shift -1;;Transfer learning and covariate shift -2;;Transfer learning and covariate shift -3;;A toy example -1;;A toy example -2;;A toy example -3;;The solution procedure -1;;The solution procedure -2;;The solution procedure -3;;Importance weighting -1;;Importance weighting -2;;Importance weighting -3;;Importance weighting -4;;Importance weighting -5;;Importance weighting -6;;Importance weighting -7;;Alternatives to density estimation -1;;Alternatives to density estimation -2;;maximum mean discrepancy;;Function Showing Difference in Distributions -1;;Function Showing Difference in Distributions -2;;Function Showing Difference in Distributions -3;;Function Showing Difference in Distributions -4;;Function Showing Difference in Distributions -5;;Function Showing Difference in Distributions -6;;Function Showing Difference in Distributions -7;;Function Showing Difference in Distributions -8;;Function Showing Difference in Distributions -9;;Function Showing Difference in Distributions -10;;Function Showing Difference in Distributions -11;;Transfer learning using maximum mean discrepancy;;Transfer learning by KMM -1;;Transfer learning by KMM -2;;Transfer learning by KMM -3;;Transfer learning by KMM -4;;Transfer learning by KMM -5;;Transfer learning by KMM -6;;Transfer learning by KMM -7;;Transfer learning by KMM -8;;Transfer learning by KMM -9;;Transfer learning by KMM -10;;Transfer learning by KMM -11;;Reweighting by classification -1;;Reweighting by classification -2;;Experiments;;Breast Cancer data -1;;Breast Cancer data -2;;Breast Cancer data -3;;Toy example revisited;;Large scale experiments -1;;Large scale experiments -2;;Large scale experiments -3;;Large scale experiments -4;;Large scale experiments -5;;Large scale experiments -6;;Further work: model selection -1;;Further work: model selection -2;;Summary;;Acknowledgements;;Questions?;;Blank page;;Bibliography;;Characteristic kernels;;Characteristic kernels -1;;Characteristic kernels -2;;Characteristic kernels -3;;Characteristic kernels -4;;Characteristic kernels -5;;Characteristic kernels -6;;Characteristic kernels -7;;Characteristic kernels -8;;Characteristic kernels -9;;Characteristic kernels -10;;Characteristic kernels -11;;Characteristic kernels -12;;Characteristic kernels -13;;Characteristic kernels -14;;Summary: Characteristic Kernels -1;;Summary: Characteristic Kernels -2;;Summary: Characteristic Kernels -3;;Summary: Characteristic Kernels -4'
11284,'lecture','en',11295,'2009-12-12','2010-01-19','Kernel Learning and Meta Kernels for Transfer Learning',NULL,'Kernel Learning and Meta Kernels for Transfer Learning;;Outline;;Kernel-Based Inductive Transfer;;Kernel Learning -1;;Kernel Learning -2;;Projection-Based Kernel Learning;;SDP - Based Approach -1;;SDP - Based Approach -2;;Meta - Kernels;;Histogram Kernel -1;;Histogram Kernel -2;;Histogram Kernel -3;;Histogram Kernel -4;;Histogram Kernel -5;;Histogram Kernel -6;;Histogram Kernel -7;;Gaussian Meta Kernel;;Gaussian Mixture Meta Kernel;;Feature Meta Kernel;;Experiments;;Conclusion;;Thanks;;Capacity Estimates for Partial Orders -1;;Capacity Estimates for Partial Orders -2'
11286,'keynote','en',11295,'2009-12-12','2010-01-19','No-Free-Lunch Theorems for Transfer Learning ','I will present a formal framework for transfer learning and investigate under which conditions is it possible to provide performance guarantees for such scenarios. I will address two key issues:\n*1) Which notions of task-similarity suffice to provide meaningful error bounds on a target task, for a predictor trained on a (different) source task?\n*2) Can we do better than just train a hypothesis on the source task and analyze its performance on the target task? Can the use of unlabeled target samples reduce the target prediction error?','No Free Lunch Theorems for Domain Adaptation;;Outline;;Our Goal;;Naive user view of machine learning;;Learning requires prior knowledge;;A concrete setting for our problem;;Main issue;;The Covariate Shift assumption may be useless;;How should one measure similarity of distributions?;;A new distribution-similarity measure;;Demonstration of the new distance;;Estimating;;The Covariate Shift assumption may be useless even when D (P, Q) is small;;More relevant measure of label relatedness;;Resulting generalization error bound;;Sufficient conditions for DA learning;;Demonstarting uselessness of the Covariate Shift asumption;;Conservative vs. Adaptive algorithms;;Demonstrating the failure of the importance reweighting paradigm;;Can any algorithm do better? -1;;Can any algorithm do better? -2;;Conclusion;;Major remaining open questions;;A pessimistic conclusion;;Conclusions;;Success example;;Structural Correspondence Learning -1;;Structural Correspondence Learning -2;;Our Inductive Transfer Paradigm;;The Common-Feature-Space Idea;;A Bound on Target Domain Error;;The notation above;;Visualizing the Classifiers;;Vizualizing the dh - distance ;;The algorithmic conclusion;;Demonstrating uselessness of the Covariate Shift assumption'
11319,'lecture','en',11294,'2009-12-12','2010-01-19','Learning a Region-based Scene Segmentation Model','In recent years, machine learning has seen the development of a series of algorithms for parameter learning that avoid estimating the partition function and instead, rely on accurate approximate MAP inference. Within this framework, we consider two new topics. \n\nIn the first part, we discuss parameter learning in a semi-supervised scenario. Specifically, we focus on a region-based scene segmentation model that explains an image in terms of its underlying regions (a set of connected pixels that provide discriminative features) and their semantic labels (such as sky, grass or foreground). While it is easy to obtain (partial) ground-truth labeling for the pixels of a training image, it is not possible for a human annotator to provide us with the best set of regions (those that result in the most discriminative features). To address this issue, we develop a novel iterative MAP inference algorithm which selects the best subset of regions from a large dictionary using convex relaxations. We use our algorithm to \"complete\" the ground-truth labeling (i.e. infer the regions) which allows us to employ the highly successful max-margin training regime. We compare our approach with the state of the art methods and demonstrate significant improvements. \n\nIn the second part, we discuss a new learning framework for general log-linear models based on contrastive objectives. A contrastive objective considers a set of \"interesting\" assignments and attempts to push up the probability of the correct instantiation at the expense of the other interesting assignments. In contrast to our approach, related methods such as pseudo-likelihood and contrastive divergence compare the correct instantiation only to nearby instantiations, which can be problematic when there is a high-scoring instantiation far away from the correct one. We present some of the theoretical properties and practical advantages of our method, including the ability to learn a log-linear model using only (approximate) MAP inference. We the theoretical properties and practical advantages of our method, including the ability to learn a log-linear model using only (approximate) MAP inference. We also show results of applying our method to some simple synthetic examples, where it significantly outperforms pseudo-likelihood.','Learning a Region-basedScene Segmentation Model;;Aim;;Why Regions? (1);;Why Regions? (2);;Why Regions? (3);;Why Regions? (4);;Why Regions? (5);;Outline (1);;Region-based Segmentation Model (1);;Region-based Segmentation Model (2);;Outline (2);;Ground Truth Labeling (1);;Ground Truth Labeling (2);;Learning with Coarse Labels (1);;Learning with Coarse Labels (2);;Outline (3);;Region Selection (1);;Region Selection (2);;Integer Program;;Linear Program (1);;Linear Program (2);;The Learning Approach;;Outline (4);;Stanford Background Dataset;;Completing the Ground Truth (1);;Completing the Ground Truth (2);;Completing the Ground Truth (3);;Pixel-wise Accuracy;;Examples (1);;Examples (2);;Examples (3);;Summary;;Future Work;;Questons?'
11337,'lecture','en',11336,'2009-12-03','2010-04-14','SINDBAD and SiQL: An Inductive Database and Query Language in the Relational Model','The speaker presented the concepts and implementation of SINDBAD, a prototype of an inductive database - as proposed by Imielinski and Mannila - in the relational model. The goal is to support all steps of the knowledge discovery process on the basis of queries to a database system. The query language SiQL (structured inductive query language), an SQL extension, offers query primitives for feature selection, discretization, pattern mining, clustering, instance-based learning and rule induction.\n\n','Sindbad and SiQL: An Inductive Database and Query Language in the Relational Model;;Outline;;Database View of Data Mining - 1;;Database View of Data Mining - 2;;Database View of Data Mining - 3;;Database View of Data Mining - 4;;Database View of Data Mining - 5;;Database View of Data Mining - 6;;An Inductive Database in the Relational Model;;Implementation;;Supported Algorithms;;SiQL - Structured Inductive Query Language;;Relational Data Mining;;Relational Data Mining - Distance Functions;;SINDBAD SAILS;;Application Scenario: Gene Expression Analysis;;Application Scenario: Gene Regulation Prediction;;Gene Regulation Prediction - Data Representation;;Application Scenario: Structure-Activity Relationship;;Structure-Activity Relationship'
11351,'lecture','en',11361,'2009-12-12','2010-01-19','Retrospective Change-point Approaches and Sequential Modelling','We propose for the analysis of array-CGH data, a new stochastic segmentation model and an associated\nestimation procedure that has attractive statistical and computational properties. An important benefit of\nthis Bayesian segmentation model is that it yields explicit formulas for posterior means, which can be used\nto estimate the signal directly without performing segmentation. Other quantities relating to the posterior\ndistribution that are useful for providing confidence assessments of any given segmentation can also be\nestimated by using our method. We propose an approximation method whose computation time is linear in\nsequence length which makes our method practically applicable to the new higher density arrays. Simulation\nstudies and applications to real array-CGH data illustrate the advantages of the proposed approach.',NULL
11352,'lecture','en',11361,'2009-12-12','2010-01-19','A Dynamic HMM for Online Segmentation','We propose a novel method for the analysis of sequential data\nthat exhibits an inherent mode switching. In particular, the data\nmight be a non-stationary time series from a dynamical system\nthat switches between multiple operating modes. Unlike other approaches, our method processes the data incrementally and without\nany training of internal parameters. We use an HMM with a dynamically changing number of states and an on-line variant of the\nViterbi algorithm that performs an unsupervised segmentation and\nclassification of the data on-the-y, i.e. the method is able to process incoming data in real-time. The main idea of the approach is\nto track and segment changes of the probability density of the data\nin a sliding window on the incoming data stream. The usefulness\nof the algorithm is demonstrated by an application to a switching\ndynamical system.',NULL
11353,'lecture','en',11361,'2009-12-12','2010-01-19','Distributed Detection and Localization of Network Anomalies using Rank Tests','We propose an efficient and decentralized method for detecting change-points in high-dimensional data. This issue is of growing concern to the network security community since, in this context, network anomalies such as denial of service (DoS) attacks are likely to lead to statistical changes in Internet traffic. Our method proposes a way of distributing a centralized approach called TopRank, which consists of a data reduction stage based on record filtering, followed by a nonparametric change-point detection test based on U-statistics. The key point is to aggregate censored time series built locally and to perform a nonparametric test for doubly censored time series resulting from this aggregation. With this new approach, called distributed TopRank in the following, we can address massive data streams and perform network anomaly detection and localization on the fly while limiting the quantity of data exchanged within the network.',NULL
11354,'lecture','en',11361,'2009-12-12','2010-01-19','Product Partition Models for Modelling Changing Dependency Structure in Time Series ','We show how to apply the efficient Bayesian changepoint detection techniques of Fearnhead in the\nmultivariate setting. We model the joint density of vector-valued observations using undirected Gaussian\ngraphical models, whose structure we estimate. We show how we can exactly compute the MAP\nsegmentation, as well as how to draw perfect samples from the posterior over segmentations, simultaneously\naccounting for uncertainty about the number and location of changepoints, as well as uncertainty about the\ncovariance structure. We illustrate the technique by applying it to financial data and to bee tracking data.',NULL
11356,'lecture','en',11361,'2009-12-12','2010-01-19','Hierarchical-Dirichlet-Process-based Hidden Markov Models','We consider the problem of speaker diarization, the problem of segmenting an audio recording of a meeting\ninto temporal segments corresponding to individual speakers. The problem is rendered particularly dicult\nby the fact that we are not allowed to assume knowledge of the number of people participating in the meeting.\nTo address this problem, we take a Bayesian nonparametric approach to speaker diarization that builds on\nthe hierarchical Dirichlet process hidden Markov model (HDP-HMM) of Teh et al. (2006). Although the\nbasic HDP-HMM tends to over-segment the audio data{creating redundant states and rapidly switching\namong them{we describe an augmented HDP-HMM that provides effective control over the switching rate.\nWe also show that this augmentation makes it possible to treat emission distributions nonparametrically.\nTo scale the resulting architecture to realistic diarization problems, we develop a sampling algorithm that\nemploys a truncated approximation of the Dirichlet process to jointly resample the full state sequence,\ngreatly improving mixing rates. Working with a benchmark NIST data set, we show that our Bayesian\nnonparametric architecture yields state-of-the-art speaker diarization results.',NULL
11357,'lecture','en',11361,'2009-12-12','2010-01-19','Quickest Change Detection','This work examines the problem of sequential change detection in the constant drift of a Brownian motion in the case of multiple alternatives. As a performance measure an extended Lordenas criterion is proposed.\nWhen the possible drifts, assumed after the change, have the same sign, the CUSUM rule, designed to detect\nthe smallest in absolute value drift, is proven to be the optimum. If the drifts have opposite signs, then\na specific 2-CUSUM rule is shown to be asymptotically optimal as the frequency of false alarms tends to\ninfinity.',NULL
11358,'lecture','en',11361,'2009-12-12','2010-01-19','Mode Estimation of Autonomous Systems',NULL,NULL
11359,'lecture','en',11361,'2009-12-12','2010-01-19','Adaptive Sequential Bayesian Change-point Detection ','Nonstationarity, or changes in the generative parameters, are often a key aspect of real world time\nseries, which comprise of many distinct parameter regimes. An inability to react to regime changes\ncan have a detrimental impact on predictive performance. Change point detection (CPD) attempts\nto reduce this impact by recognizing regime change events and adapting the predictive model appropriately.\nAs a result, it can be a useful tool in a diverse set of application domains including\nrobotics, process control, and finance. CPD is especially relevant to finance where risk resulting\nfrom parameter changes is often neglected in models. For example, Gaussian copula models used in\npricing collateralized debt obligations (CDOs) had two key flaws: assuming that subprime mortgage\ndefaults have a fixed correlation structure, and using a point estimate of these correlation parameters\nlearned from historical data prior to the burst of the real-estate bubble [1, 2]. Bayesian change point\nanalysis avoids both of these problems by assuming a change point model of the parameters and\nintegrating out the uncertainty in the parameters rather than using a point estimate.','Adaptive Sequential Bayesian Change Point Detection;;Motivation;;Ingredients;;Previous Work;;The BOCPD Algorithm;;Learning;;Improvements;;Well Log Data;;Industry Portfolios;;Results;;Summary'
11360,'lecture','en',11361,'2009-12-12','2010-01-19','Temporal Segmentation with Kernel Change-point Detection','We introduce a kernel-based method for change-point analysis within a sequence\nof temporal observations. Change-point analysis of an unlabeled sample of observations\nconsists in, first, testing whether a change in the distribution occurs within\nthe sample, and second, if a change occurs, estimating the change-point instant\nafter which the distribution of the observations switches from one distribution to\nanother different distribution. We propose a test statistic based upon themaximum\nkernel Fisher discriminant ratio as a measure of homogeneity between segments.\nWe derive its limiting distribution under the null hypothesis (no change occurs),\nand establish the consistency under the alternative hypothesis (a change occurs).\nThis allows to build a statistical hypothesis testing procedure for testing the presence\nof a change-point, with a prescribed false-alarm probability and detection\nprobability tending to one in the large-sample setting. If a change actually occurs,\nthe test statistic also yields an estimator of the change-point location. Promising\nexperimental results in temporal segmentation of mental tasks from BCI data and\npop song indexation are presented.',NULL
11408,'lecture','en',11190,'2008-03-03','2010-06-07','Presentation 1: Global port cities',NULL,NULL
11409,'lecture','en',11190,'2008-03-07','2010-06-07','Presentation 2: Decorative brickwork: a global history',NULL,NULL
11410,'lecture','en',11190,'2008-03-10','2010-06-07','Presentation 3: Before the scramble for Africa: tracing African architecture through trade',NULL,NULL
11411,'lecture','en',11190,'2008-03-13','2010-06-07','Presentation 4: 20th century African urbanism: three vignettes',NULL,NULL
11412,'lecture','en',11190,'2008-03-15','2010-06-07','Presentation 5: A global history of pilgrimage: an introduction',NULL,NULL
11413,'lecture','en',11190,'2008-03-18','2010-06-07','Presentation 6: The temple in the cave: rock-cut architecture',NULL,NULL
11414,'lecture','en',11199,'2008-09-02','2010-04-16','Lecture 1: The importance of chemical principles',NULL,NULL
11415,'lecture','en',11199,'2008-09-05','2010-07-28','Lecture 2: Discovery of electron and nucleus, need for quantum mechanics',NULL,NULL
11417,'lecture','en',11199,'2008-09-12','2010-07-28','Lecture 4: Wave-particle duality of matter, SchrÃ¶dinger equation',NULL,NULL
11418,'lecture','en',11199,'2008-09-15','2010-07-28','Lecture 5: Hydrogen atom energy levels',NULL,NULL
11419,'lecture','en',11199,'2008-09-16','2010-07-28','Lecture 6: Hydrogen atom wavefunctions (orbitals)',NULL,NULL
11420,'lecture','en',11199,'2008-09-19','2010-07-28','Lecture 7: p-orbitals',NULL,NULL
11421,'lecture','en',11199,'2008-09-23','2010-07-28','Lecture 8: Multielectron atoms and electron configurations',NULL,NULL
11422,'lecture','en',11199,'2008-09-25','2010-07-28','Lecture 9: Periodic trends',NULL,NULL
11423,'lecture','en',11199,'2008-09-26','2010-07-28','Lecture 10: Periodic trends continued; Covalent bonds',NULL,NULL
11424,'lecture','en',11199,'2008-09-30','2010-07-28','Lecture 11: Lewis structures',NULL,NULL
11425,'lecture','en',11199,'2008-10-02','2010-07-28','Lecture 12: Exceptions to Lewis structure rules; Ionic bonds',NULL,NULL
11426,'lecture','en',11199,'2008-10-07','2010-07-28','Lecture 13: Polar covalent bonds; VSEPR theory',NULL,NULL
11427,'lecture','en',11199,'2008-10-10','2010-07-28','Lecture 14: Molecular orbital theory',NULL,NULL
11428,'lecture','en',11199,'2008-10-16','2010-07-28','Lecture 15: Valence bond theory and hybridization',NULL,NULL
11429,'lecture','en',11199,'2008-10-17','2010-07-28','Lecture 16: Determining hybridization in complex molecules; Thermochemistry and bond energies/bond enthalpies',NULL,NULL
11430,'lecture','en',11199,'2008-10-23','2010-07-28','Lecture 17: Entropy and disorder',NULL,NULL
11431,'lecture','en',11199,'2008-10-29','2010-07-28','Lecture 18: Free energy and control of spontaneity',NULL,NULL
11432,'lecture','en',11199,'2008-11-05','2010-07-28','Lecture 19: Chemical equilibrium',NULL,NULL
11433,'lecture','en',11199,'2008-11-07','2010-07-28','Lecture 20: Le Chatelier\'s principle and applications to blood-oxygen levels',NULL,NULL
11434,'lecture','en',11199,'2008-11-19','2010-07-28','Lecture 21: Acid-base equilibrium: Is MIT water safe to drink?',NULL,NULL
11435,'lecture','en',11199,'2008-11-21','2010-07-28','Lecture 22: Chemical and biological buffers',NULL,NULL
11436,'lecture','en',11199,'2008-11-24','2010-07-28','Lecture 23: Acid-base titrations',NULL,NULL
11437,'lecture','en',11199,'2008-11-27','2010-07-28','Lecture 24: Balancing oxidation/reduction equations',NULL,NULL
11438,'lecture','en',11199,'2008-12-01','2010-07-28','Lecture 25: Electrochemical cells',NULL,NULL
11439,'lecture','en',11199,'2009-12-04','2010-07-28','Lecture 26: Chemical and biological oxidation/reduction reactions',NULL,NULL
11440,'lecture','en',11199,'2008-12-15','2010-07-28','Lecture 27: Transition metals and the treatment of lead poisoning',NULL,NULL
11441,'lecture','en',11199,'2008-12-17','2010-07-28','Lecture 28: Crystal field theory',NULL,NULL
11442,'lecture','en',11199,'2008-11-21','2010-07-28','Lecture 29: Metals in biology',NULL,NULL
11443,'lecture','en',11199,'2008-11-24','2010-07-28','Lecture 30: Magnetism and spectrochemical theory',NULL,NULL
11444,'lecture','en',11199,'2008-11-19','2010-07-28','Lecture 31: Rate laws',NULL,NULL
11445,'lecture','en',11199,'2008-12-22','2010-07-28','Lecture 32: Nuclear chemistry and elementary reactions',NULL,NULL
11446,'lecture','en',11199,'2008-12-25','2010-07-28','Lecture 33: Reaction mechanism',NULL,NULL
11447,'lecture','en',11199,'2008-12-29','2010-07-28','Lecture 34: Temperature and kinetics',NULL,NULL
11448,'lecture','en',11199,'2009-01-02','2010-07-28','Lecture 35: Enzyme catalysis',NULL,NULL
11449,'lecture','en',11199,'2009-01-02','2010-07-28','Lecture 36: Biochemistry',NULL,NULL
11553,'lecture','fr',NULL,'2010-01-20','2010-02-01','L´oeil absolu et le monde sans limite / The universal eye and a limitless world','**L´oeil absolu et le monde sans limite**\n\nVoir est une arme du pouvoir. Depuis la vidéosurveillance jusqu’aux balayages satellitaires de la planète, en passant par l’imagerie médicale et la télé-réalité, d’innombrables dispositifs s’acharnent à nous rendre intégralement visibles et transparents. On sait que sortir faire ses courses à Londres aujourd’hui, c’est être filmé plus de trois cents fois. La science et la technique ont bricolé un dieu omnivoyant électronique, un nouvel Argos doté de millions d’yeux qui ne dorment jamais. Plus que dans une civilisation de l’image, nous sommes désormais dans une civilisation du regard. On surveillait jadis les criminels, aujourd’hui on surveille surtout les innocents. Pour la politique sécuritaire, nous sommes tous des dommages collatéraux.\nMais au-delà de la surveillance, ce regard global infiltre aujourd’hui tous les domaines de nos vies, de la naissance à la mort. La transparence n’est pas qu’une affaire sociale, elle vise aussi le privé de nos maisons et l’intérieur de nos corps, dissolvant chaque jour un peu plus l’espace de l’intime et du secret. Dans une langue brillante, documentée et très accessible, Gérard Wajcman explore et questionne cette idéologie de l’hypervisible.\n\n----\n** The universal eye and a limitless world**\n\nThe lecture focuses primarily on contemporary or hyper-modern society of\ncontrol, on the questions of gaze and image. If the advent of modernity\npresupposed full mastery of the world and events, if it announced the\ntriumph of progress and enlightenment, the exact opposite happened: the\nunexpected fulfilled itself as the predominant feature of the 21st\ncentury. Gérard Wajcman gives numerous examples: from art and cinema to\nrecent plane crashes and the modern technology of detection, all of them\nilluminating the ideology of the Completely Visible. One of the central\nproblems is exactly the question of images: Do we live in a society of\nimages? Or have we entered into the society of the gaze? There is an\nexcess of images, but the gaze reveals itself as the true problem: there\nare not enough eyes. Any absence of image becomes intolerable. If one\ncannot prevent the unexpected, if one cannot avoid accidents, one can at\nleast try to retain the power to see, namely the power to gaze at the\nunexpected.\n\n----\n**Univerzalno oko in svet brez meje**\n\nPredavanje je osredotočeno na sodobno, t.j. hipermoderno družbo nazdora,\nna vprašanje pogleda in podobe. Če je nastop moderne dobe predpostavil\nobvladovanje sveta in dogodkov, če je zmagoslavje napredka in\nrazvetljenstva, pa se je v resnici izpolnilo prav nasprotno: izpolnilo\nse je nepredvideno, in sicer kot prevladujoča poteza 21. stoletja.\nGérard Wajcman ponudi različne primere: od likovne in filmske umetnosti\ndo nedavnih letalskih nesreč in sodobne tehnologije detektiranja, ki\nosvetljujejo ideologijo V Celoti Vidnega. Eden ključnih problemov je\nprav vprašanje podob: ali živimo v civilizaciji podobe? Ali pa smo\nvstopili v civilizacijo pogleda? Podob je na pretek, kot problem pa se\nizkaže prav pogled: pogledov je premalo. Kakršno koli umanjkanje podobe\npostane nevzdržno. Če se nepredvidenega ne more preprečiti, če se\nnesreči ne da ogniti, se skuša zadržati vsaj moč videti, moč gledati\nnepredvideno.',NULL
11569,'lecture','sl',11567,'2008-06-24','2010-02-05','Projekt \"Sporazumevanje v slovenskem jeziku\"','Od junija 2008 do decembra 2013 bo potekal projekt, ki ga\n financira Ministrstvo za solstvo iz sredstev evropskih strukturnih skladov \n in izvaja podjetje Amebis s petimi konzorcijskimi partnerji. Cilji projekta \n so digitalni jezikovni viri in jezikovnotehnoloska orodja za slovenski\n jezik. \n Najpomembnejsi med njimi so novi korpus besedil, leksikon besednih oblik, \n skladenjski razclenjevalnik, leksikalna baza, pedagoska slovnica in slogovni\n prirocnik za pomoc pri pisanju besedil. Podrobneje bodo predstavljeni \n posamezni cilji projekta, udelezenci v projektu in casovni okvir izvajanja.',NULL
11732,'lecture','en',11525,'2001-04-23','2010-06-08','The Black Hole at the Center of Our Galaxy','The Nobel Prize-winning physicist talks about various aspects of our galaxy, and discusses new methods in astronomy and astrophysics that make possible explorations deep into the heart of the Milky Way.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/603|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/42|Ford/MIT Nobel Laureate Lecture Series]]**',NULL
11734,'lecture','en',11525,'2001-10-11','2010-06-08','Bose-Einstein Condensates: The Coldest Matter in the Universe','What happens when a gas is cooled to absolute zero? A new door to the quantum world opens up because all the atoms start \"marching in lockstep\", forming one giant matter wave \Z the Bose-Einstein condensate. This was predicted by Einstein in 1925, but only realized in 1995 in laboratories at JILA in Boulder and at MIT. Since then, many properties of this mysterious form of matter have been revealed, including matter wave amplification and quantized vortices. Bose condensates have been used to realize a basic atom laser, an intense source of coherent matter waves.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/77|Lecture´s Homepage]]**\n;**Series** - **[[http://mitworld.mit.edu/host/view/64|Physics Department]]**\n;**Host** - **[[http://mitworld.mit.edu/series/view/26|2001 Physics Colloquium]]**',NULL
11735,'lecture','en',11525,'2001-10-15','2010-07-21','The Philosophy of Conflict Resolution',';**Link to** - **[[http://mitworld.mit.edu/video/62|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/42|Ford/MIT Nobel Laureate Lecture Series]]**\n;**Event Co-Sponsors**\n;**[[http://mitworld.mit.edu/host/view/43|Graduate Student Council]]**\n;**[[http://mitworld.mit.edu/host/view/44|Undergraduate Association]]**\n;**[[http://mitworld.mit.edu/host/view/48|Community Services Office at MIT]]**\n;**[[http://mitworld.mit.edu/host/view/46|Office of the Chancellor]]**',NULL
11738,'lecture','en',11525,'2002-10-18','2010-07-21','2002 Nobel Prize in Physiology or Medicine Nobel Lecture','In October 2002, The Nobel Prize in Physiology or Medicine was awarded to H. Robert Horvitz, Sydney Brenner and John El Sulston \"for their discoveries concerning genetic regulation of organ development and programmed cell death.\"\n\n;**Link to** - **[[http://mitworld.mit.edu/video/71|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/58|McGovern Institute for Brain Research at MIT]]**\n;**Event Co-Sponsor** - **[[http://mitworld.mit.edu/host/view/59|MIT School of Science]]**',NULL
11801,'lecture','en',11525,'2004-03-18','2010-07-21','New Frontiers with Ultracold Gases','Better bring a sweater when you visit Wolfgang Ketterle’s laboratories. This master of cool has managed to reduce temperatures in his vacuum chambers below those found in interstellar space. “The colder we are, the more we have the potential to make new discoveries,” says Ketterle. He won the 2001 Nobel Prize in Physics for generating Bose-Einstein condensates -- atoms that clump together briefly in a gas at frigid temperatures. Now, Ketterle is manipulating these transient events in novel ways. Using a magnetic field, he can generate Bose-Einstein condensates and transport them, potentially to microchips. He envisions supersensitive chips that will help measure rotation and gravity to aid navigation and geological exploration in the decades ahead. And in his latest triumph, Ketterle actually formed ultracold molecules after bringing two atoms together in the chilliest manmade conditions ever generated. He flouted chemists’ predictions and achieved no heat release. “We’re holding atoms in a laser beam, turn down the laser power and those atoms turn into molecules…. If nature had knocked on my door and said you have one free wish, wish for something you want in science, I wouldn’t have been bold enough to ask for that!”\n\n;**Link to** - **[[http://mitworld.mit.edu/video/192|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/64|Physics Department]]**',NULL
11802,'lecture','en',11525,'2004-04-07','2010-07-21','Progress in the Study of the X-Ray Background','Riccardo Giacconi has probably seen deeper into the universe than any other human being. He has conducted his explorations not with the naked eye, but with a series of increasingly sensitive detectors, relentlessly searching for the source of cosmic x-ray radiation. In this first-person account of pursuing one question for 40 years, what emerges most clearly is the kind of focus, determination, and invention required to make discoveries in the Nobel Prize league. Giacconi confesses that “X-ray astronomy is not easy” – an admirable understatement – but he succeeds in proving three key points: from the Uhuru satellite to the Hubble and Chandra telescopes, the success of experiments depends as much on brilliant instrument design as on data analysis; individual, identifiable galaxies are the source of the universe’s x-ray radiation background; and so we are now “looking at objects whose nature we do not know” – objects that the next generation of astronomers will understand only if they have the resources to build new instruments.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/197|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/57|Massachusetts Space Grant Consortium]]**',NULL
11803,'lecture','en',11525,'2004-05-13','2010-06-08','The Origin of Mass and the Feebleness of Gravity','A stunning roster of awards all identify Frank Wilczek as one of the most profound and influential theoretical physicists alive today. This lecture proves the point, as Wilczek goes after one of the deepest questions in science: What is the origin of mass? Rewriting Einstein’s famous equation as m=E / c2 dramatizes that energy is the source of mass; energetic but massless quarks and gluons, Wilczek argues, give rise to mass by finding quasi-stable equilibrium states, better know as protons and neutrons.\n\nHaving reinterpreted the theory of quantum chromodynamics in a brisk half hour, Wilczek plunges into another brain-straining question: What makes gravity so feeble? Here the more tentative answer derives from the unimaginably tiny dimensions of the Planck scale. Fundamental forces make sense in that realm; gravity is weak only relative to the enormously larger scales we live on. Wilczek looks forward to testing some of these speculations via experimental results as early as 2009.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/204|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/64|Physics Department]]**',NULL
11804,'lecture','en',11525,'2004-10-06','2010-05-21','2004 Nobel Colloquium','There’s no magic formula for winning the Nobel Prize. But you can’t find a more classic model than the career of Frank Wilczek, Feshbach Professor of Physics and 2004 Nobel laureate.\n\nWilczek was a 21 year-old graduate student at Princeton when he made his breakthrough discovery. High energy physics was baffled by the “strong force,” which binds the quarks that make up protons and neutrons. Wilczek (with two colleagues who share the prize) was brave enough to entertain a really startling idea: the strong force works in just the opposite way from the more familiar forces in nature – the closer together the particles are, the weaker the force becomes, an idea Wilczek captured in the phrase \"asymptotic freedom.” This profound insight into the fundamental forces of nature has astonishing explanatory power, not only for physics but also for cosmology. We now understand the early universe – the first few minutes of existence – better than we understand the universe around us today.\n\nFar from resting on his Nobel laurels, Wilczek is still working at the most puzzling frontiers of his science – for example, struggling to explain The Origin of Mass and the Feebleness of Gravity, the subject of his previous Physics Colloquium.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/237|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/64|Physics Department]]**',NULL
11806,'lecture','en',11525,'2005-03-07','2010-05-21','Ending Global Poverty','Imagine a bank that loans money based on a borrower’s desperate circumstances -- where, as Muhammad Yunus says, “the less you have, the higher priority you have.” Turning banking convention on its head has accomplished a world of good for millions of impoverished Bangladeshis, as the pioneering economist Yunus has demonstrated in the last three decades. What began as a modest academic experiment has become a personal crusade to end poverty. Yunus reminds us that for two-thirds of the world’s population, “financial institutions do not exist.” Yet, “we’ve created a world which goes around with money. If you don’t have the first dollar, you can’t catch the next dollar.” It was Yunus’ notion, in the face of harsh skepticism, to give the poorest of the poor their first dollar so they could become self-supporting. “We’re not talking about people who don’t know what to do with their lives….They’re as good, enterprising, as smart as anybody else.” His Grameen Bank spread from village to village as a lender of tiny amounts of money (microcredit), primarily to women. Yunus heard that “all women can do is raise chickens, or cows or make baskets. I said, ‘Don’t underestimate the talent of human beings.’ ” No collateral is required, nor paperwork—just an effort to make good and pay back the loan. Now the bank boasts 5 million borrowers, receiving half a billion dollars a year. It has branched out into student loans, health care coverage, and into other countries. Grameen has even created a mobile phone company to bring cell phones to Bangladeshi villages. Yunus envisions microcredit building a society where even poor people can open “the gift they have inside of them.”\n\n;**Link to** - **[[http://mitworld.mit.edu/video/289|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/124|Poverty Action Lab]]**\n;**Event Co-Sponsors** \n;**[[http://mitworld.mit.edu/host/view/26|Economics Department]]**\n;**[[http://mitworld.mit.edu/host/view/67|MIT School of Humanities, Arts, and Social Sciences]]**',NULL
11807,'lecture','en',11525,'2005-10-06','2010-05-21','Leadership in a Complex, Technology-Driven World','Sometimes the best way to achieve leadership is by pursuing a vision or meeting some personal goals, these three top-flight technologists suggest.\n\nRobert Langer admits, “I don’t tend to think of myself as a leader. I have simple ideas; I just want to see if I can do some good, and get satisfaction out of that.” He counts himself lucky to have gotten a job at Harvard Medical School, which allowed him to apply engineering to medical problems. “I wanted to see if we could make things that might help improve people’s health.” He attributes some of his leadership learning to years of struggle in acquiring grant money—in one case a 17-year battle with the NIH to back a novel drug delivery system (for which Langer was awarded the Charles Stark Draper Prize in 2002).\n\nSays Robert Metcalfe, “We have an idealization of innovative leadership—that it’s lovely. But the enemy is the status quo, and it’s resourceful and determined to defeat innovation.” Metcalfe’s personal style figures in his successes. He went to war against IBM in the 1980s, “when I had an invention that was better than what they had, and they threw all their monopoly resources against me. I was alone and surrounded and I beat them.” To make progress against the status quo, Metcalfe states, “you have to be obnoxious.”\n\nDon’t forget schmoozing and team playing, reminds Nobel Laureate Phillip Sharp, who acquired much of his savvy moving through academic ranks at MIT and partnering with outside firms. “I like to set a goal – that I’d like to see this technology do that, or this scientific question answered.” While you must set goals and seize opportunities, he says, you also need to attract optimal talents to your environment and “get others to play the game.” These are skills, Sharp says, he learned in high school sports.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/304|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/131|MIT Leadership Center]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/83|The Passion to Action Summit: The MIT Leadership Center Launch]]**',NULL
11818,'lecture','en',11525,'2008-01-29','2010-05-21','How Would Climate Change Influence Society in the 21st Century? (Panel)','Rajendra K. Pachauri leads fellow members of the Nobel Prize-winning IPCC in a remarkable public session of soul-searching. Now that the IPCC has helped make climate change a signal issue of our times, what next?\n\nJohn Reilly wonders whether the IPCC should be celebrating any success, given that greenhouse gas emissions continue to rise in spite of all the comprehensive study. Given the “dismal outcome so far,” it’s important that the IPCC “avoid the complacency that comes with big awards,” and that “much, all of the work is still there to be done.”\n\n“It’s probably time for sunset, Michael Golay suggests.” Now that the IPCC has succeeded in establishing climate change as “a reality among at least the chattering classes,” the next step is actually a social question, one that is much more difficult than coming up with new technologies. “We’re really talking about interfering with markets, and doing this in a way that doesn’t become simply another vehicle for creating profits for special interests….”\n\nWilliam Moomaw believes IPCC reports have made possible policy and corporate innovations that would have been unthinkable only a decade ago, and the IPCC should continue to serve in an advisory capacity to the world, laying out the technological and economic possibilities. Says Moomaw, “We got off to a bad start. We talked about global warming as being an environmental issue when in fact global warming is a symptom of maldevelopment.\"\n\nThe IPCC “should continue as the voice of science and help a well-informed society make tough decisions,” declares Andreas Fischlin . This will mean “facing the issue of sustainability in the context of climate change to an extent many of us won’t like.” Research challenges in developing nations may impede efforts to “optimize the IPCC’s work and help in the whole issue of moving toward a more sustainable world.”\n\nAkimasa Sumi believes IPCC should continue to have a powerful role in the future, because the “climate change issue is driven by science.” He proposes refining climate models in the hope of reducing uncertainty around such matters as the role of aerosols and clouds. He says the focus must now be on adaptation and mitigation, particularly over a 30-year time scale.\n\nThe IPCC established its relevance because it drew a line between being policy relevant and policy prescriptive, says Adil Najam. Now, “we need to claim victory on understanding the mechanics of the science and stop debating.” The next step must mean “focusing not on the scope of the problem, but on potential for solutions.”\n\nShould the IPCC attempt to become more prescriptive, believes Howard Herzog, “it would lose respect.” In his years with the organization, “anytime we got into policy prescriptive areas, when we got close to the line, tensions rose, arguments intensified, we lost consensus.” He thinks it’s important to continue the IPCC’s work, because the science will change, and we need a “broker out there to summarize where science is on critical issues.”\n\n;**Link to** - **[[http://mitworld.mit.edu/video/551|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/158|MIT Energy Initiative]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/123|Alliance for Global Sustainability Conference]]**',NULL
11824,'lecture','en',11525,'2009-05-12','2010-05-21','The Energy Problem and the Interplay Between Basic and Applied Research','The situation facing our planet could hardly be more dire: There’s increasingly dangerous competition among nations for ever scarce energy resources, and climate change is racing ahead of predictions. Although Steven Chu believes “We are getting close to where it’s very nervous time,” he also sees “reason for hope.”\n\nJust as science in the 1970s produced a “green revolution” in agricultural productivity, preventing mass starvation in a swelling global population, Chu is counting on transformative scientific and engineering ideas to achieve sustainable energy and cap climate change.\n\nAs chief architect of new policy, and with tens of billions of dollars to pump into his vision, Chu is targeting key areas. Number one on his list: energy efficiency and conservation. Since buildings use 40% of the nation’s total energy, designing more efficient homes and offices will make a big difference. There are “tune ups” possible for existing buildings, and software that can direct lighting, heating and cooling where it’s needed that can achieve 50% plus energy savings, and won’t break the bank. Says Chu, “This is truly low-hanging fruit, but we have to build the tools that allow architects and structural engineers to get on with it.”\n\nOn the supply side, Chu has his heart set on transformative technologies such as nanotech breakthroughs in solar power. He’s looking for ways to scale up biomass fuel production, now that synthetic biology can make microbes manufacture gas-like fuels. Noting in particular the work of MIT’s Dan Nocera, Chu says he “wants to use nature as an inspiration, but go beyond nature,” performing artificial photosynthesis to create new hydrocarbons. And as the U.S. and China continue dependence on coal, figuring out how to capture and sequester carbon from these plants figures “high on the list of things we must do.” He’s again hoping researchers will find some analog to nature’s ability to grab and neutralize CO2.\n\nThe ideal environment for jumpstarting such urgent scientific efforts, believes Chu, is something like Bell Labs, where Chu himself worked. The Labs performed “mission-driven research” around communications and for U.S. war efforts, but along the way also developed the transistor, information theory, radio astronomy, and lasers, among many examples. These scientist-led labs emphasized exchange of ideas and rapid infusion of research funds to the most promising work. This led to inventions that in turn transformed the U.S. economy. Chu envisions energy lab equivalents that “deliver the goods” along with fundamental science, “so you can have the Nobel Prize and save the world at the same time.”\n\n;**Link to** - **[[http://mitworld.mit.edu/video/683|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/36|The Office of the President of MIT]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/108|Karl Taylor Compton Lecture]]**',NULL
11825,'lecture','en',11525,'2009-09-29','2010-05-21','Challenges in Nation Building','At times humorous and other times defiant, José Ramos-Horta describes nurturing the 21st century’s first sovereign state through its formative years. The journey of East Timor from brutal Indonesian rule to fragile self-governance has involved Ramos-Horta in conflict and debate from the halls of the U.N. to the smallest villages of this tiny Southeast Asian island.\n\nHe describes the scene in 2002, after two years of UN-supervised transition, when Indonesia handed off a nation it had governed by force for decades: “A human calamity -- close to 200 thousand people lost their lives.” Another 200 thousand were forcibly displaced into West Timor. As it departed “in anger and frustration,” Indonesia’s military orchestrated the destruction of the nation’s cities, roads, schools and clinics. “The economy was at a standstill,” says Ramos-Horta. “We received barely a sketch of a state, a skeleton.”\n\nThe challenge of rebuilding East Timor is all the more daunting given “the psychological-emotional trauma of 24 years of violence.” There are bitter disputes involving how to conduct a national process of reconciliation. Western ambassadors recently called on Ramos-Horta, “representatives of two countries most notorious…for providing weapons and the red carpet treatment to the dictatorship of Indonesia.” They advocated establishing an international tribunal to pursue crimes against humanity during Indonesian rule. Says Ramos-Horta, “Had I been in a bad mood, I would have said, ‘Excuse me, the two of you are lecturing me on human rights and justice?’”\n\nDespite warnings from the U.N. that “lack of justice encourages impunity,” he believes East Timor must travel its own path toward reconciliation. If East Timor set up such a tribunal, “Who would it start with -- Indonesia or the U.S., which provided weapons to Suharto, or Australia, or all of them at once?” He states, “If you pursue justice at any cost without being sensitive to the challenges and complexities on the ground, you undermine the incipient nation, democracy and justice.”\n\nToday, when Ramos-Horta travels in the countryside, people don’t want to discuss security and unity. Recounts Ramos-Horta, “They joke with me: ‘Mr. President, we really like your road to peace, but we prefer a road to our village.’” He’s now focused on providing his people with such essentials as clean water and electricity, and shoring up the nation’s fragile social and economic institutions. “Let’s put all the past behind us. Look after the victims, the wounded, in their minds, bodies and souls, build a country that is deserving of so much sacrifice. Chasing the ghosts of the past leads us nowhere,” says Ramos-Horta.\n\n;**Link to [[http://mitworld.mit.edu/video/714|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/175|Legatum Center for Development and Entrepreneurship]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/151|The Legatum Pericles Lecture Series]]**',NULL
11826,'lecture','en',11525,'2009-10-23','2010-06-16','America\'s Leadership in Clean Energy','In welcoming President Obama, MIT President\nSusan Hockfield summarizes the vast array of energy innovation at MIT, including the MIT Energy Initiative and the student-led 1700 member Energy Club, and declares, \"We share President Obama\'s view that clean energy is the defining challenge of this era.\"\n\nIn his introduction of President Obama, Professor Ernest Moniz, Director of the MIT Energy Initiative (MITEI) and member of the President\'s Council of Advisors on Science and Technology (PCAST), discusses global issues on clean energy, science and innovation, and credits Obama for expanding the nation\'s energy vision.\n\nBarack Obama came to MIT not just to praise the Institute\'s leading edge energy research but to encourage all of America’s “heirs to a legacy of innovation” in their pursuit of discovery. The nation owes much of its prosperity to risk-takers and entrepreneurs, Obama said, and now, given the linked challenges of energy and climate change, we need such pioneers more than ever.\n\nAfter visiting MIT labs working on more efficient solar cells and lighting, batteries “that aren’t built, but grown,” and offshore wind plants that function even when the air is still, Obama told a large crowd that as the nation inevitably transitions from fossil fuels to renewable energy, we’re counting on the kind of “innovative potential on display at MIT.”\n\nObama acknowledges the great challenges facing energy researchers and entrepreneurs. As traditional energy supplies become more precious, and energy demands grow, nations are competing to develop new ways to produce and use energy, said Obama, and the winner will lead the global economy. “I want America to be that nation. It’s that simple.”\n\nHis administration’s response has been to make massive investments in both clean energy and basic science. Obama aims these efforts at both the current recession, and the nation’s future economic health. Clean energy jobs today and research “to produce the technologies of tomorrow” will “lay a new foundation for lasting prosperity.” He hopes this comprehensive approach will culminate in legislation that will transform America’s entire energy system.\n\nBut Obama is under no delusion that all will embrace his plan. “The closer we get,” says Obama, the “more we’ll hear from those whose interest or ideology run counter to that much-needed action we’re engaged in.” What worries the president more, though, is a dangerous pessimism shared by many, “that our politics are too broken and our people too unwilling to make hard choices for us to actually deal with this energy issue.” Implicit in this argument, he says, is that America has lost its fighting spirit.\n\nObama rejects this argument “because of what I’ve seen here at MIT … and because of what we know we are capable of achieving when called upon ….” The nation that harnessed electricity and the atom is one that has always sought out new frontiers, “and this generation is no different.” Obama invokes the achievements of the past as a call to arms “in what is sure to be a difficult fight in the months and years ahead” -- to ensure that “we are the energy leader that we need to be.”\n\n;**Link to** - **[[http://mitworld.mit.edu/video/716|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/36|The Office of the President of MIT]]**',NULL
11870,'lecture','en',11743,'2002-10-28','2010-05-21','A Beautiful Mind: Genius, Madness, Reawakening','Dr. Sylvia Nasar, the author of \"A Beautiful Mind\" tells the extraordinary story of mathematician John Nash a drama about the mystery of the human mind and shares some of her experiences in writing her prize-winning biography.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/39|Lecture´s Homepage]]**\n;**Lecture Host** - **[[http://mitworld.mit.edu/host/view/25|Department of Mathematics at MIT]]**\n;**Series ** - **[[http://mitworld.mit.edu/series/view/11|Applied Mathematics Colloquium]]**',NULL
11871,'lecture','en',11743,'2003-09-15','2010-05-21','A New Kind of Science','Wouldn’t it be exciting, Stephen Wolfram wonders, to have a little computer program that could function as a precise, ultimate model of our universe? If you ran the program long enough, it would reproduce every single thing that happens. It’s not out of the question, according to Wolfram’s lecture which somehow encapsulates his 1,200-page opus, A New Kind of Science, in a single hour.\n\nWolfram’s vast and penetrating research uses simple computations to generate complex computer models that resemble designs found in nature. He embraces the really big subjects, and the really small ones—from patterns on mollusk shells and the shapes of leaves and snowflakes, to free will, evolution, and extra-terrestrial life. This new kind of thinking might provide alternatives to evolution in explaining how different forms of life emerged. Wolfram believes his work is already transforming the study of science, as well as making possible a host of new technologies.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/149|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/25|Department of Mathematics at MIT]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/11|Applied Mathematics Colloquium]]**',NULL
11872,'lecture','en',11743,'2006-09-16','2010-05-21','Space Shuttle Discovery Mission to the International Space Station (STS-121)','The sign-up sheet for astronaut school is likely to grow even longer after viewing Stephanie Wilson’s reality video about her 13 days in space. Wilson, a self-described “robo chick,” served as a specialist in July 2006 on one of NASA’s return-to-flight test missions following the Columbia accident. She narrates a video account -- a day-to-day diary –- of the work, and fun, she and fellow astronauts engaged in.\n\nMuch of Wilson’s job involved using a robotic arm to help unload supplies onto the International Space Station, to which the shuttle Discovery was docked for several days. When she wasn’t helping transfer 28,000 pounds of food, gear and experiments, she was assisting crew members on space walks, during which they assembled another piece of the space station and tested a putty-like material for repairing cracks and holes in the shuttle\'s delicate heat tiles. Wilson, who was operating a 50-foot long robotic boom arm for these jobs, describes the challenge of functioning in “45 minutes of day and 45 minutes of night,” as the astronauts swiftly circled the earth. “It got very cold and dark, and my colleagues said it was very lonely to be at the end of a bendy stick.”\n\nWilson’s video clearly demonstrates the awesome solitude of these spacewalkers, as well as the mundane, almost household nature of their chores: Astronauts used tools resembling cordless drills to assemble new hardware onto the space station. Her footage also reveals the camaraderie and joy of life above earth. She takes us spinning like a fish through the submarine-narrow chambers of the attached shuttle and space station, and we view astronauts in zero gravity play with floating balls of water containing air bubbles, and attempt to catch myriad M&Ms in their mouths. Wilson herself performs a flipping sequence, admitting, “There’s a child in all of us.”\n\nTo Wilson’s clear regret, this may be her last shuttle flight. After a mission, an astronaut goes to the bottom of a long list of flight aspirants. But more to the point: NASA, facing budget cuts and the mandate of lunar and Mars missions, will retire the shuttles in 2010, with the goal of sending a new vehicle up in 2014. During the interim years, Russia’s Soyuz space ships will exclusively bear the burden of transport to the space station.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/391|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/25|Department of Mathematics at MIT]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/11|Applied Mathematics Colloquium]]**',NULL
11873,'lecture','en',11744,'2001-09-24','2010-07-26','The Politically Correct Atomic Reactor','With energy emerging as an issue of domestic and international importance, the Nuclear Engineering Department at MIT has been quietly working on a technology that it hopes will meet the challenge of providing a clean, safe, and reliable source of electricity. What started in January 1998 as an Independent Activities Period (IAP) project, has blossomed into a full design effort whose goal is to build a nuclear plant that can compete with natural gas, be meltdown proof, and have a waste form that can be disposed of without reprocessing.\n\nThe technology chosen was a high temperature, helium cooled, gas turbine powered, modular pebble bed reactor which was originally developed in Germany in the late 70\'s and 80\'s. The MIT design team is taking a fresh look at all aspects of the technology, from factory manufacture and site assembly to advanced fuel designs, safety analyses, modularity features that allow the entire plant to be shipped by truck, and advanced instrumentation and control systems. This technology was mentioned in the current Bush national energy plan as an example of the type of fresh thinking that is needed.\n\nThe colloquium will describe the technology and identify opportunities for other departments to contribute to the design of this plant, which might actually be built as a consortium product in collaboration with other universities, national laboratories and industry.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/46|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/27|Electrical Engineering and Computer Science Department]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/12|EECS Colloquium Series]]**',NULL
11874,'lecture','en',11744,'2001-10-01','2010-07-26','Cryptography - Science or Magic?','Examples of the \"tricks\" that can be performed with modern cryptographic techniques will be presented and each trick explored to see whether it is \"science\" (i.e., it can be proved to do what it seems to do) or \"magic\" (i.e., what it seems to do is, or may be, only an illusion). The tricks considered will include no-break cryptography, no-leak secret sharing, no-key cryptography, no-see signatures, no-watch coin tossing, and no-knowledge proofs.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/42|Lecture´s Homepage]]**\n;**Host** - **[[http://mitworld.mit.edu/host/view/27|Electrical Engineering and Computer Science Department]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/12|EECS Colloquium Series]]**',NULL
11925,'panel','en',11846,'2003-10-23','2010-07-21','Space Exploration: The Next 100 Years','High hopes meet high frustration in this panel, whose participants collectively yearn for a new vision to guide our space program. Andrew Chaikin recommends a three-step self-help regimen to move the program forward: lowering the cost of access to space (the going rate is 10 thousand dollars per pound!); embracing “outside-the-box” ideas; and engaging in a national conversation about space. Supriya Chakrabarti predicts that in around 30 years, NASA will be deploying robotic terrestrial planet finders and using the moon for both tourism and commercial development like mining. This will be possible if in the short term space scientists look for low-cost launch options, which might include exploiting existing missile technology. Richard Binzel puts the odds of a civilization-threatening asteroid impact in the next 100 years at one in a million, but believes the odds are a whole lot better that human beings will be exploring asteroids in space. We’ve got a leg up since we’ve already sent robot reconnaissance to the moons of Jupiter. If we’re worried about catastrophic asteroid strikes, Binzel says, we should start taking incremental steps, such as putting nuclear reactors in space to power vehicles for long inter-planetary journeys. \n\n;**Link to** - **[[http://mitworld.mit.edu/video/167|Lecture´s Homepage]]**\n;**Lecture Host** - **[[http://mitworld.mit.edu/host/view/75|Technology and Culture Forum]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/47|100th Anniversary of Flight]]** ',NULL
11926,'panel','en',11846,'2003-11-19','2010-07-21','Flight: The Next 100 Years','This panel delves into both the fabled and likely future of air travel. As a boy, Joseph Corn treasured the Popular Mechanics issue whose cover featured a man parking a helicopter in the garage. America’s romance with aviation, which started soon after the Wright Brothers’ flight, wasn’t just about hardware or transportation, says Corn, but about a utopian dream. Air travel would bring about a world of peace and brotherhood – a dream, says Corn, shattered by the dropping of the nuclear bomb. Jane Garvey reminisces about Y2K knuckle-biting – she was bravely aloft on New Year’s Eve 1999. The tremendous growth of regional jet travel and urban hub congestion will shift aviation to rural communities, Garvey projects, but believes no new runways will be built without strong local commitment.\n\nAllen Haggerty says that with only five airplane manufacturers left, expect streamlined plane travel -- you get to your desired destination more directly but without amenities. Some new and different planes are in the works: the Airbus A-380 will carry 555 passengers, with less noise than a 747. Boeing is designing a cargo plane called “The Pelican,” which will have a 500-foot wing span and length greater than a football field. \n\n;**Link to** - **[[http://mitworld.mit.edu/video/174|Lecture´s Homepage]]**\n;**Lecture Host** - **[[http://mitworld.mit.edu/host/view/75|Technology and Culture Forum]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/47|100th Anniversary of Flight]]** ',NULL
11940,'lecture','en',11830,'2003-06-07','2010-05-21','Organizational Economics and Management Education','In less than an hour, Robert Gibbons not only gets through 200 years of economic history, but outlines a new curriculum in organizational research planned by the Sloan School. Gibbons recounts some classic business stories – for instance, how Birds Eye’s success with frozen peas made the frozen food market “thick,” opening it up to scores of smaller players. Management students must master the basics of economics, says Gibbons, but Sloan must also help them train their sights on the current economy. The planned course offerings will knit together such traditional studies as economic theory, markets and competition with the latest in the fields of corporate governance and culture, technology and innovation.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/144|Lecture´s Homepage]]**\n;**Lecture Host** - **[[http://mitworld.mit.edu/host/view/39|MIT Sloan School of Management]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/41|Back to the Classroom 2003]]** ',NULL
11941,'lecture','en',11830,'2003-06-07','2010-05-21','Innovation: Are You A Predator or Are You Prey?','It seems a well-established truth that new technologies drive out older, established ones. In this lecture, MIT Sloan Professor James Utterback demonstrates just the opposite, that a symbiotic relationship can evolve between new “predator” and older “prey” industries that can sustain both. Using such vivid historical examples as the lightbulb, safety match and mousetrap, he describes how the original companies that created these products thrived even as they were challenged by newer firms that harnessed automated manufacturing or different distribution methods. Playing a remarkable film shot in 1927, Utterback shows how the transition from ice harvesting to mechanical refrigeration expanded the market for both – exemplifying the idea that new and old business ideas can and often do reinforce each other.\n\n;**Link to** - **[[http://mitworld.mit.edu/video/142|Lecture´s Homepage]]**\n;**Lecture Host** - **[[http://mitworld.mit.edu/host/view/39|MIT Sloan School of Management]]**\n;**Series** - **[[http://mitworld.mit.edu/series/view/41|Back to the Classroom 2003]]** ',NULL
11954,'opening','sl',11316,'2008-10-02','2010-06-30','Uvodni pozdrav / Welcome address','Biologija za razliko od fi zike in kemije, ki sta svoj vzpon doživeli veliko prej in temu\nprimerno strukturirali vsebine v izobraževanju, šele v zadnjih desetletjih doživlja\nvelik razvoj, kar posledično zahteva korenitejše posodabljanje koncepta biološkega\nizobraževanja.\n\nHiter vzpon sodobne biologije je bil mogoč zaradi dovolj velikega obsega zbranih\npodatkov, večanja znanja o kompleksnih živih sistemih ter razvoja in uporabe tehnologij,\nki so omogočile večje možnosti raziskovanja njihovega delovanja.\n\nZa razliko od tako imenovanih eksaktnih znanosti je za biologijo značilno raziskovanje\nkompleksnih dinamičnih živih sistemov, ki so na vseh ravneh organizacije žive narave\nmed seboj različni. V živi naravi ne najdemo dveh identičnih sistemov ali delov znotraj\nsistemov.\n\nTa raznoličnost je temelj uspešnosti razvoja življenja na Zemlji, raziskovanje življenja pa daje biologiji status posebne\nznanosti.\n\nHiter napredek temeljnih znanstvenih spoznanj sodobne biologije vse bolj posega tudi v naše osebno in družbeno\nživljenje. Sodobna splošna biološka izobrazba je vse pomembnejša za razumevanje in reševanje različnih problemov,\nki se nanašajo npr. na presojo in odločanje o biotehnologiji, gensko spremenjenih organizmih, kloniranju, genski\nterapiji, genetski diagnostiki, uporabi v forenziki, biomedicini, na področju ohranjanja narave in varstva okolja,\nvnosa tujerodnih organizmov, trgovanja z organizmi, ter pri obravnavi vplivov človekove dejavnosti na ekosisteme,\nozonsko luknjo, povečani učinek tople grede in globalne podnebne spremembe.\n\nPoseben vidik biološkega izobraževanja je ozaveščanje o naravi kot vrednoti in o izjemni biotski pestrosti v Sloveniji.\nNa tem področju je bilo pri nas v preteklosti že precej narejeno; dr. Narcis Mršić je npr. med prvimi začel s promocijo\nbiodiverzitete, ki postaja tudi del naše nacionalne identitete.\n\nNajpomembnejše objave znanstvenih spoznanj v zadnjih desetletjih so s področja biologije. Ta razvoj in nova spoznanja\nso privedli do zelo velike količine bioloških podatkov, ki postajajo na področju biološkega izobraževanja neobvladljivi.\nZato sta bila pri prenovi koncepta biološkega izobraževanja nujna tako premik od nizanja podatkov in opisovanja k\nvpeljevanju osnovnih bioloških zakonitosti in konceptov v povezavi z delovanjem živih sistemov kot tudi prehod z\nmehanicističnega na sodobni celostni pristop obravnave živih sistemov na vseh organizacijskih ravneh v živi naravi.\nHiter razvoj znanosti, še posebej biološke, terja odzive tudi na področju izobraževanja.\n\nV ta namen izvaja Zavod RS za šolstvo v okviru Centra za razvoj in raziskovanje od leta 2007 projekt Raznoliki\npristopi k posodabljanju naravoslovnih predmetov, v okviru katerega poteka za področje biologije tudi posvet\nBiološka znanost in družba. Program posveta sledi razvoju biologije ter družbenim potrebam po sodobni splošni\nbiološki izobrazbi v skladu s sodobnim konceptom biološkega izobraževanja. Vsebina posveta celostno obravnava\ntemeljne biološke koncepte v povezavi z živimi sistemi, njihovim razvojem, delovanjem in interakcijami na različnih\norganizacijskih ravneh v živi naravi. Evolucija je glavna biološka tema, ki osmišlja in povezuje biološke koncepte.\n\nŽivljenjski pogoji na Zemlji so produkt spleta delovanja raznolikih živih sistemov v ekosferi. Za ohranjanje le-teh\nin sodelovanje v družbenih procesih odločanja in reševanja problemov trajnostnega razvoja je potrebno sodobno\nbiološko znanje. Izobraževanje nam pomaga dojeti, kaj je življenje.\nZato je nujno, da učiteljice in učitelji kot ključni\ndejavnik pri prenosu znanja na naslednje generacije razumejo sodobno biologijo in imajo zagotovljen dostop do\nizobraževanja ter da sledijo njenim novim znanstvenim spoznanjem.',NULL
11955,'opening','sl',11316,'2008-10-02','2010-06-30','Nagovor pokrovitelja posveta / Opening speech by the Patron of the Conference','V zadnjih dvesto letih je povprečni Zemljan postal mnogo bogatejši, seveda če sodimo\npo povprečnem bruto družbenem proizvodu na prebivalca planeta. Tudi zato, ker je\nčloveštvo pohlepno in lahkomiselno poseglo v kapital narave.\n\nV svoji negospodarnosti smo spregledali, da na ta način posegamo v naravne procese\nin v ekosisteme, ki nam uravnavajo sestavo zraka, vzdržujejo globalno temperaturo in\npodnebje, uravnavajo kroženje in zadrževanje vode ter nastajanje in zadrževanje tal,\nomogočajo kroženje in prevzem hranil. Ekosistemi so tudi vir biološkega materiala,\nhrane in surovin, hkrati pa zagotavljajo možnosti za rekreacijo in estetske užitke.\n\nSe mestni prebivalci sploh zavedamo, koliko ekosistemskih uslug nam nudi drevo sredi\nmesta? Da nam drevo čisti zrak, dela senco, blaži premočan veter, uravnava vlago v\nzraku, izboljšuje odpadno vodo, zagotavlja zavetje in preživetje številnim koristnim\nbitjem, od ptičev do čebel in drugih opraševalcev, nudi estetski užitek in zvišuje\nvrednost stanovanj v okolici?\n\nNarava je bogastvo ali preprosteje – kapital. V to bogastvo smo posegli, ne da bi plačali pravo ceno za usluge\nnarave.\n\nPlanet se na naše ravnanje odziva. Človek je del ekosistemov oziroma ekosfere in je odvisen od nje, kar pomeni, da\ntako kot vsa živa bitja tudi on za preživetje uporablja storitve le-teh do te mere, da se ohranjajo procesi v njej. Cena,\nki jo že in jo še bomo plačevali zaradi posledic lokalnih ekoloških katastrof in globalnih podnebnih sprememb, je\nvisoka in bo v prihodnje še višja. Nepremišljeno ravnanje povratno negativno vpliva na naše blagostanje, na kakovost\nin razpoložljivost naših osnovnih virov in s tem tudi na naše zdravje.\n\nOhranjanje biološke raznovrstnosti in ekosistemov oziroma ekosfere je zato tudi ekopolitično vprašanje, ki zahteva\nznanje, odgovornost, celostni sistemski pristop ter obravnavo planeta Zemlja kot pomembne vrednote, ki nam\nomogoča preživetje in razvoj.\n\nLetošnje poročilo OECD opozarja, da bomo – če ne bomo spremenili svojega ravnanja – potomcem zapustili neprijazne\nrazmere za življenje. Ljudi, ki bodo leta 2050 živeli na Zemlji, čakajo vročinski valovi, suše, poplave, viharji, ki bodo\nuničevali ključno infrastrukturo in poljščine. Veliko živali in rastlin, ki jih poznamo danes, bo zaradi gradnje vedno\nnove infrastrukture in širitve polj za kmetijsko pridelavo izumrlo. Samo za pridelavo hrane in bioloških goriv bo\nčloveštvo potrebovalo 10 odstotkov več polj kot danes. Kakovost življenja in gospodarska rast se bosta zmanjšali\nzaradi izgube biološke raznovrstnosti, ki zagotavlja uravnovešen ekosistem. Število ljudi, ki bodo trpeli pomanjkanje\npitne vode, se utegne povečati z 1 na 3,9 milijarde. Ljudje bodo množično zbolevali zaradi onesnaženega zraka,\npočetverilo se bo število tistih, ki bodo umrli zaradi previsoke koncentracije ozona v zraku, število smrti zaradi\ndrobnih delcev v ozračju pa se bo podvojilo. Najbolj bodo trpeli ljudje v državah v razvoju, ker so manj pripravljene\nna spremembe in imajo manj možnosti za prilagoditve.\n\nSkoraj vse članice EU in OECD so v zadnjih letih sicer zmanjšale industrijsko onesnaževanje okolja, povečale so\npovršino gozdov in ekološko zaščitenih območij – čeprav vsa zaščitena območja niso kakovostna in skorajda ni\nzaščitenih območij na morju. Zmanjšala se je poraba vode in energije na enoto proizvoda. A gledano globalno, so se\nobremenitve za okolje zaradi gospodarske rasti in rasti števila prebivalstva kljub temu povečale.\n\nGospodarska prihodnost številnih revnih držav je vprašljiva, ker netrajnostno izkoriščajo naravne vire, nezadržno\npovečujejo onesnaževanje okolja, naglo širijo mesta. Države v razvoju bodo zaradi posledic podnebnih sprememb najbolj trpele, ker nimajo fi nančnih in institucionalnih zmožnosti za izvedbo ukrepov, s katerimi bi te spremembe\nzmanjševale.\n\nGospodarski in socialni stroški zaradi pomanjkanja ukrepov ali prepoznega ukrepanja so povsod, tudi v članicah\nOECD, ogromni. Neposredno jih je mogoče izmeriti kot stroške za zdravstvo, posredno pa se kažejo v obliki\nzmanjševanja produktivnosti. Dodatne stroške bodo povzročili še zmanjšanje biološke raznovrstnosti in klimatske\nspremembe.\n\nPolitika in tudi znanost sta tako pred številnimi izzivi, s katerimi se je treba spoprijeti. Izzivi postajajo tako za politike\nkot za raziskovalce vse bolj kompleksni in globalni, ob tem pa vse bolj zmanjkuje tudi časa, saj je na izboljšanje na\npodlagi izvajanja preventivnih ukrepov treba čakati vse dalj. Večino okoljskih problemov je z usklajenimi ukrepi še\nmogoče rešiti; za reševanje le-teh mora poskrbeti oblast v sodelovanju z zasebnimi podjetji in civilno družbo. Pa tudi\nv primerih, ko preprečitev globalnega segrevanja ni mogoča, je veliko potreb po pravočasnih prilagoditvah za blažitev\nposledic. Ministrstva morajo skupaj pripraviti okoljske politike in tesno sodelovati na področju fi nanc, energije,\ntrgovine, prometa, industrije, kmetijstva in zdravja. Spoznanja sodobne biologije nam pri tem lahko pomagajo,\nseveda če bodo dostopna vsem in njihov prenos enakopravno omogočen vsem mladim, ki bodo dali svoj prispevek\nna družbenem, gospodarskem, kulturnem in drugih področjih delovanja človeške družbe.\n\nBrez kakovostne izobrazbe kot osnovne pravice se človeška družba ne bo mogla vključevati v demokratične procese\nsuverenega odločanja, nadzora različnih vplivov na ekosisteme in zdravje, v javne razprave o enakopravnosti dostopa\ndo naravnih virov ter celostno reševanje problemov v zvezi z ohranjanjem biodiverzitete in ekosistemov. Gre za\nodločanje o pomembnih pravicah človeka.\nTu je ključno poslanstvo učiteljic in učiteljev kot nosilcev izobraževanja. Zato so pomembni njihova strokovnost in z\nnjo povezana strokovna avtonomija ter dostop do izobraževanja glede na razvoj sodobne znanosti.\n\nInteres in naloga države je, da jim to zagotovi, saj država s kakovostnim javnim šolskim sistemom lahko vsem\nprebivalkam in prebivalcem omogoči enakopravni dostop do kakovostne izobrazbe.\n\nOb prihajajočem svetovnem dnevu učitelja si bomo zato prizadevali, da bi učiteljice in učitelji imeli zagotovljen\ndostop do izobraževanja skladno z razvojem znanosti in da bi bili z njo čim bolj povezani. Tako bodo v praksi lahko\nčim bolj kakovostno izpolnili svoje pomembno poslanstvo pri prenosu znanja na mlajše generacije, katerih pravica je\ndostop do znanja, ki jim bo omogočalo razvijanje vrednot, ohranjanje kakovosti življenja ter suvereno delovanje na\npoklicnem, osebnem, kulturnem in družbenem področju.\n\nTo ni pomembno poudarjati le zato, ker je Generalna skupščina Združenih narodov letošnje leto razglasila za\nmednarodno leto planeta Zemlja, ampak zaradi dolgoročne odgovornosti za življenje in ohranjanja pravice do\nkakovostnega življenja in razvoja prihodnjih generacij.',NULL
11956,'lecture','en',11316,'2008-10-02','2010-06-30','Responding to the environment: Epigenetic variations in heredity and evolution / Odgovor na razmere v okolju: Epigenetska variabilnost pri dedovanju in evoluciji','In his theory of evolution, Darwin recognized that the\nconditions of life play a role in the generation of hereditary\nvariations as well as in their selection. However,\nsince the mid 20th century, the Modern Synthesis version\nof Darwinism expelled developmental responses to environmental\nchanges from the study of heritable variation.\nIt identifi ed heredity with genetics, with hereditary variation\nbeing seen in terms of combinations of randomly generated\ngene mutations. This view has dominated evolutionary\ntheorizing for the last sixty years. Since the 1990s,\ndata coming from developmental biology (particularly\nthe molecular aspects of differentiation and morphogenesis),\nfrom ecology (in particular ideas about niche construction\nand studies of symbiosis), from behavior (where\nthe transmission of information through social learning is\na major focus), and from cultural studies (where the relation\nbetween cultural evolution and genetic evolution is\nunder scrutiny) is challenging the modern synthesis view.\nMarion Lamb and I devoted our recent book Evolution\nin Four Dimensions to this challenge, and identifi ed four\ntypes of inheritance (genetic, epigenetic, behavioral, and\nsymbol-based), each of which can provide variations on which natural selection will act. Some of these variations\narise in response to developmental and environmental\nconditions, so developmentally induced or reconstructed\nheritable variations can be selected and lead to changes\nin the nature and frequency of phenotypes in populations.\nFurthermore, under certain conditions, the mechanisms\nunderlying epigenetic inheritance can also lead to the reorganization\nof the epigenome. In this lecture I review\nthe challenge that comes from the work on epigenetics\ncarried out since the late 1980s, discuss different types of\nepigenetic inheritance mechanisms, examine the prevalence,\nstability and inducibility of cellular epigenetic variants,\nand point to some of the ways in which epigenetic\nmechanisms have affected micro- and macro-evolution.\n----\nV svoji teoriji o evoluciji je Darwin izpostavil vlogo življenjskih\nrazmer v nastanku dednih razlik in v njihovi\nselekciji. Od sredine 20. stoletja dalje je moderna sinteza\ndarvinizma izključila razvojne odgovore na okoljske\nspremembe iz študij o dednih razlikah. Dedovanje\nje izenačila z genetiko, dedne razlike pa opisovala kot\nkombinacije naključnih genskih mutacij. Ta pogled je\nprevladoval v evolucijskih polemikah zadnjih šestdeset\nlet. Od devetdesetih let dalje novi podatki iz razvojne\nbiologije (predvsem molekularni vidiki diferenciacije in\nmorfogeneze), ekologije (ustvarjanje niš, raziskave simbioze),\nraziskav vedenja (prenos informacij prek socialnega\nučenja) in kulturoloških raziskav (povezave med\ngenetsko in kulturno evolucijo) spreminjajo pogled moderne\nsinteze. Z Marion Lamb sva o teh izzivih pisali v\nnajini knjigi Evolution in Four Dimensions, v kateri sva\ndoločili štiri tipe dedovanja (genetsko, epigenetsko, vedenjsko\nin simbolno), od katerih lahko vsak predstavlja\nvir razlik, na katerih deluje naravni izbor. Nekatere od\nteh razlik izvirajo iz razvojnih in okoljskih razmer, kar\nvodi v spremembe v naravi in v frekvenci fenotipov v\npopulaciji. Nadalje lahko mehanizmi, ki so odgovorni za epigenetsko dedovanje, pod določenimi pogoji vodijo v\nreorganizacijo epigenoma. V tem predavanju bom predstavila\npregled epigenetskih raziskav od poznih osemdesetih\nlet naprej, nadalje bom predstavila različne tipe\noz. mehanizme epigenetskega dedovanja, prevalenco,\nstabilnost in inducibilnost različnih epigenetskih variant\nin izpostavila nekatere načine, s katerimi so epigenetski\nmehanizmi vplivali na mikro- in makroevolucijo.',NULL
11957,'lecture','sl',11316,'2008-10-02','2010-06-30','Okolje in evolucija / Enviroment and evolution','Evolucija organizmov se nenehno odvija v odnosu med\nnjimi in okoljem. Zaradi spremenljivosti okolja lahko\ncelo rečemo, da je evolucija edini način preživetja biosfere.\nSicer pa daje okolje organizmom priložnost za\nrazmnoževanje in jih hkrati omejuje s končnostjo svojih\nvirov. Med sabo pa vrste v okolju sklepajo povezave v\nokviru prehranjevalnih verig, pri čemer se marsikdaj srečamo\ns koevolucijo. Za odnose znotraj vrste predstavlja\nokolje prostor tekmovanja za preživetje in reprodukcijo.\nZa evolucijo vrst so pomembni tudi ekosistemi kot\nemergentni sistemi (sistemi, katerih značilnosti ne moremo\nzožiti na lastnosti in zakonitosti, ki veljajo za njihove\ndele oziroma elemente).\n----\nOrganisms evolve only through interaction between\nthemselves and their environment. Because of ceaseless\nchanges of environment we may say that the evolution is\na necessity for the survival of the biosphere. The environment\nyields an opportunity for the reproduction of organisms\nand at the same time it restricts them through its\nlimitations. The species in an ecosystem are interconnected\nthrough the food chains within which they are often\ninvolved in co-evolution. For the intra-species relations\nthe environment represents a place for the competition\nof its members for life and reproduction. Ecosystems as\nemergent systems (system with irreducible features and/\nor principles) are also very important for the evolution\nof species.',NULL
11958,'lecture','sl',11316,'2008-10-02','2010-06-30','Vpliv podnebnih sprememb na organizme v geološki znanosti / Effect of climate changes on the organisms in the geological past','Klimatske spremembe in njihovi vplivi na razvoj organizmov\nso del naravnega procesa razvoja planeta Zemlje.\nUsmerjajo njihove prilagoditve in pospešujejo ali zavirajo\nnjihovo razširjenost v prostoru. V določenih primerih\nso klimatske spremembe tako drastične, da jim določeni\norganizmi ne morejo slediti; tako podležejo spremenjenim\nživljenskim pogojem in izumrejo. Vzroki za globalne\nklimatske sprememb in posledično izumiranje so\nzelo različni. Nastajajo zaradi spremenljivega položaja\nZemlje v vesolju, zaradi potovanje kontinentalnih plošč,\nvulkanske dejavnosti, velik pomen pa imajo tudi padci meteoritov,\nki v zelo kratkem času izrazito spremenijo\npodnebje. V geološki zgodovini poznamo najmanj pet\nvelikih množičnih izumiranj, ki so zajela celoten planet.\nLe eno izumiranje se je zgodilo zaradi ohlajevanja ozračja,\nmedtem ko so vsa nadaljnja izumrtja sledila povišanjem\ntemperature. V članku so opisani vzroki za vseh pet\nmnožičnih izumrtij in njihov vpliv na takratno življenje\nna Zemlji.\n----\nClimate changes and their effects on the organisms’ development\nare part of the natural process of Earth’s evolution.\nThey direct the adaptations of the organisms and\naccelerate or reduce their distribution in the area. Climate\nchanges can be in particular cases so drastic that certain\norganisms can not follow them and for that reason\nbecome extinct. The causes for global climate changes\nand consecutive extinction are various; changable position\nof Earth in the universe, movement of continental\nplates, vulcanic activity, meteorite fall, causing big climate\nchanges in short time period. At least fi ve massive\nextinctions which affected the whole planet are known\nin the geological history. Only one of them was due to\natmosphere cooling while all the others were caused by\ntemperature increase. In the present paper, the causes of\nall fi ve extinctions and their infl uence on the life on the\nEarth are described.',NULL
11968,'lecture','sl',11316,'2008-10-02','2010-06-30','Medvrstni odnosi krojijo strukturo življenskih združb: večvrstni interakcijski kompleksi v ekosistemih / Interspecific interactions are structuring natural assemblages: multispecies interaction complexes in ecosystems','Medvrstna razmerja ali interakcije med vrstami so temeljno\ngibalo v oblikovanju združb, torej njihove vrstne\nsestave in abundance posameznih vrst v njej. Z razmerji\nrazlagamo odnose med dvema vrstama, torej v kakšnem\nneposrednem odnosu sta vrsti v okolju. Z neposrednimi\nrazmerji pa lahko le delno razložimo strukturo združb in\nekosistemov, saj so nedavne raziskave pokazale na pomen\nposrednih razmerij v biokompleksnosti ekoloških\nsistemov. Neposredna razmerja razumemo kot interakcije\nmed dvema vrstama, pri čemer zaradi delovanja ene\nvrste številčnost druge upada ali raste, pri posrednih razmerjih\npa smo soočeni s sistemom treh ali več vrst. Pravzaprav\ngre za splet različnih neposrednih interakciji, v\nkaterih dve vrsti, ki nista v neposrednem stiku, prek tretje\nposredniške vrste ali mediatorja vplivata druga na drugo.\nNajbolj preučena oblika posrednih interakcij je prikrita\nkompeticija, pri kateri je mediator vrsta, ki je navadno\nna višjem trofi čnem nivoju kot pa prikrita kompetitorja\nin je bodisi plenilec, parazit ali parazitoid. Populacija\nmediatorja se lahko povečuje zaradi alternativnega plena\nali gostitelja, ki predstavlja prikritega kompetitorja vrsti,\nki je glavni plen oziroma gostitelj mediatorja. Zaradi alternativnega\nplena se lahko povečuje število mediatorja,\ns tem pa se povečuje tudi predacijski pritisk oziroma\nverjetnost infekcije glavnega plena oziroma gostitelja.\nProces lahko pripelje do popolne izključitve glavnega\nplena oziroma gostitelja iz sistema, populaciji mediatorja\nin alternativnega plena oziroma gostitelja pa se ujameta\nv ravnovesju. Do sedaj je bilo prepoznanih že več tipov\nprikrite kompeticije, ki predstavlja negativno razmerje\nmed prikritima kompetitorjema, medtem ko je primerov\npozitivnih posrednih razmerij do sedaj znanih zelo malo\nin jih opisujejo kot prikriti mutualizem. Poznavanje posrednih\ninterakcij se je izkazalo kot zelo pomembno v\nagrarnih sistemih, zlasti kar se tiče zatiranja za kmetijstvo\nškodljivih žuželk. Veliko nevarnost pa predstavljajo\ntudi vnosi eksotov, ki lahko prek deljenega mediatorja\npovzročijo popolno izključitev in izumrtje avtohtonih\nvrst in naravnih ekosistemov.\n----\nInterspecific interactions are the fundamental motive for\nthe formation of communities, that is of their species richness\nand species abundance. Interactions are used to\nexplain the relations between two species. However, these\ndirect relations can only partially explain the structure\nof communities and ecosystems. Recent studies have\nshowed that indirect relations are important for the biocomplexity\nof ecosystems as well. Direct reationships\nare actually interspecific interactions where one species\nincreases or decreases the quantity of the other species.\nIn indirect relations three or more species are involved\nvia direct interactions. Two species which are not directly\nconnected are in the relations via the third species, the\nmediator and thus affect each other. The most investigated\ntype of the indirect interactions is the hidden competition,\nwhere the mediator species is on higher tropical\nlevel as are the hidden competitors, and is a predator, parasite\nor parasitoid. The mediator population can increase\ndue to alternative pray, causing the increase of the predation\npressure or the increase of the possibility of pray’s\nor main host’s infection. The process can lead to the total\nexclution of the main pray or host from the system,\nbut the populations of the mediator and the alternative\npray are in the equlibrium. So far, several types of hidden\ncompetition were recognized, mostly negative. Only few\npositive interactions are known and are described as hidden\nmutualism. The knowledge on indirect interactions\nwas found to be very important in agricultural systems,\nsuch as insect repellents. High risk for the environment is\nalso the intoduction of foreign species, which can cause\ntotal elimination and extinction of native species and natural\necosystems because of the same mediator.',NULL
11969,'lecture','sl',11316,'2008-10-02','2010-06-30','Ekologija populacij / Population ecology','Prispevek opisuje populacijo kot osnovno enoto v ekologiji.\nPodana sta defi nicija populacije in nabor znakov, s\nkaterimi populacijo opišemo. Predstavljeni so vsi populacijski\nprocesi in najpomembnejši populacijski parametri.\nNa kratko je razložena dinamika populacij, in sicer na\nklasičen kakor tudi na sodoben način, pri katerem populacijo\nopisujemo kot metapopulacijo.\n----\nThe article describes population as a basic unit in a science\nof ecology. The population itself is defi ned and described.\nPresented are all the population processes and\nsome of the most important population parameters used\nto describe population as a unit. The dynamics of the populations\nis explained and the modern concept of understanding\nof population dynamics called metapopulations\nis introduced.',NULL
11970,'lecture','en',11316,'2008-10-02','2010-06-30','The ecosystem concept / Koncept ekosistema','The Convention on Biological Diversity (CBD) defi nes\nan “ecosystem” as a “dynamic complex of plant, animal\nand micro-organism communities and their non-living\nenvironment interacting as a functional unit” (see also\nTansley, 1935; Christopherson, 1996). The basic idea is\nthat living (and dead?) organisms are permanently involved\nin the exchange of energy, material and information\nwith their environment. Ecosystem function is governed\nby organisms acting at various stages within the system.\nPrimary producers (green, photosynthetically active\nplants and bacteria) form the base of the system. They\nhave the unique ability to fi x and conserve the energy\nof extraterrestrial radiation and produce digestible carbohydrates,\nlipids and proteins. They are hierarchically\nfollowed by herbivorous/phytophagous organisms feeding\non them. The fi rst order consumers are the prey\nfor second order consumers (carnivores) which hunt\nand feed on herbivores. There may be further levels and\nsteps in carnivorous consumers depending on the ecosystems\nselected. Finally, decomposers (destruents and\nreducers) are mineralizing dead organic material, thus\nplaying their role in organic material recycling – a prerequisite\nfor plant growth. There is a broad spectrum of\necosystems including terrestrial and aquatic ones. Deep\nsee, coral reefs, sea shores, ponds, rivers and creeks are\naquatic ecosystems as are tundra, taiga, deserts, or grass\nlands on the terrestrial side. But also anthropogenically\ninfl uenced systems may be called ecosystems like urban\nareas, gardens or waste land. Ecosystems can be threatened\nby various stressors. The toxicity of introduced\nelements (toxic gases, heavy metals, pesticides) or the\naggressiveness of newly introduced or invasive species\n(global warming, economic globalization) are only a few\nexamples of gradually unbalancing existing ecosystems.\n----\nV konvenciji o biološki raznolikosti (CBD) je ekosistem\nopredeljen kot dinamičen kompleks združb rastlin, živali\nin mikroorganizmov ter njihovega neživega okolja, ki\nskupaj delujejo kot funkcionalna enota (glej tudi Tansley,\n1935; Christopherson, 1996). Osnovna ideja je, da so\nživi (in odmrli?) organizmi stalno vključeni v izmenjavo\nenergije, snovi in informacij s svojim okoljem. Delovanje\nekosistema poganjajo organizmi s svojim delovanjem na\nrazličnih stopnjah sistema. Primarni producenti (zelene,\nfotosintetsko aktivne rastline in bakterije) so baza ekosistema,\nker lahko sprejmejo in zadržijo energijo zunajzemeljskega\nsevanja in proizvedejo razgradljive ogljikove\nhidrate, maščobe in beljakovine. Naslednjo stopnjo predstavljajo\nrastlinojedi organizmi. To so potrošniki prvega\nreda in predstavljajo plen za potrošnike drugega reda\n(mesojedci), ki rastlinojedce lovijo in se z njimi hranijo.\nV izbranem ekosistemu je lahko več zaporednih stopenj\nmesojedih potrošnikov. Končno pa razkrojevalci razgradijo\nmrtev organski material in igrajo ključno vlogo v recikliranju\nsnovi, potrebnih za rast rastlin. Obstaja mnogo\nekosistemov, vključno s kopenskimi in vodnimi: globoko\nmorje, koralni grebeni, obale, ribniki, reke in potoki so\nprimeri vodnih ekosistemov, tako kot so tundra, tajga,\npuščava in travišča primeri kopenskih. Med ekosisteme\nlahko prištevamo tudi antropogene, kot so urbane površine,\nvrtovi, odlagališča odpadkov. Na ekosisteme lahko\nvplivajo različni stresni dejavniki (strupeni plini, težke\nkovine, pesticidi) ali agresivnost novih oz. invazivnih\nvrst (globalno segrevanje, ekonomska globalizacija).',NULL
11971,'lecture','sl',11316,'2008-10-02','2010-06-30','Življenjska združba kot subjekt življenja / Biotic community as a component of life','Življenje je organizirano na več integracijskih nivojih.\nŽivljenjska združba predstavlja temeljni subjekt biosfere\nin je kot višja integracijska oblika izjemno kompleksna.\nNaravno združbo sestavljajo populacije vrst, ki so koevoluirale.\nTako kot na nivoju populacije je tudi na nivoju\nzdružbe uspešnost in funkcionalnost sobivanja tista, ki je\npodvržena naravni selekciji. Skupno informacijsko izhodišče\nzapisano v DNK-molekulah vrst, ki bivajo skupaj,\nje tisto, kar življenjsko združbo opredeljuje kot subjekt\nživljenja. Človek mnogokrat ustvarja skupine vrst iz različnih\nbiogeografskih regij. Take skupine ne predstavljajo\nzdružbe kot subjekta življenja, saj populacije nimajo\nvzajemnega razvoja. Zaradi tega so antropogeni sistemi\nbistveno drugačni od naravnih. Njihova kompleksnost je\nkaotična in na nivoju sistema nimajo ključne funkcionalnosti.\nZaradi tega predstavljajo motnjo v višjem integracijskem\nsistemu življenja na Zemlji – biosferi.\n----\nLife is organized on several levels of integration. A biotic\ncommunity is one of the basic components of biosphere.\nAs a higher integration formation it is extremely complex.\nA natural community is composed of populations\nof species that co-evolved. Similar to the population level,\nthe success and functionality of cohabitation of populations\nat the community level is also under a strong\npressure of natural selection. The common biotic information\nwritten in the DNA of species that live together\ndefines the biotic community as a subject of life. The\nman often creates groups of species originating from different\nbiogeographic regions. Such groups do not present\na community as a subject of life, since the populations of\norganisms in them did not develop together. That is\nwhy anthropogenic systems are significantly different\nfrom natural systems. Their complexity is chaotic and on\nthe system level they’re missing the key functionalities.\nThey represent a disturbance at the higher integration level\nof life on Earth – biosphere.',NULL
11972,'lecture','sl',11316,'2008-10-02','2010-06-30','Vodni ekosistemi – struktura in funkcija / Freshwater ecosystems – structure and function','Celinski vodni ekosistemi so edinstveni v več pogledih.\nV celotni hidrosferi predstavljajo zanemarljiv delež, z\nekološkega vidika pa so pestra okolja z značilnimi združbami,\nprilagojenimi na specifične svetlobne in toplotne\nrazmere ter navzočnost raznovrstnih kemičnih snovi naravnega\nin antropogenega izvora. So tisti ekosistemi, ki\nso v zemeljski zgodovini usodno vplivali (in še danes je\ntako) na razvoj človeške družbe in številnih kultur. Abiotska\nrazličnost stoječih in tekočih voda določa različnost\nživljenjskih združb, njihovo strukturo in funkcijo. Neposredna\npovezanost organizmov in procesov v vodnem\nmediju in usedlinah vsakega vodnega okolja zagotavlja\ncelovitost kroženja snovi in energije v vodnem telesu.\nDogajanja v kopnih ekosistemih, posebej delovanje človeka,\nusodno vplivajo na spremembe dogajanj v vodnih okoljih.\n Vplivi prispevnega kopnega okolja odločujoče\ndoločajo delovanje vodnih ekosistemov, preprosto vplivajo\nna njihove naravne lastnosti. Bremena kopnih eksositemov\npostanejo bremena vodnih. Stopnja obremenitve\nin onesnaženja povsod po svetu narašča, zato je nujen\nekosistemski pristop k reševanju okoljskih problemov.\nMogoče pa je le na temelju poznavanja naravnih procesov,\nrazumevanja življenjskih prostorov in pripadajočih\nživljenjskih združb v naravnih okoljih. Pričujoči članek\ngovori o tem, kakšni sta abiotska in biotska struktura vodnih\nteles in kako delujejo celinski vodni ekosistemi.\n----\nContinental water ecosystems are unique in several respects.\nThey represent a negligible portion of total hydrosphere,\nyet they are – from the ecological point of view\n– diverse environments with typical communities adapted\nto specific light and temperature conditions and to\npresence of various chemicals of natural and anthropogenic\norigin. They are the ecosystems that fatally influenced\nthe development of the human society and cultures throughout\nthe history and still do today. Abiotic diversity of\nstagnant and running water defines the diversity of life\ncommunities, their structure and function. The immediate\nconnection of organisms and processes in the water\nmedium and sediment of every aquatic environment ensures\nthe completeness of material and energy circulation\nin it. Activities, especially human activities, in terrestrial\n environment significantly effect and change the activities\nand natural characteristics of aquatic environments.\nThe terrestrial load becomes the aquatic load. The levels\nof load and pollution are increasing all over the world\ntherefore ecosystemic approach for solving environmental\nproblems is necessary, which is only possible when\nbased on the knowledge of natural processes and understanding\nof biotopes and communities in natural environments.\nThe topic of this paper is the abiotic and biotic\nstructure of aquatic body and the activity of continental\nwater ecosystems.',NULL
11973,'lecture','sl',11316,'2008-10-02','2010-06-30','Mikrobna oaza v tleh / Microbal oasis in the soil','Ohranjanje rodovitnosti tal je temeljna zaveza človeštva,\nsaj saj tla omogočajo pridelavo hrane. Mikroorganizmi\nimajo pri tem prav posebno pomembno vlogo, saj omogočajo\nkroženje hranil in so zaradi tega nepogrešljiv partner\nrastlinam. Velja pa tudi obratno. Največ mikrobne\naktivnosti je vezano na rizosfero, to je tisto območje v\ntleh, kjer se čuti vpliv rastlinskih korenin in delovanja\nmikroorganizmov. V prispevku bodo prikazani različni\nnačini, kako v rizosferi prihaja do teh interakcij.\n----\nSoil fertility is the fundamental characteristic of soil that\nsupports plant life and enables food production. Microorganisms\nare indispensable in maintaining soil fertility due\nto their ability to sustain nutrient cycling. The majority of\nsoil microbial activity is located in rhizosphere, a narrow\nregion of soil that is directly influenced by root secretions\nand associated soil microorganisms. In the article many\ndifferent ways how microorganisms and plants interact in\nthe rhizosphere will be discussed.\n',NULL
11974,'lecture','sl',11316,'2008-10-02','2010-06-30','Pedofavna – njena raznovrstnost in vloga pri razkrojevanju organskih ostankov v tleh / Pedofauna - variability and its role in decomposition of organic matter in soil','Pomen deževnikov pri ohranjanju plodnosti tal so vrtnarji\nin kmetovalci poznali že davno. Strokovno in eksperimentalno\nje njihovo vlogo pojasnil naravoslovec Charles\nDarwin. Na trati, v svojem vrtu v vasi Down pri Londonu,\nje leta 1842 nasul poskusno »stezico« iz zdrobljene krede\nter jo prepustil naravi in času. Po 29 letih je plast krede\nprekrivala 18 cm debela plast humusne zemlje. V povprečju\nje kreda lezla v tla za 6 mm na leto. Pomikanje v\nglobino so opravljali deževniki s spodkopavanjem (rovi)\nin površinskim odlaganjem svojih iztrebkov ali »glistin«.\nS pobiranjem in tehtanjem posušenih iztrebkov na površini\nje izračunal, da znosijo deževniki v enem letu 250 kg\nprsti na 1 ar. Skoraj tri desetletja dolg poskus je objavil v\nzadnji razpravi: »The formation of vegetable mould through\nthe action of worms with observation of their habits«\n(1881). Mnogo let kasneje se je preučevanja živega sveta\nv tleh lotil nemški biolog R.H.Francé in takratno znanje\nstrnil v delu: Das Edaphon (1912) in populariziral v knjigi\n»Das Leben im Ackerboden« (1922).\n\nMedtem ko sta bila kemija tal in mikrobiologija tal, uveljavljeni\nvedi, se je zoologija tal začela uveljavljati po izidu dela\n»Soil zoology«, zbornika razprav iz Second Easter School in\nAgricultural Science (1955) univerze v Nottighamu. Po pobudah\nprofesorjev: W. L. Kubiene, W. Kűhnelta, E. J. Ruslla,\nD. K. McE. Kevana, H. Franza, G. O. Evansa, P. W. Murphija,\nW. Tischlerja, C. O. Nielsena, Nielsa Haarlǿva, A. Macfadyena\nin M. S. Ghilarova se je zanimanje za pedozoologijo\nnaglo širilo. Sedaj je to področje ekologije vzporednica precej\nstarejši limnozoologiji.\n\nV Sloveniji smo začeli s tovrstnimi raziskovanji na Biološkem\noddelku BF in na Inštitutu za biologijo na Univerzi\nv Ljubljani. Predavanja iz tega področja so bila del predavanj\niz ekologije živali. Vzporedno je potekalo tudi posebno\npredavanje »pedozoologija« v okviru zooekološke\nusmeritve. Javnosti sem predstavil pedozoologijo z delom:\n»Živi svet prsti« (1965). Obsežen sistematski pregled\nživalstva tal je napisal Narcis Mršić (1997): »Živali naših\ntal«. Delo na tem področju nadaljujejo sodelavci Katedre\nza ekologijo, na Oddelku za biologijo BF pod vodstvom\nIvana Kosa.\n\nV tej obravnavi se bom omejil na živalsko komponento\ntal, na t.i. pedofavno. Pedološki pogled in mikrobno\nkomponento tal bom vključil le po potrebi.',NULL
11975,'lecture','en',11316,'2008-10-02','2010-06-30','Molecular markers and their application in biogeography / Molekulski markerji in njihova uporaba v biogeografiji','The application of molecular tools (DNA sequences,\nDNA fingerprinting) has revolutionized biogeographic\nresearch over the last two decades. Molecular biogeography\ncan be summarized under “phylogeography”, a\nterm coined by John Avise twenty years ago. It is describing\nthe branch of science that explores and interprets the\ngeographical distribution of genealogical lineages. In my\npresentation, I am going to discuss the following issues:\n1. Why should we use molecular markers in bio geographical\nresearch?\n2. Which types of molecular markers are being used,\nhow are the data generated and how do they look\nlike?\n3. Which questions can be answered with molecular\ndata and which ones not?\nTo illustrate the above points, I will present studies that\nexplored the effect of the glaciations of the ice ages on\nthe flora of the Alps as well as the EU 6th framework project\n“INTRABIODIV” as an example for the integration\nof molecular data, habitat data and species distribution\ndata.\nA starting point for that project was that species richness\nis the most widely used measure for biodiversity assessment.\nHowever, it is intraspecific diversity (genetic\npolymorphism) that represents the evolutionary and\nadaptive potential of each species in changing environments.\nThe main point of the project was to study possible correlations\nbetween intraspecific diversity and species richness\nor habitat variation. The objectives were:\n(i) to fi nd and explain possible relationships among inter-\nand intraspecifi c plant diversity and habitat variation,\n(ii) to elaborate a modeling approach to predict intraspecific plant diversity, using more efficiently accessible\nsurrogates, on a large scale,\n(iii) to establish tools for the design of a network of protected\nareas to effectively ensure the sustainable management\nof natural genetic resources.\nThe following questions were asked, using the Alps and\nthe Carpathians as model systems:\n(i) Is there congruence between intra-/interspecific biodiversity?\n(ii) Do areas of high endemism, often coinciding with\nglacial refugia, harbour a great degree of intraspecific\ndiversity?\n(iii) Is habitat variation, characterized by environmental\nparameters, a good surrogate for intra- and interspecific diversity?\nIn order to accomplish the aims, intraspecific diversity was\nmapped by using molecular markers in 25 model species,\nthe species richness was mapped on the same area using\nmainly existing data on plant distributions. Furthermore,\nenvironmental data were compiled for a map of habitat\ndiversity, and finally these maps were compared to find\npossible correlations among these variables.\n----\nUporaba molekularnih orodij (zaporedje DNA, prstni\nodtis DNA) je v zadnjih dvajsetih letih prevetrila biogeografske\nraziskave. Molekularno biogeografi jo lahko\npovzamemo kot filogeografijo (izraz je skoval John\nAvise) in predstavlja tisto znanost, ki odkriva in razlaga\ngeografsko razširjenost genealoških linij. Predstavil bom\nnaslednja vprašanja:\n1. Zakaj uporabljati molekularne markerje v biogeografskih\nraziskavah?\n2. Tipe molekularnih markerjev, načine pridobivanja\nin vrste podatkov.\n3. Na katera vprašanja lahko odgovorimo z molekularnimi\npodatki in na katera ne moremo?\nKot primer povezovanja molekularnih, habitatnih in podatkov\no razširjenosti vrst bom predstavil raziskavo o\nposledicah poledenitev med ledenimi dobami na alpsko\nfloro in evropski program 6. okvira INTRABIODIV. Izhodišče\ntega projekta je bilo dejstvo, da je pestrost vrst\nnajpogostejši kazalnik biodiverzitete. Vendar pa intraspecifi\nčna raznolikost (genetski polimorfizem) predstavlja\nevolucijsko in prilagoditveno moč vsake od vrst v\nspreminjajočih se okoljih. Glavni poudarek projekta je\nbila možnost povezave med intraspecifi čno raznolikostjo\nin pestrostjo vrst oz. ranolikostjo habitatov. Cilji so bili:\n1) poiskati in razložiti možna razmerja med inter- in intraspecifi\nčno raznolikostjo rastlin ter habitatno raznolikostjo,\n2) izdelati model za napoved intraspecifi čne raznolikosti\nrastlin v velikem obsegu z uporabo bolj dostopnih nadomestkov,\n3) določiti orodja za izdelavo mreže zaščitenih območij\nin s tem zagotoviti učinkovito trajnostno upravljanje\nnaravnih genetskih virov.\nŽeleli smo odgovoriti na naslednja vprašanja, pri čemer\nsmo uporabili Alpe in Karpate kot modelna sistema:\n1) Ali obstaja skladnost med intra- in interspecifično raznolikostjo?\n2) Ali imajo območja z veliko pojavnostjo endemitov in\nobenem tudi ledenodobnih reliktov visoko stopnjo intraspecifične raznolikosti?\n3) Ali so habitatne razlike, ki jih določajo okoljski parametri,\ndober približek za intra- in interspecifično raznolikost?\nDa bi dosegli naš namen, smo pregledali intraspecifično\nraznolikost z molekularnimi markerji pri 25 modelnih\nvrstah. Na istih območjih smo ocenili vrstno pestrost iz\ndostopnih podatkov o razširjenosti rastlin. Okoljske podatke\nsmo vključili kot kazalnike habitate raznolikosti.\nNa koncu smo vse tri vrste podatkov primerjali, da bi\nnašli morebitne povezave med vsemi spremenljivkami.',NULL
11976,'debate','sl',11316,'2008-10-02','2010-06-30','Okrogla miza / Round table',NULL,NULL
11977,'lecture','sl',11316,'2008-10-03','2010-06-30','Ohranjanje ekosistemskih storitev – osnova našega preživetja / Conservation of ecosystem services – the basis of human survival','Ekosistemi so funkcionalne enote pokrajine, ki imajo\nsposobnost samovzdrževanja. Delovanje ekosistemov\ntemelji na mreži povezav med organizmi in je odvisno\nod njihove velikosti, zgradbe, vitalnosti in prožnosti. V\nnaravnih razmerah so elementi v dinamičnem ravnovesju\nin ne prihaja do presežkov oziroma primanjkljajev v\npretoku energije in motenj v kroženju snovi. Taki ekosistemi\ns svojim delovanjem oblikujejo ugodne življenjske\nrazmere in zagotavljajo različne vire za človeka in druge\norganizme, kar danes poznamo kot ekosistemske storitve.\nNaši vplivi in posegi mrežo odnosov in procesov v\nekosistemu prekinejo ali zmotijo kar se odraža v pomanjkanju\nin slabi kakovosti virov in spreminjanju razmer v\nokolju. Zato je edina nadaljnja pot človeštva ohranjanje\nprocesov v naravi. To pomeni da moramo gospodariti\nekološko trajnostno, ekonomsko učinkovito in pošteno s\nsocialnega vidika.\n----\nEcosystems are functional units of landscape with high\nself-regulation potential. Ecosystems’ functions base on\nthe web of relations among organisms and depend on\ntheir size, structure, vitality and resilience. Under natural\nconditions the elements of the ecosystem are in a\ndynamic equilibrium, therefore neither a surplus, nor a\nshortage in energy through fl ow and no disturbances in\nmatter cycling occur. Such ecosystems assure favourable\nconditions for life and different resources for mankind\nand other organisms, which are nowadays recognized as\necosystem services. Human infl uences and activity affected\nthe structure and function of ecosystems that resulted\nin shortage and worsened quality of resources as well as\nin changes of environmental conditions. Therefore our\nonly future is preserving the processes in nature by ecologically\nsustainable, economically effi cient and socially\nfair management.',NULL
11978,'lecture','sl',11316,'2008-10-03','2010-06-30','Spoznavanje narave in družbe – SND / Cognition of nature and society','Razmerje med naravo in družbo je bilo vedno vznemirljivo,\nše posebej dramatičen pa je odnos družbe do žive\nnarave in še posebej odnos do drugih živali. V modernih\ndružbah se je uveljavila preprosta interpretacija, da\nje človek sicer naravno bitje, vendar tudi še nekaj »več«.\nToda »novo krasno« stoletje biotehnologije obeta radikalne\npremike pri razjasnjevanju »nadvprašanja«, kaj je\nto »nekaj več«. Pojem narave izgublja diskriminatorni\npomen, zato se radikalno spreminja uokvirjanje mnogih\npovezanih vprašanj. Korenitost napovedanih sprememb\nnaravnost spodbuja interdisciplinarno komunikacijo med\nbiologijo in sociologijo oz. vsemi drugimi družboslovnimi\nin humanističnimi strokami. Besedilo utemeljuje aktualnost\nvzpostavitve in poglobitve transdisciplinarne sociobiološke\nrefleksije dogajanja v razmerju med družbo\nin naravo, ki verjetno še nikoli v zgodovini ni bilo tako\naktualno, kot je na začetku enaindvajsetega stoletja.\n----\nRelation between society and nature was always exciting.\nEspecially dramatic are social relations to living nature\nand in particularly to other animals. In modern societies\nthe simple interpretation that humans are something\nmore but only natural creatures was quite popular. But\n»new brave« biotechnological century is promising to\nproduce radical shifts in exploring the »super question«\nwhat means »something more«. The concept of nature is\nlosing its discriminatory meaning, and this causes radical\nchanges in framing many connected topics. Predicted\nradical changes nevertheless encourage interdisciplinary\ncommunication between biology and sociology and every\nother social and humanistic discipline. The text supports\nestablishing transdisciplinary sociobiological reflexion of the social natural relations which has probably\nnever been as acute as at the beginning of the twenty-first\ncentury.',NULL
11979,'lecture','sl',11316,'2008-10-03','2010-06-30','Odpadki v regulacijski povratni zanki ohranjanja ekološkega ravnovesja / Wastes in regulating feedback of conservation of ecological balance','Ekosistem kot povezan sistem biocenoze in biotopa\nobravnavamo kot celoto. Pri tem so po navadi v ospredju\norganizmi, med seboj povezani v prehranjevalne verige\nin splete. Čim večja je biodiverziteta, tem stabilnejši je\nekosistem, zato pojmujemo onesnaževanje okolja, zaradi\nkaterega se spremeni vrstna sestava v ekosistemu, kot\ntveganje za ekosistem in človeka. Onesnaževanje je lahko\nposledica kopičenja določenih snovi – odpadkov, ki se\nne vključijo v prehranjevalne splete ampak spreminjajo\nbiotop do te mere, da v njem prisotna biocenoza ne preživi.\nOnesnaževanje je lahko tudi posledica vnosa škodljivih\nsnovi – nevarnih odpadkov, ki v prehranjevalne\nsplete sicer vstopijo, vendar ob tem organizme spremenijo\nali uničijo in s tem spreminjajo biocenozo. Ekonomski\ntrendi v sodobni industrijski družbi stimulirajo potrošnjo\ndobrin in s tem tudi proizvodnjo odpadkov. Razvija se\nstrokovno področje načrtnega ravnanja z odpadki, ki\nzmanjšuje njihove negativne učinke, vendar je javnost\ntudi do dobrih rešitev zaradi neozaveščenosti pogostokrat\nodklonilna.\n----\nEcosystem is a unity of biotop and biocenosis. Usually\nwe focus on organisms forming food chains and food\nwebs. Because ecosystem stability increases with increasing\nbiodiversity and because pollution influences species\ncomposition the pollution represents one of risks for\necosystems and humans. Pollution results from accumulation\nof certain material – waste that can not enter the\nfood web but can change the biotop that biocenosis can\nnot survive there. Pollution also results from presence of\nharmful material – hazardous waste, entering the food\nchain and affecting organisms and thus changing the biocenosis.\nEconomical trends in modern industrial society\nstimulate the consumption of goods and consequently\nalso the waste production. Technical aspects of waste\nmanagement are becoming more and more important but\nthey are often socially rejected because of lack of information.',NULL
11980,'lecture','sl',11316,'2008-10-03','2010-06-30','Varstvo ekosistemov / Protecting ecosystems','Varstvo ekosistemov s trajnostno rabo predstavlja nov\npristop varstva, ki poleg ohranjanja vključuje tudi revitalizacije\n(izboljšave) ekosistemov in rabo, ki bo trajnostna.\n\nPotrebe po varovanju so se pojavile, ko smo začeli okolje\nintenzivno spreminjati, kar vključuje tako onesnaževanje\nkot fi zično spreminjanje. Površina zaščitenih območij\nje v devetdesetih letih 20. stoletja dosegala manj kot 4\n% svetovnega ozemlja. Tudi zato so v razvitejših delih\nsveta sprevideli, da zavarovanje le nekaterih območij ob\ntrenutnem trendu spreminjanja narave ne bo omogočilo\ntrajnostnega razvoja. Zato so si za izziv postavili najprej\npripraviti smernice in kasneje tudi načrte upravljanja, ki\nbodo omogočali trajnostno rabo ekosistemov. Naravni\nekosistemi so ogroženi zaradi vpliva delovanja človeka,\nki izhaja predvsem iz rasti prebivalstva in njegovih potreb.\nNajpomembnejše obremenitve, ki jih povzročamo\nin s katerimi vplivamo na ekosisteme, so sprememba\nhabitata, fragmentacija habitata, čezmerno izkoriščanje\nekosistemov in vrst, vnos tujerodnih vrst, onesnaževanje,\nodvzemi vode in klimatske spremembe. Ob sedanjem\ntrendu zmanjševanja ekosistemske pestrosti celinskih\nvoda in povečevanju pritiskov na ekosisteme bomo kmalu\ndosegli raven, ki bo skrajno zaskrbljujoča, posledice\npa bodo katastrofalne. Tudi zaradi tega potrebujemo ekosistemski\npristop varstva. Ekosistemski pristop varstva\npomeni upravljanje naravnih dobrin z uporabo sistemsko\nširokih konceptov, ki zagotavljajo, da so rastline in živali\nv ekosistemu ohranjene v dobrem stanju v izhodiščnih\n– naravnih habitatih in delovanje ekosistemov ni moteno.\nZa uspešno varstvo je zelo pomembno, da pri tem sodelujejo\ntako država kot tudi regionalna in lokalna oblast. Del\nekosistemskega varstva je tudi ekonomija okolja. Vrste,\nzdružbe in ekosisteme moramo ovrednotiti, da jih bomo\nlahko neposredno primerjali z vrednostjo projektov, ki\nbi povzročili njihovo izginotje. \n\nKoraki v ekosistemskem\npristopu varstva so:\\\\\n1. izbor območja zanimanja oz. ekosistema in vključitev\ndéležnikov;\\\\\n2. opis značilnosti izhodiščnega (naravnega) ekosistema;\\\\\n3. opis značilnosti sedanjih ekonomskih, okoljskih in socialnih\nrazmer in trendov;\\\\\n4. razvoj skupne vizije želenega stanja in določitev okoljskih\nciljev;\\\\\n5. razvoj in implementacija načrta upravljanja;\\\\\n6. spremljanje stanja in vrednotenje rezultatov;\\\\\n7. dopolnitev načrta upravljanja oz. ukrepanje, če je treba.\n\nVarujemo lahko primarne – naravne ali sekundarne – delno\nspremenjene ekosisteme. Naravni ekosistemi, ki jih\nnajdemo na določenem območju, so rezultat delovanja\nnaravnih abiotskih in biotskih dejavnikov in so optimalna\nrešitev. Za varovanje spremenjenih ekosistemov se po\nnavadi odločimo takrat, ko od teh ekosistemov koristimo\nposebne usluge (npr. pridobivanje električne energije).\nČe ekosistemi ne dosegajo želenega stanja, ekosistem\nobnovimo. Opravimo lahko popolno obnovitev (renaturacijo)\nekosistema ali vzpostavimo le stanje, podobno\nizhodiščnemu, in opravimo izboljšanje (rehabilitacijo)\nekosistema. Ko na degradirano območje naselimo povsem\ndrugačno združbo, opravimo nadomestitev. Ker je\ndojemanje ekosistemov in ekosistemskih uslug različno,\nrabimo zakonodajo. Zakonodaja, ki vključuje ekosistemski\npristop varstva, omogoča izkoriščanje ekosistemskih\nuslug, vendar le tistih, ki bodo ohranjale osnovno zgradbo\nin delovanje naravnega ekosistema. V Sloveniji imamo\ntemeljna izhodišča varstva okolja vključena že v ustavo\nRepublike Slovenije, ki nam nalaga skrb za ohranjanje\nnaravnega bogastva in možnosti za skladen civilizacijski\nin družbeni razvoj. Ekosistemski pristop varstva je vključen\ntudi v politiko Evropske unije. Vendar na evropski\nravni sprejemamo le smernice, države članice pa morajo\nv skladu s smernicami ukrepe za doseganje ciljev direktiv\npopolno in pravilno prenesti v svojo zakonodajo. V\nSloveniji imamo več zakonov, ki neposredno obravnavajo\nvarstvo ekosistemov. To so Zakon o varstvu okolja,\nZakon o ohranjanju narave, Zakon o gozdovih, Zakon o\nkmetijskih zemljiščih in Zakon o vodah. Poleg zakonov\nsmo sprejeli tudi številne podzakonske akte, kot so uredbe\nin predpisi, ki podrobneje določajo pravila varstva in\nupravljanja ekosistemov. Zakon o varstvu okolja je krovni\nzakon, ki ureja varstvo okolja pred obremenjevanjem\nkot temeljni pogoj za trajnostni razvoj. Namen varstva\nokolja je spodbujanje in usmerjanje takšnega družbenega\nrazvoja, ki omogoča dolgoročne pogoje za človekovo\nzdravje, počutje in kakovost njegovega življenja ter\nohranjanje biotske raznovrstnosti. Zakon o ohranjanju\nnarave določa ukrepe ohranjanja biotske raznovrstnosti\nin sistem varstva naravnih vrednot z namenom prispevati\nk ohranjanju narave. Vendar pa zakon ne predvideva\nle ohranjanja, kot bi lahko sklepali iz imena, ampak\nv primerih spremenjene naravne vrednote predvideva\nnajprej vzpostavljanje izhodiščnega stanja in šele nato\nohranjanje. Ekosistemska raven je v zakonu zajeta tako\nv biotski raznovrstnosti (raznovrstnost ekosistemov) kot\ntudi v naravnih vrednotah. Za ohranjanje biodiverzitete\nna ekosistemski ravni zakon nalaga ohranitev habitatnih\ntipov, določitev ekološko pomembnih območij, določitev\nposebnih varstvenih območij – območja Natura 2000 in\nvarstvo naravnih vrednot.\n\nZakon o gozdovih predvideva nacionalni gozdni program,\nv katerem se določijo nacionalna politika trajnostnega,\nsonaravnega in večnamenskega gospodarjenja z gozdovi\nin usmeritve za ohranitev in razvoj gozdov ter pogoji\nza njihovo izkoriščanje oziroma večnamensko rabo. Cilj\nzakona je trajnostno upravljanje gozdov ter ohranitev in\nizboljšanje življenjskih razmer za živali, ki prosto živijo\nv gozdu. Za doseganje ciljev uporabljamo gozdnogospodarske\nin lovskoupravljavske načrte območij. Kljub temu\nda skoraj 60 % Slovenije poraščajo gozdovi, dejanska\ndrevesna sestava obstoječih gozdov v precejšnji meri odstopa\nod potencialne vegetacije. Na mnogih območjih so\nprevladujoče vrste, ki so bile tja zasajene ali so posledica\ngospodarjenja z gozdovi v preteklosti. S tem smo v mnogih\nprimerih gozdne ekosisteme vsaj delno spremenili.\nKmetijska zemljišča so močno degradirani gozdni ekosistemi,\nki so spremenjeni zaradi kmetijske rabe. Zakon o\nkmetijskih zemljiščih ureja tako rabo kmetijskih zemljišč\nkot njihovo varstvo predvsem pred onesnaževanjem.\nEkosistemski pristop varstva je vključen tudi v politiko\nEvropske unije do voda. Leta 2000 je bila objavljena t.\ni. Vodna direktiva – Direktiva 2000/60/ES, ki smo jo v\nslovensko zakonodajo prenesli z Zakonom o vodah. Izhodišče\nza upravljanje voda je določitev t. i. za tip značilnih\nreferenčnih razmer, pri čemer v izhodišče postavimo\nnaravne razmere in jih opišemo s štirimi skupinami\norganizmov: fi toplanktonom, fi tobentosom in makrofi ti,\nbentoškimi nevretenčarji ter ribami. Na vseh teh vodah\nlahko izkoriščamo različne ekosistemske usluge, vendar\nle v taki meri, da bistveno ne poslabšamo stanja voda.\nVsaka država Evropske unije mora zagotoviti doseganje\ndobrega ekološkega stanja vseh površinskih voda do leta\n2015. Kljub temu da je v Vodni direktivi postavljeno v\nizhodišče naravno stanje, pa direktiva dopušča tudi izjeme.\nVodnim telesom z rabo, ki je za državo ekonomsko\npomembna (npr. hidroelektrarne, zajetja pitne vode), kot\nizhodišče ne določimo naravnih razmer, ampak razmere,\nki so optimalne ob obstoječi rabi. V teh primerih varujemo\nsekundarne ekosisteme. Ekosistemsko varstvo je\nkompleksen proces, v katerem se soočajo različni interesi.\nPogosto lahko trajnostno rešitev dobimo le s širokim\nsoglasjem.\n----\nEcosystem protection by sustainable use is a new approach\nto environment protection. Beside ecosystem conservation,\nthis approach includes ecosystem revitalization\n(improvement) and sustainable use. \n\nThe need for protection\nfirst arose as the environment was being intensively\naltered, which includes both pollution and physical alterations.\nIn the 1990s, the total area of protected ecosystems\ncomprised less than 4 % of the Earth’s surface\narea. This was one of the reasons the developed countries\nrealized that protecting isolated areas with the current\ntrends of changes in nature will not enable sustainable\ndevelopment. They therefore set a goal of preparing directives\nand after that management plans that will enable\nsustainable use of ecosystems. Natural ecosystems are\nendangered as a consequence of human actions that stem\nmostly from the needs of rapidly growing population.\nThe most important burdens we impose on ecosystems\nare habitat changes and fragmentation, over exploitation\nof ecosystems and species, introduction of alien species,\npollution, water removal and climate change. With the\npresent-day trend of reducing the diversity of freshwater\necosystems, we will soon reach an alarming level and\ncan expect catastrophic consequences. This is an important\nreason why an ecosystem approach to protection is\nimperative. The ecosystem approach signifies management\nof natural goods by using broad concepts that ensure\nthat plants and animals are kept in good condition in\ntheir original (natural) habitats and that ecosystem functioning\nis not impaired. For protection to be efficient, it\nis very important to have the cooperation of national, regional\nand local authorities. Part of ecosystem protection\nis also environmental economics. Species, communities\nand ecosystems have to be evaluated so that it is possible\nto compare them with the value of projects that would\ncause their loss. \n\nThe steps in the ecosystem approach are\nthe following:\\\\\n1. Selection of the area of interest or ecosystem and inclusion\nof stake-holders;\\\\\n2. Description of the original (natural) ecosystem;\\\\\n3. Description of current economic, environmental and\nsocial conditions and trends;\\\\\n4. Development of joint vision of the desired state and\nestablishment of environmental goals;\\\\\n5. Development and implementation of the management\nplan;\\\\\n6. Monitoring and evaluation of results;\\\\\n7. Supplementation of the plan or action, if necessary.\n\nThe object of protection can be either natural or secondary\n(partially altered) ecosystems. Natural ecosystems are\nthe result of the functioning of natural abiotic and biotic\nfactors and are the optimum solution in the given environment.\nThe protection of altered ecosystems is usually\ndecided upon when the ecosystems provide us with\ncertain ecosystem services (e.g. obtaining electrical energy).\nIf ecosystems do not reach the desired state, they\nneed to be restored. This can either be complete renaturation\nof the ecosystem or restoration of the state similar\nto the original one (ecosystem rehabilitation). When a\ndegraded area is populated with a completely different\ncommunity, this is called substitution. The perception of\necosystems and ecosystem services is very variable and\ntherefore requires legislation. A legislation that includes\nthe ecosystem approach of protection enables exploitation\nof ecosystem services, but only those that retain the\noriginal structure and function of natural ecosystems.\nIn Slovenia the basic points of environment protection are\nincluded in the Constitution of the Republic of Slovenia,\nwhich charges us with protecting natural wealth and possibilities\nfor harmonious development of the civilization\nand society. The ecosystem approach to protection is included\nalso in the politics of the European Union. However,\nat the European level, only directives are passed\nand the member countries have to integrate the measures\nfor reaching the goals set by the directives completely\nand correctly into their own legislation. There are several\nlegal acts in Slovenia that directly deal with the topic of\necosystem protection. These are the Environment Protection\nAct, the Nature Conservation Act, the Act on Forests,\nthe Agricultural Land Act and the Water Act. Beside\nthese acts, there are also several decrees and regulations\nthat define in more detail the policy of ecosystem protection\nand management. The Environment Protection Act\nis the main law that defines protecting the environment\nform loads as the basic condition for sustainable development.\nThe aim of environment protection is encouraging\nand directing such a way of social development\nthat enables long-term conditions for human health and\nquality of life and preservation of biodiversity. The Nature\nConservation Act defines the measures for preserving\nbiodiversity and the system of protecting natural values\nwith the intention of contributing to preserving the natural\nenvironment. However, despite its name, this law\ndoes not only envisage conservation but in the cases of\naltered natural values requires first the reestablishment\nof the natural conditions and only then conservation. The\necosystem level in the law is comprised both in the biodiversity\n(ecosystem diversity) as well as in natural values.\nFor preserving biodiversity on the ecosystem level, the\nAct dictates the preservation of habitat types, the establishment\nof ecologically significant sites, the establishment\nof special protection areas – Natura 2000 sites and\nthe protection of natural values.\n\nThe Act on Forests defines the national forest program\nwherein the national policy of sustainable and multipurpose\nforest management is delineated, as well as the guidelines\nfor the preservation and development of forests\nand the terms of their exploitation or multipurpose use.\nThe aims of the Act are sustainable forest management,\npreservation of forests and amelioration of the living\nconditions for animals living freely in forests. To achieve\nthese aims, regional forest and hunting management\nplans are set. Forests grow over almost 60 % of the Slovene territory. Nonetheless, the actual tree composition\nof these forests is largely different from the potential vegetation.\nThe prevalent species in many areas are those\nthat have been planted or are the consequence of forest\nmanagement in the past. Many forest ecosystems have\nbeen at least partially altered in this way. Farmlands are\nseverely degraded forest ecosystems that had been altered\nfor the purposes of farming. The Agricultural Land Act\nmanages the use of farmlands as well as their protection\nagainst pollution. The ecosystem approach to protection\nis included also in the water policy of the European Union.\nIn the year 2000 the EU passed the Water Framework\nDirective (Directive 2000/60/EC) which has been incorporated\ninto the Slovene legislation with the Water Act.\nThe starting point of water ecosystem management is the\ndefining of the so-called type specific reference conditions.\nThis is done by starting form natural conditions and\ndescribing them with four groups of organisms: phytoplankton,\nphytobenthos and macrophytes, benthic invertebrates\nand fi sh. Ecosystem services can be used in all\nwaters but only insofar as they do not significantly impair\nthe conditions of these ecosystems. Each EU member is\nrequired to ensure good ecological state of all its surface\nwaters by the year 2015. Although the Water Framework\nDirective sets the natural conditions as the starting point,\nit allows for certain exceptions. For water bodies being\nused in a way that is of national economic importance\n(e.g. hydroelectric power plants, drinking water impounds)\nthe starting point are not natural conditions,\nbut those that are optimal for the existing use. In these\ncases, secondary ecosystems are protected. Ecosystem\nprotection is a complex process where different interests\nare confronted. The sustainable solution can often only\nbe achieved by a wide consensus.',NULL
11981,'lecture','sl',11316,'2008-10-03','2010-06-30','Napačne in nepopolne predstave o živih sistemih / Misconceptions about living systems','Posodobitev biološkega izobraževanja temelji na premiku\nod opisovanja pojavov in učenja pretežno nepovezanih\npodatkov na pamet proti celostnemu razumevanju\ndelovanja narave, ki ga je treba pri učencih začeti razvijati\nže zgodaj v procesu izobraževanja in nato postopno\nnadgrajevati. Ta premik od učitelja zahteva spremembo\nnjegovega razmišljanja o biologiji ter večjo pozornost\npri identifi kaciji in odpravljanju napačnih in nepopolnih\npredstav, ki ovirajo postopno izgradnjo mreže znanja pri\nučencih. Dodatni izziv za učitelje predstavlja nujnost\nobravnavanja aktualnih družbenih tem, ki pogosto izhajajo\niz nedavnih novih znanstvenih spoznanj (npr. gensko\nspremenjeni organizmi, kloniranje, človekovi vplivi na\nekosisteme), hkrati pa obsegajo poleg naravoslovnih tudi\ndružboslovne vidike. Zaradi zahtevnosti posodobitve\nbiološkega izobraževanja moramo učiteljem biologije\nzagotoviti kakovostno, dolgoročno in vsestransko podporo.\n----\nModern biology education requires a shift from description\nof phenomena and rote learning of fragmented facts\ntoward an integral conceptual understanding about the\nfunctioning of nature. The development of conceptual\nunderstanding in students should start early and then be\nupgraded and complemented in higher grades. This new\napproach to education depends upon a change in the way\nthat teachers think about biology. Teachers should also\naddress misconceptions commonly held by students, since\nincorrect notions interfere with the gradual construction\nof conceptual understanding. An additional challenge\nfor the teachers is the need to address socially important\ntopics, which often encompass very recent scientific discoveries\n(e.g. genetically modified organisms, cloning,\nhuman impact on ecosystems) as well as aspects related\nto social sciences. Teachers need adequate long-term support\nto accomplish these essential changes in biology\neducation.',NULL
11982,'lecture','sl',11316,'2008-10-03','2010-06-30','Taksonomije in znanje / Taksonomies and knowledge','Bloomova taksonomija ciljev vzgoje in izobraževanja v\nSloveniji že desetletja vpliva na kurikularno načrtovanje\nin preverjanje znanja, med drugim tudi pri predmetu biologija.\nAvtor besedila skuša pokazati, da je bil ta vpliv\nvseskozi problematičen. Strokovna besedila in celo uradni\nšolski dokumenti pogosto potvarjajo taksonomijo.\nSporna je tudi izvirna različica taksonomije. Nastala je\nna opisnih in izkustvenih izhodiščih, kar jo uvršča med\nklasifi kacije, ki so nastajale v času pred Linnéjem. V taksonomijo\nje vgrajena logika, ki neustrezno razdvaja psihološko\nin epistemsko razsežnost učenja. Avtorji taksonomije\nse zavzemajo za načelo učenčeve avtonomnosti,\nvendar se v njihovi razlagi to načelo nanaša le na psihološko\nrazsežnost učenja. Bloomova skupina je znanje\nenačila z informacijami, čeprav so že sočasne spoznavne\nteorije skoraj enotno trdile, da je znanje sestavljeno iz\npojmov. Zato taksonomija ne upošteva dejstva, da je vse\n(tudi biološko) znanje perspektivično. Kako sporne zamisli\nso vgrajene v Bloomovo taksonomijo, je mogoče\npokazati na primeru biološkega pouka in znanja.',NULL
11983,'lecture','sl',11316,'2008-10-03','2010-06-30','Izobrazba in demokracija / Education and democracy','Sodobna družba je privzdignila pomen znanja. Govorimo\ncelo o družbi znanja; znanje je tisto, ki zagotavlja\ndružbeni razvoj in pomembno vpliva na položaj posameznika.\nNa njegovo zmožnost, da je subjekt družbenega\ndelovanja v sicer kompleksnem svetu. Prav zato se zdi\nnaravno, da ima šola, ki je bila ustanovljena za posredovanje\nznanja, v sodobni družbi poseben položaj. Posebnost\nnjenega položaja se kaže v tem, da je v večini držav\nobvezna za določen del populacije, in to celo vse daljši\nčas. Po drugi strani se šola še nikoli ni soočala s perečimi\nvprašanji absentizma, šolsko neuspešnostjo, nemotiviranostjo\nučencev za učenje, upadanjem radovednosti, želje\npo novem znanju. Šola naj bi v preteklosti mnogo laže\nnačrtovala, kakšno in katero znanje učenci potrebujejo.\nDanes pa se zdi, da mladi preprosto ne pristajajo več\nna opise sedanjosti (sveta), kot jo prikazujemo starejši.\nKako v spremenjenem dojemanju našega bivanja (prostora\nin časa) in ob še večji kompleksnosti prihodnjega\nsveta premišljati o tem, kaj naj bo dediščina in popotnica\nmlajšim generacijam? Kako v tem svetu razumeti poslanstvo\npedagoškega dela?\n----\nThe modern society has elevated the signifcance of knowledge.\nNowadays we can even talk about the society of\nknowledge; for knowledge is the driving power for social\ndevelopment and considerately influences the individual’s\nstanding and his/her ability of being a social active subject\nin complex world. For this it seems naturally that\neducational establishment, which was founded to mediate\nthe knowledge, has a unique position in the modern\nsociety. Its specialty is expressed by its obligation for a\nparticular part of the population in many countries, and\nthe time of education has been even prolonged. On the\nother hand, in school man has to struggle with absenteeism,\nfailure, pupils’ unmotivated to study, decline of curiosity\nand desire for new knowledge. In the past, it was\nsupposedly easier to plan the variety and quality of the\nrequired knowledge. Today it seems that young people\nrefuse to accept the description of the present time and\nworld as given by the older generations. What should be\nthe heritage to younger generations in changed comprehension\nof our being in time and space, combined with\neven larger complexity of the world in the future? In this\nsituation, what is the mission of the pedagogical work/\nactivity.',NULL
11984,'debate','sl',11316,'2008-10-03','2010-06-30','Okrogla miza / Round table',NULL,NULL
12136,'demonstration video','sl',9979,'2010-03-10','2010-04-28','Zobna preventiva','Zdravko Črv, voditelj informativne oddaje Ščetnik napove prispevek novinarke Miše Karies, ki se v živo javlja iz OŠ Jurija Dalmatina v Krškem,. Miša želi s sprva narediti nekaj kratkih intervjujev o ljubezni in o mesecu maju, vendar se začne vmes vpletati zgodba o ohranjanju zdravih zob, aktivnostih in ljudeh, ki so za to zaslužni. Na koncu je voditelj Zdravko Črv popolnoma zmeden, ker ne razume kaj ima ta zgodba opraviti z ljubeznijo. Ler je sam zaljubljen v Mišo, se odloči, da jo povabi na zmenek. Tam pa pogovor spet nanese na zdrave zobe...\n',NULL
12137,'demonstration video','sl',9979,'2010-03-10','2010-06-16','Odvisniki','V učnem načrtu za slovenščino je pod izobraževalnimi cilji zapisano, da se učenci v 8.razredu seznanijo s podredno zloženo povedjo, tj. z vrstami odvisnikov. Posnetek na zabaven način pomaga učencem utrditi znanje o vrstah odvisnikov. Vsi izobraževalni cilji so vpleteni v vloženo zgodbo dečka (oddaja Zmenkarije), ki po dolgotrajnem učenju sanja o vprašačnicah in vrstah odvisnikov, ki so personificirani v podobi deklet in fantov. Predstavitev je prilagojena različnim zaznavnim tipom učencem (vizualnim, slušnim in kinestetičnim), saj so informacije podane skozi vse skozi vse omejene kanale. Dodana vrednost posnetka je tudi možnost vključitve interaktivnih vaj z glasovalnimi sistemi in vpeljavo videa v programe za interaktivno tablo. Učitelj slovenščine lahko posnetek uporabi v vseh fazah učnega procesa (od uvodne motivacije do utrjevanja), hkrati pa z njim spodbudi kreativnost učencem, s katero bi lahko presegli zgolj suhoparno, nedinamično teoretično obravnavo novih slovničnih tem. \n',NULL
12139,'demonstration video','sl',9979,'2010-03-10','2010-05-27','Zemlja, Voda, Zrak',' Učenke 6. razreda so pri filmskem krožku z velikim veseljem oblikovale izobraževalno temo, ki je vezana tudi na ekologijo in osveščenost nas vseh, ki živimo na planetu zemlja. Domiselnost, vutrajnost in delavnost, so odlike učenk, ki se kažejo na različnih področjih in prepričani smo, da niso rekle še zadnje besede. ',NULL
12140,'demonstration video','sl',9979,'2010-03-10','2010-05-27','Fizikalni poizkusi',NULL,NULL
12169,'lecture','en',12154,'2010-01-05','2010-05-06','Lecture 1: Behaviorism',NULL,NULL
12170,'lecture','en',12154,'2010-01-05','2010-05-06','Lecture 2: Behaviorism 2',NULL,NULL
12171,'lecture','en',12154,'2010-01-07','2010-03-16','Lecture 3: Behaviorism 3',NULL,NULL
12172,'lecture','en',12154,'2010-01-07','2010-05-06','Lecture 4: Behaviorism 4',NULL,NULL
12173,'lecture','en',12154,'2010-01-12','2010-05-06','Lecture 5: The Cognitive Architecture 1',NULL,NULL
12174,'lecture','en',12154,'2010-01-12','2010-05-06','Lecture 6: The Cognitive Architecture 2',NULL,NULL
12175,'lecture','en',12154,'2010-01-12','2010-05-06','Lecture 7: The Cognitive Architecture 3',NULL,NULL
12176,'lecture','en',12154,'2010-01-14','2010-05-06','Lecture 8: The Cognitive Architecture 4',NULL,NULL
12177,'lecture','en',12154,'2010-01-14','2010-05-06','Lecture 9: The Cognitive Architecture 5',NULL,NULL
12178,'lecture','en',12154,'2010-01-19','2010-05-06','Lecture 10: The Cognitive Architecture 6',NULL,NULL
12179,'lecture','en',12154,'2010-01-19','2010-05-06','Lecture 11: Theories of Knowledge 1',NULL,NULL
12180,'lecture','en',12154,'2010-01-19','2010-05-06','Lecture 12: Theories of Knowledge 2',NULL,NULL
12181,'lecture','en',12154,'2010-01-21','2010-05-06','Lecture 13: Theories of Knowledge 3',NULL,NULL
12182,'lecture','en',12154,'2010-01-21','2010-03-16','Lecture 14: Theories of Knowledge 4',NULL,NULL
12183,'lecture','en',12154,'2010-01-26','2010-03-16','Lecture 17: Theories of Knowledge 5',NULL,NULL
12184,'lecture','en',12154,'2010-01-26','2010-05-06','Lecture 15: Complex Cognition 1',NULL,NULL
12185,'lecture','en',12154,'2010-01-26','2010-05-06','Lecture 16: Complex Cognition 2',NULL,NULL
12186,'lecture','en',12154,'2010-01-28','2010-05-06','Lecture 18: Complex Cognition 3',NULL,NULL
12187,'lecture','en',12154,'2010-01-28','2010-05-06','Lecture 19: Complex Cognition 4',NULL,NULL
12188,'lecture','en',12154,'2010-02-04','2010-05-06','Lecture 20: Emotion, Motivation, and Volition 1',NULL,NULL
12189,'lecture','en',12154,'2010-02-04','2010-05-06','Lecture 21: Emotion, Motivation, and Volition 2',NULL,NULL
12190,'lecture','en',12154,'2010-02-09','2010-05-06','Lecture 22: Emotion, Motivation, and Volition 3',NULL,NULL
12191,'lecture','en',12154,'2010-02-09','2010-05-06','Lecture 23: Emotion, Motivation, and Volition 4',NULL,NULL
12192,'lecture','en',12154,'2010-02-11','2010-05-06','Lecture 25: Emotion, Motivation, and Volition 5',NULL,NULL
12193,'lecture','en',12154,'2010-02-11','2010-05-06','Lecture 26: Emotion, Motivation, and Volition 6',NULL,NULL
12194,'lecture','en',12154,'2010-02-11','2010-05-06','Lecture 24: Cognitive Development Through the Life Span 1',NULL,NULL
12195,'lecture','en',12154,'2010-02-16','2010-05-06','Lecture 27: Cognitive Development Through the Life Span 2',NULL,NULL
12196,'lecture','en',12154,'2010-02-16','2010-05-06','Lecture 28: Cognitive Development Through the Life Span 3',NULL,NULL
12197,'lecture','en',12154,'2010-02-16','2010-05-06','Lecture 29: Cognitive Development Through the Life Span 4',NULL,NULL
12198,'lecture','en',12154,'2010-02-23','2010-05-06','Lecture 30: Cognitive Development Through the Life Span 5',NULL,NULL
12199,'lecture','en',12154,'2010-02-23','2010-05-06','Lecture 31: Cognitive Development Through the Life Span 6',NULL,NULL
12200,'lecture','en',12154,'2010-02-25','2010-05-06','Lecture 32: The Brain and Cognition 1',NULL,NULL
12201,'lecture','en',12154,'2010-02-25','2010-05-06','Lecture 33: The Brain and Cognition 2',NULL,NULL
12208,'lecture','sl',12146,'2010-03-12','2010-03-30','Pregled procesa komercializacije tehnologij in obveznosti raziskovalca do intelektualne lastnine',NULL,'Pregled procesa komercializacije tehnologij in obveznosti raziskovalca do intelektualne lastnine;;Institut;;TT na IJS;;Pregled;;Od kod denar za raziskave?;;Intelektualna lastnina;;Čigava je?;;Od financiranja do rezultata - 1;;Od financiranja do rezultata - 2;;Povečati absorbcijsko sposobnost v podjetjih;;Pogodbeno raziskovanje / Raziskovanje v sodelovanju z industrijo;;Licenciranje / Spin-offing;;Od financiranja do rezultata - 3;;10 korakov do komercializacije na MIT;;Procesi na IJS;;Od financiranja do rezultata - 4;;TT na NCSU;;TT v CERNu;;Primerjava med NCSU, CERN, JSI;;4 slovenske raziskovalne organizacije;;Od financiranja do rezultata - 5;;Kaj je spin-off/out? (lastniški / licenčni model) - 1;;Kaj je spin-off/out? (lastniški / licenčni model) - 2;;Spin-off (odprta vprašanja);;Deleži v spin-off/out-ih;;Od financiranja do rezultata - 6;;Od financiranja do rezultata - 7;;Kako naprej?;;Hvala'
12209,'lecture','sl',12146,'2010-03-12','2010-03-30','Kaj je intelektualna lastnina',NULL,'Kaj je intelektualna lastnina;;Znanje brez meja;;Intelektualna lastnina;;Kaj sodi med pravice intelektualne lastnine;;Formalne razlike;;Avtorska pravica in sorodne pravice;;Izumi in patenti;;Patentno varstvo;;Model;;Znamka;;Pravice intelektualne lastnine = lastnina;;Hvala za pozornost'
12210,'lecture','sl',12146,'2010-03-12','2010-03-30','Vloga patentnega zastopnika',NULL,'Vloga patentnega zastopnika pri gospodarskem izkoriščanju industrijske lastnine;;Industrijska lastnina - 1;;Za pridobitev patenta, modela, blagovne znamke je potreben ...;;Industrijska lastnina - 2;;Valvasorjev izum;;Codellijev izum;;Negospodarsko izkoriščanje;;Patentni zastopnik v Sloveniji;;Evropski patentni zastopnik;;Zastopnik za modele in blagovne znamke ... - 1;;Zastopnik za modele in blagovne znamke ... - 2;;Evropski zastopnik za modele in blagovne znamke;;Seznami patentnih zastopnikov;;Gospodarsko izkoriščanje;;Patentni zastopnik;;Poslovni načrt;;Znano stanje tehnike;;V času R&R;;Industrijska lastnina - 3;;Industrijska lastnina - 4;;Industrijska lastnina - 5;;Industrijska lastnina - 6;;Pridobitev IL - 1;;Pridobitev IL - 2;;Pridobitev IL - 3;;Pridobitev IL - 4;;Prijavitelj – izumitelj se odloča - 1;;Načelo za odločitve;;Pravice IL - 1;;Pravice IL - 2;;Prodaja pravice IL;;Prijavitelj – izumitelj se odloča - 2;;Prijavitelj – izumitelj se odloča - 3;;Koristni naslovi;;Hvala za pozornost'
12211,'lecture','sl',12146,'2010-03-12','2010-03-30','Osnove pridobivanja tveganega kapitala',NULL,'Rules and the players;;Licenčni vs kapitalski;;Barva denarja - 1;;Lastnosti sredstev;;Barva denarja - 2;;Faze podjetja;;Pred-semenska faza;;Semenska faza;;Zgodnja faza;;Faza rasti;;Izhod;;Ključni igralci;;Hi-tech start-up: ključni igralci – “egotripi”;;Poslovni angeli;;Rizični kapitalisti, EXIT!!!;;Vizija - Razlog – Energija'
12213,'introduction','sl',12206,'2007-10-26','2010-06-07','Čas za vire se izteka',NULL,NULL
12215,'lecture','sl',12206,'2007-10-26','2010-06-07','Osnovna opremljenost jezika s prostodostopnimi (pisnimi) viri in njihova standardizacija',NULL,NULL
12248,'lecture','en',11336,'2010-03-19','2010-04-12','The Cyc Lexicon','The Cyc knowledge base (KB) is a formalized representation of a vast quantity of fundamental human knowledge: facts, rules of thumb, and heuristics for reasoning about the objects and events of everyday life. The medium of representation is the formal language CycL, described below. The KB consists of terms--which constitute the vocabulary of CycL--and assertions which relate those terms. These assertions include both simple ground assertions and rules. Cyc is not a frame-based system: the Cyc team thinks of the KB instead as a sea of assertions, with each assertion being no more \"about\" one of the terms involved than another.\n\nThe Cyc KB is divided into many (currently thousands of) \"microtheories\", each of which is essentially a bundle of assertions that share a common set of assumptions; some microtheories are focused on a particular domain of knowledge, a particular level of detail, a particular interval in time, etc. The microtheory mechanism allows Cyc to independently maintain assertions which are prima facie contradictory, and enhances the performance of the Cyc system by focusing the inferencing process.\n\nAt the present time, the Cyc KB contains nearly five hundred thousand terms, including about fifteen thousand types of relations, and about five million facts (assertions) relating these terms. New assertions are continually added to the KB through a combination of automated and manual means. Additionally, term-denoting functions allow for the automatic creation of millions of non-atomic terms, such as (LiquidFn Nitrogen); and Cyc adds a vast number of assertions to the KB by itself as a product of the inferencing process.','The Cyc Lexicon;;Overview - 1;;Themes;;Language Microtheories;;Favour-TheWord;;Lexicon Microtheories;;Overview - 2;;Two string-concept routes;;Kinds of semantic predicates;;nameString;;nameStrings-like predicates;;Lexical Info for ECoppock;;Assertion - 1;;Predicate : denotation;;Last query in EverythingPSC;;Predicate : speechPartPreds;;Constant : Ring-Theword;;Constant : Coke-Theword;;Mass nouns vs. Count nouns;;brownbag_coppock_tcl_01_Page_20;;Predicate : multiWordString;;Mt - 1;;Mt - 2;;Predicate : compoundString;;CompoundString or MultiWordString;;What if I can\'t remember this;;Dictionary Assistant - 1;;Dictionary Assistant - 2;;Dictionary Assistant - 3;;Dictionary Assistant - 4;;Nouns like mother and temperature;;denotesArglnReln;;RelationParaphraseMt;;nounSemTrans;;verbSemTrans;;verbSemTrans-Canonical;;Kinds of semantic predicates;;genTemplate;;That genTemplate in tree form;;Deriving genTemplates;;Assertion - 2;;Kinds of semantic predicates;;Overview - 3;;Two string-concept routes;;Two kinds of morphology;;Prototypical Inflectional Morphology;;Inflectional Morphology in Cyc - 1;;Inflectional Morphology in Cyc - 2;;EnglishSuffixationFn;;Mt - 3;;Prototypical Derivational Morphology;;Derivational Morphology in Cyc;;Individual;;nounSemTrans;;Comparatives and superlatives: Inflectional or Derivational;;Inflectional Analysis of Comparatives;;Derivational Analysis of Comparatives;;Application: Interpreting queries;;A rule for comparative semantics;;Assertion - 3;;To do - 1;;Nouns with arguments;;Do nouns have argument structure like verbs;;Nouns - verbs;;CP complements;;Infinitival complements;;Locative PP complement;;Nouns: optional arguments;;Result vs. Process Readings;;examination vs. exam;;-ing:unambiguosly process;;frequent: disambiguates;;constant: also disambiguates;;role of possessors;;agent-by makes of obligatory;;author-by: of optional;;Nouns vs. Verbs;;What nouns have process readings;;Counterexample;; A rule for deriving lexical entries;;Assertion - 4;;To do - 2;;Conclusions'
12290,'tutorial','en',12246,'2010-03-22','2010-04-14','PAC-Bayes Theory in Supervised Learning',NULL,'PAC-Bayes theory in supervised Learning Universite Laval, Quebec, Canada;;Summary (1);;Summary (2);;Denitions (1);;Denitions (2);;Denitions (3);;Denitions (4);;Denitions (5);;The Gibbs clasier (1);;The Gibbs clasier (2);;The Gibbs clasier (3);;The Gibbs clasier (4);;GQ; BQ, and KL(QkP) (1);;GQ; BQ, and KL(QkP) (2);;GQ; BQ, and KL(QkP) (3);;GQ; BQ, and KL(QkP) (4);;GQ; BQ, and KL(QkP) (5);;A PAC-Bayes bound to rule them all !, Theorem 1 Germain et al. 2009;;A PAC-Bayes bound to rule them all !, Theorem 1+ Lever et al (2010);;Proof of Theorem 1 (1);;Proof of Theorem 1 (2);;Proof of Theorem 1 (3);;Proof of Theorem 1 (cont) (1);;Proof of Theorem 1 (cont) (2);;Proof of Theorem 1 (cont) (3);;Applicability of Theorem 1;;The Seeger\'s bound (2002), Seeger Bound;;The Seeger\'s bound (2002), Note;;Graphical illustration of the Seeger bound;;Proof of the Seeger bound (1);;Proof of the Seeger bound (2);;Proof of the Seeger bound (3);;Proof of the Seeger bound (4);;Proof of the Seeger bound (5);;The McAllester\'s bound (1998);;The McAllester\'s bound (1998), Note;;The Catoni\'s bound (2004) (1);;The Catoni\'s bound (2004), Catoni\'s bound;;The Catoni\'s bound (2004), Catoni\'s bound, Because;;Observations about Catoni\'s bound (1);;Observations about Catoni\'s bound (2);;Observations about Catoni\'s bound (3);;Observations about Catoni\'s bound (cont) (1);;Observations about Catoni\'s bound (cont) (2);;Observations about Catoni\'s bound (cont) (3);;Bounding E S~D E hP emD(RS (h);R(h)) : other ways (1);;Bounding E S~D E hP emD(RS (h);R(h)) : other ways (2);;Bounding E S~D E hP emD(RS (h);R(h)) : other ways (3);;Bounding E S~D E hP emD(RS (h);R(h)) : other ways (4);;Bounding E S~D E hP emD(RS (h);R(h)) : other ways (5);;Bounding E S~D E hP emD(RS (h);R(h)) : other ways (6);;Supervised learning in the non iid case (1);;Supervised learning in the non iid case (2);;Supervised learning in the non iid case (3);;The problem of bounding E S~D E hP emD(RS (h);R(h)) (1);;The problem of bounding E S~D E hP emD(RS (h);R(h)) (2);;The fractional chromatic number of the dependency graph (1);;The fractional chromatic number of the dependency graph (2);;The fractional chromatic number of the dependency graph (3);;The fractional chromatic number of the dependency graph (4);;Theorem 1 (revisited);;The problem of bounding R(GQ) instead of R(BQ) (1);;The problem of bounding R(GQ) instead of R(BQ) (2);;Specialization to Linear classiers (1);;Specialization to Linear classiers (2);;Specialization to Linear classiers (3);;Specialization to Linear classiers (4);;Bayes-equivalent classiers (1);;Bayes-equivalent classiers (2);;Bayes-equivalent classiers (3);;Gibbs\' risk;;Probit loss;;Objective function from Catoni\'s bound (1);;Objective function from Catoni\'s bound (2);;Objective function from Catoni\'s bound (3);;Objective function from Catoni\'s bound (4);;Objective function from Catoni\'s bound (5);;Objective function from Catoni\'s bound (6);;Objective function from Catoni\'s bound (7);;Numerical result [ICML09];;Majority vote of weak classiers (1);;Majority vote of weak classiers (2);;Majority vote of weak classiers (3);;Majority vote of weak classiers (4);;Majority vote of weak classiers (5);;Answer # 1 (1);;Answer # 1 (2);;Answer # 1 (3);;Numerical result [ICML09], with decision stumps as weak learners;;Answer # 2: generalize the PAC-Bayes theorem to something else than the Gibbs\'s risk ! (1);;Answer # 2: generalize the PAC-Bayes theorem to something else than the Gibbs\'s risk ! (2);;Answer # 2: generalize the PAC-Bayes theorem to something else than the Gibbs\'s risk !;;Answer # 2: generalize the PAC-Bayes theorem to something else than the Gibbs\'s risk ! (3);;pacbayesian_laviolette_pbts_01_Page_094;;Answer # 2: generalize the PAC-Bayes theorem to something else than the Gibbs\'s risk ! (4);;R(BQ)  2R(GQ);;Catoni\'s bound for a general loss;;Answer # 2 (cont) (1);;Answer # 2 (cont) (2);;Answer # 2 (cont) (3);;Minimizing Catoni\'s bound for a general loss (1);;Minimizing Catoni\'s bound for a general loss (2);;Minimizing Catoni\'s bound for a general loss;;Empirical results (Nips[09]);;From KL(QkP) to `2 regularization (1);;From KL(QkP) to `2 regularization (2);;From KL(QkP) to `2 regularization (3);;PAC-Bayes vs Boosting and Ridge regression (cont) (1);;PAC-Bayes vs Boosting and Ridge regression (cont) (2);;PAC-Bayes vs Boosting and Ridge regression (cont) (3);;PAC-Bayes vs Boosting and Ridge regression (cont) (4);;PAC-Bayes vs Boosting and Ridge regression (cont) (5);;Answer#2 and kernel methods (1);;Answer#2 and kernel methods (2);;Conclusion (1);;Conclusion (2);;Conclusion (3);;Conclusion (4);;Conclusion (5);;Conclusion (6);;Conclusion (7);;Conclusion (8);;Conclusion (9);;Conclusion (10);;Conclusion (11);;Conclusion (12);;QUESTIONS ?'
12291,'tutorial','en',12246,'2010-03-23','2010-04-14','PAC-Bayesian Bounds and Aggregation',NULL,'PAC-Bayesian bounds and aggregation;;Outline;;Supervised learning;;Measuring the quality of prediction;;Kullback-Leibler (KL) divergence;;Legendre transform of the KL divergence;;PAC-Bayesian analysis;;McAllester’s bound (1998,1999);;Seeger’s proof (slightly revisited);;Seeger’s proof (second step);;Minimizing McAllester’s bound and Gibbs estimator;;Seeger’s bound for classification (2002);;This time, it suffices to prove;;McAllester’s bound vs Seeger’s bound;;Catoni’s old bound for classification (2002);;Audibert’s bound (2004);;Zhang’s bound (2005);;Catoni’s bound (2007);;Comparison of the bounds in classification;;Least square regression setting;;Optimal rates of aggregation;;Optimal rates of aggregation (Tsybakov, 2003);;Unusual properties;;Progressive mixture rule (Catoni, 1999; Yang, 2000);;Progressive indirect mixture rules (A., 2009);;Excess risk deviations abnormally high;;Getting round the previous limitation (A., 2007);;Different approaches;;A PAC-Bayesian approach (A., 2004);;The minimizer of the PAC-Bayes bound;;(Birgé and Massart, 1998);;A PAC-Bayesian approach with Gaussian prior (A. and Catoni, 2009);;n << d << en;;A model selection approach'
12292,'invited talk','en',12246,'2010-03-22','2010-04-14','Some PAC-Bayesian Theorems',NULL,'Some PAC-Bayesian Theorems;;SVM;;Bayesian Inference;;Failure of Square Root Bounds;;PAC-Bayesian Theorem;;L2 Prior;;L1 Prior;;L0 Prior;;The Hinge Loss Problem;;Structured Prediction with an L2 Prior;;Digression: Ignore Regularization;;Structured Hinge Generalizes Binary Hinge;;Margin Bounds;;Perceptron-like Updates;;Direct Loss Update;;Direct Loss Theorem;;Proof Hint (1);;Proof Hint (2);;Approximate Inference and Hidden Information;;Experiments (Joseph Keshet);;Loss Functions;;Results;;Differentiating the PAC-Bayes bound;;Summary'
12293,'invited talk','en',12246,'2010-03-22','2010-04-14','Incompatibilities(?) between PAC-Bayes and Exploration',NULL,'Incompatibilities(?) between PACBayes and Exploration;;What is a PAC-Bayes bound?;;What is a PAC-Bayes bound?, Tightness;;What is a PAC-Bayes bound?, Luckiness ;;What is a PAC-Bayes bound?, Indierence;;Outline, Supervised Learning and PAC-Bayes Review;;Supervised Learning Setting;;Typical Algorithm and Theorem (1);;Typical Algorithm and Theorem (2);;Typical Algorithm and Theorem (3);;Luckiness and Indierence for Supervised Learning (1);;Luckiness and Indierence for Supervised Learning (2);;Outline, Active Learning and PAC-Bayes;;Active Learning Setting;;Typical Algorithm and Analysis (1);;Typical Algorithm and Analysis (2);;The disagreement cofficient (1);;The disagreement cofficient (2);;The disagreement cofficient (3);;The disagreement cofficient (4);;The disagreement cofficient (5);;Luckiness and Indierence for Active Learning, Luckiness (1);;Luckiness and Indierence for Active Learning, Luckiness (2);;Luckiness and Indierence for Active Learning, Indierence (1);;Luckiness and Indierence for Active Learning, Indierence (2);;Some objections you might have (1);;Some objections you might have (2);;Some objections you might have (3);;Some objections you might have (4);;Some objections you might have (5);;Outline, Contextual Bandits and PAC-Bayes;;Contextual Bandits Setting;;Yahoo! (example);;A Simple Algorithm and theorem (1);;A Simple Algorithm and theorem (2);;A Simple Algorithm and theorem (3);;Computation of R;;Luckiness and Indierence for Contextual Bandit, Luckiness (1);;Luckiness and Indierence for Contextual Bandit, Luckiness (2);;Luckiness and Indierence for Contextual Bandit, Indierence (1);;Luckiness and Indierence for Contextual Bandit, Indierence (2);;Conclusion (1);;Conclusion (2);;Conclusion (3);;Bibliography'
12294,'invited talk','en',12246,'2010-03-23','2010-04-14','Bounding the Gaussian Process Information Gain: Applications to PAC-Bayes and GP Bandit Optimization',NULL,'Bounding the Gaussian Process Information Gain: Applications to PAC-Bayes and GP Bandit Optimization;;PAC-Bayesian Recipe (1);;PAC-Bayesian Recipe (2);;PAC-Bayesian Recipe (3);;PAC-Bayesian Recipe, Variational (Fenchel/Legendre) inequality;;PAC-Bayesian Recipe, PAC-Bayesian Theorem;;Data Dependent Bounds, Problem;;Data Dependent Bounds, Data;;Data Dependent Bounds, Problem dependence;;Problem dependence, more work;;Gaussian Process Information Gain (1);;Gaussian Process Information Gain (2);;Gaussian Process Information Gain (3);;Gaussian Process Information Gain (4);;D[Q kP] For Gaussian Processes (1);;D[Q kP] For Gaussian Processes (2);;D[Q kP] For Gaussian Processes (3);;D[Q kP] For Gaussian Processes (4);;D[Q kP] For Gaussian Processes (5);;D[Q kP] For Gaussian Processes (6);;Sequential Prediction (1);;Sequential Prediction, Bayesian strategy;;Sequential Prediction, Expert strategy;;Information Consistency (1);;Information Consistency (2);;Information Consistency of GP Prediction (1);;Information Consistency of GP Prediction (2);;Information Consistency of GP Prediction (3);;Proof Idea (1);;Proof Idea (2);;Proof Idea (3);;Bounding Expected Information Gain (1);;Bounding Expected Information Gain (2);;Bounding Expected Information Gain (3);;Bounding Expected Information Gain (4);;Bounding Expected Information Gain (5);;Comments (1);;Comments (2);;Stochastic Optimization (1);;Stochastic Optimization (2);;Stochastic Optimization (3);;Stochastic Optimization (4);;Stochastic Optimization (5);;Gaussian Process Optimization Algorithm (1);;Gaussian Process Optimization Algorithm (2);;Gaussian Process Optimization Algorithm (3);;Gaussian Process Optimization Algorithm (4);;Gaussian Process Optimization Algorithm (5);;Analysis of GP-UCB, Maximum information gain;;Analysis of GP-UCB, Theorem;;Analysis of GP-UCB, Maximum information gain (1);;Analysis of GP-UCB, Maximum information gain (2);;Analysis of GP-UCB, Maximum information gain (3);;Analysis of GP-UCB, Maximum information gain (4);;GP Optimization and Experimental Design (1);;GP Optimization and Experimental Design (2);;GP Optimization and Experimental Design (3);;GP Optimization and Experimental Design (4);;GP Optimization and Experimental Design (5);;Bounding Maximum Information Gain (1);;Bounding Maximum Information Gain (2);;Bounding Maximum Information Gain (3);;Bounding Maximum Information Gain (4);;Bounding Maximum Information Gain (5);;Bounding Maximum Information Gain (6);;Bounding Maximum Information Gain (7);;Bounding Maximum Information Gain (8);;Bounding Maximum Information Gain (9);;Bounding Maximum Information Gain (10);; Conclusions (1);;Conclusions (2);;Conclusions (3);;Conclusions (4);;Conclusions (5);;A Few Open Problems (1);;A Few Open Problems (2);;A Few Open Problems (3);;A Few Open Problems (4)'
12295,'invited talk','en',12246,'2010-03-23','2010-04-14','Robust PAC-Bayes Bounds',NULL,'Robust PAC-Bayes bounds;;Plot of x 7--> (x), (x);;Starting from 0.5, confidence level = 1 − 2, n = 100, v = 1 (1);;Starting from 0.5, confidence level = 1 − 2, n = 100, v = 1 (2)'
12296,'lecture','en',12246,'2010-03-22','2010-04-14','PAC-Bayes, Sample Compress and Kernel Methods',NULL,'PAC-Bayes, Sample Compress & Kernel Methods;;Outline;;Outline, Sample-Compress theory;;The Classification problem;;Elements of the Sample Compression theory;;Risk of a sc-classifier;;Outline, Majority Vote of Sample-Compressed classifiers;;Redefining the SVM as a Majority Vote of sc-classifiers;;sc-classifier hμ i ∈ HS, Distribution Q;;sc-classifier hμ i ∈ HS, Distribution Q, probability distribution;;sc-classifier hμ i ∈ HS, Distribution Q, posterior Q.. (1);;sc-classifier hμ i ∈ HS, Distribution Q, posterior Q... (2);;sc-classifier hμ i ∈ HS, Distribution Q, Qi - QMi;;sc-classifier hμ i ∈ HS, Distribution Q, reconstruction function (1);;sc-classifier hμ i ∈ HS, Distribution Q, reconstruction function (2);;Outline, Use the PAC-Bayes theory to upper-bound the risk of our Sc-SVM;;PAC-Bayes bounds for Sc-SVM (1);;PAC-Bayes bounds for Sc-SVM (2);;Margin of the majority vote classifier;;First PAC-Bayes theorem;;Second PAC-Bayes theorem1;;General theorem, Aligned posterior theorem;;First, note that as we have h ∈ HS ⇒ −h ∈ HS;;Outline, Minimize this PAC-Bayes bound and present experimental results;;We have designed two learning algorithms (1);;We have designed two learning algorithms (2);;Algorithm with KL, Algorithm without KL;;Experimental results (RBF kernel, 10-folds CV);;Outline, and Conclude...;;Future works'
12297,'lecture','en',12246,'2010-03-22','2010-04-14','PAC-Bayes Analysis: Links to Luckiness and Applications',NULL,'PAC-Bayes Analysis: Links to Luckiness and Applications;;Outline;;Luckiness definitions (1);;Luckiness definitions (2);;Example (1);;Example (2);;Example (3);;Example (4);;Example (5);;Example (6);;Defining priors from data distributions (1);;Defining priors from data distributions (2);;Defining priors from data distributions (3);;Defining priors from data distributions (4);;Defining priors from data distributions (5);;Defining priors from data distributions (6);;Defining priors from data distributions (7);;Defining priors from data distributions (8);;Defining priors from data distributions (9);;Defining priors from data distributions (10);;Defining priors from data distributions (11);;Maximum entropy learning (1);;Maximum entropy learning (2);;Maximum entropy learning (3);;Posterior distribution Q(w) (1);;Posterior distribution Q(w) (2);;Error expression (1);;Error expression proof;;Generalisation error;;Base result (1);;Base result (2);;Base result (3);;Interpretation (1);;Interpretation (2);;Interpretation (3);;Boosting the bound (1);;Boosting the bound (2);;Full result (1);;Full result (2);;Full result (3);;Algorithmics (1);;Algorithmics (2);;Dual optimisation (1);;Dual optimisation (2);;Dual optimisation (3);;Dual optimisation (4);;Results: effect of varying T;;Results;;Gaussian Process Regression (1);;Gaussian Process Regression (2);;Gaussian Process Regression (3);;Gaussian Process Regression (4);;Applying PAC-Bayes theorem (1);;Applying PAC-Bayes theorem (2);;Applying PAC-Bayes theorem (3);;GP Result;;GP Experimental Results (1);;GP Experimental Results (2);;GP Experimental Results (3);;GP Experimental Results (4);;Stochastic Differential Equation Models (1);;Stochastic Differential Equation Models (2);;Stochastic Differential Equation Models (3);;Variational approximation (1);;Variational approximation (2);;Girsanov change of measure (1);;Girsanov change of measure (2);;KL divergence;;Variational approximation (1);;Variational approximation (2);;Algorithmics (1);;Algorithmics (2);;Error estimation (1);;Error estimation (2);;Error estimation (3);;Error estimation (4);;Generalisation analysis (1);;Generalisation analysis (2);;Generalisation analysis (3);;Error estimates (5);;Error estimates (6);;Error estimates (7);;Refining the distributions (1);;Refining the distributions (2);;Final result ;;Small scale experiment (1);;Small scale experiment (2);;Small scale experiment (3);;Conclusions (1);;Conclusions (2);;Conclusions (3);;Conclusions (4);;Conclusions (5);;Conclusions (6)'
12298,'lecture','en',12246,'2010-03-22','2010-04-14','Distribution-Dependent PAC-Bayes Priors',NULL,'Distribution-Dependent PAC-Bayes Priors;;Overview;;Preliminaries- Typical PAC-Bayes Analysis;;Localization - Motivation;;Localization 2 - Our interpretation;;Stochastic ERM 1 - Risk Bound;;Stochastic ERM 2 - Complexity;;Regularized Stochastic ERM;;Regularization in Intrinsic Geometry of Data;;Capturing Intrinsic Geometry of Data;;Capturing Intrinsic Geometry of Data;;PAC-Bayes U-process concentration;;Bound for Intrinsic Regularization;;Gaussian Process Prediction;;Gaussian Process Prediction 2 - Bounding the KL;;Gaussian Process Prediction 3 - Risk bound;;Conclusions'
12299,'lecture','en',12246,'2010-03-22','2010-04-14','Expectation-prior PAC-Bayes Bounds for SVMs',NULL,'Expectation-Prior PAC-Bayes Bounds for SVMs;;Roadmap;;Expectation-Prior Based Bound: Motivation & Setting;;Single-Expectation-Prior PAC-Bayes Bound;;Single-Expectation-Prior PAC-Bayes Bound;;Single-Expectation-Prior PAC-Bayes Bound;;Proof. (1);;Proof. (cont.) (1);;Proof. (cont.) (2);;Multiple-Expectation-Prior PAC-Bayes Bound;;Expectation-Prior PAC-Bayes Bound with Non-identity Gaussian;;Proof. (2);;Proof. (cont.) (3);;Proof. (cont.) (4);;Insights for Training SVMs;;Thank You!'
12300,'lecture','en',12246,'2010-03-22','2010-04-14','Data-dependent Prior PAC-Bayes Bounds: Empirical Study',NULL,'Data-dependent prior PAC-Bayes Bounds: Empirical study;;Outline;;Experimental setup;;Data-dependent priors;;Mean vector;;Covariance Matrix;;Algorithms;;Data sets description;;SVM: Bound tightness;;ηPrior SVM: Bounds;;Quality of Priors;;SVM model selection;;Model Selection PSVM;;Summary'
12301,'lecture','en',12246,'2010-03-23','2010-04-14','PAC-Bayesian Analysis in Unsupervised Learning',NULL,'PAC-Bayesian Analysis in Unsupervised Learning;;Motivation (1);;Motivation (2);;Example;;Outline;;Discriminative Prediction with Co-clustering (1);;Discriminative Prediction with Co-clustering (2);;Discriminative Prediction with Co-clustering (3);;Co-occurrence Data Analysis (1);;Co-occurrence Data Analysis (2);;Density Estimation with Co-clustering;;Discriminative prediction based on co-clustering;;PAC-Bayesian Analysis;;Prior Construction (1);;Prior Construction (2);;Prior Construction (3);;Prior Construction (4);;Prior Construction (5);;Calculation of D(Q||P) (1);;Calculation of D(Q||P) (2);;Calculation of D(Q||P) (3);;Calculation of D(Q||P) (4);;Calculation of D(Q||P) (5);;Generalization Bound (1);;Generalization Bound (2);;Generalization Bound (3);;Application;;13x6 Clusters;;50x50 Clusters;;283x283 Clusters;;PAC-Bayesian Bound for Discrete Density Estimation (1);;PAC-Bayesian Bound forDiscrete Density Estimation (2);;PAC-Bayesian Bound forDiscrete Density Estimation (3);;Special case: bound for classification;;Proof Idea (1);;Proof Idea (2);;Proof Idea (3);;A Bound on... (1);;A Bound on... (2);;A Bound on... (3);;Density Estimation with Co-clustering (1);;Density Estimation with Co-clustering (2);;Density Estimation with Co-clustering (3);;Density Estimation with Co-clustering (4);;Density Estimation with Co-clustering (5);;Density Estimation with Co-clustering (6);;Graphical Models;;Tree-Shaped Graphical Models;;Graph Clustering, Pairwise Clustering;;Summary of main contributions;;Future Directions'
12302,'lecture','en',12246,'2010-03-23','2010-04-14','Bayes Average Case Performance of PAC - Bayes Bounds',NULL,'Bayes average case performance of PAC - Bayes bounds;;PAC Bayes;;PAC Bayes Bounds;;Bayes Average of PAC Bound;;Bayes average loss bound;;Comparison I;;A bound on the mutual information;;Combine with a lower bound;;Lower bound on Bayes loss (no noise);;Comparison II;;Conclusion'
12303,'lecture','en',12246,'2010-03-23','2010-04-14','PAC Bayesian Bounds for Spare Regression Estimation with Exponential Weights',NULL,'PAC-Bayesian Bounds for Sparse Regression Estimation with Exponential Weights;;High-dimensional regression estimation;;Measures of the risk;;Sparse regression estimation;;p`0-type penalization;;Results with `0-type penalization (1);;Results with `0-type penalization (2);;`1-type penalization;;Variants, Problem;;Bayesian statistics;;PAC-Bayesian approach;;Overview of the talk;;The submodels;;Definition (1);;Theoretical result (1);;Theoretical result (2);;Denition (2);;Motivation for definition;;Theoretical result (3);;MCMC methods for the computation of the estimators;;Hastings-Metropolis algorithm (1);;Hastings-Metropolis algorithm (2);;Reversible Jump MCMC algorithm;;Empirical remarks;;Conclusion'
12304,'lecture','en',12246,'2010-03-23','2010-04-14','Efficient Mixture Modeling with RKHS Embeddings: A PAC-Bayesian Analysis',NULL,'Efficient Mixture Modeling with RKHS Embeddings A PAC-Bayesian Analysis;;Outline;;Outline, Motivation (1);;Maximum Mean Discrepancy ;;Maximum Mean Discrepancy, Definition;;Maximum Mean Discrepancy, Examples;;Unit-ball in RHKS;;Unit-ball in RHKS, Proposition;;Unit-ball in RHKS, Corollary;;Outline,Motivation (2);;Reproducing KMM Mixture Model;;Reproducing KMM Mixture Model, Corollary (KMM [Song et al., 2008]);;Reproducing KMM Mixture Model, Question;;Outline, First Order PAC-Bayes Bound (1);;U-Statistic PAC-Bayes Bound;;U-Statistic PAC-Bayes Bound, Corollary;;Proof: iid blocks;;Proof: iid blocks, Theorem;;Proof: Bounded to Bernoulli;;Proof: Bounded to Bernoulli, Proposition;;Outline, First Order PAC-Bayes Bound (2);;Is ||kQb - kDn||2 H a U-statistic? (1);;Is ||kQb - kDn||2 H a U-statistic? (2);;Is ||kQb - kDn||2 H a U-statistic? (3);;Is ||kQb - kDn||2 H a U-statistic? (4);;Is ||kQb - kDn||2 H a U-statistic? (5);;Is ||kQb - kDn||2 H a U-statistic? (6);;Outline, Close (1);;Choosing KL;;Choosing KL, Example (Dirichlet);;Log-Normal Projection (1);;Log-Normal Projection (2);;Log-Normal Projection (3);;Outline, Close (2);;Conclusion, Summary;;Conclusion, Future work;;Questions'
12339,'keynote','en',12153,'2010-03-30','2010-05-03','Reconstructing networks from experimental and natural genetic perturbations','Functional genomics has demonstrated considerable success in inferring the inner working of a cell through analysis of its response to various perturbations. Perturbations can take the form of experimental interventions, like gene deletions or RNA interference, or natural perturbations, like SNPs or copy-number alterations. In my talk I will describe methods my lab has developed to reconstruct networks from the phenotypic effects of gene perturbations. In particular, I will (1) describe Nested Effects Models, a class of probabilistic graphical to reconstruct signaling pathways from downstream effects, and (2) introduce methods to correlate the impact of copy-number variation on gene expression with different sub-types of breast cancer.','Reconstructing networks from experimental and natural genetic perturbations;;How to understand a complex system?;;Breaking the system;;Phenotype: viability versus cell death;;Phenotype. pathway activity;;Phenotype: organism morphology;;Phenotype: cell morphology;;Phenotype: global gene expression;;External signals;;Network reconstruction from phenotypes;;Nested Effects Models - 1;;Nested Effects Models - 2;;Marginal likelihood;;NEM model space;;Anatomy of the NFkB pathway;;Nested Effect Models for NFkB;;Natural experiments;;Copy number variation;;The METABRIC project;;Impact of CNA on expression;;Differential regulation - 1;;Differential regulation - 2;;Reference network (ER+/-);;Differential network (ER+/-);;Summary;;Future plans;;How to Understand the Cell by Breaking it;;Acknowledgements;;Thank you'
12340,'keynote','en',12153,'2010-03-30','2010-05-03','Networking genes and drugs: Understanding gene function and drug mode of action from large-scale experimental data','A gene regulatory network, where two genes are connected if they are directly, or functionally, regulating each other, can be \'reverse-engineered\' from large-scale experimental data such as gene expression profiles. Here used a simple but effective reverse-engineering approach using all the available gene expression profiles in mammals, solving along the way the problems of handling, normalizing and analysing such massive dataset. We reverse-engineered a coexpression network for Homo Sapiens (Mus Musculus) from a set of 20,255 (8895) gene expression profiles. The human (mouse) network is characterized by a set of 22283 (45101) nodes (i.e. genes) and a set of 4,817,629 (14,641,095) edges, where the edge is weighted by the Mutual Information (MI) measure between the two genes.\n\n\nWe show how the resulting network can be then used to understand the function of a gene, the modularity of gene regulation, as well as, as a tool to analyse \"gene signatures\" to identify the mode of action of a drug.\n\n\nWe will also show how it is possible to use gene expression profile to build a \"drug network\", where drugs can be automatically grouped in subnetworks (\'communities\') of drugs sharing a similar mode of action.','Networking Genes and Drugs;;The problems we (and everybody else) are tackling:;;Systems Biology - 1;;Systems Biology - 2;;Let\'s use Synthetic Biology to validate Systems Biology;;Reverse - engineering algorithms;;Mutual Information ;;Reverse engineering human and mouse gene networks;;Data collection and distribution;;Normalization procedure -1;;Normalization procedure -2;;Mutual Information computation;;Network atatistics and proprerties;;Network overview and validation;;Network validation against known interactions;;A view of the most significant 1000 interactions;;Validation of novel interactions;;Y2H validation of predicted Protein - Protein interactions;;Using network to understand gene function;;Computational validation of guilty-by-association predictions;;Experimental validation of guilty-by-association predictions;;The modular structure of the human and mouse gene regulatory networks;;A view of the network - can we find modules?;;A modular view of the network - 1;;A modular view of the network - 2;;A modular view of the network - 3;;Chromosomes, Chromatin and Co-expression;;The closer the genes (in genomic distance) the more likely are the genes to interact;;A little disgression on 3D chromatin structure;;A closer view on chromosome 19;;Gene network signature analysis;;Gene Signature Analysis Analysis Pipeline;;Analysis of a poor-prognosis related gene signature in glioma;;Conclusion of Part 1;;Part II: Understanding Drug Mode of Action;;The Problems;;Transcriptional responses to drugs;;From transcriptional responses to a drug network;;Construction of the Prototype Ranked List;;Computation of the drug distance -1;;Computation of the drug distance -2;;Enrichment function;;Experimental validation with three HSP90 inhibitors;;And CDK and Topoisomerase inhibitors;;Drug repositioning: a novel autophagy inducer drug -1;;Drug repositioning: a novel autophagy inducer drug -2;;Mapping gene changes due to drug treatment:;;Part II: Conclusions;;Systems, Synthetic and Computational Biology Lab;;Mantra;;Blank page;;Genes within chromosomes tend to interact more with each-other:;;What is the connectivity map?;;Community Enrichment Analysis'
12342,'lecture','en',12153,'2010-03-30','2010-05-03','Estimating the contribution of non-genetic factors to gene expression using Gaussian process latent variable models','Thanks to the recent increase in the amount of genetic profiling data available and to the ability to characterize disease activity through gene expression, it is possible to understand more in detail the multitude of causal factors linked with each disease. This is a challenging task because the integration of different sources of biological data is not straightforward and because non-genetic factors (such as differences in the experimental setting or individual characteristics such as gender and ethnicity) are not always artificially controlled. Since these non-genetic factors may cause most of the variation in gene-expression reducing the accuracy of genetic studies, there’s a pressing need for models that take them explicitly into account. We present a model in which non-genetic factors are unobserved latent variables the gene expression levels can be described as linear functions of both these latent variables and Single Nucleotide Polymorphisms (SNPs). From a generative point of view, we can see the gene expression levels Y as \n\nY = SV + XW +mu 1^T + epsilon \n\nWhere S is the matrix containing the SNPs, X are the latent variables, V and W are mapping matrices, is a Gaussian distributed isotropic error model and mu allows the model to have non-zero mean.\n\nThe model is inspired by the one proposed by Stegle et al. [1], but instead of optimizing parameters and marginalising latent variables (as in Probabilistic PCA), we marginalise the parameters and optimize the latent variables. For a particular choice of prior over the mapping matrices W and V the two approaches are equivalent.\n\nThis kind of model is called dual Probabilistic PCA and it belongs to a wider class of models called Gaussian Process - Latent Variable Models. Indeed, dual PPCA is the special case where the output dimensions are assumed to be linear, independent and identically distributed. Each of these assumptions can be relaxed obtaining new probabilistic models. Many extensions of this model are possible, but even in its simplest form the eQTL study results are extremely promising in terms of number of significant associations found.\n','Estimating the contribution of non-genetic factors to gene expression using Gaussian Process Latent Variable Models;;Outline -1;;Outline -2;;Expression Quantitative Trait Loci - eQTL -1;;Expression Quantitative Trait Loci - eQTL -2;;Expression Quantitative Trait Loci - eQTL -3;;Outline -3;;Single Nucleotide Polymorphisms -1;;Single Nucleotide Polymorphisms -2;;Single Nucleotide Polymorphisms -3;;The Hapmap dataset -1;;The Hapmap dataset -2;;The Hapmap dataset -3;;Project GENEVAR - GENe Expression VARiation -1;;Project GENEVAR - GENe Expression VARiation -2;;Project GENEVAR - GENe Expression VARiation -3;;Outline -4;;Confounding factors -1;;Confounding factors -2;;Confounding factors -3;;Modelling non-genetic factors -1;;Modelling non-genetic factors -2;;Modelling non-genetic factors -3;;Modelling non-genetic factors -4;;Modelling non-genetic factors -5;;Modelling non-genetic factors -6;;Modelling non-genetic factors -7;;Modelling non-genetic factors -8;;Modelling non-genetic factors -9;;dual Probabilistic Principal Component Analysis -1;;dual Probabilistic Principal Component Analysis -2;;dual Probabilistic Principal Component Analysis -3;;dual Probabilistic Principal Component Analysis -4;;dual Probabilistic Principal Component Analysis -5;;Population structure;;Accounting for population structure -1;;Accounting for population structure -2;;Accounting for population structure -3;;Outline -5;;eQTL scan using data from Hapmap and GENEVAR;;Traditional eQTL scan - 1 ;;eQTL scan accounting for non-genetic factors;;Traditional eQTL scan - 2;;eQTL scan accounting for non-genetic factors;;Outline -6;;Conclusions'
12343,'lecture','en',12153,'2010-03-30','2010-05-03','Using sequential Monte Carlo approaches as a design tool in synthetic biology','In many engineering contexts it is easy to state what we want but hard to achieve our desired outcomes. The more potential solutions exist, the harder it becomes to identify optimal solutions. Here we show how this problem can be approached in an approximate Bayesian computation framework. Our approach has the advantage that it builds on the powerful Bayesian model selection formalism, includes sensitivity and robustness analysis at no extra cost, and flexibly incorporates diverse design objectives. We illustrate the performance of this approach in the context of bacterial two-component systems (TCS). These systems enable prokaryotes (and some simple eukaryotes and plants) to sense their environments and adapt their internal state to changing circumstances. We present a detailed analysis of orthodox and unorthodox TCSs and show how we can rationally construct TCS that show robust and optimal response characteristics to different stimuli encountered during bacterial infections or in biotechnological (e.g. biofuels production and bioremediation) applications. We conclude by elaborating on the connections between our approach and maximum-entropy procedures and the advantages over traditional engineering strategies.\n','Using sequential Monte Carlo approaches as a design tool in synthetic biology;;Introduction - 1;;Introduction - 2;;Introduction - 3;;Introduction - 4;;Synthetic biology vs Systems biology - 1;;Synthetic biology vs Systems biology - 2;;Synthetic biology vs Systems biology - 3;;Approximate Bayesian Computation - 1;;Approximate Bayesian Computation - 2;;Approximate Bayesian Computation - 3;;Approximate Bayesian Computation - 4;;Approximate Bayesian Computation - 5;;Approximate Bayesian Computation - 6;;Approximate Bayesian Computation - 7;;Approximate Bayesian Computation - 8;;Approximate Bayesian Computation - 9;;Approximate Bayesian Computation - 10;;Approximate Bayesian Computation - 11;;Approximate Bayesian Computation - 12;;Approximate Bayesian Computation - 13;;Approximate Bayesian Computation - 14;;Approximate Bayesian Computation - 15;;Approximate Bayesian Computation - 16;;Approximate Bayesian Computation - 17;;Approximate Bayesian Computation - 18;;Approximate Bayesian Computation - 19;;Approximate Bayesian Computation - 20;;Approximate Bayesian Computation - 21;;Approximate Bayesian Computation - 22;;Approximate Bayesian Computation - 23;;Approximate Bayesian Computation - 24;;Approximate Bayesian Computation ABC;;ABC SMC - 1;;ABC SMC - 2;;ABC SMC - 3;;ABC SMC - 4;;ABC SMC - 5;;ABC SMC - 6;;ABC SMC - 7;;ABC SMC - 8;;ABC SMC - 9;;ABC SMC - 10;;ABC SMC - 11;;Bacterial two component systems (TCS) - 1;;Bacterial two component systems (TCS) - 2;;Bacterial two component systems (TCS) - 3;;Bacterial two component systems (TCS) - 4;;Example 1: Fast response - 1;;Example 1: Fast response - 2;;Example 2: Robust to noise - 1;;Example 2: Robust to noise - 2;;Example 3: Fast response, high maximum, low minimum ;;Example 3: posteriors;;Example 3: Trajectory evolution;;Example 3: Comparison to sensitivity analysis - 1;;Example 3: Comparison to sensitivity analysis - 2;;Example 3: Comparison to sensitivity analysis - 3;;Future work;;Acknowledgements'
12345,'lecture','en',12153,'2010-03-30','2010-05-03','Decoding underlying behaviour from destructive time series experiments through Gaussian process models','A major problem for biological time series is that often experiments (such as gene expression measurements using microarrays or RNA-seq) require the organism or cells to be destroyed. This means that a particular time series is often a series of measurements of different organisms (or batches of cells) at different times. Biological replicates normally consist of a separate biological sample measured at the same time. With the advent of single cell expression experiments, where it is not currently conceivable to make genome-wide gene expression measurements without destroying the cell, we expect such set ups to be sustained.\n\nMany existing approaches to modelling transcriptional data postulate a differential equation model for continuous-time expression profiles from which the repeated observations arise. Two ways of modelling repeat experiments would be either to handle repeated observations as being from a shared profile, or from completely independent profiles. The former approach assumes that gene expression profile for each experiment does not vary, whilst the latter approach assumes no relationship between the gene expression profiles. For many experimental set ups we might expect something in between these two extremes where, whilst each individual measurement comes from a different collection of cells or a different organism, the experimental set up is broadly the same. We therefore expect some shared affects and some independent affects for the experiments.\n\nIn this work we propose an integrated Gaussian process framework for analysis of such experiments. In our approach, independent aspects of the experiments are modelled as independent Gaussian process draws, while the common profile across the experiments is modelled by a separate Gaussian process. The method adds power through sharing of replicates for the common profile while being robust to outliers from individual rogue experiments.','Decoding Underlying Behaviour from Destructive Time Series Experiment through Gaussian Process Models;;Molecular biology time series;;Outline - 1;;Outline - 2;;Simulated molecular biology time series - 1;;Simulated molecular biology time series - 2;;Simulated molecular biology time series - 3;;Simulated molecular biology time series - 4;;Simulated molecular biology time series - 5;;Simulated molecular biology time series - 6;;Simulated molecular biology time series - 7;;Simulated molecular biology time series - 8;;Simulated molecular biology time series - 9;;Simulated molecular biology time series - 10;;Simulated molecular biology time series - 11;;Simulated molecular biology time series - 12;;Real gene expression time series;;Outline - 3;;Example model: Linear ODE model of transcription;;How to connect the model to data?;;Exchangeability analysis;;Solution: hierarchical GP model;;Exchangeability analysis revisited;;Outline - 4;;ODE model of translation and transcription;;Independent profiles;;Hierarchical model;;Conclusion;;Acknowledgements;;Transcription factor Inference through Gaussian process Expression Reconstruction;;References'
12347,'lecture','en',12153,'2010-03-31','2010-05-03','Identifying interactions in the time and frequency domains in local and global networks','Reverse-engineering approaches such as Bayesian network inference, ordinary differential equations (ODEs) and information theory are widely applied to deriving causal relationships among different elements such as genes, proteins, metabolites, neurons, brain areas and so on, based upon multi-dimensional spatial and temporal data. Here we focused on the Granger causality approach in both the time and frequency domains in local and global networks, and applied our approach to experimental data (genes and proteins). For a small gene network, Granger causality outperformed all the other three approaches mentioned above. A global protein network from 812 proteins was reconstructed, using a novel approach. The obtained results fitted well with known experimental findings and opened up many experimentally testable predictions. In addition to interactions in the time domain, interactions in the frequency domain were also recovered. Our approach is general and can be easily applied to other types of temporal data.','Identifying interactions in the time and frequency domains in local and global networks - A Granger causality approach;;Outline;;Pair - wise Granger Causality - 1;;Pair - wise Granger Causality - 2;;Pair - wise Granger Causality - 3;;Conditional Granger Causality - 1;;Conditional Granger Causality - 2;;Conditional Granger Causality - 3;;Conditional Granger Causality - 4;;Partial Granger Causality - 1;;Ancestor - Finding Partial Granger Causality - 1;;Ancestor - Finding Partial Granger Causality - 2;;Ancestor - Finding Partial Granger Causality - 3;;Ancestor - Finding Partial Granger Causality - 4;;Local Network Result - 1;;Local Network Result - 2;;Global Network Result;;Recent Result - 1;;Recent Result - 2;;Recent Result - 3;;Recent Result - 4;;Recent Result - 5;;Recent Result - 6;;Thank you'
12349,'lecture','en',12153,'2010-03-31','2010-05-03','Deterministic and stochastic models of bicoid protein gradient formation in Drosophila embryos: Modelling maternal mRNA degradation','Passive diffusion of a class of molecules known as morphogens as a mechanism that helps to establish spatial patterns of gene expression during embryonic development was proposed by Turing [1]. This mechanism is usually modelled as passive diffusion of morphogen proteins translated from maternally deposited messenger RNAs. Such diffusion models assume a constant supply of morphogens at the source throughout the establishment of the required profile at steady state [2]. Working with the bicoid morphogen which establishes the anterior-posterior axis in the Drosophila embryo, we note that this constant source assumption is unrealistic since the maternal mRNA is known to decay after a certain time since egg laying. In [3], we have incorporated a more realistic model of the morphogen source since the maternal mRNA should be expected to decay.We explicitly model the source as a constant supply followed by exponential decay and solve the reaction diffusion equation numerically for one dimensional morphogen propagation. By minimising the squared error between model outputs and measurements published in the FlyEx database, we show how parameters of diffusion rate, mRNA and protein decay constants, and the onset of maternal mRNA decay can be assigned sensible values. We also extend this work to further show how such a realistic source model may be combined with a recently published flow model [4] that takes into account advective transport. Moreover, a stochastic simulation based model [5] which includes Bicoid molecule reactions has also been implemented with new source model in our work.','Deterministic and Stochastic Models of Bicoid Protein Gradient Formation in Drosophila Embryos;;Drosophila;;French Flag;;Bicoid Morphogen;;Bicoid Morphogen Concentration;;Constant Source;;New Source Model;;Reaction Diffusion Equation;;Reaction Diffusion Equation in Flow model;;Stochastic Model;;Solution to Model with Constant Source;;Solution to Model with Combined Source;;Solution to Stochastic model;;Measured Data - 1;;Measured Data - 2;;Matching Models to Data;;Comparison Between Model Output and Database in Cycle 14A with 8 Classes -1;;Comparison Between Model Output and Database in Cycle 14A with 8 Classes -2;;Estimating Parameter Values;;Matching Parameter Values to Data;;Conclusion;;Thanks;;Letters to Nature'
12350,'lecture','en',12153,'2010-03-31','2010-05-06','Statistical analysis of protein patternation on cell membranes during immunological synapse','A statistical analysis of two different experiments is considered. Both of them are related to understanding the mechanism behind the distribution of molecules involved in formation of organized patterns of protein complexes and molecules in the contact interface between the membranes of an immune cell and an antigen presenting cell. Such patterns are called immunological synapses.\n\nIn the first experiment a T-cell is adhering to the flat surface of a lipid bilayer. There are molecules of two types on the surface of the bilayer. They are fluorescently labelled with different colours so their distribution can be observed using microscope. During the contact molecules of one type are binding while second type molecules stay unbound. This results in segregation of different type molecules and forming a synapse pattern that can be observed and scanned using confocal microscopy. In the case of lipid bilayer the contact interface is flat and the whole contact interface can be scanned as a single image.\n\nThe second experiment deals with NK-cells forming synapses with target antigen presenting cells. Two-colour fluorescent labelling is used again and a similar protein patternation on the cell-cell contact interface can observed using confocal microscopy. The main difference with the first experiment is in imaging technique as instead of a single image a series of confocal images is made along the same axis which is approximately parallel to the synapse interface. As a result a stack of cross-section fluorescence images of the interacting cells is considered for the quantitative analysis.\n\nIn both experiments it is possible to observe the segregation of labelled molecules during the formation of the synapse pattern. In terms of fluorescence intensity values this is expressed in strong negative correlation between different colour fluorescence. We introduce a model based on the hypothesis of exclusion by size which explains the mutual segregation of molecules as a result of elastic properties of single molecules and bonds combined with the properties of the cell membrane. Based on this model a computational algorithm for the Bayesian statistical analysis of fluorescence images is developed in order to estimate relevant physical parameters that cannot be measured explicitly.\n','Statistical analysis of protein patternation on cell membranes during immunological synapse;;The immunological synapse;;Target and NK Cell;;The immunological synapse. T-cell data;;Synapse environment modeling and quantification - 1;;Synapse environment modeling and quantification - 2;;Exclusion by size;;Problem statement;;Statistical inference;;Bayesian approach. Separate analysis.;;Introducing the dependence into the model. Joint analysis;;MCMC inference algorithm;;MCMC algorithm. Tests and improvements;;Output of the MCMC algorothm;;Results of separate and joint analysis;;Extending to 3D stacks. NK-cell data;;(s, w) data representation;;Membrane width modeling;;g1 vs g2 plot for NK-cell data;;Collaborators'
12351,'lecture','en',12153,'2010-03-31','2010-05-03','Machine learning methods for effective proteomics image analysis','Two-dimensional gel electrophoresis (2DGE) remains the most widely used method for proteins identification and differential expression analysis, due to its lower cost and the existence of mature commercial software tools for 2DGE image analysis, despite the fact that non-gel based methods are gaining in popularity. Although there are several software packages that promise automation of the whole protein spot detection and quantification process, the hard reality remains today [1] that as Fey and Larsen stated in 2001, \"There is no program that is remotely automatic when presented with complex 2-DE images\" ... \"most programs require often more than a day of user hands-on time to edit the image before it can be fully entered into the database‚\" [2]. \n\nTo address these limitations and develop an automated 2DGE image analysis workflow we have developed in previous works an effective image analysis methodology that first denoises the 2DGE image based on the Controurlet transform [3] and then separates effectively the parts of the denoised image which include true protein spots (to be called Regions of Interest (ROIs) from the background-only areas, by using Active Contours (AC) without edges [4]. In this work we complete the image analysis workflow by adding a well tuned pipeline of operations based on unsupervised machine learning methods for analyzing further each isolated ROI, in order to \"fish\" in it the centers and estimate the quantities of the individual \"hidden\" spots.One-dimensional mixture modeling of the ROI pixel intensities histogram is applied first to identify and remove any remaining background pixels. Then the surviving ROI pixels are used as \"molecules generators\", in order to convert (by random sampling) the processed ROI image to an isomorphic dataset (through appropriate random sampling) representing the distribution of molecules of the underlying protein species (that are \"projected\" as spots on the gel image). This reverse engineering action rooted on machine learning constitutes a unique innovation of this work that, to the best of our knowledge, has not been applied before in 2DGE image analysis. The candidate protein spot centers are then located by applying hierarchical clustering. Finally the individual spot boundaries are delineated by fitting 2D Gaussian models to the data using generalized mixture modeling and the Minimum Message Length (MML) criterion to control the best model complexity. An extensive evaluation of this novel spot modeling methodology using both real and synthetic 2DGE images reveals that it is more precise and more specific than PDQuest in terms of spot detection while both methods achieve comparable high sensitivity. Furthermore, it can estimate more reliably the volumes of the extracted spots, even in the presence of substantial noise and in areas of the image where faint and overlapping (or saturated) spots are located close to each other. It should be noted that the end-to-end workflow that we have developed for 2DGE image analysis does not require any re-calibration of parameters every time a new gel image is presented for analysis. This desirable characteristic makes it a suitable candidate for the automatic processing of image stacks, as needed for highthroughput proteomics analysis to support systems biology projects.','Machine learning methods for effective proteomics image analysis;;Overview;;2DGE analysis;;Difficulties with image analysis;;Difficulties with 2DGE image analysis;;2DGE differential proteomics workflow;;Research Motivation;;Summary of Contributions;;Traditional image segmentation approaches;;ROIs extraction algorithm - Demo;;ROIs extraction algorithm - Validation;;Fishing for spots inside ROIs - overview;;Fishing for spots - background pixels removal;;Local Background removal - examples;;Fishing for spots - locating candidate spot centres;;Inverse modeling - from pixels to molecules;;Spot detection - Finding the best mixtures model that fits the generated dataset;;Examples of applying proposed method;;More complex spot detection example;;Spot detection evaluation;;Spot quantitation evaluation;;Summary - 1;;Summary - 2;;Further research directions;;Questions?;;Related Publications;;Difficulties with 2DGE image analysis;;Image denoising - 1;;Contourlets - based denoising;;Image denoising - 2;;Effect of denoising on spot detection;;Denoising effect on spot detection ;;Denoising assessment;;Denoising - effect on spot volume estimation;;Extracting ROIs - Active Contours;;Rois extreme - some details;;Denoising evaluation - SNR improvement;;Picture - 1;;Picture - 2;;Picture - 3;;Picture - 4;;Picture - 5;;Picture - 6;;Picture - 7;;Picture - 8;;Picture - 9;;Spot detection - Finding the best mixtures model that fits the generated dataset;;Picture - 10;;Picture - 11;;Picture - 12;;Picture - 13;;Picture - 14;;Picture - 15;;Picture - 16;;Picture - 17'
12355,'lecture','en',NULL,'2010-04-06','2010-04-19','Ethics for the New Millennium','Ethics for the New Millennium is addressed to a general audience. It presents a moral\nframework based on universal rather than religious principles. It rests on the observation\nthat those whose conduct is ethically positive are happier and more satisfied and the belief\nthat much of the unhappiness we humans endure is actually of our own making. Its\nultimate goal is happiness for every individual, irrespective of religious belief.\nThough the Dalai Lama is himself a practicing Buddhist, his approach to life and the moral\ncompass that guides him can be of use to each and every one of us – Muslim, Christian,\nJew, Buddhist or atheist – in our quest to lead a happier, more fulfilling life.\nAccording to the Dalai Lama our survival has depended and will continue to depend on our\nbasic goodness as human beings. In the past, the respect people had for their religion\nhelped maintain ethical practice through a majority following one religion or another.\nToday, with the growing secularization and globalization of society, we must find a way\nthat transcends religion to establish consensus as to what constitutes positive and negative\nconduct, what is right and wrong and what is appropriate and inappropriate.\n\nLink to [[http://www.dalailama.com/| The Office of His Holiness the Dalai Lama]]\\\\\nLink to [[http://www.dalailamafoundation.org/dlf/en/index.jsp| The Dalai Lama Foundation]]',NULL
12366,'opening','sl',12151,'2010-04-08','2010-04-23','Uvodni nagovor',NULL,NULL
12367,'opening','sl',12151,'2010-04-08','2010-04-23','Uvodni nagovor',NULL,NULL
12368,'lecture','sl',12151,'2010-04-08','2010-04-23','Mikrofluidika na poti do nanotehnologije',NULL,'Mikrofluidika – na poti do nanotehnologije;;Pregled;;Mikrofluidika;;Mikrofluidika in nanotehnologija;;Lab-on-a-chip;;Eksperimentalna orodja;;Koloidi;;Laserska pinceta;;Magnetna pinceta in magnetni koloidi;;Magnetna pinceta in magnetni koloidi – primeri;;Litografija – primer izdelave vezja;;Enostavne črpalke ;;Manj enostavne črpalke;;Napaka;;Migetalke – biomimetični sistem ;;Migetalke – delovanje;;Koloidne membrane – biomimetični sistem;;Laboratorij za eksperimentalno mehko snov, FMF'
12369,'lecture','sl',12151,'2010-04-08','2010-04-23','Polimerni materiali in nanotehnologija',NULL,'POLIMERNI MATERIALI IN NANOTEHNOLOGIJA (usmeritve razvoja in področja uporabe);;Polimeri, polimerni materiali, plastika;;Proizvodnja in uporaba polimerov;;Polimeri v vsakdanjem življenju;;Vloga polimernih materialov danes;;Razvoj polimernih materialov - 1;;Razvoj polimernih materialov - 2;;Napoved usmeritev razvoja polimerne znanosti v 21. stoletju;;Novi katalizatorji;;Nove metode polimerizacije;;Polimeri z nelinearno arhitekturo;;Uporaba visoko razvejenih polimerov;;Supramolekularni polimeri;;Prevodni polimeri;;Biodegradabilni polimeri;;Uporaba polimernih nanodelcev;;Dendritski nosilci za dostavne sisteme;;Polimerne micele-nosilci za zdravilne učinkovine;;Polimerne ščetke –uporaba v bio-in nanotehnologiji;;Hibridni nanokompozitni materiali - 1;;Hibridni nanokompozitni materiali - 2;;Polimerni nanokompoziti - 1;;Polimerni nanokompoziti - 2;;Stabilizacija nanodelcev;;Polimerni nanokompoziti - 3;;Polimerni nanokompoziti z glino;;Polimerni nanokompoziti s CNT;;Polimerni nanokompoziti z anorganskimi nanodelci;;Uporaba polimernih nanokompozitov z anorganskimi nanodelci;;Nanokompoziti poli(metilmetakrilata) in ZnO;;Morfologija ZnO vrazličnih diolih;;Morfologija nanokompozitov PMMA/ZnO - 1;;Morfologija nanokompozitov PMMA/ZnO - 2;;Termična obstojnost PMMA/ZnO;;Kinetika polimerizacije MMA;;UV-VIS absorpcija nanokompozitov PMMA/ZnO;;Prozornost ploščic PMMA/ZnO;;Center odličnosti za polimerne materiale in tehnologije (PoliMaT);;Strateški cilji CO PoliMaT;;CO PoliMaT;;Program CO PoliMaT - 1;;Program CO PoliMaT - 2;;Zahvala'
12370,'lecture','sl',12151,'2010-04-08','2010-04-23','Nanomateriali v medicini',NULL,'Nanomaterial v medicini;;Velikostne primerjave;;Medicinska nanotehnologija;;Učinki nanodimenzije;;Pasti nanotehnologije;;Azbest;;TiO2;;Nanomateriali v medicini;;Kosti implantanti;;Nanobiomateriali;;Cilijana dostava zdravilnih učinkovin - 1;;Možni nosilci dostave zdravil;;Ciljana dostava zdravillnih učinkovin - 2;;Liposomi;;Toplotna ablacija rakavih celic - 1;;Toplotna ablacija rakavih celic - 2;;Nanotehnologija v diagnostiki;;Nanožični senzor;;Nanoročice;;Nanobarvila;;Kontrastna sredstva;;Molekularno slikanje;;Superparamagnetni nanodelci;;MR molekularno slikanje;;Nanoroboti v medicini?;;Sklep'
12371,'lecture','sl',12151,'2010-04-08','2010-04-23','Nanotehnologija in tribologija',NULL,'Od tribologije ... do nanotribologije in nanotehnologij;;Vsebina;;Tribo… kaj?;;Tribologija;;Kaj pa industrija, podjetja?;;Širši pomen;;Režimi (“kvaliteta”) mazanja;;Popolni mazalni film: (E)HD;;Debelina filma .. ?;;“Idealno” mazanje EHD kontaktov;;Tribološki kontakti;;Kako vplivati na kritične kontakte?;;Poznati in obvladovati površine ..;;Poznati in obvladovati maziva ..;;Poznati in obvladatikontaktev Meš.&Mej. - 1;;Poznati in obvladatikontaktev Meš.&Mej. - 2;;Nanotehnologije;;Nanotribologija - 1;;Nanotribologija - 2;;Nanotribologija - 3;;Nanotribologija - 4;;Nanotribologija - 5;;Nanotribologija - 6;;Nanotribologija - 7;;Nanotribologija - 8;;Nanotribologija - 9;;Nanotribologija - 10;;Mejno mazanje in mejni filmi ...;;Nanotribologija in nanotehnologije;;Zaključki;;Hvala za pozornost'
12372,'lecture','sl',12151,'2010-04-08','2010-04-23','Predstavitev novosti in novega Nanocentra IJS',NULL,'Center odličnost nanoznanosti in nanotehnologije – Nanocenter;;Storitve;;Rezervacije'
12373,'lecture','sl',12151,'2010-04-08','2010-04-23','Dosežki na področju uporabe nanotehnologije v realni praksi industrije',NULL,'Dosežki na področju uporabe nanotehnologije v realni praksi industrije;;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - prikaz različnih aplikacij;;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - število patentnih inovacij;;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - pričakovani prihodki od nano-industrije;;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - dosedanje izkušnje iz ZDA;;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primeri prakse v Sloveniji;;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - HELIOS kot razvojno intenzivno podjetje (1);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - HELIOS kot razvojno intenzivno podjetje (2);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (1);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (2);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (3);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (uporaba nano TiO2 v rutilni obliki) (1);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (uporaba nano TiO2 v rutilni obliki) (2);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (uporaba nano TiO2 v anatasni obliki);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (uporaba nano SiO2 in Al2O3) (1);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (uporaba nano SiO2 in Al2O3) (2);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (4);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (5);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (6);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (7);;UPORABA NANOTEHNOLOGIJE V INDUSTRIJI - primer HELIOS (8)'
12374,'lecture','sl',12151,'2010-04-08','2010-04-23','Izdelki nanotehnologij in tveganje',NULL,'Učinki nanodelcev na biološke sisteme;;Nanodelci TiO2;;Nanotoksikologija;;Paracelsus (1493-1541);;In vivo and in vitro biological system;;Izkušnje;;Trenutni izziv;;Biološki potencial nanodelev - 1;;Biološki potencial nanodelev - 2;;Se delci akumulirajo?;;Eksperiment - 1;;Eksperiment - 2;;Eksperiment - 3;;Eksperiment - 4;;Eksperiment - 5;;Delci se ne akumulirajo!;;Imajo delci učinek? - 1;;Imajo delci učinek? - 2;;Nano delci imajo učinek na biološke sisteme!;;Poškodbe celic zaradi izpostavitve delcem!;;PROBLEM: Kako ugotoviti, katera je varna doza uporabe nanodelcev?;;Titanov dioksid (TiO2);;Hvala za pozornost!'
12378,'lecture','en',12154,'2010-03-02','2010-05-06','Lecture 34: The Brain and Cognition 3',NULL,NULL
12379,'lecture','en',12154,'2010-03-02','2010-05-06',' Lecture 35: The Brain and Cognition 4',NULL,NULL
12380,'lecture','en',12154,'2010-03-04','2010-05-06',' Lecture 36: The Brain and Cognition 5',NULL,NULL
12381,'lecture','en',12154,'2010-03-04','2010-05-06','Lecture 37: Assessment and Individual Differences 1',NULL,NULL
12382,'lecture','en',12154,'2010-03-04','2010-05-06','Lecture 38: Assessment and Individual Differences 2',NULL,NULL
12383,'lecture','en',12154,'2010-03-09','2010-04-12','Lecture 39: Assessment and Individual Differences 3',NULL,NULL
12384,'lecture','en',12154,'2010-03-09','2010-05-06','Lecture 40: Assessment and Individual Differences 4',NULL,NULL
12385,'lecture','en',12154,'2010-03-09','2010-05-06','Lecture 41: Intelligence 1',NULL,NULL
12386,'lecture','en',12154,'2010-03-11','2010-05-06',' Lecture 42: Intelligence 2',NULL,NULL
12387,'lecture','en',12154,'2010-03-11','2010-05-06','Lecture 43: Intelligence 3',NULL,NULL
12388,'lecture','en',12154,'2010-03-11','2010-05-06','Lecture 44: Intelligence 4',NULL,NULL
12398,'opening','sl',12152,'2010-04-08','2010-04-29','Otvoritev konference',NULL,'InCo gibanje za inovativne preboje;;InCo gibanje – primer družbene inovacije (1);;InCo gibanje – primer družbene inovacije (2);;InCo gibanje – primer družbene inovacije (3);;InCo gibanje – primer družbene inovacije (4);;InCo gibanje – primer družbene inovacije (5);;InCo gibanje – primer družbene inovacije (6);;InCo gibanje – primer družbene inovacije (7);;InCo gibanje – primer družbene inovacije (8);;InCo gibanje – primer družbene inovacije (9);;Namesto zaključka….'
12399,'lecture','sl',12152,'2010-04-08','2010-04-29','Sistemski pristop k zavestnemu so-ustvarjanju družbe prihodnosti',NULL,'Sistemski pristop k zavestnemu soustvarjanju družbe prihodnosti;;Russell Ackoff;;Sistemski pristop;;Sistem in skupine delov;;Sistemi;;Tri kategorije sistemov - 1;;Tri kategorije sistemov - 2;;Tri kategorije sistemov - 3;;Analitično in sistemsko mišljenje;;Analitično mišljenje;;Sistemsko mišljenje;;Proces - črna škatla;;Načela sistemskega mišljenja;;Vrh ledene gore kot past;;Prepoznavanje dogodkov, vzorcev in strukture problema;;Sistemska prihodnost;;Kdo je sistemski mislec;;Premik zavesti;;Univerzalna, sistemska zavest;;Evolucija ciklusov zavesti;;Kaj vidite najprej?;;Levo - desni konflikt;;Zaključek;;Hvala za pozornost'
12400,'best paper','sl',12152,'2010-04-08','2010-04-29','Slavnostna podelitev InJo nagrad 2010',NULL,NULL
12401,'promotional video','sl',12152,'2010-04-08','2010-04-29','Glasbeni nastop',NULL,NULL
12429,'opening','sl',9979,'2010-03-27','2010-04-21','Otvoritev in začetek tekmovanja',NULL,NULL
12430,'opening','sl',9979,'2010-03-27','2010-04-21','Otvoritveni nagovor',NULL,NULL
12431,'lecture','sl',9979,'2010-03-27','2010-04-21','Kako računalniki vidijo - računalniški vid in njegova uporaba v praksi',NULL,'Kako računalniki vidijo:računalniški vid in njegova uporaba v praksi;;MVL (FE) in VICOS (FRI);;Kaj je računalniški vid? - 1;;Kaj je računalniški vid? - 2;;Senzor: Kamera;;Razvoj računalniškega vida;;Človeški vs. Računalniški vid - 1;;Človeški vs. Računalniški vid - 2;;Trenutno stanje področja;;Izbrane aplikacije računalniškega vida;;Aplikacije računalniškega vida - 1;;Vizualna kontrola izdelkov;;Aplikacije računalniškega vida - 2;;Avtonomna navigacija - 1;;Avtonomna navigacija - 2;;Avtonomna navigacija - 3;;Avtonomna navigacija - 4;;Avtonomna navigacija - 5;;Avtonomna navigacija - 6;;Avtonomna navigacija - 7;;Avtonomna navigacija - 8;;Aplikacije računalniškega vida - 3;;Kontrola dostopa - 1;;Kontrola dostopa - 2;;Kontrola dostopa - 3;;Kontrola dostopa - 4;;Aplikacije računalniškega vida - 4;;Analiza človeškega gibanja - 1;;Analiza človeškega gibanja - 2;;Analiza človeškega gibanja - 3;;Analiza človeškega gibanja - 4;;Aplikacije računalniškega vida - 5;;Ambientalna inteligenca - 1;;Aplikacije računalniškega vida - 6;;Razširjena resničnost - 1;;Razširjena resničnost - 2;;Aplikacije računalniškega vida - 7;;Avtomatska izgradnja 3D objektov;;Aplikacije računalniškega vida - 8;;Vizualno poizvedovanje;;Program openURSA;;Več o računalniškem vidu... - 1;;Več o računalniškem vidu... - 2;;Konec;;Sledenje športnikov;;Vizualno poizvedovanje;;Učenje vizualnih konceptov;;Učenje vizualnih kategorij'
12432,'demonstration video','sl',9979,'2010-03-27','2010-04-21','Predstavitev nalog in rešitev tekmovanja v znanju',NULL,NULL
12433,'summary','sl',9979,'2010-03-27','2010-04-21','Razglasitev rezultatov in podelitev priznanj in nagrad',NULL,NULL
12434,'lecture','sl',12427,'2010-04-15','2010-05-06','Raznolikost živalskih glasov','Živali proizvajajo zvok, da bi pritegnile osebke iste vrste, ali da bi izzvale odgovor pri drugi vrsti. Živalski zvoki so valovanja, ki se širijo po zraku, vodi ali trdni podlagi in jih proizvajajo na zelo različne načine. Ljudje s prostimi ušesi lahko slišimo sesalce, ptice, žabe in žuželke. Popolnoma nov svet, pogosto zelo hrupen, pa se nam odpre nad in pod našim slušnim območjem, ki ju imenujemo ultrazvok in infrazvok.','Raznolikost živalskih glasov;;Bioakustika;;Ivan (Janez, Johann, Johanes) Regen(1868 –1947);;Zvočno sporazumevanje;;Kako žuželke proizvajajo zvok;;Stridulacija;;Stridulacijska letev na krilu kobilice;;Ilirska cvrčalka (Psorodonotus illyricus);;Vrečenoska (Rileyana (=Thecophora) fovea);;Timbal;;Kalabita operculata;;Pomponia pendleburyi / Pomponia imperatoria / Pomponia merula;;Vibracijsko sporazumevanje;;Napev dvorjenja stenice vrste Sehirus luctuosus;;Lišček (Tritomegas bicolor);;Kaj pa pod vodo?;;Veliki bogomolčar ali morska bogomolka (Squillamantis);;Kozice strelke ali pokajoče kozice (Alpheussp.);;Kako ribe proizvajajo zvok;;Konj (Sciaena umbra);;Hribski urh (Bombina variegata);;Česnovka (Pelobates fuscus);;Zelena krastača (Bufo viridis);;Bramor (Gryllotalpa gryllotalpa);;Trstni cvrčalec (Locustella luscinoides);;Podhujka (Caprimulgus europaeus);;Plavček (Rana arvalis) - 1;;Plavček (Rana arvalis) - 2;;Plavček (Salvinia natans);;Plavček (Parus caeruleus);;Sekulja (Rana temporaria);;Rosnica (Rana dalmatina);;Laška žaba (Rana latastei) - 1;;Laška žaba (Rana latastei) - 2;;Koliko vrst pic se oglaša?;;Stržek (Troglodytes troglodytes);;Ščinkavec (Fringilla coelebs);;Sonogram dialektov ščinkavca;;Sonogram: Rumenoglavi kraljiček (Regulus regulus) / Rdečeglavi kraljiček (Regulus ignicapillus);;Dolgoprsti plezalček (Certhia familiaris) / Kratkoprsti plezalček (Certhia brachydactyla);;Lesna sova (Strix aluco);;Gozdne ptice Slovenije;;Kozača (Strix uralensis);;Mali skovik (Glaucidium passerinum);;Veliki detel (Dendrocopos major);;Sonogram: Veliki detel / Srednji detel / Belohrbti detel / Triprsti detel;;Škrlatec (Carpodacus erythrinus);;Sloka (Scolopax rusticola);;Divji petelin (Tetrao urogallus);;Slovenski arhiv živalskih zvokov - 1;;Slovenski arhiv živalskih zvokov - 2;;Napevi evropskih škržatov (spletna stran);;Phantastic songs of the S.E. Asian cicadas (spletna stran);;Slovenski arhiv živalskih zvokov - 3;;Šakal (Canis aureus);;Hvala za pozornost'
12437,'lecture','en',12435,'2009-11-09','2010-05-21','Cholera, Canker Rash and Consumption: Historical epidemiology and nosology in Massachusetts, 1850-1920',NULL,NULL
12438,'lecture','en',12435,'2010-01-11','2010-05-21','Leadership, Regulatory Agencies and Public Health',NULL,NULL
12439,'lecture','en',12435,'2010-01-25','2010-05-21','California Department of Public Health and Pandemics: All Hands on Deck!',NULL,NULL
12440,'lecture','en',12435,'2010-02-08','2010-05-21','Health Under Siege: The Gazan Model',NULL,NULL
12441,'lecture','en',12435,'2010-02-22','2010-05-21','Rural Hypertension in China, a Growing Epidemic',NULL,NULL
12442,'lecture','en',12435,'2010-03-08','2010-05-21','Homelessness in Orange County',NULL,NULL
12443,'lecture','en',12435,'2010-04-12','2010-05-21','Stress and Health Disparities',NULL,NULL
12469,'lecture','en',12447,'2006-04-10','2010-05-06','Course introduction','In the first lecture, an introduction to solar cells is given. Simple examples illustrate the relevance of this topic. The question: Why solar cells? Will be answered in more than one way.',NULL
12470,'lecture','en',12447,'2006-04-17','2010-05-06','Solar radiation','In this session, solar radiation is reviewed. Spectralconsiderations and its relation to improve the performance of solar cells isaddressed.',NULL
12471,'lecture','en',12447,'2006-04-17','2010-05-06','Semiconductor properties','In this lecture, the semiconductor physics thatare involved in the generation of photovoltaic energy are studied. Theabsorption, separation and collection concepts are explained',NULL
12472,'lecture','en',12447,'2006-04-17','2010-05-06','PN junction','After the study of the physics principles, in this session a deeper review of the topic is carry on. In the lecture, the PN junction is covered: Part 1 presents the basics to be used in Part 2.',NULL
12473,'lecture','en',12447,'2006-04-17','2010-05-06','Losses and Optimization','In this lecture, the cell performance limits are explained. Techniques to improve the performance of the solar cells end up with the record c-Si solar cells. Topics related to losses (Part 1) and optimization (Part 2) are shown.',NULL
12474,'lecture','en',12447,'2006-04-17','2010-05-06','Crystalline Si Technology','In this lecture, crystalline silicon technology is reviewed in two parts:Part 1 and Part 2.',NULL
12475,'lecture','en',12447,'2006-04-17','2010-05-06','PV system + design','Practical use of solar cells is as important as understand it, therefore a design strategy for PV systems is made in this lecture.PV systems are studied in two parts: Part 1 and Part 2.',NULL
12476,'lecture','en',12447,'2006-04-17','2010-05-06','Organic solar cells','Organic solar cells are an excellent option to continue with the research of solar cells. In this lecture the last principles and advances in organic solar cells are presented: Part 1 and Part 2.',NULL
12478,'introduction','en',12402,'2010-04-26','2010-05-17','Introduction to Semantic Search 2010',NULL,NULL
12479,'invited talk','en',12402,'2010-04-26','2010-05-17','Why users need semantic search ','While users dependence on search continues to increase, user satisfaction is not improving. This is partly because search is hard, and partly because users are becoming more demanding and pushing search beyond the traditional scope of information retrieval. Our research reveals three key problems of search: imprecise results, need for query refinement, and need to support complex tasks and decisions. Semantic technologies can help address these problems by providing improvements to core search results and also through enabling richer user experiences such as faceted navigation, entity-centered experiences, and task completion and decision tools.','Why users need semantic search;;Today\'s Discussion;;Online Information Explosion;;Users Depending More on Search;;Unmet Needs: The 3 Problems of Search;;Typical Session: Digital Camera Purchase;;Digital Camera Purchase;;Typical Session: Health - 1;;Typical Session: Health - 2;;Typical Session: Travel;;Sessions are Decision Oriented;;Opportunities for Innovation;;Entity Centered Experiences;;E - Card, Toc;;Semantic Improvements to Core Search;;Semantic Retrieval & Ranking;;Semantic Query Understanding;;Presentation & Captions;;Smarter Text Selections;;Smart Summarization;;Captions with Word Variation;;Captions with Structured Data;;Faceted Search - 1;;Faceted Search - 2;;Task-oriented Experiences;;Converational Assistant;;Summary;;Concluding remarks;;Microsoft'
12480,'lecture','en',12402,'2010-04-26','2010-05-17','Paraphrasing Invariance Coefficient: Measuring Para-Query Invariance of Search Engines ','Paraphrasing is the restatement (or reuse) of text which preserves its meaning in another form. A para-query is a paraphrase of a search query. Humans easily recognize paraqueries, but search engines are still far away from it. We claim that in order for a search engine to be called semantic it is necessary that it recognizes para-queries by returning the same search results for all para-queries of a given query.\nRecognizing para-queries is an important and desired ability of a search engine. It can relieve users of the burden of rephrasing queries in order to improve the relevance of results.','Volunteer ?;;What\'s the population of Raleigh ?;;How many people live in Raleigh ?;;Paraphrasing Invariance Coefficient;;Outline;;Search Engines are becoming semantic;;Are they really semantic ?;;Today: Users have to ask nicely;;Returned Results;;Why ?;;Measure Metric;;Data Collection - 1;;Data Collection - 2;;Collective Wisdom;;Rephraser Game - 1;;Rephraser Game - 2;;Amodal Perception;;Visible Objects - 1;;Visible Objects - 2;;Occluded by a pipe - 1;;Occluded by a pipe - 2;;Generate para-Queries from the Game;;Measurement;;Paraphrasing Invariant Coefficient;;Result - 1;;Entropy;;Result - 2;;Conclusion;;Future Work;;Thanks for your attention'
12481,'lecture','en',12402,'2010-04-26','2010-05-17','Using BM25F for Semantic Search','Information Retrieval (IR) approaches for semantic web search engines have become very popular in the last years. Popularization of different IR libraries, like Lucene, that allows IR implementations almost out-of-the-box have make easier IR integration in Semantic Web search engines. However, one of the most important features of Semantic Web documents is the structure, since this structure allow us to represent semantic in a machine readable format. In this paper we analyze the specific problems of structured IR and how to adapt weighting schemas for semantic document retrieval.','Using BM25F for Semantic Search;;Outline - Introduction;;Keyword-based Semantic Search;;Two main problems - 1;;Two main problems - 2;;Outline - Indexing RDF using inverted indexes;;Problem;;Solutions - 1;;Solutions - 2;;Index Structure based on SEMPLORE model;;Two dbpedia entries;;Triple;;Using inlink text to index the landing URL;;Outline - Ranking based retrieval for RDF objects based on structured IR;;Classical IR;;Consequence;;Simplication;;Structured IR;;Ranking functions;;The Problem;;Lucene\'s ranking function;;Outline - A Semantic Search evaluation framework;;The collection;;DBpedia entries: A sort of structured documents;;Statistics of the collections;;Outline - The case study: Lucene Vs BM25F;;Semantic Search Engines;;Using TITLE, DESCRIPTION and NARRATIVE from Topics;;Sensibility test for BM25F;;Density of the MAP values;;Outline - Conclusions and Future Work;;Conclusions;;Future Work;;BM25F implementation for Lucene is available'
12482,'lecture','en',12402,'2010-04-26','2010-05-17','Distributed Indexing for Semantic Search','In this paper we describe the process of building indices for semantic search using MapReduce. We compare the two most straightforward representations of RDF data, the horizontal index structure using parallel indices and the vertical index structure using fields. We measure the cost of building indices and also compare retrieval performance on keyword queries and queries restricted to particular properties.','Distributed Indexing for Semantic Search;;MapReduce;;Text indexing using MapReduce;;RDF indexing using MapReduce;;Post-fixing;;Horizontal indexing;;Vertical indexing;;Implementation - 1;;Implementation - 2;;Evaluation;;Indexing cost;;Keyword query performance (4450 unique queries);;Unigram field query performance (4450 unique queries);;Conclusions'
12483,'lecture','en',12402,'2010-04-26','2010-05-17','Dear Search Engine: What’s your opinion about...? - Sentiment Analysis for Semantic Enrichment of Web Search Results ','Search Engines have become the main entry point to Web content, and a large part of the \\visible\" Web consists in what is presented by them as top retrieved results. Therefore, it would be desirable if the first few results were a representative sample of the entire result set. This paper provides a preliminary study about opinions contained in search engine results for controversial queries such as \"cloning\" or \"immigration\". To this end, we extract sentiment metadata from web pages, and compare search engine results for several queries. Furthermore, we compare opinions expressed in the top results to those in other retrieved results to examine whether the top-ranked pages are a good sample of all results from an opinion perspective. In a preliminary empirical analysis, we compare up to 50 results from 3 commercial search engines on 14 controversial queries to study the relation between sentiments, topics, and rankings.','Dear search engine: what\'s your opinion about... ?;;Motivation;;Our contribution;;Outline;;Euthanasia;;The ideal result;;Related work;;Extracting sentiment from web pages;;Sentiment estimation methods;;Experimental analysis;;Method comparation;;Sentiment for different se;;Sentiment at different ranks;;Sentiment about different topics;;Future work - 1;;Future work - 2;;www2010_demartini_dse_01_Page_17'
12484,'lecture','en',12402,'2010-04-26','2010-05-17','Automatic Modeling of User\'s Real World Activities from the Web for Semantic IR','We have been developing a task-based service navigation system that offers to the user services relevant to the task the user wants to perform. The system allows the user to concretize his/her request in the task-model developed by human-experts. In this study, to reduce the cost of collecting\na wide variety of activities, we investigate the automatic modeling of users’ real world activities from the web. To extract the widest possible variety of activities with high precision and recall, we investigate the appropriate number of contents and resources to extract. Our results show that we do not need to examine the entire web, which is too time consuming; a limited number of search results (e.g. 900 from among 21,000,000 search results) from blog contents are needed. In addition, to estimate the hierarchical relationships present in the activity model with the lowest possible error rate, we propose a method that divides the representation of activities into a noun part and a verb part,\nand calculates the mutual information between them. The result shows almost 80% of the hierarchical relationships can be captured by the proposed method. ','Automatic Modeling of User’s Real World Activities fromthe Web for Semantic IR;;Outline;;Task-model [ISWC2005,2006];;Purpose;;Past approach to automatic task modeling;;Light-weight task-model;;Activity extraction process (Process 1 and 2);;Process 3 Relating the activities;;Problems with past approach;;Ideal combination;;Problem with Ideal combination;;Approaches;;Method 2;;Method 3 - 1;;Method 3 - 2;;Experimental Setup;;Metric used;;Results (movie domain);;Results (book domain);;Discussion - 1;;Discussion - 2;;Discussion - 3;;Conclusion'
12485,'lecture','en',12402,'2010-04-26','2010-05-17','The Wisdom in Tweetonomies: Acquiring Latent Conceptual Structures from Social Awareness Streams','Although one might argue that little wisdom can be conveyed in messages of 140 characters or less, this paper sets out to explore whether the aggregation of messages in social awareness streams, such as Twitter, conveys meaningful information about a given domain. As a research community, we know little about the structural and semantic properties of such streams, and how they can be analyzed, characterized and used. This paper introduces a network-theoretic model of social awareness stream, a so-called \"tweetonomy\", together with a set of stream-based measures that allow researchers to systematically define and compare different stream aggregations. We apply the model and measures to a dataset acquired from Twitter to study emerging semantics in selected streams. The network-theoretic model and the corresponding measures introduced in this paper are relevant for researchers interested in information retrieval and ontology learning from social awareness streams. Our empirical\nfindings demonstrate that different social awareness stream aggregations exhibit interesting differences, making them amenable for different applications.','The Wisdom in Tweetonomies;;Social Awareness Streams (SAS);;www2010_wagner_twt_01_Page_03;;Structure of SAS;;A network-theoretic model of SAS;;Example;;Experiment - 1;;Dataset;;Structual Stream Measures - 1;;Structual Stream Measures - 2;;Experiment - 2;;Network Transformations;;First Result - 1;;First Result - 2;;First Result - 3;;Conclusion;;www2010_wagner_twt_01_Page_17;;Thank You;;www2010_wagner_twt_01_Page_19'
12486,'lecture','en',12402,'2010-04-26','2010-05-17',' A Large-Scale System for Annotating and Querying Quotations in News Feeds','In this paper, we describe a system that automatically extracts quotations from news feeds, and allows efficient retrieval of the semantically annotated quotes. APIs for real-time querying of over 10 million quotes extracted from recent news feeds are publicly available. In addition, each day we add around 60 thousand new quotes extracted from around 50 thousand news articles or blogs. We apply computational\nlinguistic techniques such as co-reference resolution, entity recognition and disambiguation to improve both precision and recall of the quote detection. We support faceted search on both speakers and entities mentioned in the quotes.','A Large-Scale System for Annotating and Quering Quotations in News Feeds;;Challenges;;Overview;;Quotation Search;;Search Service;;Indexed Triples;;Entity Repository;;Entity Properties;;Quote Extraction;;Quote Detection;;Quote Annotation;;Quote Indexing;;Example ;;Query Examples;;Public APIs;;Performance;;Links;;Future Work'
12487,'lecture','en',12402,'2010-04-26','2010-05-17','Entity Search: Building Bridges between Two Worlds','We consider the task of entity search and examine to which extent state-of-art information retrieval (IR) and semantic web (SW) technologies are capable of answering information needs that focus on entities. We also explore the potential of combining IR with SW technologies to improve the end-to- end performance on a specfiic entity search task. We arrive at and motivate a proposal to combine text-based entity models with semantic information from the Linked Open Data cloud.','Entity Search: Building Bridges between Two Worlds;;Entity search;;Entity search tasks;;Motivation;;Where are we now? - Information Retrieval;;Where are we now? - Semantic Web;;Where are we now?;;Example topics - 1;;Aim;;Related entity finding;;Example topic - 2;;IR approaches;;A typical IR approach;;Two SW approaches;;SPARQL on DBPedia - 1;;SPARQL on DBPedia - 2;;SPARQL on DBPedia - 3;;Findings - 1;;Next;;SPARQL on LOD;;Graph search on LOD;;Findings - 2;;Summarizing findings - 1;;Summarizing findings - 2;;Zooming out;;TREC Entity 2010;;Questions?'
12488,'lecture','en',12402,'2010-04-26','2010-05-17','Methodology and Campaign Design for the Evaluation of Semantic Search Tools','The main problem with the state of the art in the semantic search domain is the lack of comprehensive evaluations. There exist only a few efforts to evaluate semantic search tools and to compare the results with other evaluations of their kind.\nIn this paper, we present a systematic approach for testing and benchmarking semantic search tools that was developed within the SEALS project. Unlike other semantic web evaluations our methodology tests search tools both automatically and interactively with a human user in the loop. This allows us to test not only functional performance measures, such as precision and recall, but also usability issues, such as ease of use and comprehensibility of the query language. The paper describes the evaluation goals and assumptions; the criteria and metrics; the type of experiments we will conduct as well as the datasets required to conduct the evaluation in the context of the SEALS initiative. To our knowledge it is the first effort to present a comprehensive evaluation methodology for Semantic Web search tools.','Methodology and Campaign Design for the Evaluation of Semantic Search Tools;;Outline;;SEALS initiative;;SEALS goals;;Targeted technologies;;What’s our general approach?;;SEALS Platform;;Search evaluation design;;What do we want to do?;;Evaluation criteria - 1;;Two phase approach;;Evaluation criteria - 2;;Running the evaluation;;Automated evaluation;;User in the loop evaluation;;API;;API – common;;API – user in the loop;;API – automated;;Data;;Data set – user in the loop;;Data set – automated;;Results and analyses;;Questionnaires;;System Usability Scale (SUS) score;;Demographics;;Automated;;User in the loop;;Dissemination;;Conclusions - 1;;Conclusions - 2;;Thank you;;Get involved!;;Timeline;;Best paper award'
12489,'debate','en',12402,'2010-04-26','2010-05-17','Discussion on the Entity Search Track',NULL,NULL
12490,'lecture','en',12402,'2010-04-28','2010-05-17','Predicting Positive and Negative Links in Online Social Networks','We study online social networks in which relationships can be both positive (indicating friendship) and negative (indicating opposition or antagonism). Such a mix of positive and negative links arise in a variety of online settings; we study datasets from Epinions, Slashdot and Wikipedia. Despite the diversity of settings considered, we find that the signs of links in the underlying social networks can be predicted with high accuracy using models that generalize across the different domains. These models provide insight into some of the fundamental principles that drive the formation of signed links in networks, and also shed light on theories of balance and status from social psychology.','Predicting Positive and Negative Links in Online Social Networks;;Social Interaction on the Web;;Networks with signed edges;;Datasets for sign prediction;;Summary of our findings;;Predict edge sign;;Features for learning;;Edge sign prediction;;Conection to social theories;;Theory of Structural Balance;;Theory of Status;;Balance and Status - 1;;Balance and Status - 2;;Balance theory;;Status theory;;Learned vs. Deterministic models;;Generalization;;Does negative information help?;;From Local to Global Structure - 1;;From Local to Global Structure - 2;;Conclusion;;Thanks;;www2010_leskovec_ppn_01_Page_23'
12491,'lecture','en',12402,'2010-04-28','2010-05-17','Empirical Comparison of Algorithms for Network Community Detection','Detecting clusters or communities in large real-world graphs such as large social or information networks is a problem of considerable interest. In practice, one typically chooses an objective function that captures the intuition of a network cluster as set of nodes with better internal connectivity than external connectivity, and then one applies approximation algorithms or heuristics to extract sets of nodes that are related to the objective function and that “look like” good communities for the application of interest. In this paper, we explore a range of network community detection methods in order to compare them and to understand their relative performance and the systematic biases of clusters they identify. We evaluate several common objective functions that are used to formalize the notion of a network community, and examine several different classes of approximation algorithms that aim to optimize such objective functions. In addition, rather than simply fixing an objective and asking for an approximation to the best cluster of any size, we consider a size-resolved version of the optimization problem. Considering community quality as a function of its size provides a much finer lens with which to examine community detection algorithms, since objective functions and approximation algorithms often have non-obvious size-dependent behavior.','Empirical Comparasion of Algorithms for Network Community Detection;;How we think about networks?;;Micro-markets in sponsored search;;Social Network Data;;Finding communities;;Focus and issues;;Comparasion;;Clustering objective functions;;Experimental methodology;;Typical NCP;;Plan for the talk;;Many classes of algorithms;;Clusterts based on conductance;;Result (Livejournal network);;Properties of clusters - 1;;Properties of clusters - 2;;Other clustering methods;;8 objective functions;;Multi- criterion objectives;;Single - criterion objectives;;Lower and upper bounds;;Conclusion;;Thanks'
12492,'lecture','en',12402,'2010-04-29','2010-05-18','Statistical Models of Music-listening Sessions in Social Media','User experience in social media is characterized by rich interaction with the media content and other participants within the online community. We use statistical models to describe the patterns of music listening in online communities at different levels of model complexity. First, we adapt the LDA model to capture the users’ taste in songs and identify the corresponding clusters of media and users. Second, we define a graphical model that takes into consideration the listening sessions and captures the listening mood of users. Our session model yields clusters of media and users that capture the behavior exhibited across listening sessions, and it allows faster inference when compared to the LDA model. Our experiments with the data from an online media site (Zune Social music community) demonstrate that the session model is better in terms of the perplexity on the music genre co-occurrence compared to the LDA-based taste model that does not incorporate cross-session information and a baseline model that does not use latent clusters.','Statistical models of music-listening sessions in social media;;Online social media;;Online music communities;;Zune Social - 1;;Zune Social - 2;;Genre taxonomy – 2-level;;Motivation;;Applications;;Models for clustering media;;Media clusters;;Topic models and social media;;LDA model;;Topic models and social media - 1;;Topic models and social media - 2;;Taste model;;Media clusters;;Session model;;Evaluation;;Zune Social data set;;Experimental setup - 1;;Experimental setup - 2;;Predictive power - 1;;Predictive power - 2;;Discovered clusters – session model;;Training time;;Conclusions;;Applications and future work;;Questions?'
12493,'panel','en',12402,'2010-04-30','2010-05-17','Video Search: Are Algorithms All We Need?','During the 1990s, search technology improved sufficiently to handle large volumes of textual material without the need for manual abstracting, indexing, and cataloging. Taking professional cataloguers out of the process of text indexing created enormous value; an analogous set of advances is underway with video in the 2010s. But how and when will it be possible to take professionals out of the process of cataloging video manually? How can we expect different approaches to video search and search UI to evolve, and which ones will prove most useful? What kind of societal value can we reap by making making all of our broadcast history as readily accessible as books, journal articles, and newspapers are now? How can the W3C help with the development of appropriate standards for video description and search? Answers to and debate about these questions will be the focus of this panel, which has representatives from some of the largest, most viewed, and carefully indexed collections of digital video available online.','Quest for metadata;;Netherlands Institute for Sound and Vision - 1;;Netherlands Institute for Sound and Vision - 2;;Netherlands Institute for Sound and Vision - 3;;Netherlands Institute for Sound and Vision - 4;;Netherlands Institute for Sound and Vision - 5;;Netherlands Institute for Sound and Vision - 6;;Netherlands Institute for Sound and Vision - 7;;The digital archive - 1;;The digital archive - 2;;The digital archive - 3;;To be useful we need metadata - 1;;Metadata generation - 1;;Metadata generation - 2;;To be useful we need metadata - 2;;Metadata extraction;;Cataloguer support system - 1;;Cataloguer support system - 2;;Slajd;;Costs;;Conclusions;;Thank you!;;VideoLectures.Net;;Scientific and educational video services;;Some features of the VideoLectures.NET service;;Are algorithms enough? - 1;;Are algorithms enough? - 2;;Are algorithms enough? - 3;;Why algorithms might not be enough?;;Video Search at TRECVID;;What is TRECVID?;;TRECVID Philosophy;;TRECVID Yearly Cycle;;TRECVID Evolution;;TRECVID 2010 Tasks and Data;;TRECVID search types so far;;Panofsky/ Shamord mode/ facet matrix;;24 Topics from TRECVID 2009;;Drilling down in the search landscape;;Finding meaning in text (words) versus images (pixels);;One image/video – many different (changing) views of content;;One person/thing/location – many different (changing) appearances;;Can multimedia features serve as “words”?;;LSCOM feature sample;;Simulation study suggests ….;;A generic TRECVID search system;;Innovative search interfaces … WWW 2010;;Some results;;Varia:on in Average Precision by topic;;Observations, questions - 1;;Observations, questions - 2;;Observations, questions - 3;;Observations, questions - 4;;Observations, questions - 5'
12616,'lecture','sl',12427,'2010-05-13','2010-05-17','Biotska raznovrstnost na Krasu','Velika raznovrstnost rastlinstva na Krasu je predpogoj za veliko raznovrstnost živalstva, predvsem žuželk. Vzroke za oboje pa lahko iščemo\\\\ \n(1) v apnenčasti kamninski podlagi in tanki prsti nad njo, ki otežujeta intenzivno kmetijstvo,\\\\\n(2) razmeroma toplem submediteranskem podnebju, ki omogoča preživetje toploljubnim vrstam,\\\\ \n(3) močni burji, ki zavira zaraščanje z gozdom vsaj na vršnih grebenih in morda tudi\\\\\n(4) občasnim požarom, ki v sušnih letih vračajo rastje v zgodnejše stopnje zaraščanja.','Biotska raznovrstnost na Krasu;;Stipa eriocaulis;;Kraški travnik - 1;;Kraški travnik - 2;;Vpliv vode na apnenec - 1;;Vpliv vode na apnenec - 2;;Vpliv vode na apnenec - 3;;Frangula rupestris;;Kmetovanje na Krasu;;Vrtovi v vrtačah;;Crocus reticulatus;;Pulsatilla montana;;Muscari botryoides;;Fritillaria orientalis;;Ophrys sphegodes - Ophrys insectifera;;Narcissus radiiflorus;;pms2010_gogala_brk_01_Page_17;;Paeonia officinalis;;Gladiolus illyricus;;Asphodelus albus;;Eryngium amethystinum;;Stenobothrus rubicundulus;;Prionotropis hystrix;;Arcyptera fusca;;Metrioptera kuntzeni;;Odontotarsus purpureolineatus;;Copium clavicorne;;Dorcadion arenarium;;Sisyphus schaefferi;;Zerynthia polyxena;;Coenonympha oedippus;;Colletes graeffei;;Hoplitis pallicornis;;Platystoma sp.;;Archaeognatha, Machilidae;;Mantis religiosa;;Rhynocoris rubricus;;Libelloides macaronius;;Chilosphex argyrius;;Hogna radiata;;Eresus sp.;;Euscorpius italicus;;Scolopendra cingulata;;Podarcis melisellensis;;Zaraščanje Krasa;;Juniperus communis;;Cotinus coggygria;;Prunus mahaleb;;Quercus pubescens;;Asparagus acutifolius;;Barbitistes ocskayi;;Cyrtaspis scutata;;Andricus quercustozae;;Lachnus roboris;;Cicada orni;;Lucanus cervus;;Iphiclides podalirius;;Prikaz potencialne vegetacije - 1;;Prikaz potencialne vegetacije - 2;;Prikaz potencialne vegetacije - 3;;Vremščica;;Dimorphocoris saulii;;Vremščica - Catria;;Genista sericea;;Platycranus boreae - Halticus henschii;;Posledice burje - 1;;Mokovec na Vremščici;;Zamrznjeni viri vode;;Posledice burje - 2;;Quercus ilex;;Moehringia tommasinii;;Serratula lycopifolia;;Melitta tomentosa - 1;;Melitta tomentosa - 2;;Najdišča žaboroške čebele;;Podzemlje na Krasu - 1;;Podzemlje na Krasu - 2;;Presihajoče jezero;;Arctodiaptomus laticeps, Helophorus sp.;;Allium angulosum;;Umetno zadrževanje vode;;Rana sp.;;Notonecta maculata;;Gozdni požar pri Komnu, 22. julij 2006;;Sv. Katerina nad Škrbino, 30. julij 2006;;Teden po požaru, 30. julij 2006;;Tettigonia viridissima;;Tri mesece po požaru, 29. oktobra 2006 - Anthracobia macrocystis;;Echinops ritro'
12618,'tutorial','en',12403,'2010-05-06','2010-06-15','Machine learning for cognitive science 1: What is machine learning?',NULL,'What is Machine Learning? (Part 1);;Outline - 1;;Outline - 2;;What is Machine Learning? - 1 ;;What is Machine Learning? - 2;;What is Machine Learning? - 3;;What is Machine Learning? - 4 ;;What is Machine Learning? - 5 ;;What is Machine Learning? - 6;;What is Machine Learning? - 7;;History of Machine Learning (personal) - 1;;History of Machine Learning (personal) - 2;;History of Machine Learning (personal) - 3;;History of Machine Learning (personal) - 4;;Machine Learning Today - 1;;Machine Learning Today - 2;;Machine Learning Today - 3;;Machine Learning Today - 4;;Machine Learning Today - 5;;Machine Learning Today - 6;;Machine Learning Today - 7;;Machine Learning Today - 8;;Statistics ;;Early 20th Century Statistics;;Outline - 3;;Supervised Learning;;Outline - 4;;Classification;;Classification Examples;;The Perceptron;;Perceptron-like Algorithm;;Perceptron Algorithm - 1;;Perceptron Algorithm - 2;;Perceptron Algorithm - 3;;Perceptron Algorithm - 4;;Perceptron Algorithm - 5;;Perceptron Algorithm - 6;;Perceptron Algorithm - 7;;Perceptron Algorithm - 8;;Perceptron Algorithm - 9;;Perceptron Algorithm - 10;;Perceptron Algorithm - 11;;Perceptron Algorithm - 12;;Perceptron Algorithm - 13;;Perceptron Algorithm - 14;;Perceptron Algorithm - 15;;Perceptron Algorithm - 16;;Perceptron Algorithm - 17;;Perceptron Algorithm - 18;;Ouline - 5;;Regression Examples;;Linear Regression;;Updating Bias/Intercept;;Updating Slope;;Linear Regression Example - 1;;Linear Regression Example - 2;;Linear Regression Example - 3;;Linear Regression Example - 4;;Linear Regression Example - 5;;Linear Regression Example - 6;;Linear Regression Example - 7;;Linear Regression Example - 8;;Linear Regression Example - 9;;Linear Regression Example - 10;;Linear Regression Example - 11;;Linear Regression Example - 12;;Linear Regression Example - 13;;Linear Regression Example - 14;;Linear Regression Example - 15;;Linear Regression Example - 16;;Linear Regression Example - 17;;Linear Regression Example - 18;;Linear Regression Example - 19;;Linear Regression Example - 20;;Linear Regression Example - 21;;Linear Regression Example - 22;;Linear Regression Example - 23;;Linear Regression Example - 24;;Linear Regression Example - 25;;Linear Regression Example - 26;;Linear Regression Example - 27;;Linear Regression Example - 28;;Linear Regression Example - 29;;Linear Regression Example - 30;;Linear Regression Example - 31;;Linear Regression Example - 32;;Linear Regression Example - 33;;Linear Regression Example - 34;;Linear Regression Example - 35;;Linear Regression Example - 35;;Linear Regression Example - 36;;Linear Regression Example - 37;;Linear Regression Example - 38;;Linear Regression Example - 39;;Linear Regression Example - 40;;Linear Regression Example - 41;;Linear Regression Example - 42;;Linear Regression Example - 43;;Linear Regression Example - 44;;Linear Regression Example - 45;;Linear Regression Example - 46;;Linear Regression Example - 47;;Linear Regression Example - 48;;Linear Regression Example - 49;;Linear Regression Example - 50;;Linear Regression Example - 51;;Linear Regression Example - 52;;Linear Regression Example - 53;;Linear Regression Example - 54;;Linear Regression Example - 55;;Linear Regression Example - 56;;Linear Regression Example - 57;;Linear Regression Example - 58;;Basis Functions;;Quadratic Basis - 1;;Quadratic Basis - 2;;Quadratic Basis - 3;;Functions Derived from Quadratic Basis - 1;;Functions Derived from Quadratic Basis - 2;;Functions Derived from Quadratic Basis - 3;;Radial Basis Functions - 1;;Radial Basis Functions - 2;;Radial Basis Functions - 3;;Functions Derives from Radial Basis - 1;;Functions Derives from Radial Basis - 2;;Functions Derives from Radial Basis - 3;;Nonlinear Regression Example - 1;;Nonlinear Regression Example - 2;;Nonlinear Regression Example - 3;;Nonlinear Regression Example - 4;;Nonlinear Regression Example - 5;;Nonlinear Regression Example - 6;;Nonlinear Regression Example - 7;;Nonlinear Regression Example - 8;;Nonlinear Regression Example - 9;;Nonlinear Regression Example - 10;;Nonlinear Regression Example - 11;;Nonlinear Regression Example - 12;;Nonlinear Regression Example - 13;;Nonlinear Regression Example - 14;;Nonlinear Regression Example - 15;;Nonlinear Regression Example - 16;;Nonlinear Regression Example - 17;;Nonlinear Regression Example - 18;;Nonlinear Regression Example - 19;;Nonlinear Regression Example - 20;;Nonlinear Regression Example - 21;;Nonlinear Regression Example - 22;;Nonlinear Regression Example - 23;;Nonlinear Regression Example - 24;;Nonlinear Regression Example - 25;;Nonlinear Regression Example - 26;;Nonlinear Regression Example - 27;;Nonlinear Regression Example - 28;;Nonlinear Regression Example - 29;;Nonlinear Regression Example - 30;;Nonlinear Regression Example - 31;;Nonlinear Regression Example - 32;;Nonlinear Regression Example - 33;;Nonlinear Regression Example - 34;;Nonlinear Regression Example - 35;;Nonlinear Regression Example - 36;;Nonlinear Regression Example - 37;;Nonlinear Regression Example - 38;;Nonlinear Regression Example - 39;;Nonlinear Regression Example - 40;;Nonlinear Regression Example - 41;;Nonlinear Regression Example - 42;;Nonlinear Regression Example - 43;;Nonlinear Regression Example - 44;;Nonlinear Regression Example - 45;;Nonlinear Regression Example - 46;;Nonlinear Regression Example - 47;;Nonlinear Regression Example - 48;;Nonlinear Regression Example - 49;;Nonlinear Regression Example - 50;;Nonlinear Regression Example - 51;;Nonlinear Regression Example - 52;;Nonlinear Regression Example - 53;;Nonlinear Regression Example - 54;;Nonlinear Regression Example - 55;;Nonlinear Regression Example - 56;;Outline - 6;;Mathematical Interpretation - 1;;Mathematical Interpretation - 2;;Learning is Optimization - 1;;Learning is Optimization - 2;;Minimization via Gradient Descent ;;Steepest Descent - 1;;Steepest Descent - 2;;Steepest Descent - 3;;Steepest Descent - 4;;Steepest Descent - 5;;Steepest Descent - 6;;Steepest Descent - 7;;Steepest Descent - 8;;Steepest Descent - 9;;Steepest Descent - 10;;Steepest Descent - 11;;Steepest Descent - 12;;Steepest Descent - 13;;Steepest Descent - 14;;Steepest Descent - 15;;Steepest Descent - 16;;Steepest Descent - 17;;Steepest Descent - 18;;Steepest Descent - 19;;Steepest Descent - 20;;Steepest Descent - 21;;Steepest Descent - 22;;Stochastic Gradient Descent - 1;;Stochastic Gradient Descent - 2;;Stochastic Gradient Descent - 3;;Stochastic Gradient Descent - 4;;Stochastic Gradient Descent - 5;;Stochastic Gradient Descent - 6;;Stochastic Gradient Descent - 7;;Stochastic Gradient Descent - 8;;Stochastic Gradient Descent - 9;;Stochastic Gradient Descent - 10;;Stochastic Gradient Descent - 11;;Stochastic Gradient Descent - 12;;Stochastic Gradient Descent - 13;;Stochastic Gradient Descent - 14;;Stochastic Gradient Descent - 15;;Stochastic Gradient Descent - 16;;Stochastic Gradient Descent - 17;;Stochastic Gradient Descent - 18;;Stochastic Gradient Descent - 19;;Stochastic Gradient Descent - 20;;Stochastic Gradient Descent - 21;;Stochastic Gradient Descent - 22;;Stochastic Gradient Descent - 23;;Stochastic Gradient Descent - 24;;Stochastic Gradient Descent - 25;;Stochastic Gradient Descent - 26;;Stochastic Gradient Descent - 27;;Stochastic Gradient Descent - 28;;Stochastic Gradient Descent - 29;;Stochastic Gradient Descent - 30;;Stochastic Gradient Descent - 31;;Stochastic Gradient Descent - 32;;Stochastic Gradient Descent - 33;;Stochastic Gradient Descent - 34;;Stochastic Gradient Descent - 35;;Stochastic Gradient Descent - 36;;Stochastic Gradient Descent - 37;;Stochastic Gradient Descent - 38;;Modern View of Error Functions;;Important Concepts Not Covered;;Outline - 7;;Outline - 8;;Clustering;;K - means Clustering - 1;;Objective Function;;K - means Clustering - 2;;K - means Clustering - 3;;K - means Clustering - 4;;K - means Clustering - 5;;K - means Clustering - 6;;K - means Clustering - 7;;K - means Clustering - 8;;K - means Clustering - 9;;K - means Clustering - 10;;K - means Clustering - 11;;K - means Clustering - 12;;Other Clustering Approaches;;Outline - 9;;High Dimensional Data - 1;;High Dimensional Data - 2;;High Dimensional Data - 3;;High Dimensional Data - 4;;Simple Model of Digit - 1;;Simple Model of Digit - 2;;Simple Model of Digit - 3;;Simple Model of Digit - 4;;Simple Model of Digit - 5;;Simple Model of Digit - 6;;Simple Model of Digit - 7;;Simple Model of Digit - 8;;Simple Model of Digit - 9;;MATLAB Demo - 1;;MATLAB Demo - 2;;MATLAB Demo - 3;;Low Dimensional Manifolds;;Notation;;Reading Notation;;Data Representation;;Interpoint Distances for Rotated Sixes;;Multidimensional Scaling;;Feature Selection - 1;;Feature Selection - 2;;Feature Selection - 3;;Feature Selection - 4;;Reconstruction from Latent Space - 1;;Reconstruction from Latent Space - 2;;Considering Rotations;;Feature Extraction - 1;;Feature Extraction - 2;;Feature Extraction - 3;;Feature Extraction - 4;;Feature Extraction - 5;;Feature Extraction - 6;;Feature Extraction - 7;;Which Rotation?;;Rotation Reconstruction from Latent Space - 1;;Rotation Reconstruction from Latent Space - 2;;Outline - 10;;Principal Component Analysis - 1;;Principal Component Analysis - 2;;Lagrangian;;Conclusions;;References - 1;;References - 2;;Outline - 11;;Lagrange Multiplier;;Further Directions;;Further Eigenvectors;;Principle Coordinate Analysis;;An Alternative Formalism - 1;;An Alternative Formalism - 2;;An Alternative Formalism - 3;;Uq Diagonalizes the Inner Product Matrix - 1;;Uq Diagonalizes the Inner Product Matrix - 2;;Uq Diagonalizes the Inner Product Matrix - 3;;Uq Diagonalizes the Inner Product Matrix - 4;;Uq Diagonalizes the Inner Product Matrix - 5;;Uq Diagonalizes the Inner Product Matrix - 6;;Uq Diagonalizes the Inner Product Matrix - 7;;Uq Diagonalizes the Inner Product Matrix - 8;;Uq Diagonalizes the Inner Product Matrix - 9;;Uq Diagonalizes the Inner Product Matrix - 10;;Uq Diagonalizes the Inner Product Matrix - 11;;Uq Diagonalizes the Inner Product Matrix - 12;;Uq Diagonalizes the Inner Product Matrix - 13;;Equivalent Eigenvalue Problems;;The Covariance Interpretation;;Distance to Similarity;;Standard Transformation;;What is Machine Learning? (Part 1);;Outline - 1;;Outline - 2;;What is Machine Learning? - 1;;What is Machine Learning? - 2;;What is Machine Learning? - 3;;What is Machine Learning? - 4;;What is Machine Learning? - 5;;What is Machine Learning? - 6;;What is Machine Learning? - 7;;History of Machine Learning (personal) - 1;;History of Machine Learning (personal) - 2;;History of Machine Learning (personal) - 3;;History of Machine Learning (personal) - 4;;Machine Learning Today - 1;;Machine Learning Today - 2;;Machine Learning Today - 3;;Machine Learning Today - 4;;Machine Learning Today - 5;;Machine Learning Today - 6;;Machine Learning Today - 7;;Machine Learning Today - 8;;Statistics;;Early 20th Century Statistics;;Outline - 4;;Supervised Learning;;Outline - 5;;Classification;;Classification Examples ;;The Perceptron;;Perceptron - like Algorithm;;Perceptron Algorithm - 1;;Perceptron Algorithm - 2;;Perceptron Algorithm - 3;;Perceptron Algorithm - 4;;Perceptron Algorithm - 5;;Perceptron Algorithm - 6;;Perceptron Algorithm - 7;;Perceptron Algorithm - 8;;Perceptron Algorithm - 9;;Perceptron Algorithm - 10;;Perceptron Algorithm - 11;;Perceptron Algorithm - 12;;Perceptron Algorithm - 13;;Perceptron Algorithm - 14;;Perceptron Algorithm - 15;;Perceptron Algorithm - 16;;Perceptron Algorithm - 17;;Perceptron Algorithm - 18;;Outline - 5;;Regression Examples;;Linear Regression;;Updating Bias/Intercept;;Updating Slope;;Linear Regression Example - 1;;Linear Regression Example - 2;;Linear Regression Example - 3;;Linear Regression Example - 4;;Linear Regression Example - 5;;Linear Regression Example - 6;;Linear Regression Example - 7;;Linear Regression Example - 8;;Linear Regression Example - 9;;Linear Regression Example - 10;;Linear Regression Example - 11;;Linear Regression Example - 12;;Linear Regression Example - 13;;Linear Regression Example - 14;;Linear Regression Example - 15;;Linear Regression Example - 16;;Linear Regression Example - 17;;Linear Regression Example - 18;;Linear Regression Example - 19;;Linear Regression Example - 20;;Linear Regression Example - 21;;Linear Regression Example - 22;;Linear Regression Example - 23;;Linear Regression Example - 24;;Linear Regression Example - 25;;Linear Regression Example - 26;;Linear Regression Example - 27;;Linear Regression Example - 28;;Linear Regression Example - 29;;Linear Regression Example - 30;;Linear Regression Example - 31;;Linear Regression Example - 32;;Linear Regression Example - 33;;Linear Regression Example - 34;;Linear Regression Example - 35;;Linear Regression Example - 36;;Linear Regression Example - 37;;Linear Regression Example - 38;;Linear Regression Example - 39;;Linear Regression Example - 40;;Linear Regression Example - 41;;Linear Regression Example - 42;;Linear Regression Example - 43;;Linear Regression Example - 44;;Linear Regression Example - 45;;Linear Regression Example - 46;;Linear Regression Example - 47;;Linear Regression Example - 48;;Linear Regression Example - 49;;Linear Regression Example - 50;;Linear Regression Example - 51;;Linear Regression Example - 52;;Linear Regression Example - 53;;Linear Regression Example - 54;;Linear Regression Example - 55;;Linear Regression Example - 56;;Linear Regression Example - 57;;Linear Regression Example - 58;;Linear Regression Example - 59;;Basis Functions;;Quadratic Basis - 1;;Quadratic Basis - 2;;Quadratic Basis - 3;;Functions Derived from Quadratic Basis - 1;;Functions Derived from Quadratic Basis - 2;;Functions Derived from Quadratic Basis - 3;;Radial Basis Functions - 1;;Radial Basis Functions - 2;;Radial Basis Functions - 3;;Functions Derived from radial Basis - 1;;Functions Derived from radial Basis - 2;;Functions Derived from radial Basis - 3;;Nonlinear Regression Example - 1;;Nonlinear Regression Example - 2;;Nonlinear Regression Example - 3;;Nonlinear Regression Example - 4;;Nonlinear Regression Example - 5;;Nonlinear Regression Example - 6;;Nonlinear Regression Example - 7;;Nonlinear Regression Example - 8;;Nonlinear Regression Example - 9;;Nonlinear Regression Example - 10;;Nonlinear Regression Example - 11;;Nonlinear Regression Example - 12;;Nonlinear Regression Example - 13;;Nonlinear Regression Example - 14;;Nonlinear Regression Example - 15;;Nonlinear Regression Example - 16;;Nonlinear Regression Example - 17;;Nonlinear Regression Example - 18;;Nonlinear Regression Example - 19;;Nonlinear Regression Example - 20;;Nonlinear Regression Example - 21;;Nonlinear Regression Example - 22;;Nonlinear Regression Example - 23;;Nonlinear Regression Example - 24;;Nonlinear Regression Example - 25;;Nonlinear Regression Example - 26;;Nonlinear Regression Example - 27;;Nonlinear Regression Example - 28;;Nonlinear Regression Example - 29;;Nonlinear Regression Example - 30;;Nonlinear Regression Example - 31;;Nonlinear Regression Example - 32;;Nonlinear Regression Example - 33;;Nonlinear Regression Example - 34;;Nonlinear Regression Example - 35;;Nonlinear Regression Example - 36;;Nonlinear Regression Example - 37;;Nonlinear Regression Example - 38;;Nonlinear Regression Example - 39;;Nonlinear Regression Example - 40;;Nonlinear Regression Example - 41;;Nonlinear Regression Example - 42;;Nonlinear Regression Example - 43;;Nonlinear Regression Example - 44;;Nonlinear Regression Example - 45;;Nonlinear Regression Example - 46;;Nonlinear Regression Example - 47;;Nonlinear Regression Example - 48;;Nonlinear Regression Example - 49;;Nonlinear Regression Example - 50;;Nonlinear Regression Example - 51;;Nonlinear Regression Example - 52;;Nonlinear Regression Example - 53;;Nonlinear Regression Example - 54;;Nonlinear Regression Example - 55;;Nonlinear Regression Example - 56;;Outline - 7;;Mathematical Interpretation - 1;;Mathematical Interpretation - 2;;Learning is Optimization - 1;;Learning is Optimization - 2;;Minimization via Gradient Descent;;Steepest Descent - 1;;Steepest Descent - 2;;Steepest Descent - 3;;Steepest Descent - 4;;Steepest Descent - 5;;Steepest Descent - 6;;Steepest Descent - 7;;Steepest Descent - 8;;Steepest Descent - 9;;Steepest Descent - 10;;Steepest Descent - 11;;Steepest Descent - 12;;Steepest Descent - 13;;Steepest Descent - 14;;Steepest Descent - 15;;Steepest Descent - 16;;Steepest Descent - 17;;Steepest Descent - 18;;Steepest Descent - 19;;Steepest Descent - 20;;Steepest Descent - 21;;Steepest Descent - 22;;Stochastic Gradient Descent - 1;;Stochastic Gradient Descent - 2;;Stochastic Gradient Descent - 3;;Stochastic Gradient Descent - 4;;Stochastic Gradient Descent - 5;;Stochastic Gradient Descent - 6;;Stochastic Gradient Descent - 7;;Stochastic Gradient Descent - 8;;Stochastic Gradient Descent - 9;;Stochastic Gradient Descent - 10;;Stochastic Gradient Descent - 11;;Stochastic Gradient Descent - 12;;Stochastic Gradient Descent - 13;;Stochastic Gradient Descent - 14;;Stochastic Gradient Descent - 15;;Stochastic Gradient Descent - 16;;Stochastic Gradient Descent - 17;;Stochastic Gradient Descent - 18;;Stochastic Gradient Descent - 19;;Stochastic Gradient Descent - 20;;Stochastic Gradient Descent - 21;;Stochastic Gradient Descent - 22;;Stochastic Gradient Descent - 23;;Stochastic Gradient Descent - 24;;Stochastic Gradient Descent - 25;;Stochastic Gradient Descent - 26;;Stochastic Gradient Descent - 27;;Stochastic Gradient Descent - 28;;Stochastic Gradient Descent - 29;;Stochastic Gradient Descent - 30;;Stochastic Gradient Descent - 31;;Stochastic Gradient Descent - 32;;Stochastic Gradient Descent - 33;;Stochastic Gradient Descent - 34;;Stochastic Gradient Descent - 35;;Stochastic Gradient Descent - 36;;Stochastic Gradient Descent - 37;;Stochastic Gradient Descent - 38;;Modern View of error Functions;;Important Concepts Not Covered;;Outline - 8;;Outline - 9;;Clustering;;K - means Clustering - 1;;Objective Function;;K - means Clustering - 2;;K - means Clustering - 3;;K - means Clustering - 4;;K - means Clustering - 5;;K - means Clustering - 6;;K - means Clustering - 7;;K - means Clustering - 8;;K - means Clustering - 9;;K - means Clustering - 10;;K - means Clustering - 11;;K - means Clustering - 12;;Other Clustering Approaches;;Outline - 10;;High Dimensional Data - 1;;High Dimensional Data - 2;;High Dimensional Data - 3;;High Dimensional Data - 4;;Simple Model of Digit - 1;;Simple Model of Digit - 2;;Simple Model of Digit - 3;;Simple Model of Digit - 4;;Simple Model of Digit - 5;;Simple Model of Digit - 6;;Simple Model of Digit - 7;;Simple Model of Digit - 8;;Simple Model of Digit - 9;;MATLAB Demo - 1;;MATLAB Demo - 2;;MATLAB Demo - 3;;Low Dimensional Manifolds;;Notation;;Reading Notation;;Data Representation;;Interpoint Distances for Rotated Sixes;;Multidimensional Scaling;;Feature Selection - 1;;Feature Selection - 2;;Feature Selection - 3;;Feature Selection - 4;;Reconstruction from Latent Space - 1;;Reconstruction from Latent Space - 2;;Considering Rotations;;Feature Extraction - 1;;Feature Extraction - 2;;Feature Extraction - 3;;Feature Extraction - 4;;Feature Extraction - 5;;Feature Extraction - 6;;Feature Extraction - 7;;Which Rotation?;;Rotation Reconstructed from Latent Space - 1;;Rotation Reconstructed from Latent Space - 2;;Outline - 11;;Principal Component Analysis - 1;;Principal Component Analysis - 2;;Lagrangian;;Conclusions;;References - 1;;References - 2;;Outline - 12;;Lagarnge Multiplier;;Further Directions;;Further Eigenvectors;;Principal Coordinate Analysis;;An Alternative Formalism - 1;;An Alternative Formalism - 2;;An Alternative Formalism - 3;;Uq Diagonalizes the Inner Product Matrix - 1;;Uq Diagonalizes the Inner Product Matrix - 2;;Uq Diagonalizes the Inner Product Matrix - 3;;Uq Diagonalizes the Inner Product Matrix - 4;;Uq Diagonalizes the Inner Product Matrix - 5;;Uq Diagonalizes the Inner Product Matrix - 6;;Uq Diagonalizes the Inner Product Matrix - 7;;Uq Diagonalizes the Inner Product Matrix - 8;;Uq Diagonalizes the Inner Product Matrix - 9;;Uq Diagonalizes the Inner Product Matrix - 10;;Uq Diagonalizes the Inner Product Matrix - 11;;Uq Diagonalizes the Inner Product Matrix - 12;;Uq Diagonalizes the Inner Product Matrix - 13;;Equivalent Eigenvalue Problems;;The Covariance Interpretation;;Distance to Similarity: A Gaussian Covariance Interpretation;;Standard Transformation;;Behavioural Learning: Inspiration from Nature?;;Plan of talk;;Machine learning: structure of the field;;Example: Supervised Learning;;Reinforcement Learning;;Reinforcement Learning: motivating the model - 1;;Reinforcement Learning: motivating the model - 2;;RL: Intuitions;;RL: Markov Decision Processes;;An example MDP: Robot Golf;;Three types of control;;Choosing actions: by look-ahead search;;Choosing actions: by stored policy;;Choosing actions: by stored value function;;Optimising policy and values together;;Q - Learning - 1;;Q - Learning - 2;;Developments in RL;;Successes of RL;;Limitations of RL;;Plausibility of RL;;Part 2: RL in Animals;;Conditioning Experiments;;Classical Conditioning;;Keller and Marian Breland;;Breland and Breland (1951);;\'The Misbehaviour of Organisms\' (1961);;The Misbehaviour of Organisms - 1;;The Misbehaviour of Organisms - 2;;Rooting;;The Misbehaviour of Organisms - 3;;Instinctive Drift;;Questions;;Discussion;;Example 2: Brood parasitism;;Brood parasitism: the Common Cuckoo;;Brood Parasitism;;95 bird species are obligate brood parasites;;The Dangers of Theory - 1;;The Dangers of Theory - 2;;Host defences against parasitic eggs;;How does host recognise parasitic egg?;;Why do hosts not imprint on their chicks also?;;Confirmation: Intra - species rejection of chicks - 1;;Confirmation: Intra - species rejection of chicks - 2;;Confirmation: Intra - species rejection of chicks - 3;;Example 3: Megapodes - 1;;Example 3: Megapodes - 2;;Example 3: a pure example of selection for annate competence;;Part 3: Learning and Evolution;;1. why learn? Phenotypic Plasticity;;2. Baldwin Effects;;3. Cultural Transmission;;4. Imitation without culture;;5. does \"Innate knowledge\" require experience for its development?;;&. Evolution is incremental optimisation;;Discussions: what don\'t we know?;;Behavioural Learning: Inspiration from Nature?;;Plan of Talk;;Machine learning: structure of the field;;Example: Supervised Learning;;Reinforcement Learning;;Reinforcement Learning: motivating the model - 1;;Reinforcement Learning: motivating the model - 2;;RL: Intuitions;;RL: Markov Decision Processes;;An example MDP: Robot Golf;;Three types of control;;Choosing actions: by look - ahead search;;Choosing actions: by stored policy;;Choosing actions: by stored value function;;Optimising policy and values together;;Q - Learning - 1;;Q - Learning - 2;;Developments in RL;;Successes of RL;;Limitations of RL;;Plausibility of RL;;Part 2: RL in Animals;;Conditioning Experiments;;Classical Conditioning;;Keller and Marian Breland;;Breland and Breland (1951);;\'The Misbehaviour of Organisms\' - 1;;The Misbehaviour of Organisms - 2;;The Misbehaviour of Organisms\'- 3;;Rooting;;The Misbehaviour of Organisms - 4;;Instinctive Drift;;Questions;;Discussion;;Example 2: Brood parasitism;;Brood parasitism: the Common Cuckoo;;Brood Parasitism;;95 bird species are obligate brood parasites;;The Dangers of Theory - 1;;The Dangers of Theory - 2;;Host defences against parasitic eggs;;How does host recognise the parasitic egg?;;Why do hosts not imprint on their chicks also?;;Confirmation: Intra - species rejection of chicks - 1;;Confirmation: Intra - species rejection of chicks - 2;;Confirmation: Intra - species rejection of chicks - 3;;Example 3: Megapodes - 1;;Example 3: Megapodes - 2;;Example 3: A pure example of selection for innate competence;;Part 3: Learning and Evolution;;1. Why learn? Phenotypic Plasticity;;2. Baldwin Effects;;3. Cultural Transmission;;4. Imitation without culture;;5. Does \"Innate knowledge\" require experience for its development?;;6. Evolution is incremental optimisation;;Discussions: what don\'t we know?'
12619,'tutorial','en',12403,'2010-05-06','2010-06-29','Cognitive science for machine learning 1:What is cognitive science?',NULL,'Cognitive science for machine learning 1: What is cognitive science?;;Overview;;1. Cognitive Science Meets Machine Learning;;Cognitive Science as Reverse Engineering;;But, in practise, the concerns of cog sci and ML may appear to clash;;Cognitive Science and Machine Learning: Why are we all here?;;2. Historical Background;;Wundt and the Beginning of Experimental Psychology;;The Introspective Method;;The Method in Action;;The Collapse of Introspection;;The Unreliability of Introspection in Perception - 1;;The Unreliability of Introspection in Perception - 2;;The Unreliability of Introspection in Perception - 3;;Little Better for Knowledge or Decision;;Introspection is Hugely Powerful but Reports Output, Not Process;;Behaviorism;;Setting the Stage: Pavlov (1849 - 1936);;J. B. Watson (1878 - 1959) Founder of Behaviorism;;B. F. Skinner (1904 - 1990) Radical Behaviorism;;And it Was Radical;;Somewhat Anachronistically: Behaviorism in Computational Terms;;By Contrast Rescorla - Wagner (1970) Model of Classical Conditional;;Kamin Blocking: Training Phase 1;;Kamin Blocking: Training Phase 2;;Problems for Behaviorism;;Flexibility of behaviour - 1;;Flexibility of behaviour - 2;;Flexibility of behaviour - 3;;Flexibility of behaviour - 4;;Flexibility of behaviour - 5;;Suggests the Need to Peer Inside the Black Box;;Cognitive Science;;Symbolic Knowledge Representation;;Problem Solving as Symbolic Search;;Language Processing as Symbol Manipulation;;Two challenges for the symbolic approach;;Connectionism;;Which is the right challenge;;3. Levels of Explanation;;Marr\'s (1982) Levels;;\"Discovering\" the Pocket Calculator;;Matching Random Dot Stereograms;;Illustration;;Summary;;Cognitive science for machine learning 1: What is cognitive Science?;;Overview;;1. Cognitive Science Meets Machine Learning;;Cognitive Science as Reverse Engineering;;But, in practise, the concerns of cog sci and ML may appear to clash;;Cognitive Science and Machine Learning: Why are we all Here?;;2. Historical Background;;Wundt and the Beginning of Experimental Psychology;;The Introspective Method;;The Method in Action;;The Collapse of Introspection;;The Unreliability of Introspection in Perception - 1;;The Unreliability of Introspection in Perception - 2;;The Unreliability of Introspection in Perception - 3;;Little Better for Knowledge or Decision;;Introspection is Hugely Powerful but Reports Output, not Process;;Behaviorism;;Setting the Stage: Pavlov (1849 - 1936);;J. B. Watson (1878 - 1959) Founder of Behaviorism;;B. F. Skinner (1904 - 1990) Radical Behaviorism;;And it Was Radical;;Somewhat Anachronistically: Behaviorism in Computational Terms;;By Contrast: Rescorla - Wagner (1970) Model of Classical Conditioning;;Kamin Blocking: Training Phase 1;;Kamin Blocking: Training Phase 2;;Problems for Behaviorism;;Flexibility of Behaviour - 1;;Flexibility of Behaviour - 2;;Flexibility of Behaviour - 3;;Flexibility of Behaviour - 4;;Flexibility of Behaviour - 5;;Sugests the Need to Peer Inside the Black Box;;Cognitive Science;;Symbolic Knowledge Representation;;Problem Solving as Symbolic Search;;Language Processing as Symbol Manipulation;;Two challenges for the symbolic approach;;Connectionism;;Which is the right challenge;;3. Levels of Explanation;;Marr\'s (1982) Levels;;\"Discovering\" the Pocket Calculator;;Matching Random Dot Stereograms;;Illustration;;Summary;;What is Cognitive Science?;;Pscyhology/CogSci and machine learning: a long-term relationship;;A success story in the 1980s-1990s: The “standard model of learning”;;A success story in the 1980s-1990s: The “standard model of learning”;;Outline;;The big question;;Visual perception(;;Ambiguity in visual perception;;Learning-based machine vision: state of the art(;;Learning concepts from examples;;Humans and bumble bees;;Causal inference (1);;Causal inference (2);;Language, Parsing;;Language - Google search example (1);;Language - Google search example (2);;Language - Google search example (3);;Language, Parsing, Acquisition;;Theory construction in science;;Intuitive theories, Physics (1);;Intuitive theories, Physics (2);;Intuitive theories, Physics (3);;“If you have a mate, and there is a rival, go and peck that rival…”;;Intuitive theories, Physics, Psychology;;Outline;;The big questions;;mlss2010_chater_tenenbaum_csfml_03_Page_27;;mlss2010_chater_tenenbaum_csfml_03_Page_28;;mlss2010_chater_tenenbaum_csfml_03_Page_29;;mlss2010_chater_tenenbaum_csfml_03_Page_30;;mlss2010_chater_tenenbaum_csfml_03_Page_31;;mlss2010_chater_tenenbaum_csfml_03_Page_32;;mlss2010_chater_tenenbaum_csfml_03_Page_33;;mlss2010_chater_tenenbaum_csfml_03_Page_34;;mlss2010_chater_tenenbaum_csfml_03_Page_35;;mlss2010_chater_tenenbaum_csfml_03_Page_36;;mlss2010_chater_tenenbaum_csfml_03_Page_37;;mlss2010_chater_tenenbaum_csfml_03_Page_38;;mlss2010_chater_tenenbaum_csfml_03_Page_39;;mlss2010_chater_tenenbaum_csfml_03_Page_40;;mlss2010_chater_tenenbaum_csfml_03_Page_41;;mlss2010_chater_tenenbaum_csfml_03_Page_42;;mlss2010_chater_tenenbaum_csfml_03_Page_43;;mlss2010_chater_tenenbaum_csfml_03_Page_44;;mlss2010_chater_tenenbaum_csfml_03_Page_45;;mlss2010_chater_tenenbaum_csfml_03_Page_46;;mlss2010_chater_tenenbaum_csfml_03_Page_47;;mlss2010_chater_tenenbaum_csfml_03_Page_48;;mlss2010_chater_tenenbaum_csfml_03_Page_49;;mlss2010_chater_tenenbaum_csfml_03_Page_50;;mlss2010_chater_tenenbaum_csfml_03_Page_51;;mlss2010_chater_tenenbaum_csfml_03_Page_52;;mlss2010_chater_tenenbaum_csfml_03_Page_53;;mlss2010_chater_tenenbaum_csfml_03_Page_54;;mlss2010_chater_tenenbaum_csfml_03_Page_55;;mlss2010_chater_tenenbaum_csfml_03_Page_56;;mlss2010_chater_tenenbaum_csfml_03_Page_57;;mlss2010_chater_tenenbaum_csfml_03_Page_58;;mlss2010_chater_tenenbaum_csfml_03_Page_59;;What is Cognitive Science?;;Pscyhology/CogSci and machine learning: a long-term relationship;;A success story in the 1980s-1990s: The “standard model of learning” (1);;A success story in the 1980s-1990s: The “standard model of learning” (2);;Outline;;The big question;;Visual perception;;Ambiguity in visual perception;;Learning-based machine vision: state of the art;;Learning concepts from examples;;Humans and bumble bees;;Causal inference (1);;Causal inference (2);;Language, Parsing;;Language - google search example (1);;Language - google search example (2);;Language - google search example (3);;Language, Parsing, Acquisition;;Theory construction in science;;Intuitive theories, Physics (1);;Intuitive theories, Physics (2);;Intuitive theories, Physics (3);;“If you have a mate, and there is a rival, go and peck that rival…”;;Intuitive theories, Physics (4);;Outline, How machine learning can help;;The big questions;;Machine learning provides a toolkit for answering these questions;;Basics of Bayesian inference;;Grammar G, Phrase structure S, Utterance U;;“Universal Grammar”, Grammar, Phrase structure, Utterance, Speech signal;;“Universal Grammar”, Grammar, Phrase structure, Surfaces, Image;;Learning word meanings;;Causal learning and reasoning;;Goal-directed action (production and comprehension);;Bayes meets Marr: the Sampling Hypothesis;;Outline;;Five big ideas;;Cognition as probabilistic inference;;Bayesian inference in perceptual and motor systems;;Bayesian ideal observers using natural scene statistics;;Modeling basic cognitive capacities as intuitive Bayesian statistics;;Coin flipping;;Predict a random sequence of coin flips: Mathcamp 2001, 2003;;Mathcamp 2001, 2003 data: collapsed over parity;;Zenith radio data (1930’s): collapsed over parity;;Mathcamp 2001, 2003 data, Zenith radio data (1930’s);;Coin flipping;;Predictive versus inductive reasoning (1);;Predictive versus inductive reasoning (2);;Comparing two hypotheses (1);;Comparing two hypotheses (2);;Comparing two hypotheses (3);;Comparing two hypotheses (4);;Comparing two hypotheses (5);;Comparing two hypotheses (6);;Measuring prior knowledge;;Everyday prediction problems;;Priors P(t - total), Median human judgments;;Learning words for objects'
12620,'tutorial','en',12403,'2010-05-07','2010-06-15','Machine learning for cognitive science 2: Bayesian methods and statistical learning theory',NULL,'Learning with Probabilities;;Outline - 1;;Error Functoins to Probabilities;;Outline - 2;;Probability Review 1;;A Pictoral Definition of Probability;;Different Distributions;;Notational Details;;Normalization;;The Sum Rule;;The Product Rule;;Baye\'s Rule;;Expectations;;Distribution Representation;;Binomial Distribution;;Density;;Continuous Variables;;Manipulating PDFs;;The Gaussian Density - 1;;The Gaussian Density - 2;;Gaussian PDF 1;;Outline - 3;;Sample Based Approximations 1;;Sample Mean vs True Mean;;Outline - 4;;Regression Revisited;;Noise Corrupted Mapping;;Gaussian Likelihood - 1;;Gaussian Likelihood - 2;;Gaussian Likelihood - 3;;Gaussian Likelihood - 4;;Gaussian Likelihood - 5;;Gaussian Likelihood - 6;;Gaussian Likelihood - 7;;Gaussian Likelihood - 8;;Gaussian Likelihood - 9;;Gaussian Likelihood - 10;;Probabilistic Interpretation of the Error Function;;Consistency of Maximum Likelihood;;Outline - 5;;Bayesian Approach;;Note on the Term Bayesian;;Binomial Distribution Revisited - 1;;Binomial Distribution Revisited - 2;;Binomial Distribution Revisited - 3;;Binomial Distribution Revisited - 4;;Binomial Distribution Revisited - 5;;Binomial Distribution Revisited - 6;;Simple Bayesian Inference;;Example System: Robot Location;;Gaussian Noise - 1;;Gaussian Noise - 2;;Gaussian Noise - 3;;Expectation Propagation;;Probit Likelihood;;Classification - 1;;Classification - 2;;Classification - 3;;Classification - 4;;Ordinal Noise Model;;Ordinal Regression - 1;;Ordinal Regression - 2;;Ordinal Regression - 3;;Ordinal Regression - 4;;Outline - 6;;Bayesian Linear Regression;;Marginal Likelihood;;Covariance Functions;;Covariance Samples - 1;;Covariance Samples - 2;;Covariance Samples - 3;;Covariance Samples - 4;;Gaussian Process Regression - 1;;Gaussian Process Regression - 2;;Gaussian Process Regression - 3;;Gaussian Process Regression - 4;;Gaussian Process Regression - 5;;Gaussian Process Regression - 6;;Gaussian Process Regression - 7;;Gaussian Process Regression - 8;;Learning Kernel Parametres - 1;;Learning Kernel Parametres - 2;;Learning Kernel Parametres - 3;;Learning Kernel Parametres - 4;;Learning Kernel Parametres - 5;;Learning Kernel Parametres - 6;;Learning Kernel Parametres - 7;;Learning Kernel Parametres - 8;;Learning Kernel Parametres - 9;;Outline - 7;;Outline - 8;;Mixture of Gaussians 1;;EM Algorithm - 1;;EM Algorithm - 2;;EM Algorithm - 3;;EM Algorithm - 4;;EM Algorithm - 5;;EM for Mixtures of Gaussians;;Netlab Demo;;Variational Inference;;Outline - 9;;Latent Variable Models;;Latent Variable Model - 1;;Linear Dimensionality Reduction;;Latent Variable Model - 2;;Prior in Latent Space;;Marginalization of Latent Variables;;Maximum Likelihood;;Optimum for Mean - 1;;Optimum for Mean - 2;;Optimizing Parametres - 1;;Optimizing Parametres - 2;;Oil Data;;Probabilistic Models Allow for Missing Data - 1;;Probabilistic Models Allow for Missing Data - 2;;Probabilistic Models Allow for Missing Data - 3;;Probabilistic Models Allow for Missing Data - 4;;Factor Analysis;;Conclusions;;References 1;;Learning with Probabilities;;Outline - 1;;Error Functions to Probabilities;;Outline - 2;;Probability Review 1;;A Pictoral Definition of Probability;;Different Distributions;;Notational Details;;Normalization;;The Sum Rule;;The Product Rule;;Baye\'s Rule;;Expectations;;Distribution Representation;;Binomial Distribution - 1;;Binomial Distribution - 2;;Continuous Variables;;Manipulating PDF\'s;;The Gaussian Density - 1;;The Gaussian Density - 2;;Gaussian PDF - 1;;Outline - 3;;Sample Based Approximations 1;;Sample Mean vs True Mean;;Outline - 4;;Regression Revisited;;Noise Corrupted Mapping;;Gaussian Likelihood - 1;;Gaussian Likelihood - 2;;Gaussian Likelihood - 3;;Gaussian Likelihood - 4;;Gaussian Likelihood - 5;;Gaussian Likelihood - 6;;Gaussian Likelihood - 7;;Gaussian Log Likelihood - 1;;Gaussian Log Likelihood - 2;;Gaussian Log Likelihood - 3;;Probabilistic Interpretation of the Error Function;;Consistency of Maximum Likelihood;;Outline - 5;;Bayesian Approach;;Note on the Term Bayesian;;Binomial Distribution Revisited - 1;;Binomial Distribution Revisited - 2;;Binomial Distribution Revisited - 3;;Binomial Distribution Revisited - 4;;Binomial Distribution Revisited - 5;;Binomial Distribution Revisited - 6;;Binomial Distribution Revisited - 7;;Example System: Robot Location;;Gaussian Noise - 1;;Gaussian Noise - 2;;Gaussian Noise - 3;;Expectation Propagation;;Probit Likelihood;;Classification - 1;;Classification - 2;;Classification - 3;;Classification - 4;;Ordinal Noise Model;;Ordinal Regression - 1;;Ordinal Regression - 2;;Ordinal Regression - 3;;Ordinal Regression - 4;;Outline - 6;;Bayesian Linear Regression;;Marginal Likelihood;;Covariance Functions;;Covariance Samples - 1;;Covariance Samples - 2;;Covariance Samples - 3;;Covariance Samples - 4;;Gaussian Process Regression - 1;;Gaussian Process Regression - 2;;Gaussian Process Regression - 3;;Gaussian Process Regression - 4;;Gaussian Process Regression - 5;;Gaussian Process Regression - 6;;Gaussian Process Regression - 7;;Gaussian Process Regression - 8;;Learning Kernel Parametres - 1;;Learning Kernel Parametres - 2;;Learning Kernel Parametres - 3;;Learning Kernel Parametres - 4;;Learning Kernel Parametres - 5;;Learning Kernel Parametres - 6;;Learning Kernel Parametres - 7;;Learning Kernel Parametres - 8;;Learning Kernel Parametres - 9;;Outline - 7;;Outline - 8;;Mixture of Gaussians 1;;EM Algorithm - 1;;EM Algorithm - 2;;EM Algorithm - 3;;EM Algorithm - 4;;EM Algorithm - 5;;EM for Mixtures of Gaussians;;Netlab Demo;;Variational Inference;;Outline - 9;;Latent Variable Models - 1;;Latent Variable Models - 2;;Linear Dimensionality Reduction;;Latent Variable Model;;Prior in Latent Space;;Marginalization of Latent Variables;;Maximum Likelihood;;Optimum for Mean - 1;;Optimum for Mean - 2;;Optimizing Parameters - 1;;Optimizing Parameters - 2;;Oil Data;;Probabilistic Models Allow for Missing Data - 1;;Probabilistic Models Allow for Missing Data - 2;;Probabilistic Models Allow for Missing Data - 3;;Probabilistic Models Allow for Missing Data - 4;;Factor Analysis;;Conclusions;;References ;;Statistical Learning Theory and Kernel Methods;;Statistical Learning Theory;;Example;;Pattern Recognition;;Convergence of Means to Expectations;;Consistency and Uniform Convergence;;The Importance of the Set of Functions;;Restricting the Class of Functions;;Detailed Analysis;;Chernoff\'s Bound - 1;;Chernoff\'s Bound - 2;;Uniform Convergence;;How to Prove a VC Bound;;The Case of Two Functions;;The Union Bound;;Infinite Function Classes;;Symmetrization;;Shattering Coefficient;;Putting Everything Together;;ctd.;;Confidence Intervals;;Discussion;;VC Entropy;;Further PR Capacity Concepts;;Structure of the Growth Function;;VC - Dimension Example;;A Typical Bound for Pattern Recognition;;SRM;;Finding a Good Function Class;;Kernels and Feature Spaces;;Example;;General Product Feature Space;;The Kernel Trick - 1;;The Kernel Trick - 2;;Mercer\'s Theorem;;The Mercer Feature Map;;The Kernel Trick - 3;;positive Definite Kernels;;Elementary Properties of PD Kernels;;The Feature Space for PD Kernels;;Turn it into a Linear Space;;Endow it With a Dot Product - 1;;The Reproducing Kernel Property;;Endow it With a Dot Product - 2;;An Example of a Kernel Algorithm - 1;;An Example of a Kernel Algorithm - 2;;An Example of a Kernel Algorithm - 3;;An Example of a Kernel Algorithm - 4;;When do the means coincide?;;Proposotion 2;;Proof - 1;;The mean map;;Witness function;;The map for measures;;Theorem 3;;Theorem 4;;Fourier Criterion;;Fourier Optics;;Uniform convergence bounds;;Application 1 - 1;;Application 1 - 2;;Application 2 - 1;;Application 2 - 2;;Application 2 - 3;;The Representer Theorem;;Remarks;;Proof - 2;;Proof - 3;;Application: Support Vector Classification;;Further Applications;;Conclusion;;Kernel PCA - 1;;Kernel PCA - 2;;Kernel PCA - 3;;Feature extradiction;;The Kernel PCA Map;;Toy Example with Gaussian Kernel;;Super - Resolution;;Support Vector Classifiers;;Separating Hyperplane;;Optimal Separating Hyperplane;;Eliminating the Scaling Freedom;;Canonical Optimal Hyperplane;;Formulation as an Optimization Problem;;Lagrange Function;;Derivation of the Dual Problem;;The Support Vector Expansion;;Why it is Good to Have Few SV\'s;;A Mechanical Interpretation;;Dual Problem;;The SVM Architecture;;Toy Example with Gaussian Kernel;;Nonseparable Problems;;Soft Margin SVMs;;The μ - Property;;Duals, Using Kernels;;Connection between μ - SVC and C - SVC;;SVM Training;;MNIST Benchmark;;MNIST Error Rates;;References - 1;;References - 2;;References - 3;;References - 4;;Regularization Interpretation of Kernel Machines - 1;;Regularization Interpretation of Kernel Machines - 2;;Statistical Learning Theory and Kernel Methods;;Statistical Learning Theory;;Example: Regression Estimation;;Pattern Recognition;;Convergence of Means to Expectations;;Consistency and Uniform Convergence;;The Importance of the Set of Functions;;Restricting the Class of Functions;;Detailed Analysis;;Chernoff\'s Bound - 1;;Chernoff\'s Bound - 2;;Uniform Convergence;;How to Prove a VC Bound;;The Case of Two Functions;;The Union Bound;;Infinite Function Classes;;Symmetrization;;Shattering Coefficient;;Putting Everything Together;;ctd.;;Confidence Intervals;;Discussion;;VC Entropy;;Further PR Capacity Concepts;;Structure of the Growth Function;;VC - Dimension: Example;;A Typical Bound for Pattern Recognition;;SRM;;Finding a Good Function Class;;Kernels and Feature Spaces;;Example: All Degree 2 Monomials;;General Product Feature Space;;The Kernel Trick - 1;;The Kernel Trick - 2;;Mercer\'s Theorem;;The Mercer Feature Map;;The Kernel Trick - 3;;Positive Definite Kernels;;Elementary Properties of PD Kernels;;The Feature Space for PD Kernels;;Turn Into A Linear Space ;;Endow it with a Dot Product - 1;;The Reproducing Kernel Property;;Endow it with a Dot Product - 2;;An Example of a Kernel Algorithm - 1;;An Example of a Kernel Algorithm - 2;;An Example of a Kernel Algorithm - 3;;An Example of a Kernel Algorithm - 4;;When do the means coincide?;;Proposition 2;;Proof - 1;;The mean map;;Witness function;;The mean map for measures;;Theorem 3;;Theorem 4;;Fourier Criterion;;Fourier Optics;;Uniform convergence bounds;;Application 1 - 1;;Application 1 - 2;;Application 2 - 1;;Application 2 - 2;;Application 2 - 3;;The Representer Theorem;;Remarks;;Proof - 2;;Proof - 3;;Application: Support Vector Classification;;Further Applications;;Conclusion;;Kernel PCA - 1;;Kernel PCA - 2;;Kernel PCA in Dual Variables;;Feature extraction;;The Kernel PCA Map;;Toy Example with Gaussian Kernel;;Super - Resolution;;Support Vector Classifiers;;Separating Hyperplane;;Optimal Separating Hyperplane;;Eliminating the Scaling Freedom;;Canonical Optimal Hyperplane;;Formulation as an Optimization Problem;;Lagrange Function;;Derivation of the Dual Problem;;The Support Vector Expansion;;Why it is Good to Have Few SV\'s;;A Mechanical Interpretation;;Dual Problem;;The SVM Architecture;;Toy Example with Gaussian Kernel;;Nonseparable Problems;;Soft Margin SVM\'s;;The μ - Property;;Duals, Using Kernels;;Connection between μ - SVC and C - SVC;;SVM Training;;MNIST Benchmark;;MNIST Error Rates;;References - 1;;References - 2;;References - 3;;References - 4;;Regularization Interpretation of Kernel Machines - 1;;Regularization Interpretation of Kernel Machines - 2'
12621,'tutorial','en',12403,'2010-05-07','2010-06-15','Cognitive science for machine learning 2: Empirical methods',NULL,'Cognitive science for machine learning 2: Empirical Methods;;Overview;;Observations and Experiments;;The Contrast;;Example: Human category learning;;Categories are defined by different types of dimension;;But for substances... - 1;;But for substances... - 2;;A Bayesian approach;;Now compare with experiments ...;;... and conduct new experiments;;The qualitative observations that people routinely ...;;Inferring causality from observation;;Inferring agency from observation;;Inferring communicative intentions from observation - 1;;Inferring communicative intentions from observation - 2;;Inferring communicative intentions from observation - 3;;Inferring communicative intentions from observation - 4;;Inferring communicative intentions from observation - 5;;Common knowledge is crucial - 1;;Common knowledge is crucial - 2;;Common knowledge is crucial - 3;;Common knowledge is crucial - 4;;The study of vision is heavily based on observations, not merely experiments;;A 3D variation...;;Note the difference...;;Observations may suggest general principles;;If so, can only share information wihin a single object - 1;;If so, can only share information wihin a single object - 2;;The patterns in language;;Displaying the structure;;Semantic categories;;Analysis of the structure of the environment;;Observations;;The spectrum of experimental methods;;Simple psychopysics-detection - 1;;Simple psychopysics-detection - 2;;From responses to reaction times - 1;;From responses to reaction times - 2;;From responses to reaction times - 3;;From responses to reaction times - 4;;From responses to reaction times - 5;;From responses to reaction times - 6;;Incidental variables;;And we may measure the brain, not just the eye...;;And we may wonder where in the brain;;Imaging technologies provide another role for machine learning;;Machine learning can help;;Can you play 20 questions with nature and win?;;Experimental psychology and the search for binary divisions;;But experimental psychology can never succeed alone;;But we need 20 uestions nonetheless;;Cognitive science for machine learning 2: Empirical Methods;;Overview;;Observations and experiments;;The contrast;;Example: Human category learning;;Categories are defined by different types of dimension;;But for substances... - 1;;But for substances... - 2;;A Bayesian approach;;Now compare with experiments... ;;...and conduct new experiments;;The qualitative observations that people routinely...;;Inferring causality from observation;;Inferring agency from observation;;Inferring communicative intentions from observation - 1;;Inferring communicative intentions from observation - 2;;Inferring communicative intentions from observation - 3;;Inferring communicative intentions from observation - 4;;Inferring communicative intentions from observation - 5;;Common knowledge is crucial - 1;;Common knowledge is crucial - 2;;Common knowledge is crucial - 3;;Common knowledge is crucial - 4;;The study of vision is heavily based on observations, not merely experiments;;A 3D variation...;;Note the difference...;;Observations may suggest general principles;;If so, can only share information within a single object - 1;;If so, can only share information within a single object - 2;;The patterns in language;;Displaying the structure;;Semantic categories;;Analysis of the structure of the environment;;Observations;;The spectrum of experimental methods;;Simple psychophysics-detection - 1;;Simple psychophysics-detection - 2;;From responses to reaction times - 1;;From responses to reaction times - 2;;From responses to reaction times - 3;;From responses to reaction times - 4;;From responses to reaction times - 5;;From responses to reaction times - 6;;Incidental variables;;And we may measure the brain, not just the eye...;;And we may wonder where in the brain;;Imaging technologies provide another role for machine learning;;Machine learning can help;;Can you play 20 questions with mother nature and win?;;Experimental psychology and the search for binary divisions;;But experimental psychology can never succeed alone;;But we need 20 questions nonetheless;;Cognitive Science for Machine Learning 2;;The Experimental Method - 1;;The Experimental Method - 2;;The Experimental Method - 3;;The Experimental Method - 4;;The Experimental Method - 5;;The Experimental Method - 6;;The Experimental Method - 7;;The Experimental Method - 8;;The Experimental Method - 9;;The Experimental Method - 10;;Psychophysical Method;;Traditional Psychophysical Methods;;Modern Psychophysical Methods;;Forced-choice staircases with fixed step sizes: asymptotic and small-sample properties;;and furthermore ...;;Standard Three-Step Routine in Modelling Data;;Definitions and Notation - 1;;Definitions and Notation - 2;;Definitions and Notation - 3;;Parameter Estimation - 1;;Parameter Estimation - 2;;Parameter Estimation - 3;;Parameter Estimation - 4;;Parameter Estimation - Third Source of Error: Lapses ;;Parameter Estimation - 5;;Parameter Estimation - 6;;Statistical Considerations;;Goodness-of-fit - 1;;Goodness-of-fit - 2;;Goodness-of-fit - 3;;Goodness-of-fit - 4;;Goodness-of-fit - 5;;Goodness-of-fit - 6;;Estimates of Variability - the way of Bayes ...;;... or the Traditional Way;;Literature on Psychometric Methods - 1;;The House of Blackwell;;Literature on Psychometric Methods - 2;;Essentials of Psychometric Methods ;;Signal Detection Theory;;Psychological science can improve diagnostic decision;;Binary World;;Decision Theory Applied to Perception & Cognition;;Detection, Estimation and Modulation Theory - 1;;Detection, Estimation and Modulation Theory - 2;;Detection, Estimation and Modulation Theory - 3;;Appeals of SDT;;Forced - Choice Procedures - 1;;Forced - Choice Procedures - 2;;Forced - Choice Procedures - 3;;Forced - Choice Procedures - 4;;Forced - Choice Procedures - 5;;Forced - Choice Procedures - 6;;Forced - Choice Procedures - 7;;Forced - Choice Procedures - 8;;Forced - Choice Procedures - 9;;Forced - Choice Procedures - 10;;Forced - Choice Procedures - 11;;Forced - Choice Procedures;;Interval - Bias in 2AFC;;Data from Naive Observers - 1;;Data from Naive Observers - 2;;Literature on Signal Detection Theory;;Essential Practical Implications of SDT;;Response Times;;History, Terminology & Major Findings;;Influences on RTs;;Diffusion Model - Basics;;Diffusion Model - Behaviour;;Slow Errors - Drift Variability;;Fast Errors - Starting Point Variability;;Diffusion Models - Predictions;;Literature on Response Times;;Epilog;;Thank you very much;;Cognitive Science for Machine Learning 2;;The Experimental Method - 1;;The Experimental Method - 2;;The Experimental Method - 3;;The Experimental Method - 4;;The Experimental Method - 5;;The Experimental Method - 6;;The Experimental Method - 7;;The Experimental Method - 8;;The Experimental Method - 9;;The Experimental Method - 10;;Psychophysical Methods;;Traditional Psychophysical Methods;;Modern Psychophysical Methods;;Forced - choice staircases with fixed sizes: asymptotic and small - sample properties;;and furthermore;;Standard Three - Step Routine in Modeling Data;;Definitions and Notation - 1;;Definitions and Notation - 2;;Definitions and Notation - 3;;Parameter Estimation - 1;;Parameter Estimation - 2;;Parameter Estimation - 3;;Parameter Estimation - 4;;Parameter Estimation - Third Source of Error: Lapses;;Parameter Estimation - 5;;Parameter Estimation - 6;;Statistical Considerations;;Goodness-of-fit - 1;;Goodness-of-fit - 2;;Goodness-of-fit - 3;;Goodness-of-fit - 4;;Goodness-of-fit - 5;;Goodness-of-fit - 6;;Estimates of Variability - The Way of Bayes ...;;... or the Traditional Way;;Literature on Psychometric Methods - 1;;The House of Blackwell;;Literature on Psychometric Methods - 2;;Essentials of Psychometric Methods;;Signal Detection Theory;;Psychological science can improve diagnostic decisions;;Binary World;;Decision Theory Applied to Perception & Cognition;;Detection, Estimation and Modulation Theory - 1;;Detection, Estimation and Modulation Theory - 2;;Detection, Estimation and Modulation Theory - 3;;Appeals of SDT;;Forced - Choice Procedures - 1;;Forced - Choice Procedures - 2;;Forced - Choice Procedures - 3;;Forced - Choice Procedures - 4;;Forced - Choice Procedures - 5;;Forced - Choice Procedures - 6;;Forced - Choice Procedures - 7;;Forced - Choice Procedures - 8;;Forced - Choice Procedures - 9;;Forced - Choice Procedures - 10;;Forced - Choice Procedures - 11;;Forced - Choice Procedures - 12;;Interval - Bias in 2AFC;;Data from Naive Observers - 1;;Data from Naive Observers - 2;;Literature on Signal Detection Theory;;Essential Practical Implications of SDT;;Response Times;;History, Terminology & Major Findings;;Influence on RTs;;Diffusion Model - Basics;;Diffusion Model - Behaviour;;Slow Errors - Drft Variability;;Fast Errors - Starting Point Variability;;Diffusion Models - Predictions;;Literature on Response Times;;Epilog;;Thank you very much'
12622,'tutorial','en',12403,'2010-05-08','2010-06-15','Machine learning for cognitive science 3: Kernel methods and Bayesian methods',NULL,'Introduction to Graphical Models;;Motivation - 1;;Motivation - 2;;Bayes Rule and Independece;;Basic Graph Definitions - 1;;Basic Graph Definitions - 2;;Belief Networks (Bayesian Networks);;Example Part 1 - 1;;Example Part 1 - 2;;Example Part 1 - 3;;Example Part 1 - 4;;Example- Part 2: Specifying the Tables;;Example Part 3: Inference;;Independence ╨ in Belief Networks - Part 1;;Independence ╨ in Belief Networks - Part 2;;Collider - 1;;Collider - 2;;General Rule for Independence in Belief Networks;;Example of using teh Independence Rule for Time - Series Modeling - 1;;Example of using teh Independence Rule for Time - Series Modeling - 2;;Example of using teh Independence Rule for Time - Series Modeling - 3;;Markov Network;;Example Application of MArkov Network - 1;;Example Application of MArkov Network - 2;;Independence ╨ in Markov Networks;;General Rule for Independence in Markov Networks;;Alternative Rule for Independence in Belief Networks - 1;;Alternative Rule for Independence in Belief Networks - 2;;Alternative Rule for Independence in Belief Networks - 3;;Expressiveness of Belief and Markov Networks;;Factor Graphs;;Inference - 1;;Inference - 2;;Sum- Product Algorithm for Factor Graphs - Non Branching Tree - 1;;Sum- Product Algorithm for Factor Graphs - Non Branching Tree - 2;;Sum- Product Algorithm for Factor Graphs - Non Branching Tree - 3;;Sum- Product Algorithm for Factor Graphs - Non Branching Tree - 4;;Sum- Product Algorithm for Factor Graphs - Non Branching Tree - 5;;Sum- Product Algorithm for Factor Graphs - Non Branching Tree - 6;;Sum - Procuct Algorithm for Factor Graphs;;Inference in Hidden Markov Models (HMM) - Part 1;;Inference in Hidden Markov Models - Part 2;;Localisation Example - Part 1;;Localisation Example - Part 2;;Localisation Example - Part 3;;Natural Language Model Example - Part 1;;Natural Language Model Example - Part 2;;Learning;;Summarising the Parameter Posterior;;Naive Bayes Classifier;;Naive Bayes: Learning;;Naive Bayes: Maximum Likelihood;;Naive Bayes: Bayesian Approach;;Learning in Markov Networks: Maximum Likelihood;;Learning Parameters with Hidden Variables;;Expectation Maximisation Algorithm for Maximum Likelihood;;Reading;;Appendix;;Statistical Learning Theory and Kernel Methods;;Statistical Learning Theory;;Example: Regression Estimation;;Pattern Recognition;;Convergence of Means to Expectations;;Consistency and Uniform Convergence;;The Importance of the Set of Functions;;Restricting the Class of Functions;;Detailed Analysis;;Chernoff\'s Bound - 1;;Chernoff\'s Bound - 2;;Uniform Convergence;;How to Prove a VC Bound;;The Case of Two Functions;;The Union Bound;;Infinite Function Classes;;Symmetrization;;Shattering Coefficient;;Putting Everything Together;;ctd.;;Confidence Intervals;;Discussion;;VC Entropy;;Further PR Capacity Concepts;;Structure of the Growth Function;;VC - Dimension: Example;;A Typical Bound for Pattern Recognition;;SRM;;Finding a Good Function Class;;Kernels and Feature Spaces;;Example: All Degree 2 Monomials;;General Product Feature Space;;The Kernel Trick - 1;;The Kernel Trick - 2;;Mercer\'s Theorem;;The Mercer Feature Map;;The Kernel Trick - 3;;Positive Definite Kernels;;Elementary Properties of PD Kernels;;The Feature Space for PD Kernels;;Turn it Into a Linear Space;;Endow it With a Dot Product - 1;;The Reproducing Kernel Property;;Endow it With a Dot Product - 2;;An Example of a Kernel Algorithm - 1;;An Example of a Kernel Algorithm - 2;;An Example of a Kernel Algorithm - 3;;An Example of a Kernel Algorithm - 4;;When do the means coincide?;;Proposition 2;;Proof - 1;;The mean map;;Witness functions;;The mean map for measures;;Theorem 3;;Theorem 4;;Fourier Criterion;;Fourier Optics;;Uniform convergence bounds;;Application 1 - 1;;Application 1 - 2;;Application 2 - 1;;Application 2 - 2;;Application 2 - 3;;The Representer Theorem;;Remarks;;Proof - 2;;Proof - 3;;Application: Support Vector Classification;;Further Applications;;Conclusion;;Kernel PCA - 1;;Kernel PCA - 2;;Kernel PCA - 3;;Feature extraction;;The Kernel PCA Map;;Toy Example with Gaussian Kernel;;Super - Resolution;;Suppert Vector Classifiers;;Separating Hyperplane;;Optimal Separating Hyperplane;;Eliminating the Scaling Freedom;;Canonical Optimal Hyperplane;;Formulation as an Optimization Problem;;Lagrange Function;;Derivate of the Dual Problem;;The Support Vector Expansion;;Why it is Good to Have Few SV\'s;;A Mechanical Interpretation;;Dual Problem;;The SVM Architecture;;Toy Example with Gaussian Kernel;;Nonseparable Problems;;Soft Margin SVM\'s;;The μ - Property;;Duals, Using Kernels;;Connection between μ - SVC and C - SVC;;SVM Training;;MNIST Benchmark;;MNIST Error Rates;;Reference - 1;;Reference - 2;;Reference - 3;;Reference - 4;;Regularization Interpretation of Kernel Machines - 1;;Regularization Interpretation of Kernel Machines - 2;;Statitical Learning Theory and Kernel Methods;;Statistical Learning Theory;;Example: Regression Estimation;;Pattern Recognition;;Convergence of Means to Expectations;;Consistency and Uniform Convergence;;The Importance of the Set of Functions;;Restricting the Class of Functions;;Detailed Analysis;;Chernoff\'s Bound - 1;;Chernoff\'s Bound - 2;;Uniform Convergence ;;How to Prove a VC Bound;;The Case of Two Functions;;The Union Bound;;Infinite Functions Classes;;Symmetrization;;Shattering Coefficient;;Putting Everything Together;;ctd.;;Confidence Intervals;;Discussion;;VC Entropy;;Further PR Capacity Concepts;;Structure of the Growth Function;;VC - Dimension ;;A Typical Bound for Pattern Recognition;;SRM;;Finding a Good Function Class;;Kernels and Feature Spaces;;Example;;General Product Feature Space;;The Kernel Trick - 1;;The Kernel Trick - 2;;Mercer\'s Theorem;;The Mercer Feature Map;;The Kernel trick - 3;;Positive Definite Kernels;;Elementary Properties of PD Kernels;;The Feature space for PD Kernels;;Turn it Into a Linear Space;;Endow it With a Dot Product - 1;;The Reproducing Kernel Property;;Endow it With a Dot Product - 2;;An Example of a Kernel Algorithm - 1;;An Example of a Kernel Algorithm - 2;;An Example of a Kernel Algorithm - 3;;An Example of a Kernel Algorithm - 4;;When do the means coincide?;;Proposition 2;;Proof - 1;;The mean map;;Witness function;;The mean map for measures;;Theorem 3;;Theorem 4;;Fourier Criterion;;Fourier Optics;;Uniform convergence bounds;;Application 1 - 1;;Application 1 - 2;;Application 2 - 1;;Application 2 - 2;;Application 2 - 3;;The Representer Theorem;;Remarks;;Proof - 2;;Proof - 3;;Application: Support Vector Classification;;Further Applications;;Conclusion;;Kernel PCA - 1;;Kernel PCA - 2;;Kernel PCA in Dual Variables;;Feature extraction;;The Kernel PCA Map;;Toy Example with Gaussian Kernel;;Super - Resolution;;Support Vector Classifiers;;Separating Hyperplane;;Optimal Separating Hyperplane;;Eliminating the Scaling Freedom;;Canonical Optimal Hyperplane;;Formulation as an Optimization Problem;;Lagrange Function;;Derivation of the Dual Problem;;The Support Vector Expansion;;Why it is Good to Have Few SV\'s;;A Mechanical Interpretation;;Dual Problem;;The SVM Architecture;;Toy Example with Gaussian Kernel;;Nonseparable Problems;;Soft Margin SVMs;;The μ - Property;;Duals, Using Kernels;;Connection between μ - SVC and C - SVC;;SVM Training;;MNIST Benchmark;;MNIST Error Rates;;References - 1;;References - 2;;References - 3;;References - 4;;Regularization Interpretation of Kernel Machines - 1;;Regularization Interpretation of Kernel Machines - 2'
12623,'tutorial','en',12403,'2010-05-08','2010-06-15','Cognitive science for machine learning 3: Models and theories in cognitive science',NULL,'Models and theories in cognitive science;;Marr\'s three levels;;Marr on the computational level;;Questions - 1;;Questions - 2;;An approach to analyzing cognition;;Questions - 3;;A theory of induction;;Questions - 4;;Results of computational level analysis - 1;;Human learning, Machine learning - 1;;Human learning, Machine learning - 2;;Results of computational level analysis - 2;;The importance of inductive biases;;Identifying inductive biases;;Results of computational level analysis - 3;;Human learning, Machine learning - 3;;Human learning, Machine learning - 4;;Human learning, Machine learning - 5;;Currie (1798);;Does the treatment cause recovery?;;Does C cause E?;;Two models of causal judgement - 1;;Two models of causal judgement - 2;;Buehner and Cheng (1997) - 1;;Buehner and Cheng (1997) - 2;;Buehner and Cheng (1997) - 3;;Buehner and Cheng (1997) - 4;;Human learning, Machine learning - 6;;Causal graphical models - 1;;Causal graphical models - 2;;Causal graphical models - 3;;Causal graphical models - 4;;Conditional probabilities;;Causal learning - 1;;Causal learning - 2;;Causal learning - 3;;Bayesian Occam\'s Razor - 1;;Bayesian Occam\'s Razor - 2;;Bayesian Occam\'s Razor - 3;;Buehner and Cheng (1997) - 5;;Assumptions guiding inference;;Conditional probabilities;;Assumptions guiding inference;;The blicket detector;;\"Backwards blocking\";;Bayesian inference - 1;;Bayesian inference - 2;;Two key assumptions;;Modeling backwards blocking - 1;;Modeling backwards blocking - 2;;Modeling backwards blocking - 3;;Manipulating the prior - 1;;Manipulating the prior - 2;;Manipulating the prior - 3;;Theory - based causal induction;;Learning causal theories - 1;;Learning causal theories - 2;;The blicketosity meter - 1;;The blicketosity meter - 2;;The blicketosity meter - 3;;Learning functional form;;Results;;Learning an ontology;;Nonparametric Block Model (NBM);;Causal learning without a theory;;Causal learning with a (NBM) theory;;The \"blessing of abstraction\";;Human learning, Machine learning - 7;;Causal learning and graphical models;;Blank page;;Models and theories in cognitive science;;Marr\'s three levels;;Marr on the computational level;;Questions - 1;;Questions - 2;;An approach to analyzing cognition;;Questions - 3;;A theory of induction;;Questions - 4;;Results of computational level analysis ;;Human learning, Machine learning - 1;;Human learning, Machine learning - 2;;Results of computational level analysis - 1;;The importance of inductive biases;;Identifying inductive biases;;Results of computational level analysis - 2;;Human learning, Machine learning - 3;;Human learning, Machine learning - 4;;Human learning, Machine learning - 5;;Curie (1798);;Does the treatment cause recovery?;;Does C cause E?;;Two models of causal judgment - 1;;Two models of causal judgment - 2;;Buehner and Cheng (1997) - 1;;Buehner and Cheng (1997) - 2;;Buehner and Cheng (1997) - 3;;Buehner and Cheng (1997) - 4;;Human learning, Machine learning - 6;;Causal graphic models - 1;;Causal graphic models - 2;;Causal graphic models - 3;;Causal graphic models - 4;;Conditional probabilities;;Causal learning - 1;;Causal learning - 2;;Causal learning - 3;;Bayesian Occam\'s Razor - 1;;Bayesian Occam\'s Razor - 2;;Bayesian Occam\'s Razor - 3;;Buehner and Cheng (1997) - 5;;Assumptions guiding inference - 1;;Conditional probabilities;;Assumptions guiding inference - 2;;The blicket detector;;\"Backwards blocking\";;Bayesian inference - 1;;Bayesian inference - 2;;Two key assumptions;;Modeling backwards blocking - 1;;Modeling backwards blocking - 2;;Modeling backwards blocking - 3;;Manipulating the prior - 1;;Manipulating the prior - 2;;Manipulating the prior - 3;;Theory - based causal induction;;Learning causal theories - 1;;Learning causal theories - 2;;The blicketosity meter - 1;;The blicketosity meter - 2;;The blicketosity meter - 3;;Learning functional form;;Results;;Learning an ontology;;Nonparametric Block Model (NBM) - 1;;Nonparametric Block Model (NBM) - 2;;Nonparametric Block Model (NBM) - 3;;The \"blessing of abstraction\";;Human learning, Machine learning - 7;;Causal learning and graphical models;;Blank page;;Cognitive science for machine learning 3: Models and theories in cognitive science;;Overview;;1. Fragmentation in cognitive science;;Fragmentation rather than integration ...;;Machine learning and AI as an integrating force;;Reintegrating cognitive science;;Candidate questions and principles;;2. Scaling and coding;;Scale - invariance;;The ubiquity of scale - invariance - 1;;The ubiquity of scale - invariance - 2;;Scale invariance in the visual environment, and sensory systems;;From scale - invariance to psychological \"Laws\";;Weber\'s law;;Serial position in immediate free recall;;Memory retrieval over different time periods in retrospective memory;;And prospective memory;;Time - invariance of animal and human learning;;Implications;;2. Scaling and coding;;No absolute coding of magnitudes;;No stable ratio judgements;;Prospect relativity;;Predictions;;Choices strongly influenced by range of options available;;No underlying scales → no integration;;3. Inference;;The simplicity principle;;Simplicity as \"ideal\" inductive method;;Simplicity has broad scope;;Observations may suggest general principles;;Long tradition of simplicity in perception;;3. Inference;;How much of cognition is reversible?;;Evidence - 1;;Evidence - 2;;Explanation?;;Similarity for language;;And generative vs discriminative instructions may change people\'s categorizations;;4. Architecture;;Modularity of mind vs. unified single system?;;Conversely, \"central\" processes cannot be isolated ...;;Modularity is theoretically central;;How much can high - level information affect perception?;;Dallenbach\'s cow;;But manny aspects of vision are not cognitively penetrable;;Focus on learning;;Classical conditioning in computational terms;;Reminder: Kamin blocking: Training phase 1;;Reminder: Kamin blocking: Training phase 2;;Are expectations really a product of general cognition?;;So two different views of conflict, addiction, weakness of will;;3. Summary and Implications;;Aim: A principle - based approach to reverse engineering cognition - 1;;Aim: A principle - based approach to reverse engineering cognition - 2'
12624,'lecture','en',12403,'2010-05-08','2010-06-15','Computational models of vision',NULL,NULL
12625,'lecture','en',12403,'2010-05-09','2010-06-15','Kernel Methods and Perceptual Classification',NULL,'Kernel Methods and Perceptual Classification;;Picture - 1;;Picture - 2;;Picture - 3;;Picture - 4;;Picture - 5;;Picture - 6;;Picture - 7;;Picture - 8;;Picture - 9;;Picture - 10;;Picture - 11;;Picture - 12;;Picture - 13;;Picture - 14;;Picture - 15;;How many animals?;;Animal detection in natural scenes;;Critical Features: System Identification;;Gender Categorization of Human Faces;;Linear Decision Rules - 1;;Linear Decision Rules - 2;;Linear Decision Rules - 3;;Psychometric Function Along LogReg ;;Psychometric Function Along Prototype;;Summary Statistics across Observers;;How Good is the Prediction?;;Predictability and Reaction Times;;The Decision Images;;Evaluating Decision Images with Optimized Stimuli - 1;;Evaluating Decision Images with Optimized Stimuli - 2;;Interim Conclusions - 1;;Scientific Question;;Previous Work - 1;;Previous Work - 2;;Previous Work - 3;;Saliency Maps;;Machine Learning Approach;;Data Representation;;Background Examples;;Machine Learning Method - 1;;Machine Learning Method - 2;;Radial - Basis - Function Support Vector Machine (RBF - SVM);;RBF - SVM after Optimization (\"Learning\");;Randomly Selected vs. Fixated Image Patches;;Randomly Selected vs. Fixated Image Patches: PCA Basis;;Randomly Selected vs. Fixated Image Patches: ICA Basis;;Patches - 1;;Patches - 2;;Patches - 3;;Patches - 4;;Patches - 5;;Non - linear Decision Image Network for Visual Saliency;;Critical Control 1: Ground Truth Test;;Critical Control 2: Generalization to Novel Data Set;;Interim Conclusions - 2;;Literature (Heavily Biased Sample);;Tone - in - Noise Detection;;Synthetic Observers;;Observer Reconstruction;;Observer Reconstruction Continued;;Classifier performance - 1;;Classifier performance - 2;;Classifier performance - 3;;Thank you verry much'
12626,'lecture','en',12403,'2010-05-09','2010-06-15','Bayesian modeling of action and perception and some other stuff',NULL,'Bayesian modeling of action and perception and some other stuff;;Part 1: Cue Cimbination;;Modeling: Where do some cues come from?;;Optimal behaviour;;Comparison to predicted behavior;;Experimental test;;Results;;Visual Auditory combination - 1;;Traditional Bayesian model;;Visual Auditory combination - 2;;What would happen now?;;Mixture model;;p (causal model);;Independent causes: where is the auditory stimulus;;Common cause: where is the auditory stimulus;;Mean squared error estimate;;Experimental test;;Measured gain;;How can the gain be negative?;;Predicting the variance;;Same question in motor learning;;Typical behavior;;Causal inference in motor adaptation;;The essence of causal inference;;Similar problem in depth perception: structure inference;;Basic idea;;Induced likelihoods;;Two levels of uncertainty;;Effect of structure knowledge;;Nakayama et al 1990;;Effects of structure inference;;The essence of structure inference;;Part 2: Estimation for movement;;Adaptation ~ estimation;;Ambiguity - 1;;Ambiguity - 2;;Computational approaches: \"Internal models\";;Resolving ambiguity;;Simulating trajectories;;Influences on trajectories;;Assuming changes over time;;Force field learning;;Shadmehr and Mussa Ivaldi 1994;;Criscimagna Hemminger et al 2003;;Dizio and Lackner 1995;;Wang and Sainburg 2004;;Asymmetry of transfer;;Motor Adaptation: Why;;Take home message'
12627,'lecture','en',12403,'2010-05-09','2010-06-15','Inferring structure from data',NULL,'Inferring structure from data;;Human learning, Machine learning;;How much structure exists?;;Nonparametric Bayesian statistics;;Categorization;;Prototypes;;Exemplars;;Something in between - 1;;A computational problem;;Density estimation;;Parametric density estimation;;Nonparametric densiy estimation;;Something in between - 2;;Anderson\'s rational model;;The Chinese restaurant process;;Dirichlet process mixture model;;A unifying rational model;;The hierarchical Dirichlet process;;A unifying rational model;;HDP+,∞ and Smith & Minda (1998) - 1;;HDP+,∞ and Smith & Minda (1998) - 2;;the promise of HDP +,+;;Other uses of Dirichlet processes;;Learning the features of objects - 1;;Learning the features of objects - 2;;Learning the features of objects - 3;;Binary matrix factorization - 1;;Binary matrix factorization - 2;;The nonparametric approach;;The Indian buffet process - 1;;The Indian buffet process - 2;;Austerweil & Griffiths;;An experiment ...;;Results;;Other uses of the IBP;;Nonparametric Bayes and the mind;;Blank page - 1;;Learning language;;An artificial language;;Discriminative Logistic regression vs. Generative Hierarchical Bayesian model;;Model Predictions;;Condition 1: Generative learning - 1;;Condition 1: Generative learning - 2;;Condition 1: Generative learning - 3;;Condition 1: Generative learning - 4;;Condition 1: Generative learning - 5;;Condition 1: Generative learning - 6;;Condition 1: Generative learning - 7;;Condition 1: Generative learning - 8;;Condition 1: Generative learning - 9;;Condition 1: Generative learning - 10;;Condition 1: Generative learning - 11;;Condition 1: Generative learning - 12;;Condition 2: Discriminative learning - 1;;Condition 2: Discriminative learning - 2;;Condition 2: Discriminative learning - 3;;Human language learning;;Blank page - 2'
12628,'lecture','en',12403,'2010-05-09','2010-06-29','Finding structure in data',NULL,'Finding structure in data;;The big question;;The approach;;Property induction;;Hierarchical Bayesian Framework;;Experiments on property induction;;Feature rating data;;The computational problem;;Similarity-based induction;;Beyond similarity-based induction;;Hierarchical Bayesian Framework;;Horses have T9 hormones- Rhinos have T9 hormones: Hypotheses h;;Horses have T9 hormones- Rhinos have T9 hormones - Prediction P(Y | X) ;;Where does the prior come from?;;The need for inductive bias;;Theory-based priors;;P(h): Taxonomic similarity (1);;P(h): Taxonomic similarity (2);;A graph-based prior;;Results (1);;Results (2);;Hierarchical Bayesian Framework;;Structure S, Data D, Features;;Structure S ;;Structure S, features f, New property;;Hierarchical Bayesian Framework;;Best Cluster Structure(DP mixture);;Cows have property P, Elephants have property P (cluster, tree);;Results with DP mixture model;;Hierarchical Bayesian Framework;;Hierarchical Bayesian Framework - form;;Cows have property P, Elephants have property P (2D, Tree);;Reasoning about spatially varying properties;;Do people learn explicit structures of different forms? (1);;Do people learn explicit structures of different forms? (2);;Property type,Theory Structure, Properties ;;Reasoning with linear-threshold properties;;Reasoning with two property ypes;;Summary so far;;Hierarchical Bayesian framework;;Learning structural forms;;Goal: A universal framework for unsupervised learning;;Hypothesis space of structural forms;;Node-replacement graph grammars (1);;Node-replacement graph grammars (2);;Node-replacement graph grammars (3);;A hierarchical Bayesian approach;;features, animals, cases, judges;;judges, objects, similarities;;How many different ways to structure a domain? (1);;How many different ways to structure a domain? (2);;How many different ways to structure a domain? (3);;Conclusions'
12629,'lecture','en',12403,'2010-05-10','2010-06-15','Language acquisition and Kolmogorov complexity: Why is language acquisition possible',NULL,'Language acquisition and Kolmogorov complexity: Why is language acquisition possible?;;Colaborators;;Overview;;1. Brain adapted for language?;;Could brain be adapted for language?;;A language - specific faculty implies the brain is adapted for language, just as for vision - 1;;A language - specific faculty implies the brain is adapted for language, just as for vision - 2;;But perhaps language and tha language faculty co - evolved via the Baldwin effect;;The Baldwin effect;;The Baldwin effect in action;;But co - evolution pequires genetic adaptation to a varying language;;Same speed for language and genetic mutation rate;;Languages changes twice as fast;;Languages changes 10 times as fast;;Genes cannot catch a linguistic \"moving target\";;Diverging human populations;;Once populations are split, co - evolution will be specific to the local linguistic environment;;Case 1: Laguage change is fast;;Case 2: Language change is slow;;Is language shaped by the brain?;;Two problems of induction;;So language emerges from interacting constraints ... ;;Language is optimised to these factors over generations;;Learning language;;3. What can be learned from positive data;;The logical problem of language acquisition;;Specifying an \"ideal\" learning set - up;;Prediction by simplicity;;Prediction is possible!;;Logical problem of overgeneralization is solvable;;Absence as implicit negative evidence;;Extensions - 1;;Extensions - 2;;But abstract results are only a start;;4. What can be learned from positive data: II. A recipe;;Poverty of the stimulus: The recipe;;Nativism vs. Empiricism, the debate;;Easy example;;Lexical alternations;;Contractions;;Preliminary results;;Summary'
12630,'lecture','en',12403,'2010-05-10','2010-06-15','Monte Carlo and the mind',NULL,'Monte Carlo and the mind;;Two uses of Monte Carlo methods;;Answers and expectations - 1;;Answers and expectations - 2;;The Monte Carlo principle - 1;;The Monte Carlo principle - 2;;When simple Monte Carlo fails - 1;;When simple Monte Carlo fails - 2;;When simple Monte Carlo fails - 3;;Why Bayesian inference is hard;;Modern Monte Carlo methods;;Importance sampling - 1;;Importance sampling - 2;;An alternative scheme…;;Optimal importance sampling - 1;;Optimal importance sampling - 2;;Optimal importance sampling - 3;;Likelihood weighting;;Approximating Bayesian inference;;Exemplar models - 1;;Exemplar models - 2;;Equivalence;;Predicting the future - 1;;Predicting the future - 2;;Importance sampling;;Updating distributions over time...;;Particle filter;;Dynamic hypotheses;;Particle filters;;The promise of particle filters;;Two uses of Monte Carlo methods;;Three uses of Monte Carlo methods - 1;;Three uses of Monte Carlo methods - 2;;Two deep questions - 1;;Two deep questions - 2;;Markov chains;;Markov chain Monte Carlo;;Gibbs sampling - 1;;Gibbs sampling - 2;;Iterated learning;;Objects of iterated learning;;Analyzing iterated learning - 1;;Analyzing iterated learning - 2;;Iterated Bayesian learning;;Stationary distributions;;Explaining convergence to the prior;;Iterated function learning;;Function learning experiments - 1;;Function learning experiments - 2;;Iterated predicting the future;;Chains of predictions;;Stationary distributions;;Identifying inductive biases;;Comparing to universals…;;Metropolis-Hastings algorithm - 1;;Metropolis-Hastings algorithm - 2;;Metropolis-Hastings algorithm - 3;;Metropolis-Hastings algorithm - 4;;Metropolis-Hastings algorithm - 5;;Metropolis-Hastings algorithm - 6;;Metropolis-Hastings algorithm - 7;;Sampling subjective quantities;;An example: categorization;;Collecting the samples;;Sampling from natural categories;;Choice task;;Samples from Subject 3;;Mean animals by subject;;Marginal densities;;Relative volume of categories;;Discrimination method;;Parameter space for discrimination;;MCMC and discrimination means;;MCMC and the mind ;;;;mlss2010_griffiths_mcm_Page_76'
12631,'lecture','en',12403,'2010-05-11','2010-06-15','Machine learning and the cognitive science of natural language',NULL,'Machine learning and the cognitive science of natural language;;Three fields;;Outline;;Cognitive science and linguistics - 1;;Cognitive science and linguistics - 2;;Unsupervised Learning;;Outline;;The argument from the poverty of the stimulus;;Pullum and Scholz (2002);;Empirical version - 1;;Empirical version - 2;;Empirical version - 3;;The argument from the poverty of the stimulus;;Linguistic nativism - 1;;Linguistic nativism - 2;;The formal version of the APS;;Problem with the argument;;Study of Language acquisition - 1;;Study of Language acquisition - 2;;Standard methodology;;Step 1;;Step 2;;Tension;;Principles and Parameters models;;Linguists don’t know what the representations are - 1;;Linguists don’t know what the representations are - 2;;Reasonable Research Strategy - 1;;Reasonable Research Strategy - 2;;Outline;;Current NLP;;mlss2010_clark_mlatcs_Page_031;;mlss2010_clark_mlatcs_Page_032;;mlss2010_clark_mlatcs_Page_033;;mlss2010_clark_mlatcs_Page_034;;Unsupervised learning;;Grammar induction;;Empirical results;;Two problems of grammar induction - 1;;Two problems of grammar induction - 2;;Overview;;Regular inference;;Why are DFAs learnable?;;Empiricist models;;Go backwards - 1;;Go backwards - 2;;Outline ;;Summary;;Where’s the data?;;Basic assumptions;;Example;;Learning problem;;Distributional learning;;Problems - 1;;Problems - 2;;Problems - 3;;Distribution - 1;;Distribution - 2;;Distribution - 3;;Example;;Distributional learning -1 ;;Distributional learning - 2;;Distributional learning - 2;;Finite representation;;Partition;;Context free grammar - 1;;Context free grammar - 2;;Example - 1;;Example - 2;;Example - 3;;Example - 4;;Example - 5;;Example - 6;;Two Distributional Strategies;;Old concept;;Congruence class results;;Limitations - 1;;Limitations - 2;;Observation table - 1;;Observation table - 2;;Substitutable;;Concepts ;;Concepts - 2;;mlss2010_clark_mlatcs_Page_083;;mlss2010_clark_mlatcs_Page_084;;mlss2010_clark_mlatcs_Page_085;;mlss2010_clark_mlatcs_Page_086;;mlss2010_clark_mlatcs_Page_087;;Relation to CFGs;;Formally;;Partial order - 1;;Partial order - 2;;Greatest lower bound;;Formally;;Concatenation;;Dyck language - 1;;Dyck language - 2;;Dyck language - 3;;Constructing a representation - 1;;Constructing a representation - 2;;Representation;;A problem;;Representation - 1;;Representation - 2;;Dyck language;;mlss2010_clark_mlatcs_Page_105;;Learnability;;Change the set of strings - 1;;Change the set of strings ;;Increasing K;;Power of Representation;;mlss2010_clark_mlatcs_Page_111;;Change the set of context;;Search problem is trivial;;Context sensitive example;;mlss2010_clark_mlatcs_Page_115;;Context free languages;;Switch to non context-free representation;;Outline;;A serious criticism;;Associativity;;Obligatory choice;;Free word order in Finnish;;Bracketing paradoxes;;Romance clitics - 1;;Romance clitics - 2;;Non constituent coordination;;Movement;;Cross-serial dependencies;;Phonology;;Alternations;;Etc.;;Standard linguistic counter-arguments;;Uncontroversial - 1;;Uncontroversial - 2;;mlss2010_clark_mlatcs_Page_135;;mlss2010_clark_mlatcs_Page_136;;mlss2010_clark_mlatcs_Page_137;;mlss2010_clark_mlatcs_Page_138;;mlss2010_clark_mlatcs_Page_139;;Idea for structural descriptions - 1;;Idea for structural descriptions - 2;;Why the delay? - 1;;Why the delay? - 2;;Linguistic concepts;;Outline;;Conclusion'
12632,'lecture','en',12403,'2010-05-11','2010-06-29','Baysian models and cognitive development',NULL,'Bayesian models and cognitive development;;Co-workers;;Why study cognitive development? (1);;Why study cognitive development? (2);;Why study cognitive development? (3);;The empirical picture (1);;The empirical picture (2);;The empirical picture (3);;The empirical picture (4);;The modeling challenge;;Outline (1);;Goal inference as inverse probabilistic planning;;Inferring social goals;;Social Agents (1);;Social Agents (2);;Two Models;;Social Agents -Setup;;Social Agents -Demo;;Social Agents - Results (1);;Social Agents - Results (2);;Outline (2);;Nativism vs. empiricism (1);;Nativism vs. empiricism (2);;Learning words for objects;;Word learning as Bayesian inference (1);;Word learning as Bayesian inference (2);;Word learning as Bayesian inference (3);;Word learning as Bayesian inference (4);;Sensitivity to sampling in word learning (1);;Sensitivity to sampling in word learning (2);;Sensitivity to sampling in word learning (3);;Sensitivity to sampling in word learning (4);;Sensitivity to sampling in word learning (5);;Sensitivity to sampling in word learning (6);;Sensitivity to sampling processes and property extensions in 15-month-olds;;Word learning in a novel world (1);;Word learning in a novel world (2);;Word learning in a novel world (3);;Origins of the hypothesis space (1);;Origins of the hypothesis space (2);;Origins of the hypothesis space (3);;Learning to learn: what object features count for word learning?;;Transfer to real-world vocabulary;;Learning about feature variability (1);;Learning about feature variability (2);;A hierarchical Bayesian model (1);;A hierarchical Bayesian model (2);;A hierarchical Bayesian model (3);;Learning the shape bias;;Second-order generalization test;;Learning overhypotheses with hierarchical Bayesian models;;Learning selective inductive biases (1);;Learning selective inductive biases (2);;Learning selective inductive biases (3);;One-shot learning of real world object concepts (1);;One-shot learning of real world object concepts (2);;Learning to learn: what is the right form of structure for the domain?;;A hierarchical Bayesian approach;;Model fitting;;Development of structural forms as more data are observed;;Beyond “Nativism” versus “Empiricism”;;“Poverty of the Stimulus” argument;;Hierarchical phrase structure;;Hierarchical Bayesian model ;;Hierarchical Bayesian model (2);;Hierarchical Bayesian model (3);;Results: Full corpus;;Generalization results;;Results: First file (90 mins);;Outline (3);;Learning abstract structure in social relations;;Lab studies of learning structural forms (1);;Lab studies of learning structural forms (2);;Lab studies of learning structural forms (3);;Theory construction;;Causal learning and reasoning (1);;Causal learning and reasoning (2);;Causal learning and reasoning (3);;Causal learning and reasoning (4);;Learning a physical theory (1);;Learning a physical theory (2);;Learning a simple theory (1);;Learning a simple theory (2);;The causal blocks world (1);;The causal blocks world (2);;The causal blocks world (3);;Outline (4);;Theory learning as stochastic search in a space of logical rules (1);;Theory learning as stochastic search in a space of logical rules (2);;A probabilistic grammar for theories;;Proposing alternative theories (1);;Proposing alternative theories (2);;Proposing alternative theories (3);;Proposing alternative theories (4);;Learning simple magnetism;;Learning taxonomy;;The really big questions;;Church: a universal probabilistic language (1);;Church: a universal probabilistic language (2);;Church: a universal probabilistic language (3);;Church: a universal probabilistic language (4);;Church: a universal probabilistic language (5);;Learning natural number (1);;Learning natural number (2);;Learning natural number (3);;Learning natural number (4);;Learning natural number (5);;Conclusions'
12633,'lecture','en',12403,'2010-05-12','2010-06-15','Neuroscience, cognitive science and machine learning',NULL,'Neuroscience, cognitive science and machine learning;;Level 3 Marr: Implementation;;Neurons generate spikes;;It is a big problem;;Hope #1;;Hope #2;;Hope #3;;Hope #4: New technologies;;A well known Law;;Implications;;A Much Less known Law;;Implications;;Outline of talk;;Part 1: How neurons relate to the outside world;;Experimental studies;;Motor Tuning in M1;;Orientation Tuning in V1;;Disparity Tuning in V1;;Spatial Tuning;;Bygone Actress Tuning;;Bayesian tuning curve analysis;;Part 2: How neurons may represent uncertainty;;Many theories;;Distributed representation ;;Representation by samples;;Part 3: Reverse engineering the way neurons interact;;Why model interactions;;A generative model of spikes;;Explaining away;;Results from real neurons;;A more general model;;Graphical version;;Information per Neuron;;Spikes Timing Dependent Plasticity;;Tuning curves are  explained away;;Countless future machine learning problems;;Acknowledgements'
12634,'lecture','en',12403,'2010-05-12','2010-06-15','How could networks of neurons learn to carry out probabilistic inference?',NULL,'How could Networks of Neurons Learn to Carry Out Probabilistic Inference ?;;„cortical microcircuits“;;Local structure in generic cortical microcircuits;;Generic modules ;;Understanding synaptic plasticity;;STDP (= Spike-Timing-Dependent plasticity);;STDP curves ;;Dependent changes in neurons - Example;;Result;;Role of lateral inhibition in this context;;Demonstrating the possibility;;Uncovering the hidden process;;Output of the 4 z-neurons;;Link between the STDP and probability theory;;Result;;Analysis of the implicit generative model;;More abstract analysis of the behaviour of STDP;;The objective function minimized by SEM through STDP;;This unraveling of STDP;;MNIST dataset;;Resulting implicit generative models of 100 z-neurons;;Resulting spike output of the WTA-circuit;;Application to a more brain-like discrimination task;;Emerging detectors automatically generalize to time-warped variations;;Experimentally testable predictions ;;Experimental data confirm both of these two predictions;;Networks of very similar neural circuit moduls;;Gibbs sampling;;A generic neural network module;;Suitable STDP learning rules;;Computer test for a concrete Bayesian network;;Outlook;;Conclusions of my talk - 1;;Conclusions of my talk - 2;;Conclusions of my talk - 3'
12635,'lecture','en',12403,'2010-05-12','2010-06-15','Models of Human decision-making',NULL,'Models of human decision-making;;People;;OVERVIEW;;1. MAGNITUDE PERCEPTION WITHOUT INTERNAL SCALES?;;ABSOLUTE MAGNITUDE IDENTIFICATION: THE PUZZLE;;SIMILAR RESULTS ACROSS TYPES OF MAGNITUDE;;AND SPACING HARDLY MATTERS;;A RELATIVEJUDGMENT MODEL;;2. DECISION WITHOUT INTERNAL SCALES?;;WHAT THE COGNITIVE SYSTEM DOESN’T HAVE;;WHAT THE COGNITIVE SYSTEM DOES HAVE;;ONLY RANK MATTERS;;KEY ISSUE: HOW DO PEOPLE SAMPLE COMPARISON ANCHORS?;;DIMINISHING “UTILITY” OF MONEY;;ESTIMATED GAINS/LOSSES FROM A UK HIGH STREET BANK;;RANK VS. MONEY GAIN;;+$300 IS COMPARED WITH 5 RANDOM CREDITS;;COMBINE DISTRIBUTIONS FROM DIFFERENT CREDITS;;LOSSES LOOM LARGER THAN GAINS;;PROSPECT THEORY’S VALUE FUNCTION, RECONSTRUCTED;;SIMILARLY, FOR RISK AND TIME…;;3. VALUATION WITHOUT INTERNAL SCALES?;;ECONOMICS TYPICALLY ASSUMES;;EXPERIMENTAL “MARKET”;;BUYING RELIEF;;WE USED THREE PAIN LEVELS AND TWO MONETARY ENDOWMENTS;;AVERAGE PRICE OFFERS;;DISCREPANCY PROVIDED BY THE CONTEXT INCREASES THROUGH EACH BLOCK;;mlss2010_chater_mohdm_Page_29;;mlss2010_chater_mohdm_Page_30;;mlss2010_chater_mohdm_Page_31;;mlss2010_chater_mohdm_Page_32;;SECOND EXPERIMENT;;SUMMARY AND CONCLUSIONS 1;;SUMMARY AND CONCLUSIONS 2;;4. REINFORCEMENT LEARNING MEETS PRISONER’S DILEMMA;;PRISINOR\'S DILEMMA;;AN EXPERIMENT - 1;;AN EXPERIMENT - 2;;AN EXPERIMENT - 3;;AN EXPERIMENT - 4;;AN EXPERIMENT - 5;;MODEL AND MULTI-AGENT SIMULATION;;MULTI-AGENT SIMULATION: COORDINATION - 1;;MULTI-AGENT SIMULATION: COORDINATION - 2;;mlss2010_chater_mohdm_Page_46;;mlss2010_chater_mohdm_Page_47;;COOPERATION VIA REINFORCEMENT LEARNING'
12636,'lecture','en',12403,'2010-05-12','2010-06-15','Reinforcement learning: Tutorial + Rethinking State, Action & Reward',NULL,'Reinforcement Learning;;People;;Outline;;RL is Learning from Interaction;;RL Abstractly...;;RL and Machine Learning;;(Partial) List of Applications;;Markov Decision Process (MDP);;Bellman Optimality Equations;;Planning (Policy Evalution);;Planning (Optimal Control);;Convergence of Value Iteration;;Learning in MDPs;;Indirect Methods for Learning in MDPs;;Direct Method: Q-Learning;;Q-Learning Convergence w.p.1;;So far...;;Exploration‐Exploitation;;So far…;;General Idea;;Gradient Descent;;Sparse Coarse Coding;;FAs & RL;;Sampling Trees Approach;;Sparse Sampling;;So far…;;States?;;Approaches;;In this part…;;POMDPs…;;Predictions / futures;;System Dynamics Vector;;System Dynamics Matrix - 1;;System Dynamics Matrix - 2;;System Dynamics Matrix - 3;;nth‐order Markov Models;;K‐history Markov models…;;POMDPs… - 1;;POMDPs… - 2;;POMDPs… - 3;;POMDPs… - 4;;PSRs - 1;;PSRs - 2;;Updating Linear PSRs;;Update Parameters…;;Linear PSRs;;Actions…;;Actions?;;Options;;Rooms Example;;Options define a Semi‐Markov Decison Process (SMDP);;MDP + Options = SMDP;;What does the SMDP connection give us?;;Models of Options;;Room Example;;Example: Synchronous Value IterationGeneralized to Options;;Rooms Example;;mlss2010_singh_rlt_Page_58;;mlss2010_singh_rlt_Page_59;;mlss2010_singh_rlt_Page_60;;mlss2010_singh_rlt_Page_61;;mlss2010_singh_rlt_Page_62;;Landmarks Task;;Termination Improvement for Landmarks Task;;Intra‐Option Learning Methods for Markov Options - 1;;Intra‐Option Learning Methods for Markov Options - 2;;Summary: Benefits of Options;;Rewards…;;Rewards?;;Power and generality of RL;;Preferences‐Parameters Confound;;Example ‐Rewards as Parameters;;Disentangling the PP Confound;;Sanity Check;;Natural Agents - 1;;Natural Agents -2;;Computational Experiments;;Solving the Meta-Problem;;Experiment: Fish-or-Bait;;Reward Space - 1;;Reward Space - 2;;More result;;Change in Agent Rewards;;ML: The PP Confound;;Mitigation?;;Experiment: Foraging;;Mitigating Agent-State Boundedness;;Mitigating Agent-State Boundedness;;Experiment: Foraging;;mlss2010_singh_rlt_Page_90;;mlss2010_singh_rlt_Page_91;;Distribution over MDPs;;Mean-MDP + Reward Bonus;;Variance of Posterior;;Variance of Posterior as Reward;;Hunt-the-Wumpus World;;Wumpus Result;;Random Thought'
12717,'opening','en',12406,'2010-05-17','2010-06-21','Welcome Addresses',NULL,NULL
12718,'lecture','sr',12406,'2010-05-17','2010-06-21','Climate Change as Ecological Threat - Challenges and Solutions',NULL,'Climate Change as ecological threat - challenges and solutions;;Geopolitical map;;Biogeographical map;;Logo;;Global problems;;Life on the Earth depends on ...;;Nuclear Fusion on the Sun;;The electromagnetic spectrum of the Sunlight;;Radiation from the Sun;;Sun and Earth Radiation;;Global climate change;;Greenhouse gas effect;;Global warming is SWITCHED ON - 1;;Climate projections;;Climate change directly affects oceans current;;Global warming is SWITCHED ON - 2;;Climate change analysis on the regional level;;Projected increase in annual mean air temperature in Europe;;Trend of annual precipitation and mean annual air temperature in Serbia;;Fractions of Greenhouse gases;;Air Composition;;Increase of CO2 concetration 1958 -1998;;Increase of CO2 concetration 1958 -2005;;The Earthonce a year “breathes in” and “breathes out” CO2;;CO2 and H2O are inputs for organic synthesis;;The United Nations and the Environment;;International climate change policy - 1;;International climate change policy - 2;;Copenhagen Conference - results;;The Copenhagen Accord;;Importance of adaptation;;Adaptation and SEE region;;Message from New Delhi Conference;;Solutions are required;;A man and his dependence on elements of the surroundings'
12719,'advertisement','en',12406,'2010-05-17','2010-06-21','Building the Knowledge Base for Environmental Governance - EU Perspectives',NULL,NULL
12720,'advertisement','en',12406,'2010-05-17','2010-06-21','Teaching Climate Change and the UN System in Southeast Europe',NULL,NULL
12721,'lecture','en',12406,'2010-05-17','2010-06-21','The Role of UNESCO in Climate Change Education and Education for Sustainable Development in Southeast Europe',NULL,'The role of UNESCO in climate change education and ESD in SEE;;Venice - 1;;Venice - 2;;Venice - 3;;The context - 1;;The context - 2;;The context - 3;;The context - 4;;The context - 5;;Education for sustainable development;;The elephant;;Dance of the elephants;;UNESCO Programmes and CC - 1;;UNESCO Programmes and CC - 2;;UNESCO Programmes and CC - 3;;UNESCO Programmes and CC - 4;;UNESCO Programmes and CC - 5;;UNESCO Programmes and CC - 6;;UNESCO Programmes and CC - 7;;UNESCO Programmes and CC - 8;;UNESCO Programmes and CC - 9;;UNESCO Programmes and CC - 10;;UNESCO Programmes and CC - 11;;Regional initiatives in SEE - 1;;Regional initiatives in SEE - 2;;890 site in 186 States Parties;;UNESCO site;;Ochrid;;Local management;;Mission impossible? - 1;;Mission impossible? - 2;;The Dinaric Arc Initiative (DAI);;Platform of cooperation;;Balkan overview;;Venice - 4;;Venice - 5;;Thank you'
12722,'lecture','en',12406,'2010-05-17','2010-06-21','Regional Coordination of Nationale Climate Change Strategies and the Role of Human/Scientific Capacity Building',NULL,NULL
12723,'lecture','en',12406,'2010-05-17','2010-06-21','Climate Change Capacity Building of United Nations Environment Programme',NULL,NULL
12724,'introduction','en',12406,'2010-05-17','2010-06-21','Introduction',NULL,NULL
12725,'lecture','en',12406,'2010-05-17','2010-06-21','Teaching Climate Change: the multiple relationships between climate change related education, climate (un)sustainability, business sector and civil society',NULL,'Teaching Climate Change: the multiple relationships between climate change related education, climate (un)sustainability, business sector and civil society;;Introduction;;Climate Change Science: Meaning;;Common understanding ;;Global governance ;;Corporate mitigation strategy ;;Corporate adaptation strategy ;;Climate change information;;Participation in decision making relevant processes ;;The state of art in Serbia ;;Needs assessments in western balkan region;;Bells training and education initiative;;Bells regional courses;;Multiple relationships '
12726,'lecture','en',12406,'2010-05-17','2010-06-21','Innovative Diplomatic Training on Climate Change - Harnessing the Potentials of Modern Information and Communication Technologies',NULL,'Capacity development in climate change;;Presentation by Avatar;;Climate Change Capacity Development;;Why?;;What?;;Who?;;How? - 1;;How? - 2;;Next? - 1;;Next? - 2'
12727,'lecture','en',12406,'2010-05-17','2010-06-21','UNITAR Approach to Capacity Building and Development for Climate Change',NULL,'Approach to capacity building and development for climate change;;Guided by UNITARs mandate;;Our services to address climate change;;Climate Change Capacity Development - C3D+;;The partners;;Advancing Capacity to support Climate Change Adaptation in Africaand Asia - ACCCA;;One UN Training Service Platform on Climate Change - 1;;One UN Training Service Platform on Climate Change - 2;;One UN Training Service Platform on Climate Change - 3;;Thank you for your attention'
12728,'lecture','en',12406,'2010-05-17','2010-06-21','Innovative Funding of Scientific Capacity Building on Climate Change - the IPCC Scholarship Programme',NULL,NULL
12729,'lecture','en',12406,'2010-05-17','2010-06-21','UN Studies Portal and Preparation of a SEE specific Subportal',NULL,NULL
12730,'lecture','en',12406,'2010-05-17','2010-06-21','Practical Experience with Regional Climate Change related Capacity Building in CEE and SEE',NULL,'Practical Experience with Regional Climate Change related Capacity Building in CEE and See;;Sustainable Development;;Solution;;What is to be done ?;;The REC;;Bridging - Across Borders;;What do we do ?;;Our Main Activities;;Article 6;;Action Plan;;Attitude & Behaviour;;Education for the youngest;;Kyoto in the home;;Green Pack;;Courses for Sustainable Development;;The Climate Project;;Act before it\'s too late'
12731,'lecture','en',12406,'2010-05-27','2010-06-21','Belgrade Initiative on Climate Change for Scientific Capacity Building and Policy Development in the SEE Region',NULL,NULL
12732,'lecture','en',12406,'2010-05-17','2010-06-21','Building the Knowledge base for Climate Change Governance in the SEE',NULL,'Building the Knowledge Base for Climate Change Governance in South East Europe;;Aims/Content of the Presentation;;Starting point;;Awareness Raising;;Building the Knowledge Base;;Examples/Photos;;Bled Forum on Europe;;United Nations;;DEKTI;;ACUNS;;Global Challenges Song World Cup;;The Vision;;Thank You'
12733,'lecture','en',12406,'2010-05-17','2010-06-21','How to achieve Interministerial and International Cooperation related to Climate Change Capacity Building in SEE',NULL,'Diplomacy for Primary Schools: Teaching Climate Change;;Diplomacy for Primary Schools: The purpose;;Diplomacy for Primary Schools: Topics;;Diplomacy for Primary Schools: The event;;Diplomacy for Primary Schools: Lessons learned;;Diplomacy for Primary Schools: Plans'
12734,'opening','en',12406,'2010-05-17','2010-06-21','Opening of the Workshop',NULL,NULL
12735,'demonstration video','en',12406,'2010-05-17','2010-06-21','Climate Protection Song World Cup',NULL,NULL
12736,'lecture','en',12406,'2010-05-18','2010-06-21','International and Crosssectoral Cooperation of Climate Change Scientists:Slovenian Experience and Issues for SEE region',NULL,NULL
12737,'lecture','en',12406,'2010-05-18','2010-06-21','Graz Climate Change research in SEE networking expiriences and outlook',NULL,'JOANNEUM Research, Graz Climate Change research in SEE networking experiences and outlook;;ccandun2010_turk_creo_01_Page_02;;JR Climate Change Competences;;Our network countries;;Network Activities - 1;;Network Activities - 2;;ccandun2010_turk_creo_01_Page_07;;Kyoto Mechanism;;ccandun2010_turk_creo_01_Page_09;;Solutions;;ccandun2010_turk_creo_01_Page_11;;Biomass Potentials;;New challenges;;Climate Change;;Thank you'
12738,'lecture','en',12406,'2010-05-18','2010-06-21','Teaching Climate Change: The Role of Tertiary Education Institutions and Barriers to Effective Curriculum Transformation',NULL,'The role of Tertia Education Institutios and Barriers to Effective Curricula Transformation;;Recognizing Climate Change For What It Really is;;Reccognizing What The Real Problem Is ?;;So what is the problem;;Is this the way;;Or this;;What really is climate change science;;Despite the shape;;Inappropriate solutions;;Setting the stage;;Who do we teach;;The role of tertiary education;;What role can we play;;Leaders;;Asking the right questions;;Doing the right thing;;Paradigm;;Teaching educators first;;What are the barriers;;Need to teach;;Shift mindsets;;Making of the business case;;Brutally simple;;In conclusion;;Thank You;;ccandun2010_bozic_idtc_01_Page_26;;ccandun2010_bozic_idtc_01_Page_27;;ccandun2010_bozic_idtc_01_Page_28;;ccandun2010_bozic_idtc_01_Page_29;;ccandun2010_bozic_idtc_01_Page_30;;ccandun2010_bozic_idtc_01_Page_31;;ccandun2010_bozic_idtc_01_Page_32;;ccandun2010_bozic_idtc_01_Page_33;;ccandun2010_bozic_idtc_01_Page_34'
12739,'lecture','en',12406,'2010-05-18','2010-06-21','Climate Change and United Nations Studies in the Context of SEE Regional Inter-University Co-operation',NULL,'Climate Change and United Nations Studies in the Context of SEE Regional Inter-University Co - operation;;Climate change is a global problem;;Migrations;;Climate change between science society & policies;;How climate will change;;Accumulated knowledge - 1;;Accumulated knowledge - 2;;International strategy;;Climate change is ireversibile process - 1;;Climate change is ireversibile process - 2;;Decision makers are all around - 1;;Decision makers are all around - 2;;Educasion;;Harmonisation - 1;;Harmonisation - 2;;Harmonisation - 3;;University curricula;;Improving university curricula'
12740,'lecture','en',12406,'2010-05-18','2010-05-22','Green Industrial MBA',NULL,'International Centre for Promotion of Enterprises - ICPE and Jožef stefan International Postgraduate School;;International Centre for Promotion of Enterprises;;Green Industry MBA;;Green Industry MBA - Sinergy;;Green Industry MBA - Development;;Green Industry MBA - window of opportunity;;Green Industry MBA WELCOME'
12741,'lecture','en',12406,'2010-05-18','2010-06-21','Global Challenges and the Need for International Cooperation in SEE',NULL,'Global Challenges and the Need for International Cooperation in See;;ccandun2010_eric_gcnic_01_Page_2;;ccandun2010_eric_gcnic_01_Page_3;;Climate Excanges;;Climate Excange'
12742,'lecture','en',12406,'2010-05-18','2010-06-21','Global Climate Change Situation Room-an Innovative Way of Global Knowledge Collaboration','zdruzi z videom ki pride',NULL
12743,'summary','en',12406,'2010-05-18','2010-06-21','Closing of the conference',NULL,NULL
12744,'opening','en',12531,'2010-05-20','2010-06-14','Welcome address',NULL,'ProSense '
12745,'lecture','en',12531,'2010-05-20','2010-06-14','Technology Park Ljubljana and Hi-Tech SME development in Slovenia','The current situation and perspectives for new High-tech SMEs are presented. The basic steps needed for the commercialization of an idea are listed, emphasizing the concrete procedures and experiences from the Technological park Ljubljana.','Technology Park Ljubljana and Hi.Tech SME development in Slovenia;;Why ? - 1;;Top 20 financial institutions by market capitalisation;;Why? - 2;;ECO System;;Podjetniški Portal;;Imam idejo!;;www.businessincubation.si;;STP / Incubators?;;Definition;;Technology Park Ljubljana - Vision;;Founders;;Added value of location - 1;;Added value of location - 2;;Technology Park Model;;Micro location of Technology Park Ljubljana;;Technology Park Ljubljana Brdo Project;;Technology Park Ljubljana Brdo Project in Pictures - 1;;Technology Park Ljubljana Brdo Project in Pictures - 2;;Technology Park Ljubljana Brdo Project in Pictures - 3;;Advantages of Technology Park Ljubljana;;Services cycle of Technology Park Ljubljana - 1;;Services cycle of Technology Park Ljubljana - 2;;Financial schema;;Specialized programs;;EU Projects;;Activities of Technology Park Ljubljana ;;Member companies and sectors;;The most successive stories in 2009;;Tehnološki Park Ljubljana - 1;;Tehnološki Park Ljubljana - 2;;wsnsme2010_lesjak_htse_01_Page_32;;wsnsme2010_lesjak_htse_01_Page_33;;wsnsme2010_lesjak_htse_01_Page_34;;wsnsme2010_lesjak_htse_01_Page_35;;wsnsme2010_lesjak_htse_01_Page_36;;Thank you for your attention'
12746,'lecture','en',12531,'2010-05-20','2010-06-14','From Wireless Sensor Networks to Internet of Things and Future Internet','In this presentation, first an overview of the main PROSENSE project goals and achievements is presented. The main wireless sensor networks topics as well as the application addressed are described. Building on this, a view on the further technological development of the domain towards Internet of Things and Future Internet is given. Finally, the main research topics, visions and activities on the Europe level in the Internet of Things domain are overviewed.','From Wireless Sensor Networks to Internrt of Things and Future Internet;;What shall I talk about;;Wireless sensor networks;;What are WSNs?;;How the researcher envisioned it;;Typical WSN applications;;Typical research problems;;FP7 PROSENSE;;Prosense;;Objectives;;Some of the achievements;;Description and scenario system structure;;Smart Road Monitoring;;Orig. SRT scenario;;Waste management;;Towards Internet of Things;;Vision: 50 billion connections by 2020;;Connect my things;;Internet of things;;Smart city Scenario;;wsnsme2010_krco_wsni_01_Page_22;;wsnsme2010_krco_wsni_01_Page_23;;Join us at our next events;;ERICSSON'
12747,'lecture','en',12531,'2010-05-20','2010-06-14','Smart Grids and WSN in Slovenia','New concepts of smart electricity networks - SmartGrids represent the (r)evolution in the production and efficient use of electricity. On the one hand, the developed system-oriented solutions will allow high penetration of distributed energy resources and, on the other, consumer-oriented solutions will allow the efficient use of energy for end-users.','Smart Grids and WSN in Slovenia;;Content;;Why do we need an electricity networks technology platform?;;Characteristic of today\'s(yesterday\'s)power networks;;Characteristics of the networks of tomorrow;;European vision of the networks of tomorrow;;How to realize the vision?;;Slovenian Electricity Networks Technology Platform;;Members of the Electricity Networks Technology Platform;;Members of TP;;Strategic goals;;Research & Technology Development areas;;National strategic demonstration projects proposal;;Opportunities for WSN - 1;;Opportunities for WSN - 2;;Opportunities for WSN - 3;;Opportunities for WSN - 4;;Conclusions - where are we now?'
12748,'lecture','en',12531,'2010-05-20','2010-06-14','Antennas and electromagnetic simulators for demanding wireless applications in complex environments','Antennas for wireless sensor applications need to be extremely versatile: small, adaptive, low-cost, mobile, “smart”. Efficient and versatile software tools for antenna analysis and simulation are presented. Modeling approaches for electromagnetic radiation in layered structures or in biological tissues are introduced with practical realizations of adequate antennas. Some antenna applications in wireless sensor networks (WSN) on/in a human or animal body are also addressed.','Antennas and electromagnetic simulators for demanding wireless applications in complex environments;;Antennas for demanding applications (wireless sensors);;Antenas for WSN operate in unfavorable electromagnetic environments;;Antenna design;;Our software for antenna design;;Antennas above and in real ground and layered media;;Interaction between mobile handsets and the human head;;Mobile handset radiation diagram;;Absorbed power and radiation efficiency;;Partners;;Antennas on and inside human body for wireless body-area network - 1;;Antennas on and inside human body for wireless body-area network - 2;;Antennas on and inside human body for wireless body-area network - 3;;Results for transfer between antennas;;Simulation models can be much more realistic and detailed;;Conclusion;;Thank you'
12749,'lecture','en',12531,'2010-05-20','2010-06-14','Sensor networks in telemedicine and telecare','The development of information technology and telecommunications has reached a level where its usefulness can be applied for health care needs. Telemedicine and telecare rely on two extensive and interconnected professional fiels: Information and Communication Technology (ICT) and medicine. An approach for use of sensors for data capture, along with telecommunication connections and program tools harmonized with the biomedical profession and the organization of health care activities will be proposed.','Sensor Networks in Telemedicine and Telecare;;Medicine & ICT - Telemedicine and Telecare;;ICT in Telemedicine and Telecare;;Telemedicine and Telecare;;WSN in Telemedicine and Telecare;;Telemedicine and Telecare;;Possible involment of SMEs;;Wearable Body Sensors;;Wireless biopotential electrode;;12-lead ECG;;Reconstruction of a standard 12-lead ECG;;Reconstructed standard 12-lead ECG from 3 WBE;;Know-how still needed;;Thank You for your attention'
12750,'lecture','en',12531,'2010-05-20','2010-06-14','Applying integrated sensor networks in public distribution systems','Experiences with integration of various WSNs in a single global sensor network, with possibilities for alerting and subscribing sensor data to interested users, could be efficiently used in public distribution systems. In today’s public distribution systems, regardless it is a water, gas, or public heat distribution, there are large number of installed sensor nodes, with accompanying software for monitoring and alerting, provided usually from a single vendor, making the network very homogeneous. Our solution tries to provide more flexible system with integration of various installed sensors from different vendors, which enable scalability of the system, with facilitated installation of new sensors in the future. In the same time, the unified functions of alerting, subscribing and monitoring are still preserved.','Applying integrated sensor networks in public distribution systems;;Introduction;;The ProSense Common Gateway - Interface;;The ProSense Common Gateway -General Principle;;The Application;;The Distric heating systems:Available Softvare Systems;;The Distric heating systems: Our approach;;Main software functionalities;;The pilot project;;Other applications;;Questions? Comments?'
12751,'lecture','en',12531,'2010-05-20','2010-06-14','Enhancing fitness with WSN systems: From the laboratory to the market','Personal WSN systems have to be targeted to individual users. The system can offered on the market as a package of the necessary devices and software for monitoring. Another approach would be to target groups of users, providing them with the entire exercise environments and competitive exercising. Finally, with the Smart Running Track (SRT) equipment already in use and collected sensor data a digital image of the person’s level of fitness can be maintained. Future Internet technology can be used to provide various services to the users of WNS supported fitness systems.','Enhancing fitness with WSN system from the laboratory to the market;;Presentation Outline;;Smart Running Track;;SRT System;;Market strategy - Support for peresonal fitness;;Market strategy - Competitive running;;Market strategy - Part of the Future Internet - 1;;Market strategy - Part of the Future Internet - 2;;Questions? Comments?'
12752,'lecture','en',12531,'2010-05-20','2010-06-14','Versatile Sensor Node - A Platform for the Sensor as a Service Concept','Versatile Sensor Node (VSN) is a high performance sensor network platform with modular structure, long-life autonomy and flexible radio. Wireless interface spans over several industrial, scientific and medical frequency bands and supports multiple communication technologies, including ZigBee, 6LoWPAN, Bluetooth and WiFi. Various sensors and actuators can be connected via digital and analog peripherals, which makes VSN adaptable to diverse application requirements. By supporting semantic technologies and intelligent machine learning algorithms it provides a transparent infrastructure in which sensors are offered as a service.\n\n\n','Versatile Sensor Node;;Outline;;SensorLab;;Wireless Sensor Networks;;Current state in WSN;;WSN Technologies;;WSN Implementation;;Versatile Sensor Node - 1;;Versatile Sensor Node - 2;;Versatile Sensor Node - 3;;Vertical Integration;;VSN in multi-tier WSN;;Bluetooth equiped VSN;;VSN for loT & WoT;;VSN Application Areas;;Thank you'
12753,'lecture','en',12531,'2010-05-20','2010-05-24','APSIS - Autonomous surface vehicle for measurements and logistic','A miniature boat is designed to perform hydrographic surveys, on-line measurements and sample collection in shallow waters. The boat is light-weight, measuring 220 x 65 x 40 cm and is easy to handle by two persons.','Autonomous Surface Vehicle;;Logistic Support on missions'
12754,'lecture','en',12531,'2010-05-20','2010-05-24','DIONIS: Efficient monitoring system for vineyards','A novel vineyard monitoring WSN based application currently under development as a joint collaboration between FEEIT – Skopje and ECS – Skopje is presented. The application, named DIONIS, incorporates various sensors (temperature, humidity and chemical substances sensors) for data gathering, wireless communication devices for data dissemination to relevant entities, database for storing the acquired data and a Graphical User Interface (GUI) for user friendly data statistics monitoring. Based on the extracted field parameters, DIONIS is able to detect abnormal situations and alarm local and remote authorities. DIONIS can enhance the grape growing process and provide higher wine quality, as well as exhibit water savings and more efficient pesticide use.','Dionis: efficient monitoring system for vineyards;;Macedonia: Facts & Numbers;;Trend of wine production;;Precision Agriculture;;Existing implementations and experiences;;Experiences: Camalie Vineyards;;Dionis;;Sensor system;;Visualization System - 1;;Visualization System - 2;;Process of implementation;;Popova Kila;;Implementation constrains;;Conclusion - 1;;Conclusion - 2;;About us - 1;;About us - 2;;Thank you for your attention'
12755,'lecture','en',12531,'2010-05-20','2010-06-14','Power and Energy Management with Energy Control Modules','Future households\' requirements for demand-side management are auto demand response (AutoDR) function and full control over distributed power sources. Existing solutions feature a direct link between power meters and appliances. A new concept called Smart Distribution Box (SmartDB) provides complete energy and power management solution. It represents an intermediate layer, extending smart grid power meter functionality to support AutoDR with fast and guaranteed response times, distributed power sources, and full control over energy management with extra safety functions. Demo implementation of Smart Distribution Box is composed of Energy Control modules and management applications running on mobile phones and Linux/Windows systems.','Power anf Energy Management;;Contens - 1;;Energy Consumption;;Fluctations of Energy Distibution;;Contens - 2;;Efficient Solution for Energy Conservation;;Conservation based on subscriber power decrease;;Conservation based on energy consumption decrease;;Conservation based on hopping to lower energy classes;;Contents - 2;;EC Key Features;;Protection against common over-current - 1;;Protection against common over-current - 2;;Protection against common over-current - 3;;Energy Conservation;;Fault detection;;Anti-Smog;;Integration of Alternative Sources;;Contents - 3;;Installation;;wsnsme2010_platise_pem_01_Page_21;;wsnsme2010_platise_pem_01_Page_22;;wsnsme2010_platise_pem_01_Page_23;;wsnsme2010_platise_pem_01_Page_24;;wsnsme2010_platise_pem_01_Page_25;;wsnsme2010_platise_pem_01_Page_26;;wsnsme2010_platise_pem_01_Page_27;;wsnsme2010_platise_pem_01_Page_28;;Long-term Benefits;;wsnsme2010_platise_pem_01_Page_30'
12756,'lecture','en',12531,'2010-05-20','2010-06-14','Application of biosensors in sport and medicine - dynamics of muscles','A rapid development of low-power electronic biosensors is enabling a production of devices that are small enough not to constrain the measured subject thus providing the scientists with a whole new insight in both dynamical and electrical properties of muscles. The usage of biosensors can be applied in medicine, sport, industry or any field where work output quality depends on any kind of muscle activity. Knowledge obtained through biosensors will lead in development both in medicine, sport and other related fields.',NULL
12757,'lecture','en',12531,'2010-05-20','2010-06-14','Harvesting Wireless Sensor Solutions and Networks by EnOcean technology','Most wireless sensors, which are connected standalone or into a network are battery-driven. In the last time new batteryless and wireless sensors are in use, based on new approaches with extremely small amount of energy for sending information that even harvesting from environment energy can be sufficient. The environment energy can be present in mechanical thermal or photonic form. Sensors, which are harvesting environment energy are result of EnOcean technology that is spreading very successfully for example in the field of electrical installations and industry.','Harvesting wireless sensors;;Smart Energy Sensor;;Radio Communication;;Frequency Selection;;Energy Management;;EnOcean communication;;Energy Harvesting;;Energy Converters - in Detail;;Hardware modules 1 st generation;;Structure of EnOcean switch;;Smart Energy Sensors: Building Applications;;Smart Energy Sensors: Industrial Applications;;Uni-directional Sensors;;Hardware modules 2 nd generation;;Bi-directional sensors;;Harvesting temperature difference;;EnOcean Wireless Sensor Network;;Actuators;;Wireless applications;;Your payback - 1;;Your payback - 2;;Your payback - 3;;References;;Buildings;;Enocean Alliance;;Distributor for EnOcean technology'
12758,'lecture','en',12531,'2010-05-20','2010-06-14','Wireless sensor network measurements of high density wind dynamics in the region Vipavska dolina, Slovenia with embedded real-time algorithm for prediction of the wind conditions','We will demonstrate case of intelligent wireless sensor network algorithm for prediction of wind conditions in the region of Vipavska dolina. The system was developed for traffic security on the highway during the periods of evolution of high density wind energy. Detection wireless sensor network communicate with host super computing system for real-time computation of fluid dynamics based on boundary condition from discrete nodes and GPU technology. We apply self organized neural network dynamics of attractor space on sensor nodes and fuzzy network prediction for detection the threshold for traffic security.',NULL
12759,'lecture','en',12531,'2010-05-20','2010-06-14','Examples of WSN applications through EU-funded projects','In this talk an overview is given of different applications of wireless sensor networks developed in the framework of recent EU founded projects and cooperating industrial partners. These \"success stories\" illustrate how WSN can lead to the development of new services.','Examples of WSN applications trough EU - funded projects;;POPS research group;;Summary;;Inria;;WSN : from theory...;;Event-driven model;;On-demand model;;Sensor Nets for Search and Rescue - 1;;Sensor Nets for Search and Rescue - 2;;Sensor Nets for Search and Rescue - 3;;Protocol Stack;;GG over CDS;;Real Applications;;Sensor applications - 1;;Sensor applications - 2;;Dispositif experimental;;Focus on localization;;Location Positioning;;Centroid improvements;;DV-hop improvement - 1;;DV-hop improvement - 2;;wsnsme2010_simplot_ryl_ewsn_01_Page_22;;RFID middleware;;wsnsme2010_simplot_ryl_ewsn_01_Page_24;;wsnsme2010_simplot_ryl_ewsn_01_Page_25;;wsnsme2010_simplot_ryl_ewsn_01_Page_26;;Conclusion - 1;;IEEE 802.15.4;;Conclusion - 2;;wsnsme2010_simplot_ryl_ewsn_01_Page_30;;Conclusion - 3;;Smart buildings;;Conclusion - 4;;Future Internet;;wsnsme2010_simplot_ryl_ewsn_01_Page_35'
12760,'summary','en',12531,'2010-05-20','2010-06-14','Prosense workshop Closing',NULL,NULL
12817,'lecture','sl',12427,'2010-05-20','2010-06-28','200 let Botaničnega vrta v Ljubljani','Botanični vrt je v vsej 200 letni zgodovini skrbel za predstavitev raznolikosti rastlinskega sveta, jo raziskoval in hkrati služil kot izredno bogat učni pripomoček za različne ravni šolanja. Poleg tega je bil vrt odprt tudi za širšo javnost. Ko se še ni govorilo o varovanju vrst na nadomestnih rastiščih, je že kmalu postal edino nadomestno rastišče za vrsto z bližnjega gradu Fleischmannov rebrinec. Danes botanični vrt skuša predstavljati čimbolj celovit pogled na rastline in njihova življenjska okolja.',NULL
12818,'lecture','sl',12427,'2010-05-27','2010-06-05','Glive - ne rastline, ne živali','Ta samosvoja skupina živih bitij je naselila vsa okolja in je nepogrešljiva za vzdrževanje življenja na Zemlji. V številnih posebnostih se glive razlikujejo od rastlin, živali in drugih organizmov, zato jih že več kot 50 let obravnavajo kot svoje kraljestvo. V razvojnih krogih pogosto oblikujejo večje število različnih oblik trosišč in trosov in ta pojav je lahko tako kompliciran in čudovit, da nima primere v živem svetu. Poznamo jih slabo, saj so doslej opisali le približno 5% vrst od množice gliv, ki so povsod okoli nas. Dobro bi bilo, da jih začnemo bolje spoznavati.','Uvod;;GLIVE – ne rastline, ne živali;;Kraljestvo GLIVE;;Vrste gliv;;Število vrst v Sloveniji;;Kraljestvo PRAŽIVALI;;Kraljestvo KROMISTI;;Phytophthora cambivora;;Kraljestvo GLIVE - 1;;Kraljestvo GLIVE - 2;;Kraljestvo GLIVE - 3;;Kraljestvo GLIVE - 4;;Rjava trohnoba;;Bela trohnoba;;Kraljestvo GLIVE - 5;;Coprinus atramentarius;;Deblo Ascomycota;;Thyriopsis halepensis - 1;;Thyriopsis halepensis - 2;;Thyriopsis halepensis - 3;;Epichloë typhina;;Ascodichaena rugosa - 1;;Ascodichaena rugosa - 2;;Asterosporium asterospermum - 1;;Asterosporium asterospermum - 2;;Nectria coccinea - 1;;Nectria coccinea - 2;;Libertella faginea - 1;;Libertella faginea - 2;;Anthostoma turgidum;;Anthostoma sp.;;Biscogniauxia nummularia - 1;;Biscogniauxia nummularia - 2;;Biscogniauxia mediterranea;;Eutypella parasitica - 1;;Eutypella parasitica - 2;;Eutypella parasitica - 3;;Ocena tveganja za Eutypella parasitica v Evropi;;Rhytisma salicinum;;Erysiphe elevata - 1;;Erysiphe elevata - 2;;Ampelomyces quisqualis;;Erysiphe flexuosa - 1;;Erysiphe flexuosa - 2;;Erysiphe azaleae - 1;;Erysiphe azaleae - 2;;Erysiphe arcuata - 1;;Erysiphe arcuata - 2;;Deblo Basidiomycota - 1;;Deblo Basidiomycota - 2;;Gymnosporangium sabinae - 1;;Gymnosporangium sabinae;;Gymnosporangium sabinae - 2;;Coleosporium tussilaginis - 1;;Coleosporium tussilaginis - 2;;Coleosporium tussilaginis - 3;;Gymnosporangium gracile - 1;;Gymnosporangium gracile - 2;;Gymnosporangium gracile - 3;;Gymnosporangium gracile - 4;;Gymnosporangium gracile - 5;;Gymnosporangium gracile - 6;;Gymnosporangium gracile - 7;;Puccinia adoxae;;Joannes Antonius Scopoli;;Wilhelm Voss;;Herbariji gliv Prirodoslovnega muzeja Slovenije;;Mikološka zveza Slovenije;;Sparassis crispa;;Cordyceps militaris'
12852,'lecture','en',12408,'2010-05-30','2010-07-02','Overview and Goals of LarKC',NULL,'Agenda for today;;Welcome to the 3rdLarKC Early Adopters Workshop ;;Health Warning;;Goals of today;;Goals of LarKC (1);;Goals of LarKC (2) ;;Goals of LarKC (3);;What do we mean by (1);;What do we mean by (2);;What do we mean by (3);;Overall approach of LarKC;;How to deploy LarKC;;Why would people (like you ) want to use LarKC;;What does a workflow look like? (1);;What does a workflow look like? (2);;What does a workflow look like? (3);;What does a workflow look like? (4);;What does a workflow look like? (5);;What does a workflow look like? (6);;What does a workflow look like? (7);;What does a DECIDEr look like?;;Already any plugins available?;;Goals of LarKC, and where we are;;What we will not show today;;Agenda for today'
12853,'lecture','en',12408,'2010-05-30','2010-07-02','Introduction to the LarKC Architecture',NULL,NULL
12854,'lecture','en',12408,'2010-05-30','2010-07-02','Hands-on 1: Working with an existing LarKC workflow',NULL,'Introduction to the LarKC code base.Working with a simple workflow;;Working with a simple workflow;;Distributed and Parallel Processing - The LarKC platform from the user perspective;;Distributed and Parallel Processing - The content of the USB flash stick;;Distributed and Parallel Processing - Exploring the Platform;;Distributed and Parallel Processing - Playing with a simple workflow;;Distributed and Parallel Processing - Getting more plug-ins;;Distributed and Parallel Processing - Using the Command Line;;Distributed and Parallel Processing - Submitting a query;;Working with a simple workflow - LarKC@SourceForge;;Working with a simple workflow - Code management system;;Working with a simple workflow - Getting help and support;;Working with a simple workflow - Feedback to the developers;;Questions ?'
12855,'lecture','en',12408,'2010-05-30','2010-07-02','Hands-on 2: Building a LarKC decider plug-in to create a workflow from existing plug-ins',NULL,'Cyc-Gateworkflow;;Goal;;External tools used;;Workflow diagram;;Example;;Query;;Identify;;Transform;;Select;;Reason;;Scripted decider;;Write a new scripted decider plug-in;;Run the workflow on your computer!;;Run SPARQL client;;Run example query (missing examples);;Other interesting queries (1);;Other interesting queries (2);;eswc2010_bradesko_hobald_01_Page_18;;eswc2010_bradesko_hobald_01_Page_19;;eswc2010_bradesko_hobald_01_Page_20;;eswc2010_bradesko_hobald_01_Page_21'
12856,'lecture','en',12408,'2010-05-30','2010-07-02','Introduction to Distributed Processing in LarKC',NULL,'Introduction to Distributed and Parallel Processing in LarKC;;Distributed and Parallel Processing;;Distributed and Parallel Processing - Application;;Distributed and Parallel Processing - Motivation and use case;;Distributed and Parallel Processing - Distribution, Parallelization;;Distributed and Parallel Processing - LarKC Distribution Model (graph);;Distributed and Parallel Processing - LarKC Distribution Model - Realization;;Distributed and Parallel Processing - LarKC Distribution Model - Supported host types;;Distributed and Parallel Processing - LarKC Distribution Model - Supported access protocols;;Distributed and Parallel Processing - LarKC Distribution Model (Distribution technologies enabled by LarKC);;Grid Access Toolkit (GAT) - Usage in LarKC;;Grid Access Toolkit (GAT) - Limitations of GAT;;Grid Access Toolkit (GAT) - GAT manager architecture;;Grid Access Toolkit (GAT) - Prerequisites to the remote host;;Grid Access Toolkit (GAT) - Realization (Resource Description);;Grid Access Toolkit (GAT) - Realization (GAT Managers);;Grid Access Toolkit (GAT) - A short demo;;Industry standard Web technologies - Basically RPC over HTTP;;Industry standard Web technologies - Servlet wrapper (war);;Industry standard Web technologies - Initialise, Invoke, Destroy;;Industry standard Web technologies - Use with existing Plug-Ins;; Applying parallelization for Plug-Ins - Parallelism is everywhere nowadays;; Applying parallelization for Plug-Ins - Multithreading mechanism for the Plug-Ins;; Applying parallelization for Plug-Ins - Performance effect of multithreading;; Applying parallelization for Plug-Ins - Parallelism is everywhere nowadays;; Applying parallelization for Plug-Ins - Domain decomposition mechanism;;Discussions and recommendations;;Questions ?'
12857,'lecture','en',12408,'2010-05-30','2010-07-02','Hands-on 3: Building a LarKC plug-in and integrating it into an existing workflow',NULL,NULL
12858,'lecture','en',12408,'2010-05-30','2010-07-02','Hands-on 4: Understanding and Manipulating the Urban Computing workflow',NULL,'Understanding and Manipulating the Urban Computing workflows;;Context – Urban Computing;;Context – Urban Data Availability;;Sample Usage Scenario: Alpha Urban LarKC ;;Alpha Urban LarKC challenges;;Alpha Urban LarKC at a glace;;Alpha Urban LarKC workflows - monument destination selection workflow;;Monument Destination Selection Worflow;;Alpha Urban LarKC workflows - event destination selection workflow;;Events retrieval;;Events representation;;Query: SPARQL query to get the events;;Event Selection Workflow;;SparqlToCityQuery Transformer (1/2);;SparqlToCityQuery Transformer (2/2);;SparqlToCityQuery Transformer (2/2);;Event Identifier (2/2);;XML2RDF Tranformer (1/2);;XML2RDF Tranformer (2/2);;Execution optimization: Thread pooling;;Alpha Urban LarKC workflows - path finding workflow;;Input data: Street Topology in RDF;;Output data: path definition in RDF;;Query: SPARQL query to get the path;;Alpha Urban LarKC Path Finding Workflow ;;Identifier strategy;;OpResPathFinder Reasoner (1/2);;OpResPathFinder Reasoner (2/2);;Much more to come! Traffic aware pathfinding;;Much more to come! Korea Road Sign Management;;Much more to come! Urban Social Media Analytics;;Thank you! Questions?;;References'
12859,'lecture','en',12408,'2010-05-30','2010-07-02','Closing and Open Discussion',NULL,NULL
12860,'lecture','en',12408,'2010-05-31','2010-06-30','Real-time processing on intensive web streams',NULL,'Real-time processing on intensive streams;;Outline;;Overview of real-time processing research;;Motivation;;Introduction – Who?;;Introduction – What?;;Approaches;;Applications;;Application: Stock Monitoring;;Applications: Telecommunication Network Monitoring;;Application: Online Advertising for NYTimes (microtrends detection);;Application: Topic Tracking;;Application: Content recommendation system;;Design of a real-time processing system;;Objectives for a scalable real-time processing system;;Multimodal data;;Ontological background knowledge;;Top level QMiner architecture;;QMiner architecture for real-time recommendation;;Raw event data (web log);;Each event is enriched into multiple fields for indexing and querying;;Amazon Cloud services in use;;Figures for one day of data for NYTimes application;;Overall view;;Users query;;Pages query;;User data aggregation;;Scenario 1: C-Suits;;Example: Visiting page (1);;Example: Issues queries (1);;Graph (1);;Scenario 2: Female Market Multipliers;;Example: visited page (2);;Example: Issues queries (2);;Graph (2);;Final thoughts;;Books on Stream & Event processing;;Related Wikipedia Links;;Video Tutorials;;Future Challenges'
12861,'lecture','en',12408,'2010-05-31','2010-06-30','Logic-based ad-hoc business process management: Concepts and challenges ',NULL,'An approach for the semantic contextualization of the web advertisement process;;Use Case: Online Advertisement;;Online Advertisement;;Advertisement process;;Advertisement process: modeling dynamics (1);;Advertisement process: modeling dynamics (2);;Business process: modeling dynamics;;Overview;;Events in Advertising;;Events Patterns;;Event Modelling;;Selection of appropriate Semantic Context;;RDFa;;Contribution;;Related Work;;Future Work;;eswc2010_stojanovic_lbahbp_01_Page_17;;eswc2010_stojanovic_lbahbp_01_Page_18'
12862,'lecture','en',12408,'2010-05-31','2010-06-30','From Web 2.0 to Web 3.0 using Data Mining','Web 2.0 applications such as Flickr offer a rich set of data with a huge potential for exploitation by the human users.\nUnfortunately, the sifting through such data is far from easy and rewarding due to a lack of semantics on the one side and a\nlack of rich data description on the other side. For instance, most photos on Flickr have very little description attached that could be used for retrieving or exploring the photos. In this talk, we demonstrate how the enrichment of Web 2.0 data by automatically discovered (more or less) semantic relationships improves the user experience.\n\n','From Web 2.0 to Web 3.0 using Data Mining, Steffen Staab & Rabeeh Abbasi;;Web 2.0 Folksonomies ;;Why do you want to have a Semantic Web at all? (1);;Why do you want to have a Semantic Web at all? (2);;Why I want to have a Semantic Web!;;Why I want to have a Semantic Web! Intelligent queries;;Why I want to have a Semantic Web! Faceted Search & Browsing;;Is there a quantifiable benefit in Ontology Learning?;;Problems and Features of Folksonomies- Folksonomy (1);;Problems and Features of Folksonomies- Folksonomy (2);;Improving Search in Folksonomies - 1;;Search in Folksonomies;;Still many photos are unsearchable, because:;;Sparseness in Folksonomies - graph;;Simple Vector Space Model of a Folksonomy;;Discovering Semantically Related Tags;;Resource vs. User Context;;Semantically Related Tags – Tag Distribution (1);;Semantically Related Tags – Tag Distribution (2);;enRiched Vector Space Models for Folksonomies;;Examples – Context and Distribution of Tags;;Evaluation (1);;Evaluation (2);;Results – Sparse Results - 1 to 10 relevant resources ;;Results -11 to 50 relevant resources ;;Results – Large Result Set - More than 50 relevant resources;;Browsing (landmarks) in Folksonomies- 2a;;One prominent photo returned ;;Usage context: Faceted Browsing;;Finding Landmark Photos;;Building a Classifier;;SMV - classifier;;User Evaluation;;Semantic Browsing in Folksonomies - 2b;;Social Tagging Systems – Browsing?;;T-ORG – Classification;;T-ORG;;Classifying the tags using T-KNOW;;T-KNOW – Computing Similarity;;Experimental Setup;;Experimental Setup – Classifiers ;;Experimental Setup – Evaluation ;;Results – F-Measure;;Tag Recommendations in Folksonomies Simplifying the annotation process - 3;;Tag Recommendation (1);;Tag Recommendation (2);;Tag Recommendation (3);;Tag Recommendation (4);;Features Available in Large Datasets;;Tag Recommender – System Overview;;System Overview;;Clustering;;Identifying Representative Tags from Clusters;;Classification;;Evaluation;;Micro Precision;;Micro Recall;;Micro F-Measure;;Coverage;;Summary;;Lessons Learned;;A Castle half an hour away from Koblenz;;More details in:;;Thank you for your attention!'
12863,'lecture','en',12408,'2010-05-31','2010-06-30','An XML Schema and a Topic Map Ontology for Formalization of Background Knowledge in Data Mining ','Background (or sometimes referred to as domain) knowledge is extensively used in data mining for data pre-processing and for\nnugget-oriented data mining tasks: it is essential for constraining the\nsearch space and pruning the results. Despite the costs of eliciting background knowledge from domain experts, there has been so far little effort\nto devise a common exchange standard for its representation. This paper proposes the Background Knowledge Exchange Format (BKEF), a\nlightweight XML Schema for storing information on features and patterns, and the Background Knowledge Ontology (BKOn), as its semantic abstraction. The purpose of BKOn is to allow reasoning over and\nintegration of analysed data with existing domain ontologies. We show\nan elicitation interface producing BKEF and discuss the possibilities for\nintegration of such background knowledge with domain ontologies.','Background Knowledge in Data Mining;;Background Knowledge;;Design Objectives (1);;Design Objectives (2);;Basic Concepts;;BKEF;;BKOn;;BKEF, BKOn and Data Mining (1);;BKEF, BKOn and Data Mining (2);;Conclusions'
12864,'lecture','en',12408,'2010-05-31','2010-06-30','Importing Knowledge Fragments to CMS-Enabled Data Mining Analytical Reports','Descriptive data mining only brings its fruits when the results are provided\nto the end user in a palatable form. The vehicle for end-user delivery of mining\nresults (and associated information such as data schema, task settings, and domain background knowledge) are so-called analytical reports. In order to manage\na huge number of reports referring to different mining sessions, we designed a\ndata mining web portal based on a content management system, together called\nSEWEBAR-CMS.1 One of the requirements on the CMS was the ability to interact with semantic knowledge sources and other structured data, see [1].\nThe data analyst who authors an analytical report in the CMS has different\npossibilities of (semi-)automatically entering structured data into the text.\nFirst, for locally stored data such as mining task/result/data descriptions\nexported from mining tools in PMML (Predictive Model Mark-Up Language), a\nCMS plugin can pick marked segments of HTML code, produced from PMML\nusing XSLT, and insert them into the report as indicated by the analyst.\nSecond, sophisticated support for remote data/knowledge has been newly\nadded. The infrastructure for this functionality allows to persistently specify\n– Links to queriable resources\n– Template queries for these resources (which can be paramatrized by the\nend-user at runtime)\n– XSLT transformations allowing to insert the results of queries as HTML\nfragments, either static or dynamically updated from the resources.\nCurrently we experiment with queriable resources in the form of native XML\ndatabase (Berkeley, queried via XQuery), which stores PMML data, and semantic knowledge bases both in the form of SPARQL endpoint and Ontopia Knowledge Suite (a Topic Maps tool, queried via a Prolog-like language called tolog).\nInclusion of further types of resources such as Lucene indices is in progress.\n','Knowledge Base and CMS Integration;;Our Goals;;Our Approach;;Load Local Sources;;Remote Sources;;Analytical Report (1);;Analytical Report (2);;Status'
12865,'lecture','en',12408,'2010-05-31','2010-06-30','Towards a semantic foundation for bioinformatics','With a two and half thousand year tradition logic is the best understood way of\nrepresenting scientific knowledge. Only logic provides the semantic clarity necessary\nto ensure the comprehensibility, reproducibility, and free exchange of knowledge.\nThe use of logic is also necessary to enable computers to play a full part in science\n[1]. The semantic web is transforming the dissemination of science by making for the\nfirst time making a large amount of scientific knowledge available expressed in logic.\nBioinformatics is one of the undoubted successes stories of the semantic web, with\nbioinformatic knowledge making up a large percentage of the scientific semantic web.\nMany of the problems that make semantic web reasoning difficult don\'t apply to\nbioinformatics: a ground truth of scientific knowledge exists, top level ontologies\nhave been agreed (BFO), many other ontological standards exist, and the\nbioinformatic semantic web is large but not too large.\nThe use of bioinformatic software is essential to modern biology. However, there\nis a clear mismatch between the increasing use of the semantic web and logic, and the\nway bioinformatic systems utlilise and make inferences with this knowledge. This is\nbecause almost all computer based bioinformatic reasoning is done using ad hoc\nprograms. From a formal point of view these programs are invariably making logical\ninferences: deductions, abductions, inductions, with perhaps a probabilistic element.\nHowever, what exactly these inferences exactly are is generally unclear.\nThe aim of my research is to make these inferences clear and to express them in\nlogic, and make them executable across the semantic web.\n','Towards a Semantic Foundation For Bioinformatics;;The Formalization of Science;;The Semantic Web and Science;;Reasoning and the Semantic Web;;Bioinformatics and the Semantic Web;;Mismatch: Semantic Web V Bioinformatics;;The Idea;;Example: Protein Structure Prediction (1);;Example: Protein Structure Prediction (2);;Acknowledgments'
12867,'opening','en',12408,'2010-06-01','2010-06-30','Opening',NULL,'7th Extended Semantic Web Conference;;ESWC2010 People;;Participant Countries @ ESWC2009;;Participants across Continents;;PC Chairs;;ESWC2010 Eight Research Tracks;;ESWC2010 Submissions & Acceptance Rates;;A Truly International Conference;;Invited Speakers at the ESWC2010 (1);;Invited Speakers at the ESWC2010 (2);;Workshops Co-Chairs;;10 Workshops @ ESWC2010 (138 participants);;Tutorials Co-Chairs;;9 Tutorials @ ESWC2010 (81 participants);;PhD Symposium Co-Chairs;;PhD Symposium ;;Posters & Demos @ ESWC2010;;ESWC2010 Panel;;News from the Front: Latest results from 11 EU projects;;Semantic Web Technologies Co-ordinators;;More of the Organization Team;;Sponsors;;Social ESWC2010;;Have an Inspiring Conference!'
12868,'keynote','en',12408,'2010-06-01','2010-06-30','From Disasters to WoW: Using Web Science to understand and enable 21st century multidimensional networks','Recent advances in Web Science provide comprehensive digital traces of social actions, interactions, and transactions. These data provide an unprecedented exploratorium to model the socio-technical motivations for creating, maintaining, dissolving, and reconstituting multidimensional social networks. Multidimensional networks include multiple types of nodes (people, documents, datasets, tags, etc.) and multiple types of relationships (co-authorship, citation, web links, etc). Using examples from research in a wide range of activities such as disaster response, public health and massively multiplayer online games (WoW - the World of Warcraft), Contractor will argue that Web Science serves as the foundation for the development of theories and methods to help advance our ability to understand and enable multidimensional networks.','From Disasters to WoW: Using Web Science to understand and enable 21st century multidimensional networks;;Key Takeaways;;The Origins of Network Analysis;;Example;;Aphorisms about Networks;;Cognitive Knowledge Networks;;Emergent Structures in the Blogosphere by Language;;Generative Mechanisms;;Generative Mechanisms: Why do we create and sustain networks?;;“Structural signatures”;;Statistical “MRI” for Structural Signatures;;A contextual “meta-theory” of social drivers for creating and sustaining communities;;Projects Investigating Social Drivers for Communities;;Contextualizing Goals of Communities;;Multidimensional Networks in the Semantic Web;;Its all about “Relational Metadata”;;The Hubble telescope: $2.5 billion;;CERN particle accelerator: $1 billion/year;;The Web: priceless;;Computional Social Science;;Harvesting of Digital Relational Metadata;;eswc2010_contractor_fdtw_01_Page_22;;eswc2010_contractor_fdtw_01_Page_23;;Hurricane Katrina 2005;;SITREP Content;;Typical SITREP;;Human Coding Procedure;;Automatic Coding;;Time Slice 1: 8/23 to 8/25/2005;;Time Slice 1 to 2;;Time Slice 2: 8/26 to 8/27/2005;;Time Slice 2 to 3;;eswc2010_contractor_fdtw_01_Page_33;;eswc2010_contractor_fdtw_01_Page_34;;eswc2010_contractor_fdtw_01_Page_35;;eswc2010_contractor_fdtw_01_Page_36;;eswc2010_contractor_fdtw_01_Page_37;;eswc2010_contractor_fdtw_01_Page_38;;eswc2010_contractor_fdtw_01_Page_39;;Change in Network Centrality Rankings;;Projects Investigating Social Drivers for CommunitiesEntertainment;;Online and Offline;;Four Types of Relations in EQ2;;Data Description (1);;Data Description (2);;Results;;Projects Investigating Social Drivers for Communities;;Friendship in Second Life Teen Grid;;Data;;eswc2010_contractor_fdtw_01_Page_50;;From Understanding to Enabling Networks Move to Team Science;;Move to VirtualTeam Science;;Cyber-Community: A multidimensional network;;CI-KNOW: Harvesting the online community’s relational meta-data (1);;CI-KNOW: Harvesting the online community’s relational meta-data (2);;Semantic web enhanced recommending;;Semantic Web Integration Initial Test Bed;;Demo;;Summary;;Thank You;;eswc2010_contractor_fdtw_01_Page_61'
12869,'debate','en',12408,'2010-06-01','2010-07-13','Linked Data: Now what?','Since the Linked Data principles were first outlined we have witnessed an outstanding growth and heterogeneity of linked data publicly available on the Web, which has even managed to trigger the interest of large companies and governmental bodies world-wide. In the light of this evolution and given the current take up and expectations raised, we believe it is now time to reflect about the progress thus far and plan for the future challenges and opportunities that the Web of Data will bring to us. In this panel we shall discuss what has worked and what has not so far, and we shall try to identify what we should do and what we should not do in the future.',NULL
12870,'lecture','en',12408,'2010-06-02','2010-06-30','The Semantic Product Memory: An Interactive Black Box for Smart Objects','A semantic product memory stores a diary of an individual physical object in a persistent way on an embedded sensor system that is networked by wireless communication to a smart environment. The product monitors itself and its environment. Semantic technologies based on OWL ontologies guarantee interoperability of the product memory across the complete supply chain and lifecycle of smart objects and enable end user access to the product’s lifelog.\nIn this talk, we present the layered architecture together with the representation and inference formalisms used in our SemProM project, funded by the German Ministry of Education and Research (BMBF) with 16 Million Euro. SemProM goes well beyond traditional RFID technology and is the basis for intelligent automation in smart factories, event-driven logistics as well as smart retail and after-sales. Collecting information logs about objects in such smart environments and making it available - for example about an object’s origin, location, movements, physical properties, environmental conditions, usage history, as well as warranty and maintenance data - can help enterprises to improve their business processes and create new ones. Existing business process models become more accurate since information taken directly from the point of action can be used to manage or adapt processes in real time for the emerging Internet of Things.\nWe show how such embedded “black box” event recorders can transform everyday objects like cars, circuit boards, pizzas and drug blister packs into smart products. We show how consumers of smart products can access the lifelogs of products by NFC-enabled smartphones using SemProM’s browser and track the complete history of a product in multimodal dialogues. A role-based access control mechanism ensures privacy and security of the SemProM product memories. We will discuss fully operational pilot implementations of semantic product memories developed in the SemProM consortium together with major German companies like SAP, BMW, Siemens, DHL, Globus Retail and Kohl Pharma.','The Semantic Product Memory: An Interactive Black Box for Smart Objects;;The Future Semantic Web– Enabler for Semantic Business Networks;;From RFID to Smart Sensor Items: Identification and Monitoring;;The Semantic Product Memory:From Production to Consumption (1);;The Semantic Product Memory:From Production to Consumption (2);;The Semantic Product Memory:From Production to Consumption (2);;The Semantic Product Memory:From Production to Consumption (4);;The Semantic Product Memory:From Production to Consumption (3);;The Semantic Product Memory:From Production to Consumption (6);;The Semantic Product Memory:From Production to Consumption (4);;Open-loop Product Memories Require Semantic Technologies for Interoperability;;Simple Product Memories for Food Traceability ;;Domino’s Pizza Tracker for the Complete Order Status;;Tracking of Processes as a Consumer Obsession;;Outline of the Talk;;SemProM;;SemProM: Semantic Product Memories From Manufacturing to Retail and After-Sales;;Products with Integrated Dynamic Digital Storage, Sensing, and Wireless Communication Capabilities ;;DFKI’s Living Lab for AI and AutomationThe SmartFactory: Producing Bottled Soap in Dispensers;;Future Manufacturing in DFKI’s SmartFactory;;The Layered SemProM-Architecture;;Four Hardware Realizations of SemProMs;; Three SemProM Components;;Realtime Monitoring of Small and Large Containers;;SemProM in the logistics chain;;SemProM’s Fembot AILA;;DFKI’s Two-armed Robot AILA Reading Digital Product Memories ;;Checking the Oil Type and Storing the Oil Change Event in the Car’s Black Box;;Using the Semantic Product Memory in BMW Cars for Mobile Verification of Maintenance Materials ;;Tracking and Verification of the Exchange of a Breaking Unit during Car Maintenance;;The Memory Format of SemProM;;The General Part of the Semantic Product Memory;;The Specific Part of the Semantic Product Memory;;Basic SemProm Data Stored on Smart Labels (1);;Basic SemProm Data Stored on Smart Labels (2);;Cashierless Checkout with the Semantic Product Memory;;Using the Smart Key’s Shopping List for Checking the Shopping Basket In the Car;;Monitoring the Pizza Cool Chain in the Car;;Tracking the Temperature History for the Semantic Product Memory;;Augmented SUMO Ontologies for the SemProM Product Memories;;The Structure of the Semantic Product Memory;;Example for the Semantic Product Memory;;Browsing the Semantic Product Memory at the Fridge‘s Display at the Customer‘s Home;;The Innovative Retail Laboratory (IRL) of DFKI sponsored by the Globus Hypermarket Chain;;Information Security and Privacy can be guaranteed by Encrypted NF Communication;;SemProM Guarantees the Complete Backtracability of All Ingredients and Production Details;;Personal data on the Product;;Secure Role-Based Access to the Semantic Product ;;Using the nPA – the New Electronic Identity Card ;;Would you leave the semantic product memory intact on the product after you bought it?;;Acknowledgements;;Conclusions (1);;Conclusions (2);;Thank you ;;eswc2010_wahlster_tspm_01_Page_055;;eswc2010_wahlster_tspm_01_Page_056;;eswc2010_wahlster_tspm_01_Page_057;;eswc2010_wahlster_tspm_01_Page_058;;eswc2010_wahlster_tspm_01_Page_059;;eswc2010_wahlster_tspm_01_Page_060;;eswc2010_wahlster_tspm_01_Page_061;;eswc2010_wahlster_tspm_01_Page_062;;eswc2010_wahlster_tspm_01_Page_063;;eswc2010_wahlster_tspm_01_Page_064;;eswc2010_wahlster_tspm_01_Page_065;;eswc2010_wahlster_tspm_01_Page_066;;eswc2010_wahlster_tspm_01_Page_067;;eswc2010_wahlster_tspm_01_Page_068;;eswc2010_wahlster_tspm_01_Page_069;;eswc2010_wahlster_tspm_01_Page_070;;eswc2010_wahlster_tspm_01_Page_071;;eswc2010_wahlster_tspm_01_Page_072;;eswc2010_wahlster_tspm_01_Page_073;;eswc2010_wahlster_tspm_01_Page_074;;eswc2010_wahlster_tspm_01_Page_075;;eswc2010_wahlster_tspm_01_Page_076;;eswc2010_wahlster_tspm_01_Page_077;;eswc2010_wahlster_tspm_01_Page_078;;eswc2010_wahlster_tspm_01_Page_079;;eswc2010_wahlster_tspm_01_Page_080;;eswc2010_wahlster_tspm_01_Page_081;;eswc2010_wahlster_tspm_01_Page_082;;eswc2010_wahlster_tspm_01_Page_083;;eswc2010_wahlster_tspm_01_Page_084;;eswc2010_wahlster_tspm_01_Page_085;;eswc2010_wahlster_tspm_01_Page_086;;eswc2010_wahlster_tspm_01_Page_087;;eswc2010_wahlster_tspm_01_Page_088;;eswc2010_wahlster_tspm_01_Page_089;;eswc2010_wahlster_tspm_01_Page_090;;eswc2010_wahlster_tspm_01_Page_091;;eswc2010_wahlster_tspm_01_Page_092;;eswc2010_wahlster_tspm_01_Page_093;;eswc2010_wahlster_tspm_01_Page_094;;eswc2010_wahlster_tspm_01_Page_095;;eswc2010_wahlster_tspm_01_Page_096;;eswc2010_wahlster_tspm_01_Page_097;;eswc2010_wahlster_tspm_01_Page_098;;eswc2010_wahlster_tspm_01_Page_099;;eswc2010_wahlster_tspm_01_Page_100;;eswc2010_wahlster_tspm_01_Page_101;;eswc2010_wahlster_tspm_01_Page_102;;eswc2010_wahlster_tspm_01_Page_103;;eswc2010_wahlster_tspm_01_Page_104;;eswc2010_wahlster_tspm_01_Page_105;;eswc2010_wahlster_tspm_01_Page_106;;eswc2010_wahlster_tspm_01_Page_107;;eswc2010_wahlster_tspm_01_Page_108;;eswc2010_wahlster_tspm_01_Page_109;;eswc2010_wahlster_tspm_01_Page_110'
12871,'lecture','en',12408,'2010-06-03','2010-06-30','A Pattern Science for the Semantic Web','I will present the current state of play with respect to collecting, finding, classifying, and using (design) patterns on the semantic web. The talk will compare historically related work, highlight some successful stories and curious unexpected bottlenecks, and will envision some charming research and development directions from the Web of Data.','A Pattern Science for the Semantic Web;;What kind of talk to give as a dinner keynote? (1);;What kind of talk to give as a dinner keynote? (2);;What kind of talk to give as a dinner keynote? (3);;What kind of talk to give as a dinner keynote? (4);;So what?;;Outline;;The objects of an empirical science;;A science of patterns;;Patterns in general;;Signs of a knowledge pattern science?;;Introducing Qfwfq;;A simple ordinary task;;Semantic Web 2010;;Semantic Web 2020;;In other words;;Example 1;;The frame hypothesis (1/2);;The frame hypothesis (2/2);;Cognitive foundations;;A lexical frame;;Does it really understand?;;Frames we live by;;Frames we live by (1/5);;Frames we live by (2/5);;Frames we live by (3/5);;Frames we live by (4/5);;Frames we live by (5/5);;The Discussion frame from FrameNet;;The Place content pattern;;Sample frame-like structures;;Knowledge Pattern;;Practicality of knowledge patterns;;Isn’t KR enough?;;Design patterns;;Knowledge patterns;;Ontology patterns;;Ontology Design Patterns;;Example 2;;Example 3;;Logical patterns;;Reasoning patterns;;Content patterns;;Reengineering patterns;;Correspondence patterns;;Naming patterns;;Architectural patterns;;Anti-patterns;;Experimental evidence (1);;Experimental evidence (2);;eXtreme Design camp in Bologna;;Experimental evidence (3);;Experimental evidence (4);;Experimental evidence (5);;Methods, tools and initiatives (1);;Methods, tools and initiatives (2);;Research directions;;Conclusions'
12872,'lecture','en',12408,'2010-06-03','2010-06-30','SKOS: Past, Present, Future - and a little bit of history, architecture and engineering ','SKOS (Simple Knowledge Organisation System) is a common data model for sharing and linking knowledge organization systems via the Web. Many knowledge organization systems, such as thesauri, taxonomies, classification schemes and subject heading systems, share a similar structure, and are used in similar applications. SKOS captures much of this similarity and makes it explicit, enabling data and technology sharing across diverse applications.\nThe SKOS data model provides a standard, low-cost migration path for porting existing knowledge organization systems to the Semantic Web. SKOS also provides a light weight, intuitive language for developing and sharing new knowledge organization systems. It may be used on its own, or in combination with formal knowledge representation languages such as the Web Ontology language (OWL). SKOS was published as a W3C Recommendation in August 2009 and is seeing growing take-up in a number of fields including (among others) cultural heritage, economics, astronomy, and local government. SKOS also looks set to play a key role in providing vocabularies for the Data Web through its use in Open Linked Data.','SKOS: Past, Present Future;;The view from the twitterati;;SKOS (1);;SKOS (2);;Bridging the Gap;;Personal History;;What goes around comes around;;SKOS the Brave;;Midwifery;;Knowledge Organisation Systems;;SWAD Europe;;Sem Web Best Practices & Deployment;;Semantic Web Deployment;;SKOS Use Cases;;Bridge 77, Macclesfield Canal;;SKOS Goals;;Concepts vs Terms;;SKOS Example;;SKOS Model;;Labelling;;Documentation ;;Semantic Relations;;Mapping Relations;;Collections;;What’s not there?;;Stockport Viaduct;;Bricks all the way through;;SKOS and OWL;;Containment;;Ashness Bridge;;IVOA: A Bridge to the Stars;;IVOA Vocabularies;;IVOA Scenario;;IVOA ;;Europeana;;Examples: LCSH;;LCSH;;LCSH;;A happy ending: id.loc.gov;;RDFa;;Electronic Service Delivery (ESD);;ZBW Economics (1);;ZBW Economics (2);;ONKI:Finland;;Drupal, RDFa and SKOS;;SKOS as a Gateway Drug;;Tooling;;Union Chain Bridge;;SKOS and Linked Data;;sameAs vs mapping;;The Mancunian Way;;SKOS Namespace;;Transitivity of Semantic Relations;;skos:subject;;SKOS and OWL (1);;SKOS and OWL (2);;The Forth Rail Bridge;;Are we done yet?;;Postponed Issues;;Postponed in Last Call;;Who’s under there?;;Ogres;;W3C Library Linked Data Incubator;;Community Wiki;;SKOS;;Thanks!;;Image Sources;;Let’s grab one of these...;;…some of these…;;…and do this'
12873,'best paper','en',12408,'2010-06-03','2010-06-30','Awards and Closing',NULL,'ESCW Closing & Awards;;Best Paper Award;;Best Semantic Web In Use Paper Award;;Best PhD Symposium Paper Awards;;Best Demo Award;;Best Poster Award;;SEALS Best Evaluation Paper Award;;AI Mashup Challenge 2010 Sponsors;;AI Mashup Challenge 2010 ;;Award 1;;Award 2;;Award 3;;Award 4;;The #eswc2010 twitter factor;;Be the first to LikeESWC2010 Papers;;Video + Pictures;;Results from the Social Experiments;;Thanks to...;;Where next …;;ESWC2011 Team;;Sponsors'
12884,'opening','en',12579,'2010-06-03','2010-06-21','Opening Address',NULL,NULL
12885,'opening','en',12579,'2010-06-03','2010-06-21','Opening Address',NULL,NULL
12886,'keynote','en',12579,'2010-06-03','2010-06-21','New Security Challenges',NULL,NULL
12887,'introduction','en',12579,'2010-06-04','2010-06-21','Welcome',NULL,NULL
12888,'lecture','en',12579,'2010-06-04','2010-06-21','An Agenda for Human Rights',NULL,NULL
12889,'lecture','en',12579,'2010-06-04','2010-06-21','An Agenda for Human Rights',NULL,NULL
12890,'lecture','en',12579,'2010-06-04','2010-06-21','An Agenda for Human Rights',NULL,NULL
12891,'lecture','en',12579,'2010-06-04','2010-06-21','An Agenda for Human Rights',NULL,NULL
12892,'lecture','en',12579,'2010-06-04','2010-06-21','An Agenda for Human Rights',NULL,NULL
12893,'debate','en',12579,'2010-06-04','2010-06-21','Discussion',NULL,NULL
12894,'lecture','en',12579,'2010-06-04','2010-06-21','The UN Under Fire',NULL,NULL
12895,'lecture','en',12579,'2010-06-04','2010-06-21','The UN Under Fire',NULL,NULL
12896,'lecture','en',12579,'2010-06-04','2010-06-21','The UN Under Fire',NULL,NULL
12897,'lecture','en',12579,'2010-06-04','2010-06-21','The UN Under Fire',NULL,NULL
12898,'lecture','en',12579,'2010-06-04','2010-06-21','The UN Under Fire',NULL,NULL
12899,'debate','en',12579,'2010-06-04','2010-06-21','Discussion',NULL,NULL
12900,'lecture','en',12579,'2010-06-05','2010-06-21','Nuclear and Small Arms Proliferation',NULL,NULL
12901,'lecture','en',12579,'2010-06-05','2010-06-21','Nuclear and Small Arms Proliferation',NULL,NULL
12902,'lecture','en',12579,'2010-06-05','2010-06-21','Nuclear and Small Arms Proliferation',NULL,NULL
12903,'lecture','en',12579,'2010-06-05','2010-06-21','Nuclear and Small Arms Proliferation',NULL,NULL
12904,'lecture','en',12579,'2010-06-05','2010-06-21','Nuclear and Small Arms Proliferation',NULL,NULL
12905,'lecture','en',12579,'2010-06-05','2010-06-21','Conclusions',NULL,NULL
12906,'debate','en',12579,'2010-06-05','2010-06-09','Discussion',NULL,NULL
12907,'invited talk','en',12579,'2010-06-05','2010-06-21','What Price Security?',NULL,NULL
12910,'lecture','sl',12909,'2010-06-04','2010-06-24','Kdaj inovativna Slovenija?',NULL,NULL
12911,'lecture','sl',12909,'2010-06-04','2010-06-24','Kdaj inovativna Slovenija?',NULL,NULL
12912,'lecture','en',12909,'2010-06-04','2010-06-24','When innovative Slovenia?',NULL,NULL
12913,'lecture','sl',12909,'2010-06-04','2010-06-24','Inovativna Slovenija?',NULL,'Inovativna Slovenija?;;Aktivna RRI politika - prioriteta Vlade RS;;Zmanjšati zaostanke v inovacijski sposobnosti in unčinkovitosti vlaganj - 4 prioritete'
12914,'lecture','sl',12909,'2010-06-04','2010-06-24','NRRP: Nacionalni Raziskovalno Razvojni Program',NULL,'inovativna_slovenija2010_lah_turensek_nrrp_01_Page_1;;Osnutek za izhodišča NRRP;;Ustvarjalna Slovenija;;Cilji;;Strategija inovativnosti in ustvarjalnosti;;inovativna_slovenija2010_lah_turensek_nrrp_01_Page_5'
12915,'lecture','sl',12909,'2010-06-04','2010-06-24','NRRP: Nacionalni Raziskovalno Razvojni Program',NULL,'Jasna usmeritev;;Spodbuditi raziskovalno razvojne aktivnosti;;Združitev vseh sorodnih agencij;;Omogočiti bolj samostojno oblikovanje kadrovske in programske strategije;;Zahtevati in pričakovati;;inovativna_slovenija2010_lukac_nrrp_01_Page_6;;Vrednota;;Vizija'
12916,'lecture','sl',12909,'2010-06-04','2010-06-24','Nacionalni interes: Oblikovati in izpeljati strategijo jutrišnjih zmagovalcev',NULL,'Nacionalni interes: oblikovati in izpeljati strategijo jutrišnjih zmagovalcev;;Joseph Stiglitz-Freefall;;Veriga ustvarjanja vrednosti za produktivno intelektualno lastnino;;Učinek/vložen denar davkoplačevalcev;;Alma mater, avtonomija univerze;;inovativna_slovenija2010_kucan_nio_01_Page_06;;500 največjih podjetij v RS;;Vrednost znamk;;Nagrade \"red dot\" 2005-2010 za slovenska podjetja;;Primera Carving in Iskra nas nista izučila;;Razlika med dobrim in slabim svetovanjem;;Odkrivanje tople vode;;Vrtičkarstvo;;Predlogi Ursil - vizija;;Nujni ukrepi - 1;;Naloge skupine;;Nujni ukrepi - 2;;inovativna_slovenija2010_kucan_nio_01_Page_18'
12917,'lecture','sl',12909,'2010-06-04','2010-06-24','Razprava o inovativni Sloveniji',NULL,NULL
12918,'lecture','sl',12909,'2010-06-04','2010-06-24','Razvojne investicije v oblikovanje in R&R po industrijskih panogah',NULL,'Razvojne investicije '
12919,'lecture','sl',12909,'2010-06-04','2010-06-24','Znanost in tehnološki razvoj',NULL,'Znanost in tehnološki razvoj'
12920,'lecture','sl',12909,'2010-06-04','2010-06-24','Inovativna Slovenija',NULL,'Tehnologija kot moda'
12921,'lecture','sl',12909,'2010-06-04','2010-06-24','Iskanje pravih vzvodov za razvojno inovacijski preboj',NULL,'Iskanje pravih vzvodov za razvojno inovacijski preboj;;Dodana vrednost na zaposlenca ;;European Innovation Scoreboard;;Slika kaže dva bloka EU;;Edina rešitev;;inovativna_slovenija2010_kos_ipv_01_Page_6;;Inovacijska politika je podjetniška politika;;inovativna_slovenija2010_kos_ipv_01_Page_8;;inovativna_slovenija2010_kos_ipv_01_Page_9'
12922,'lecture','sl',12909,'2010-06-04','2010-06-24','Kvalitativna preobrazba EU gospodarstev',NULL,'Qualitative Transformation Of The EU Economies Towards Knowledge-Based Economy and Society'
12923,'lecture','sl',12909,'2010-06-04','2010-06-24','Večji izkoristek potenciala inovatorjev posameznikov',NULL,'Večji izkoristek potenciala inovatorjev posameznikov'
12924,'debate','sl',12909,'2010-06-04','2010-06-24','Javna razprava',NULL,NULL
12925,'lecture','sl',12909,'2010-06-04','2010-06-24','Zaključek',NULL,NULL
12956,'opening','en',12406,'2010-05-17','2010-06-21','Welcome Addresses',NULL,NULL
12957,'opening','en',12406,'2010-05-17','2010-06-21','Welcome Addresses',NULL,NULL
12958,'opening','en',12406,'2010-05-17','2010-06-21','Welcome Addresses',NULL,NULL
12959,'opening','en',12406,'2010-05-17','2010-06-21','Welcome Addresses',NULL,NULL
12960,'opening','en',12406,'2010-05-17','2010-06-21','Welcome Addresses',NULL,NULL
12961,'opening','en',12406,'2010-05-17','2010-06-21','Welcome Addresses',NULL,NULL
12963,'opening','en',12579,'2010-06-03','2010-06-21','Opening Address',NULL,NULL
12964,'debate','en',12408,'2010-06-01','2010-06-30','Linked Data: Now what?',NULL,'Linked Data: Now What?;;What was right;;Issues;;What should(n’t) we do;;Some design directions'
12965,'debate','en',12408,'2010-06-01','2010-07-13','Linked Data: Now what?',NULL,'Linked Data: Now What?;;Without Linked Data, no Semantic Web;;Remember 2005?;;Is there a Semantic Web beyond FOAF?;;http Range 14;;Consume the \"Wine\" ontology;;Linking Open Data ;;The LOD \"Cloud\" - May 2007;;The LOD \"Cloud\" - July 2007;;The LOD \"Cloud\" - August 2007;;The LOD \"Cloud\" - November 2007;;The LOD \"Cloud\" – Feb 2008;;The LOD \"Cloud\" – Sept 2008;;The LOD \"Cloud\" ;;What Worked?;;Clarity (1);;Clarity (2);;Shared Principles/Norms;;Action!;;What Isn\'t Working?;;Terminological Confusion (1);;Terminological Confusion (2);;Terminological Confusion (3);;Terminological Confusion (4);;Terminological Confusion (5);;Now What?;;Fundamental Requirements for uptake of Linked Data;;The \'Links\' in \'Linked Data\' (1);;The \'Links\' in \'Linked Data\' (2);;The \'Links\' in \'Linked Data\' (3);;The \'Links\' in \'Linked Data\' (4);;The \'Links\' in \'Linked Data\' (5);;The \'Links\' in \'Linked Data\' (6);;The \'Links\' in \'Linked Data\' (7);;The \'Links\' in \'Linked Data\' (8);;The \'Links\' in \'Linked Data\' (9);;The \'Links\' in \'Linked Data\' (10);;The \'Links\' in \'Linked Data\' (11);;The \'Links\' in \'Linked Data\' (12);;The \'Links\' in \'Linked Data\' (13);;The \'Links\' in \'Linked Data\' (14);;The Killer App Question (1);;The Killer App Question (2);;The Killer App Question (3);;The Killer App Question (4);;The Killer App Question (5);;The Killer App Question (6);;Discuss!;;eswc2010_heath_ldnw_01_Page_49;;eswc2010_heath_ldnw_01_Page_50;;eswc2010_heath_ldnw_01_Page_51;;eswc2010_heath_ldnw_01_Page_52;;eswc2010_heath_ldnw_01_Page_53;;eswc2010_heath_ldnw_01_Page_54;;eswc2010_heath_ldnw_01_Page_55;;eswc2010_heath_ldnw_01_Page_56;;eswc2010_heath_ldnw_01_Page_57;;eswc2010_heath_ldnw_01_Page_58;;eswc2010_heath_ldnw_01_Page_59;;eswc2010_heath_ldnw_01_Page_60'
12966,'debate','en',12408,'2010-06-01','2010-07-21','Linked Data: Now what?',NULL,'Linked Data: Now What?;;Mashing data;;Querying data;;Reasoning about data;;Gains for Social Network Research;;Gains for Semantic Web community;;Untested Conjecture;;eswc2010_contractor_ldnw_01_Page_8'
12967,'lecture','en',12408,'2010-06-01','2010-06-30',' Linked Data: Now what?',NULL,'LOD achievements and challenges;;Make the Web a Linked Data Washing Machine;;Creating a network effect for Linked Data: Semantic Pingback;;Linked Government Data -Ideal application scenario for Linked Data;;Discussion'
12968,'lecture','en',12408,'2010-06-01','2010-07-13','Linked Data: Now what?',NULL,'Linked Data: Now what?;;Panel without slides'
12984,'lecture','en',13165,'2010-06-04','2010-07-15','Verbmobile - A machine translation story',NULL,NULL
12999,'opening','sl',12927,'2010-06-11','2010-07-01','Nagovor ministra za šolstvo in šport',NULL,NULL
13000,'opening','sl',12927,'2010-06-11','2010-07-01','Nagovor ministra za visoko šolstvo, znanost in tehnologijo',NULL,NULL
13001,'opening','sl',12927,'2010-06-11','2010-07-01','Nagovor predsednika Vlade',NULL,NULL
13002,'lecture','sl',12927,'2010-06-11','2010-07-01','Razprava z ministrom za visoko šolstvo, znanost in tehnologijo in s predsednico ŠOSa',NULL,NULL
13003,'lecture','sl',12927,'2010-06-11','2010-07-01','Problematika študentov',NULL,NULL
13004,'lecture','sl',12927,'2010-06-11','2010-07-01','Problematika študentov',NULL,NULL
13005,'lecture','sl',12927,'2010-06-11','2010-07-01','Problematika študentov',NULL,NULL
13006,'lecture','sl',12927,'2010-06-11','2010-07-01','O problematiki študentov',NULL,NULL
13007,'debate','sl',12927,'2010-06-11','2010-07-01','Razprava o študentskih vprašanjih',NULL,NULL
13008,'lecture','en',12409,'2010-06-15','2010-07-19','Object-Graphs for Context-Aware Category Discovery','How can knowing about some categories help us to dis-\ncover new ones in unlabeled images? Unsupervised visual\ncategory discovery is useful to mine for recurring objects\nwithout human supervision, but existing methods assume\nno prior information and thus tend to perform poorly for\ncluttered scenes with multiple objects. We propose to lever-\nage knowledge about previously learned categories to en-\nable more accurate discovery. We introduce a novel object-\ngraph descriptor to encode the layout of object-level co-\noccurrence patterns relative to an unfamiliar region, and\nshow that by using it to model the interaction between\nan image’s known and unknown objects we can better de-\ntect new visual categories. Rather than mine for all cat-\negories from scratch, our method identifies new objects\nwhile drawing on useful cues from familiar ones. We eval-\nuate our approach on benchmark datasets and demonstrate\nclear improvements in discovery over conventional purely\nappearance-based baselines.','Object‐Graphs for Context‐Aware Category Discovery;;Motivation;;Existing approaches - 1;;Existing approaches - 2;;Our idea - 1;;Our idea - 2;;Context‐aware visual discovery;;Key Ideas;;Approach Overview;;Learn “Known” Categories;;Identifying Unknown Objects - 1;;Identifying Unknown Objects - 2;;Object‐Graphs - 1;;Object‐Graphs - 2;;Object‐Graphs - 3;;Object‐Graph matching - 1;;Object‐Graph matching - 2;;Clusters from region‐region affinities;;Object Discovery Accuracy - 1;;Object Discovery Accuracy - 2;;Comparison with State‐of‐the‐art;;Example Object‐Graphs;;Examples of Discovered Categories;;Collect‐Cut (poster Thursday);;Conclusions;;Category Retrieval Results;;cvpr2010_lee_ogca_01_Page_27;;cvpr2010_lee_ogca_01_Page_28;;cvpr2010_lee_ogca_01_Page_29;;cvpr2010_lee_ogca_01_Page_30;;cvpr2010_lee_ogca_01_Page_31'
13009,'lecture','en',12409,'2010-06-15','2010-07-19','Grouplet: A Structured Image Representation for Recognizing Human and Object Interactions','Psychologists have proposed that many human-object interaction\nactivities form unique classes of scenes. Recognizing\nthese scenes is important for many social functions. To\nenable a computer to do this is however a challenging task.\nTake people-playing-musical-instrument (PPMI) as an example;\nto distinguish a person playing violin from a person\njust holding a violin requires subtle distinction of characteristic\nimage features and feature arrangements that differentiate\nthese two scenes. Most of the existing image representation\nmethods are either too coarse (e.g. BoW) or\ntoo sparse (e.g. constellation models) for performing this\ntask. In this paper, we propose a new image feature representation\ncalled “grouplet”. The grouplet captures the\nstructured information of an image by encoding a number\nof discriminative visual features and their spatial configurations.\nUsing a dataset of 7 different PPMI activities,\nwe show that grouplets are more effective in classifying and\ndetecting human-object interactions than other state-of-theart\nmethods. In particular, our method can make a robust\ndistinction between humans playing the instruments and humans\nco-occurring with the instruments without playing.','Grouplet: A Structured Image Representation for Recognizing Human and Object Interactions;;Human-Object Interaction - 1;;Human-Object Interaction - 2;;Background: Human-Object Interaction ;;Background: Human-Object Interaction - 2;;Outline;;Outline;;Recognizing Human-Object Interaction is Challenging;;Grouplet: our intuition - 1;;Grouplet: our intuition - 2;;Outline;;Grouplet representation (e.g. 2-Grouplet) - 1;;Grouplet representation (e.g. 2-Grouplet) - 2;;Grouplet representation (e.g. 2-Grouplet) - 3;;Grouplet representation (e.g. 2-Grouplet) - 4;;Grouplet representation - 1;;Grouplet representation - 2;;Outline;;A “Space” of Grouplets - 1;;A “Space” of Grouplets - 2;;A “Space” of Grouplets - 3;;A “Space” of Grouplets - 4;;We only need discriminative Grouplets;;Obtaining discriminative grouplets for a class;;Using Grouplets for Classification;;Outline;;People-Playing-Musical-Instruments (PPMI) Dataset;;Recognition Tasks on People-Playing-Musical-Instruments (PPMI) Dataset;;Classification: Playing Different Instruments;;Classifying Playing vs. Not playing - 1;;Classifying Playing vs. Not playing - 2;;Detecting people playing musical instruments -1 ;;Detecting people playing musical instruments - 2;;Detecting people playing musical instruments - 3;;Examples of Mined Grouplets;;Conclusion;;Thanks to'
13010,'lecture','en',12409,'2010-06-15','2010-07-19','Modeling Mutual Context of Object and Human Pose in Human-Object Interaction Activities','Detecting objects in cluttered scenes and estimating articulated\nhuman body parts are two challenging problems in\ncomputer vision. The difficulty is particularly pronounced\nin activities involving human-object interactions (e.g. playing\ntennis), where the relevant object tends to be small or\nonly partially visible, and the human body parts are often\nself-occluded. We observe, however, that objects and human\nposes can serve as mutual context to each other – recognizing\none facilitates the recognition of the other. In this paper\nwe propose a new random field model to encode the mutual\ncontext of objects and human poses in human-object interaction\nactivities. We then cast the model learning task as a\nstructure learning problem, of which the structural connectivity\nbetween the object, the overall human pose, and different\nbody parts are estimated through a structure search\napproach, and the parameters of the model are estimated\nby a new max-margin algorithm. On a sports data set of six\nclasses of human-object interactions [12], we show that our\nmutual context model significantly outperforms state-of-theart\nin detecting very difficult objects and human poses.','Modeling Mutual Context of Object and Human Pose in Human-Object Interaction Activities;;Human-Object Interaction - 1;;Human-Object Interaction - 2;;Human-Object Interaction - 3;;Human-Object Interaction - 4;;Human-Object Interaction - 5;;Outline - 1;;Outline - 2;;Human pose estimation & Object detection - 1;;Human pose estimation & Object detection - 2;;Human pose estimation & Object detection - 3;;Human pose estimation & Object detection - 4;;Human pose estimation & Object detection - 5;;Human pose estimation & Object detection - 6;;Human pose estimation & Object detection - 7;;Context in Computer Vision - 1;;Context in Computer Vision - 2;;Outline;;Mutual Context Model Representation - 1;;Mutual Context Model Representation - 2;;Mutual Context Model Representation - 3;;Mutual Context Model Representation - 4;;Mutual Context Model Representation - 5;;Outline;;Model Learning - 1;;Model Learning - 2;;Model Learning - 3;;Model Learning - 4;;Model Learning - 5;;Model Learning - 6;;Model Learning - 7;;Model Learning - 8;;Learning Results - 1;;Learning Results - 2;;Outline;;Model Inference - 1;;Model Inference - 2;;Model Inference - 3;;Outline;;Dataset and Experiment Setup - 1;;Dataset and Experiment Setup - 2;;Object Detection Results - 1 ;;Object Detection Results - 2;;Dataset and Experiment Setup;;Human Pose Estimation Results - 1;;Human Pose Estimation Results - 2;;Human Pose Estimation Results - 3;;Dataset and Experiment Setup;;Activity Classification Results;;Conclusion;;Acknowledgment;;cvpr2010_fei_fei_mmco_01_Page_52;;cvpr2010_fei_fei_mmco_01_Page_53;;cvpr2010_fei_fei_mmco_01_Page_54'
13011,'lecture','en',12409,'2010-06-15','2010-07-19','The chains model for detecting parts by their context','Detecting an object part relies on two sources of information\n- the appearance of the part itself, and the context\nsupplied by surrounding parts. In this paper we consider\nproblems in which a target part cannot be recognized reliably\nusing its own appearance, such as detecting lowresolution\nhands, and must be recognized using the context\nof surrounding parts. We develop the ‘chains model’\nwhich can locate parts of interest in a robust and precise\nmanner, even when the surrounding context is highly variable\nand deformable. In the proposed model, the relation\nbetween context features and the target part is modeled in a\nnon-parametric manner using an ensemble of feature chains\nleading from parts in the context to the detection target. The\nmethod uses the configuration of the features in the image\ndirectly rather than through fitting an articulated 3-D model\nof the object. In addition, the chains are composable, meaning\nthat new chains observed in the test image can be composed\nof sub-chains seen during training. Consequently,\nthe model is capable of handling object poses which are\ninfrequent, even non-existent, during training. We test the\napproach in different settings, including object parts detection,\nas well as complete object detection. The results show\nthe advantages of the chains model for detecting and localizing\nparts of complex deformable objects.','The chains model for detecting parts by their context;;Goals & Intuition;;Examples & Generality;;The chains model;;Inference;;Training & probability estimation;;Chains & Stars;;Feature graph examples;;Results;;Buehler et al 2008;;Ferrari et al 2008 ;;Movies;;UIUC cars dataset;;Summary;;The End;;cvpr2010_karlinsky_cmdp_01_Page_16;;cvpr2010_karlinsky_cmdp_01_Page_17'
13012,'demonstration video','en',12409,'2010-06-15','2010-07-09','Poster Spotlights',NULL,'cvpr2010_spotlights6a_01;;Detecting and Sketching the Common;;High Performance Object Detection by Collaborative Learning of Joint Ranking of Granule Features;;Collaborative Learning of JRoG Features;;P-N Learning:Bootstrapping Binary Classifiers by Structural Constraints - 1;;P-N Learning:Bootstrapping Binary Classifiers by Structural Constraints - 2;;3D Scene Priors for Road Detection - 1;;3D Scene Priors for Road Detection - 2;;Toward Coherent Object Detection And Scene Layout Understanding - 1;;Toward Coherent Object Detection And Scene Layout Understanding - 2;;What is an object? - 1;;What is an object? - 2;;Fast and Globally Optimal 2D Human Detection with Loopy Graph Models;;Fast and Globally Optimal 2D Human Detection;;A theory of phase-sensitive rotation invariance with spherical harmonic and moment-based representations - 1;;A theory of phase-sensitive rotation invariance with spherical harmonic and moment-based representations - 2;;Multi-class Object Localization by Combining Local Contextual Interactions - 1;;Multi-class Object Localization by Combining Local Contextual Interactions - 2;;Automatic Discovery of Meaningful Object Parts with Latent CRFs - 1;;Automatic Discovery of Meaningful Object Parts with Latent CRFs - 2;;Exploiting Hierarchical Context on a Large Database of Object Categories ;;Exploiting Hierarchical Context;;Learning Appearance in Virtual Scenarios for Pedestrian Detection - 1;;Learning Appearance in Virtual Scenarios for Pedestrian Detection - 2'
13013,'lecture','en',12409,'2010-06-15','2010-07-19','Multimodal semi-supervised learning for image classification','In image categorization the goal is to decide if an image\nbelongs to a certain category or not. A binary classifier can\nbe learned from manually labeled images; while using more\nlabeled examples improves performance, obtaining the image\nlabels is a time consuming process.\nWe are interested in how other sources of information\ncan aid the learning process given a fixed amount of labeled\nimages. In particular, we consider a scenario where\nkeywords are associated with the training images, e.g. as\nfound on photo sharing websites. The goal is to learn a\nclassifier for images alone, but we will use the keywords\nassociated with labeled and unlabeled images to improve\nthe classifier using semi-supervised learning. We first learn\na strong Multiple Kernel Learning (MKL) classifier using\nboth the image content and keywords, and use it to score\nunlabeled images. We then learn classifiers on visual features\nonly, either support vector machines (SVM) or leastsquares\nregression (LSR), from the MKL output values on\nboth the labeled and unlabeled images.\nIn our experiments on 20 classes from the PASCAL\nVOC’07 set and 38 from the MIR Flickr set, we demonstrate\nthe benefit of our semi-supervised approach over only using\nthe labeled images. We also present results for a scenario\nwhere we do not use any manual labeling but directly learn\nclassifiers from the image tags. The semi-supervised approach\nalso improves classification accuracy in this case.','Multimodal semi-supervised learning for image classication;;Motivation and goal;;Goal of this work;;Overview of the talk;;Data sets of images with tags;;Flickr tags as textual features;;Combination of several visual features;;Learning scenarios using images with tags;;Supervised multimodal classication;;Results of multimodal classication on PASCAL VOC 2007;;Learning scenarios using images with tags;;Multimodal semi-supervised scenario;;Three-step learning process;;Experimental comparison;;Results of semi-supervised learning;;Learning scenarios using images with tags;;Weakly supervised scenario;;Weakly supervised setting;;Results on 18 classes of MIR Flickr;;Conclusion;;Multimodal semi-supervised learning for image classication'
13014,'lecture','en',12409,'2010-06-15','2010-07-19','What Helps Where - And Why? Semantic Relatedness for Knowledge Transfer','Remarkable performance has been reported to recognize\nsingle object classes. Scalability to large numbers of classes\nhowever remains an important challenge for today’s recognition\nmethods. Several authors have promoted knowledge\ntransfer between classes as a key ingredient to address this\nchallenge. However, in previous work the decision which\nknowledge to transfer has required either manual supervision\nor at least a few training examples limiting the scalability\nof these approaches. In this work we explicitly address\nthe question of how to automatically decide which information\nto transfer between classes without the need of any human\nintervention. For this we tap into linguistic knowledge\nbases to provide the semantic link between sources (what)\nand targets (where) of knowledge transfer. We provide a rigorous\nexperimental evaluation of different knowledge bases\nand state-of-the-art techniques from Natural Language Processing\nwhich goes far beyond the limited use of language\nin related work. We also give insights into the applicability\n(why) of different knowledge sources and similarity measures\nfor knowledge transfer.','What Helps Where –And Why? Semantic Relatedness for Knowledge Transfer;;Knowledge transfer for zero-shot object class recognition -1;;Knowledge transfer for zero-shot object class recognition - 2;;Attribute-based model - 1;;Attribute-based model - 2;;Direct similarity-based model - 1;;Direct similarity-based model - 2;;Direct similarity-based model - 3;;Outline;;Semantic Relatedness Measures - 1;;Semantic Relatedness Measures - 2;;Semantic Relatedness Measures - 3;;Semantic Relatedness Measures - 4;;Semantic Relatedness Measures - 5;;Semantic Relatedness Measures - 6;;Outline;;Experimental Setup;;Performance of supervised approach;;Querying class-attribute association - 1;;Querying class-attribute association - 2;;Querying class-attribute association - 3;;Querying class-attribute association - 4;;Mining attributes - 1;;Mining attributes - 2;;Mining attributes - 3;;Mining attributes - 4;;Mining attributes - 5;;Mining attributes - 6;;Outline;;Direct similarity-based model;;Direct Similarity;;Attributes vs. direct similarity;;Outline;;Conclusion - 1;;Conclusion - 2;;Conclusion - 3;;Thank you!'
13015,'lecture','en',12409,'2010-06-15','2010-07-19','Towards Semantic Embedding in Visual Vocabulary','Visual vocabulary serves as a fundamental component\nin many computer vision tasks, such as object recognition,\nvisual search, and scene modeling. While state-of-the-art\napproaches build visual vocabulary based solely on visual\nstatistics of local image patches, the correlative image labels\nare left unexploited in generating visual words. In this\nwork, we present a semantic embedding framework to integrate\nsemantic information from Flickr labels for supervised\nvocabulary construction. Our main contribution is a\nHidden Markov Random Field modeling to supervise feature\nspace quantization, with specialized considerations to\nlabel correlations: Local visual features are modeled as\nan Observed Field, which follows visual metrics to partition\nfeature space. Semantic labels are modeled as a Hidden\nField, which imposes generative supervision to the Observed\nField with WordNet-based correlation constraints as\nGibbs distribution. By simplifying the Markov property in\nthe Hidden Field, both unsupervised and supervised (label\nindependent) vocabularies can be derived from our framework.\nWe validate our performances in two challenging\ncomputer vision tasks with comparisons to state-of-the-arts:\n(1) Large-scale image search on a Flickr 60,000 database;\n(2) Object recognition on the PASCAL VOC database.','Towards Semantic Embedding in Visual Vocabulary;;Overview;;cvpr2010_ji_tsev_01_Page_03;;Introduction - 1;;Introduction - 2;;Introduction - 3;;Introduction - 4;;Introduction - 5;;Overview;;Building Patch-Labeling Correspondence -1;;Building Patch-Labeling Correspondence -2;;Building Patch-Labeling Correspondence - 3;;Building Patch-Labeling Correspondence - 4;;Building Patch-Labeling Correspondence - 5;;Building Patch-Labeling Correspondence - 6;;Overview;;Generative Semantic Embedding - 1;;Generative Semantic Embedding - 2;;Generative Semantic Embedding - 3;;Generative Semantic Embedding - 4;;Generative Semantic Embedding - 5;;Generative Semantic Embedding - 6;;Generative Semantic Embedding - 7;;Generative Semantic Embedding - 8;;Generative Semantic Embedding - 9;;Generative Semantic Embedding - 10;;Generative Semantic Embedding - 11;;Generative Semantic Embedding - 12;;Overview;;Experimental Comparisons - 1;;Experimental Comparisons - 2;;Experimental Comparisons - 3;;Overview;;Conclusion;;Thank you!'
13016,'demonstration video','en',12409,'2010-06-15','2010-07-19','Poster Spotlights',NULL,'Exploiting Monge Properties in Optimum Subwindow Search - 1;;Exploiting Monge Properties in Optimum Subwindow Search - 2;;Unified Tracking and Recognition with Rotation-Invariant Fast Features - 1;;Unified Tracking and Recognition with Rotation-Invariant Fast Features - 2;;Fast Polygonal Integration - 1;;Fast Polygonal Integration - 2;;Object Detection via Boundary Structure Segmentation - 1;;Object Detection via Boundary Structure Segmentation - 2;;Implicit Hierarchical Boosting for Multi-view Object Detection - 1;;Implicit Hierarchical Boosting for Multi-view Object Detection - 2;;Connecting Modalities: Semi-supervised Segmentation and Annotation of Images Using Unaligned Text Corpora;;Connecting Modalities;;Support Vector Regression for Multi-View Gait Recognition based on Local Motion Feature Selection;;Challenges and New Solutions to Multi-view Gait Recognition;;Integrated Pedestrian Classification and Orientation Estimation;;empty;;Multi-Cue Pedestrian Classification with Partial Occlusion Handling;;Multi-Cue Pedestrian Classification;;Model Globally, Match Locally: Efficient and Robust 3D Object Recognition - 1;;Model Globally, Match Locally: Efficient and Robust 3D Object Recognition - 2;;Visual Recognition and Detection under Bounded Computational Resources - 1;;Visual Recognition and Detection under Bounded Computational Resources - 2;;Talking Pictures: Temporal Grouping and Dialog-Supervised Person Recognition - 1;;Talking Pictures: Temporal Grouping and Dialog-Supervised Person Recognition - 2;;An Efficient Divide-and-Conquer Cascade for Nonlinear Object Detection - 1;;An Efficient Divide-and-Conquer Cascade for Nonlinear Object Detection - 2;;New Features and Insights for Pedestrian Detection - 1;;New Features and Insights for Pedestrian Detection - 2;;Efficient Rotation Invariant Object Detection using Boosted Random Ferns - 1;;Efficient Rotation Invariant Object Detection using Boosted Random Ferns - 2;;Fast and Robust Object Segmentation with the Integral Linear Classifier - 1;;Fast and Robust Object Segmentation with the Integral Linear Classifier - 2;;Segmenting Video Into Classes of Algorithm-Suitability - 1;;Segmenting Video Into Classes of Algorithm-Suitability - 2;;Latent Hierarchical Structural Learning for Object Detection - 1;;Latent Hierarchical Structural Learning for Object Detection - 2;;A Steiner tree approach to efficient object detection - 1;;A Steiner tree approach to efficient object detection - 2;;Cascaded Pose Regression - 1;;Cascaded Pose Regression - 2;;Free-Shape Subwindow Search for Object Localization - 1;;Free-Shape Subwindow Search for Object Localization - 2;;Improving web image search using query-relative classifiers - 1;;Improving web image search using query-relative classifiers - 2'
13017,'lecture','en',12409,'2010-06-16','2010-07-19','Common Visual Pattern Discovery via Spatially Coherent Correspondences',NULL,'Common Visual Pattern Discovery via Spatially Coherent Correspondences;;What is Common Visual Pattern?;;General Correspondence Problem;;Schematic Illustration of Our Approach;;Candidate Correspondences;;Dynamic Correspondence Graph;;Graph Density;;Graph Mode (Dense Subgraph);;Probabilistic Coordinate;;Graph Mode and Feature Mode;;Properties of Graph Mode;;Solution;;Relation Space Analysis;;Two Sampling Strategies;;Recover Correspondences;;Experiments & Results;;Exp‐A: Point Set Matching;;Exp‐A: Point Set Matching (cont);;Exp‐B: Image Matching;;Exp‐C: Near‐duplicate Image Retrieval;;Exp‐C: Near‐duplicate Image Retrieval (cont);;Summary & Future work;;Code;;Thank You'
13018,'lecture','en',12409,'2010-06-16','2010-07-19','Unsupervised Detection and Segmentation of Identical Objects','We address an unsupervised object detection and segmentation\nproblem that goes beyond the conventional assumptions\nof one-to-one object correspondences or modeltest\nsettings between images. Our method can detect and\nsegment identical objects directly from a single image or a\nhandful of images without any supervision. To detect and\nsegment all the object-level correspondences from the given\nimages, a novel multi-layer match-growing method is proposed\nthat starts from initial local feature matches and explores\nthe images by intra-layer expansion and inter-layer\nmerge. It estimates geometric relations between object entities\nand establishes ‘object correspondence networks’ that\nconnect matching objects. Experiments demonstrate robust\nperformance of our method on challenging datasets.','Unsupervised detection and segmentation of identical objets;;Motivation;;Motivation Related Work - 1;;Motivation Related Work - 2;;Motivation what if? - 1;;Motivation what if? - 2;;Motivation what if? - 3;;Our Contribution - 1;;Our Contribution - 2;;A Brief Overview;;Problem Decomposition;;Initial Matching - 1;;Initial Matching - 2;;Multi-Layering;;Multi-Layer Match-Growing;;Bayesian Formulation - 1;;Bayesian Formulation - 2;;Multi-Layer Match-Growing - 1;;Multi-Layer Match-Growing - 2;;Multi-Layer Match-Growing - 3;;Networking - 1;;Networking - 2;;Review Demo - 1;;Review Demo - 2;;Review Demo - 3;;Review Demo - 4;;Experiments;;Experiments #1 - 1;;Experiments #1 - 2;;Experiments #1 - 3;;Experiments #1 - 4;;Experiments #1 - 5;;Experiments #2;;Experiments #3;;Experiments #4;;Conclusion;;Thank you'
13019,'lecture','en',12409,'2010-06-16','2010-07-19','A Novel Riemannian Framework for Shape Analysis of 3D Objects','In this paper we introduce a novel Riemannian framework for shape analysis of parameterized surfaces. We\nderive a distance function between any two surfaces that\nis invariant to rigid motion, global scaling, and reparametrization. It is the last part that presents the main\ndifficulty. Our solution to this problem is twofold: (1) we\ndefine a special representation, called a q-map, to represent each surface, and (2) we develop a gradient-based algorithm to optimize over different re-parameterizations of\na surface. The second step is akin to deforming the mesh\non a fixed surface to optimize its placement. (This is different from the current methods that treat the given meshes as\nfixed.) Under the chosen representation, with the L2 metric, the action of the re-parametrization group is by isometries. This results in, to our knowledge, the first Riemannian distance between parameterized surfaces to have all\nthe desired invariances. We demonstrate this framework\nwith several examples using some toy shapes, and real data\nwith anatomical structures, and cropped facial surfaces. We\nalso successfully demonstrate clustering and classification\nof these objects under the proposed metric.','A NOVEL RIEMANNIAN FRAMEWORK FOR SHAPE ANALYSIS OF 3D OBJECTS;;PROBLEM INTRODUCTION;;MOTIVATION;;CURRENT METHODS;;PARAMETERIZED SURFACES MAIN ISSUE;;NEW REPRESENTATION OF SURFACES;;SHAPE ANALYSIS OF SURFACES;;DISTANCE BETWEEN SURFACES;;OPTIMIZATION PROBLEM OVER Г;;INITIALIZATION OF GRADIENT SEARCH;;INITIALIZATION OF GRADIENT SEARCH;;BRAIN STRUCTURE SURFACESLEFT PUTAMEN AND LEFT THALAMUS;;ADHD STUDYSINGLE STRUCTURE CLASSIFICATION;;ADHD STUDYMULTIPLE STRUCTURE CLASSIFICATION;;EXTENSION TO OTHER TYPES OF SURFACES;;QUADRILATERAL SURFACESIMAGE MATCHING - 1;;QUADRILATERAL SURFACESIMAGE MATCHING - 2;;HEMISPHERICAL SURFACESCROPPED FACES;;OPTIMAL PATHS BETWEEN SURFACES;;CONCLUSION AND FUTURE WORK;;THANK YOU'
13020,'lecture','en',12409,'2010-06-16','2010-07-19','Global and Efficient Self-Similarity for Object Classification and Detection','Self-similarity is an attractive image property which has recently\nfound its way into object recognition in the form of\nlocal self-similarity descriptors [5, 6, 14, 18, 23, 27] In this\npaper we explore global self-similarity (GSS) and its advantages\nover local self-similarity (LSS). We make three contributions:\n(a) we propose computationally efficient algorithms\nto extract GSS descriptors for classification. These\ncapture the spatial arrangements of self-similarities within\nthe entire image; (b) we show how to use these descriptors\nefficiently for detection in a sliding-window framework\nand in a branch-and-bound framework; (c) we experimentally\ndemonstrate on Pascal VOC 2007 and on ETHZ Shape\nClasses that GSS outperforms LSS for both classification\nand detection, and that GSS descriptors are complementary\nto conventional descriptors such as gradients or color.','Global and Efficient Self-Similarity for Object Classification and Detection;;Conventional Image Descriptors;;Self-Similarity vsConventional Descriptors[;;Local Self-Similarity Descriptors4;;Using Local Self-Similarity Descriptors;;Self-Similarity goes Global - 1;;Self-Similarity goes Global - 2;;Global Self-Similarity Tensor;;Problems with the GSS Tensor;;Outline;;Efficient Global Self-Similarity Tensor ;;Efficient Global Self-Similarity;;Patch Prototype Codebooks;;Global Self-Similarity Descriptors;;Self-Similarity Hybercubes;;SSHsfor Detection;;Efficient Computation of SSHs;;Efficient SubwindowSearch for SSH;;Experiments: Object classification;;Classification on the PASCAL 07 objects set;;Experiments: Object detection;;Detection Results;;Runtimes for Computing Descriptors;;Runtimes for Detection;;Global and Efficient Self-Similarity for Object Classification and DetectionCVPR;;Conclusion;;Thank you for your attention;;cvpr2010_deselaers_gess_01_Page_28'
13021,'demonstration video','en',12409,'2010-06-16','2010-07-19','Poster Spotlights',NULL,'Object Matching with A Locally Affine-Invariant Constraint - 1;;Object Matching with A Locally Affine-Invariant Constraint - 2;;Unsupervised Learning of Invariant Features Using Video - 1;;Unsupervised Learning of Invariant Features Using Video - 2;;RecognitionScale-Hierarchical 3D Object Recognition in Cluttered Scenes - 1;;RecognitionScale-Hierarchical 3D Object Recognition in Cluttered Scenes - 2;;Linked Edges as Stable Region Boundaries - 1;;Linked Edges as Stable Region Boundaries - 2;;RecognitionMany-to-one Contour Matching for Describing and Discriminating Object Shape;;RecognitionMany-to-one Contour Matching for Describing and Discriminating Object Shape - 2;;Multi-View Object Class Detection with a 3D Geometric Model - 1;;Multi-View Object Class Detection with a 3D Geometric Model - 2;;Fast Directional Chamfer Matching - 1;;Fast Directional Chamfer Matching - 2;;Scale-invariant heat kernel signatures for non-rigid shape recognition;;Scale-invariant heat kernel signatures;;Object Recognition as Ranking Holistic Figure-Ground Hypotheses - 1;;Object Recognition as Ranking Holistic Figure-Ground Hypotheses - 2;;Finding Nemo: Deformable Object Class Modelling using Curve Matching - 1;;Finding Nemo: Deformable Object Class Modelling using Curve Matching - 2;;Automatic Attribution of Ancient Roman Imperial Coins - 1;;cvpr2010_spotlights6a_01_Page_22;;Multiple Object Detection by Sequential Monte Carlo and Hierarchical Detection Network - 1;;Multiple Object Detection by Sequential Monte Carlo and Hierarchical Detection Network - 2;;Putting Local Features on a Manifold - 1;;Putting Local Features on a Manifold - 2'
13022,'lecture','en',12409,'2010-06-16','2010-07-19','Object Recognition by Discriminative Combinations of Line Segments and Ellipses',NULL,'Object Recognition by Discriminative Combinations of Line Segments and Ellipses;;Goals - 1;;Goals - 2;;Existing Approaches - 1;;Existing Approaches - 2;;tokensOur contour based approach -outline;;Constructing shape tokens;;Comparing shape tokens;;Learning category-specific codebook - 1;;Learning category-specific codebook - 2;;Learning category-specific codebook - 3;;Learning category-specific codebook - 4;;Learning category-specific codebook - 5;;Learning discriminative codeword combinations - 1;;Learning discriminative codeword combinations - 2;;Learning discriminative codeword combinations - 3;;Learning discriminative codeword combinations - 4;;Learning discriminative codeword combinations - 5;;Experimental Results –Weizmann horse;;Experimental Results –Graz-17;;Summary;;Thank you'
13023,'lecture','en',12409,'2010-06-16','2010-07-19','On Detection of Multiple Object Instances using Hough Transforms','To detect multiple objects of interest, the methods based\non Hough transform use non-maxima supression or mode\nseeking in order to locate and to distinguish peaks in Hough\nimages. Such postprocessing requires tuning of extra parameters\nand is often fragile, especially when objects of interest\ntend to be closely located. In the paper, we develop a\nnew probabilistic framework that is in many ways related to\nHough transform, sharing its simplicity and wide applicability.\nAt the same time, the framework bypasses the problem\nof multiple peaks identification in Hough images, and\npermits detection of multiple objects without invoking nonmaximum\nsuppression heuristics. As a result, the experiments\ndemonstrate a significant improvement in detection\naccuracy both for the classical task of straight line detection\nand for a more modern category-level (pedestrian) detection\nproblem.','On Detection of Multiple Object Instances using Hough Transforms;;Hough transforms;;Category-level object detection - 1;;Category-level object detection - 2;;Multiple lines detection;;Our framework - 1;;Our framework - 2;;Our framework - 3;;Probabilistic derivation - 1;;Probabilistic derivation - 2;;Probabilistic derivation - 3;;Probabilistic derivation - 4;;Greedy maximization for our energy;;Inference;;Results for pedestrians detection - 1;;Results for pedestrians detection - 2;;Results for lines detection;;Conclusion'
13024,'lecture','en',12409,'2010-06-16','2010-07-19','Cascade Object Detection with Deformable Part Models','We describe a general method for building cascade classifiers\nfrom part-based deformable models such as pictorial\nstructures. We focus primarily on the case of star-structured\nmodels and show how a simple algorithm based on partial\nhypothesis pruning can speed up object detection by\nmore than one order of magnitude without sacrificing detection\naccuracy. In our algorithm, partial hypotheses are\npruned with a sequence of thresholds. In analogy to probably\napproximately correct (PAC) learning, we introduce the\nnotion of probably approximately admissible (PAA) thresholds.\nSuch thresholds provide theoretical guarantees on the\nperformance of the cascade method and can be computed\nfrom a small sample of positive examples. Finally, we outline\na cascade detection algorithm for a general class of\nmodels defined by a grammar formalism. This class includes\nnot only tree-structured pictorial structures but also\nricher models that can represent each part recursively as a\nmixture of other parts.','Cascade Object Detection with Deformable Part Models;;What we do;;Speedup examples;;Star models;;Object hypothesis score - 1;;Object hypothesis score - 2;;Object hypothesis score - 3;;Object hypothesis score - 4;;Object hypothesis score - 5;;Object hypothesis score - 6;;Object hypothesis score - 7;;Object hypothesis score - 8;;Root location score - 1;;Root location score - 2;;Root location score - 3;;Object detection;;Our object models;;Star-cascade ingredients;;Star-cascade algorithm - 1;;Star-cascade algorithm - 2;;Star-cascade algorithm - 3;;Star-cascade algorithm - 4;;Star-cascade algorithm - 5;;Star-cascade algorithm - 6;;Star-cascade algorithm - 7;;Star-cascade algorithm - 8;;Star-cascade algorithm - 7;;Star-cascade algorithm - 10;;Star-cascade algorithm - 11;;Star-cascade algorithm - 12;;Star-cascade algorithm - 13;;Star-cascade algorithm - 14;;Star-cascade algorithm - 8;;Star-cascade algorithm - 9;;Star-cascade algorithm - 10;;Star-cascade algorithm - 11;;Star-cascade algorithm - 12;;Star-cascade algorithm - 13;;Star-cascade algorithm - 14;;Star-cascade algorithm - 15;;Star-cascade algorithm - 16;;Star-cascade algorithm - 17;;Star-cascade algorithm - 18;;Star-cascade algorithm - 19;;Star-cascade algorithm - 20;;Star-cascade algorithm - 21;;Star-cascade algorithm - 22;;Star-cascade algorithm - 23;;Star-cascade algorithm - 24;;Star-cascade algorithm - 25;;Star-cascade algorithm - 26;;Star-cascade algorithm - 27;;Threshold selection;;PAA thresholds;;Example results;;Simplified part models;;Grammar models;;Conclusion'
13025,'lecture','en',12409,'2010-06-16','2010-07-19','Food Recognition Using Statistics of Pairwise Local Features','Food recognition is difficult because food items are deformable\nobjects that exhibit significant variations in appearance.\nWe believe the key to recognizing food is to exploit\nthe spatial relationships between different ingredients\n(such as meat and bread in a sandwich). We propose a\nnew representation for food items that calculates pairwise\nstatistics between local features computed over a soft pixellevel\nsegmentation of the image into eight ingredient types.\nWe accumulate these statistics in a multi-dimensional histogram,\nwhich is then used as a feature vector for a discriminative\nclassifier. Our experiments show that the proposed\nrepresentation is significantly more accurate at identifying\nfood than existing methods.','Food Recognition Using Statistics of Pairwise Local Features;;Motivation;;Challenges for Food Recognition;;Related Work;;Our Framework - 1;;Our Framework - 2;;Our Framework - 3;;Labeling Image Pixels;;Our Framework - 1;;Our Framework - 2;;Image Representation – Pairwise Features - 1;;Image Representation – Pairwise Features - 2;;Image Representation – Pairwise Features - 3;;Image Representation – Pairwise Features - 4;;Image Representation – Pairwise Features - 5;;Geometric Relationship Representation - 1;;Geometric Relationship Representation - 2;;Geometric Relationship Representation - 3;;Geometric Relationship Representation - 4;;Geometric Relationship Representation - 5;;Geometric Relationship Representation - 6;;Our Framework;;Classification;;The Complete Framework;;Experiment – Dataset;;Experiment – Soft Labels;;Experiment – Classification;;Classification Results on 61 Categories - 1;;Classification Results on 61 Categories - 2;;Classification Results on 61 Categories - 3;;Classification Results on 7 Major Groups;;Pairwise Features for Scene Recognition - 1;;Pairwise Features for Scene Recognition - 2;;Conclusion;;Acknowledgements;;Q&A?'
13026,'demonstration video','en',12409,'2010-06-16','2010-07-19','Poster Spotlights',NULL,'Dominant Orientation Templates for Real-Time Detection of Texture-Less Objects - 1;;Dominant Orientation Templates for Real-Time Detection of Texture-Less ObjectsS - 2;;The Multiscale Competitive Code via Sparse Representation for Palmprint Verification - 1;;The Multiscale Competitive Code via Sparse Representation for Palmprint Verification - 2;;Learning a Probabilistic Model Mixing 3D and 2D Primitives for View Invariant Object Recognition - 1;;Learning a Probabilistic Model Mixing 3D and 2D Primitives for View Invariant Object Recognition - 2;;Dense Interest Points - 1;;Dense Interest Points - 2;;Two Perceptually Motivated Strategies for Shape Classification - 1;;Two Perceptually Motivated Strategies for Shape Classification - 2;;Large-scale image categorizationwith explicit data embedding - 1;;Large-scale image categorizationwith explicit data embedding - 2;;Probabilistic Models for Supervised Dictionary Learning - 1;;Probabilistic Models for Supervised Dictionary Learning - 2;;Use Bin-Ratio Information for Category and Scene Classification - 1;;Use Bin-Ratio Information for Category and Scene Classification - 2;;The Role of Features, Algorithms and Data in Visual Recognition - 1;;The Role of Features, Algorithms and Data in Visual Recognition - 2;;Global Gaussian Approachfor Scene Categorization Using Information Geometry - 1;;Global Gaussian Approachfor Scene Categorization Using Information Geometry - 2;;Asymmetric Region-to-Image Matching for Comparing Images with Generic Object Categories - 1;;Asymmetric Region-to-Image Matching for Comparing Images with Generic Object Categories - 2;;Attribute-Centric Recognition for Cross-Category Generalization - 1;;Attribute-Centric Recognition for Cross-Category Generalization - 2;;Person Re-Identification by Symmetry-Driven Accumulation of Local Features - 1;;Person Re-Identification by Symmetry-Driven Accumulation of Local Features - 2'
13027,'lecture','en',12409,'2010-06-17','2010-07-19','Proximate Sensing: Inferring What-Is-Where From Georeferenced Photo Collections',NULL,'Proximate Sensing:Inferring What-Is-Where From Georeferenced Photo Collections;;Remote sensing;;Proximate sensing : use ground-level - 1;;Proximate sensing : use ground-level - 2;;Proximate Sensing;;Proximate Sensing: Context;;VGI: Flickr;;VGI: Geograph;;Objective;;Related Work;;Overview;;Ground Truth - 1;;Ground Truth - 2;;Datasets - 1;;Datasets - 2;;Image Features;;Image Classification;;Experiments - 1;;Experiments - 2;;Experiments - 3;;Experiments - 4;;Results—Manually Labelled Training Set - 1;;Results—Manually Labelled Training Set - 2;;Results—Manually Labelled Training Set - 3;;Results—Weakly-Supervised Training - 1;;Results—Weakly-Supervised Training - 2;;Results—Photographer Intent - 1;;Results—Photographer Intent - 2;;Results—Photographer Intent - 3;;30Results—Importance of Training vs. Target Set - 1;;30Results—Importance of Training vs. Target Set - 2;;Results—Filtering Out Non-informative Images - 1;;Results—Filtering Out Non-informative Images - 2;;Discussion - 1;;Discussion - 2;;Extensions;;Come to our poster this afternoon;;Acknowledgements'
13028,'lecture','en',12409,'2010-06-17','2010-07-19','Detecting Text in Natural Scenes with Stroke Width Transform','We present a novel image operator that seeks to find the value\nof stroke width for each image pixel, and demonstrate its use on\nthe task of text detection in natural images. The suggested\noperator is local and data dependent, which makes it fast and\nrobust enough to eliminate the need for multi-scale computation\nor scanning windows. Extensive testing shows that the suggested\nscheme outperforms the latest published algorithms. Its\nsimplicity allows the algorithm to detect texts in many fonts and\nlanguages.',NULL
13029,'lecture','en',12409,'2010-06-17','2010-07-19','Reading Between The Lines: Object Localization Using Implicit Cues from Image Tags','Current uses of tagged images typically exploit only\nthe most explicit information: the link between the nouns\nnamed and the objects present somewhere in the image. We\npropose to leverage “unspoken” cues that rest within an\nordered list of image tags so as to improve object localization.\nWe define three novel implicit features from an image’s\ntags—the relative prominence of each object as signified\nby its order of mention, the scale constraints implied\nby unnamed objects, and the loose spatial links hinted by\nthe proximity of names on the list. By learning a conditional\ndensity over the localization parameters (position\nand scale) given these cues, we show how to improve both\naccuracy and efficiency when detecting the tagged objects.\nWe validate our approach with 25 object categories from\nthe PASCAL VOC and LabelMe datasets, and demonstrate\nits effectiveness relative to both traditional sliding windows\nas well as a visual context baseline.','READING BETWEEN THE LINES: OBJECT LOCALIZATION USING IMPLICIT CUES FROM IMAGE TAGS;;Detecting tagged objects - 1;;Detecting tagged objects - 2;;Our Idea - 1;;Our Idea - 2;;Our Idea - 3;;Approach overview - 1;;Approach overview - 2;;Feature: Word presence/absence - 1;;Feature: Word presence/absence - 2;;Feature: Rank of tags - 1;;Feature: Rank of tags - 2;;Feature: Proximity of tags;;Feature: Proximity of tags - 2;;Approach overview;;Modeling P(X|T) - 1;;Modeling P(X|T) - 2;;Modeling P(X|T) - 3;;Approach overview;;Integrating with object detector - 1;;Integrating with object detector - 2;;Integrating with object detector - 3;;Integrating with object detector - 4;;Experiments: Datasets;;Experiments;;PASCAL: Performance evaluation;;PASCAL: Accuracy vsGist per class - 1;;PASCAL: Accuracy vsGist per class - 2;;PASCAL: Example detections - 1;;PASCAL: Example detections - 2;;PASCAL: Example failure cases;;Results: Observations;;Summary;;Future work;;Summary'
13030,'lecture','en',12409,'2010-06-17','2010-07-19','Beyond Active Noun Tagging: Modeling Contextual Interactions for Multi-Class Active Learning','We present an active learning framework to simultaneously\nlearn appearance and contextual models for scene understanding\ntasks (multi-class classification). Existing multi-class active learning\napproaches have focused on utilizing classification uncertainty\nof regions to select the most ambiguous region for labeling. These\napproaches, however, ignore the contextual interactions between\ndifferent regions of the image and the fact that knowing the label\nfor one region provides information about the labels of other\nregions. For example, the knowledge of a region being sea is informative\nabout regions satisfying the “on” relationship with respect\nto it, since they are highly likely to be boats. We explicitly model\nthe contextual interactions between regions and select the question\nwhich leads to the maximum reduction in the combined entropy of\nall the regions in the image (image entropy). We also introduce a\nnew methodology of posing labeling questions, mimicking the way\nhumans actively learn about their environment. In these questions,\nwe utilize the regions linked to a concept with high confidence as\nanchors, to pose questions about the uncertain regions. For example,\nif we can recognize water in an image then we can use the region\nassociated with water as an anchor to pose questions such as\n“what is above water?”. Our active learning framework also introduces\nquestions which help in actively learning contextual concepts.\nFor example, our approach asks the annotator: “What is\nthe relationship between boat and water?” and utilizes the answer\nto reduce the image entropies throughout the training dataset and\nobtain more relevant training examples for appearance models.','Beyond Active Noun Tagging;;What this Talk is About - 1;;What this Talk is About - 2;;What this Talk is About - 3;;What this Talk is About - 4;;What this Talk is About - 5;;What this Talk is About - 6;;What this Talk is About - 7;;What this Talk is About - 8;;Introduction;;Active Learning - 1;;Active Learning - 2;;Active Learning - 3;;Active Learning : Multi-Class;;Active Learning : Scene Understanding;;Active Learning : Image Entropy - 1;;Active Learning : Image Entropy - 2;;Active Learning : Image Entropy - 3;;Active Learning : Image Entropy - 4;;Active Learning : Image Entropy - 5;;Active Learning : Image Entropy - 6;;Active Learning : Image Entropy - 7;;Active Learning : Image Entropy - 8;;Active Learning Framework - 1;;Active Learning Framework - 2;;Types of Questions - 1;;Types of Questions - 2;;Region Labeling Questions - 1;;Region Labeling Questions - 2;;Region Labeling Questions - 3;;Region Labeling Questions - 4;;Types of Questions;;Linguistic Questions - 1;;Linguistic Questions - 2;;Linguistic Questions - 3;;Linguistic Questions - 4;;Linguistic Questions - 5;;Linguistic Questions - 6;;Linguistic Questions: Expected Entropy Reduction - 1;;Linguistic Questions: Expected Entropy Reduction - 2;;Linguistic Questions: Expected Entropy Reduction - 3;;Types of Questions;;Contextual Questions - 1;;Contextual Questions - 2;;Contextual Questions - 3;;Contextual Questions: Expected Entropy Reduction;;Experiments;;Results: MSRC Dataset –Ground Truth Segmentations - 1;;Results: MSRC Dataset –Ground Truth Segmentations - 2;;Results: MSRC Dataset –Ground Truth Segmentations - 3;;Results: MSRC Dataset –Ground Truth Segmentations - 4;;Results: MSRC Dataset –Ground Truth Segmentations - 5;;Results: MSRC Dataset –Ground Truth Segmentations - 6;;Results: MSRC Dataset –Ground Truth Segmentations - 7;;Results: MSRC Dataset –Ground Truth Segmentations - 8;;Results: MSRC Dataset –Ground Truth Segmentations - 9;;Results: Sample Questions on the MSRC Dataset - 1;;Results: Sample Questions on the MSRC Dataset - 2;;Results: Sample Questions on the MSRC Dataset - 3;;Results: Sample Questions on the MSRC Dataset - 4;;Results: Sample Questions on the MSRC Dataset - 5;;Experiments;;Results:MSRC Dataset –Automatic Segmentations - 1;;Results:MSRC Dataset –Automatic Segmentations - 2;;Results:MSRC Dataset –Automatic Segmentations - 3;;Results:MSRC Dataset –Automatic Segmentations - 4;;Experiments: Stanford Dataset;;Results:Stanford Dataset - 1;;Results:Stanford Dataset - 2;;Results:Stanford Dataset - 3;;Summary;;Questions?'
13031,'demonstration video','en',12409,'2010-06-17','2010-07-19','Poster Spotlights',NULL,'ARISTA -Image Search to Annotation on Billions of Web Photos - 1;;ARISTA -Image Search to Annotation on Billions of Web Photos - 2;;Breaking the interactive bottleneck in multi-class classification with active selection and binary feedback;;Multi-class active learning with binary feedback;;Efficient Histogram-Based Sliding Window - 1;;Efficient Histogram-Based Sliding Window - 2;;Pareto-optimal Dictionaries for Signatures - 1;;Pareto-optimal Dictionaries for Signatures - 2;;Region Moments: Fast invariant descriptors for detecting small image structures - 1;;Region Moments: Fast invariant descriptors for detecting small image structures - 2;;Optimizing One-Shot Recognition with Micro-Set Learning - 1;;Optimizing One-Shot Recognition with Micro-Set Learning - 2;;Far-sighted Active Learning on a Budget for Image and Video Recognition - 1;;Far-sighted Active Learning on a Budget for Image and Video Recognition - 2;;Fast pattern matching using orthogonal Haar transform - 1;;Fast pattern matching using orthogonal Haar transform - 2;;One-Shot Multi-Set Non-rigid Feature-Spatial Matching - 1;;One-Shot Multi-Set Non-rigid Feature-Spatial Matching - 2;;Relaxing the 3L algorithm for an accurate implicit polynomial fitting - 1;;Relaxing the 3L algorithm for an accurate implicit polynomial fitting - 2;;Online Visual Vocabulary Pruning Using Pairwise Constraints - 1;;Online Visual Vocabulary Pruning Using Pairwise Constraints - 2;;Safety in Numbers: Learning Categories from Few Examples with Multi Model Knowledge Transfer - 1;;Safety in Numbers: Learning Categories from Few Examples with Multi Model Knowledge Transfer - 2;;Rapid and Accurate Developmental Stage Recognition of C. elegans from High-Throughput Image Data - 1;;Rapid and Accurate Developmental Stage Recognition of C. elegans from High-Throughput Image Data - 2'
13032,'lecture','en',12409,'2010-06-15','2010-07-19','Rectilinear Parsing of Architecture in Urban Environment',NULL,'Rectilinear Parsing of Architecture in Urban Environment;;Outline;;Introduction;;Motivation & Problem - 1;;Motivation & Problem - 2;;Motivation & Problem - 3;;Motivation & Problem - 4;;Overview;;Environment Parsing;;Pre-processing;;Building and Ground - 1;;Building and Ground - 2;;Building and Ground - 3;;Building and Ground - 4;;Building and Ground - 5;;Sky - 1;;Sky - 2;;Sky - 3;;Sky - 4;;Building Parsing;;Formulation - 1;;Formulation - 2;;Formulation - 3;;cvpr2010_zhao_rpau_01_Page_24;;Formulation - 3;;Formulation - 4;;Features: Height & Appearance;;Features: Intersections & Edge;;Dynamic Programming Optimization - 1;;Dynamic Programming Optimization - 2;;Dynamic Programming Optimization - 3;;Dynamic Programming Optimization - 4;;Dynamic Programming Optimization - 5;;Dynamic Programming Optimization - 6;;Dynamic Programming Optimization - 7;;Unit Refinement;;Unit Refinement - 1;;Unit Refinement - 2;;Unit Refinement - 3;;Unit Refinement - 4;;Unit Refinement - 5;;Unit Refinement - 6;;Experiments;;Results - 1;;Results - 2;;Limitations;;Conclusion;;Future work;;Thank You!'
13033,'lecture','en',12409,'2010-06-15','2010-07-19','Hybrid Multi-view Reconstruction by Jump-Diffusion','We propose a multi-view stereo reconstruction algorithm\nwhich recovers urban scenes as a combination of meshes\nand geometric primitives. It provides a compact model\nwhile preserving details: irregular elements such as statues\nand ornaments are described by meshes whereas regular\nstructures such as columns and walls are described by primitives\n(planes, spheres, cylinders, cones and tori). A Jump-\nDiffusion process is designed to sample these two types of\nelements simultaneously. The quality of a reconstruction\nis measured by a multi-object energy model which takes\ninto account both photo-consistency and semantic considerations\n(i.e. geometry and shape layout). The sampler is\nembedded into an iterative refinement procedure which provides\nan increasingly accurate hybrid representation. Experimental\nresults on complex urban structures and large\nscenes are presented and compared to multi-view based\nmeshing algorithms.','Hybrid Multi-view reconstruction by Jump-Diffusion;;Urban scene modeling - 1;;Urban scene modeling - 2;;Urban scene modeling - 3;;Hybrid representation - 1;;Hybrid representation - 2;;Hybrid representation - 3;;Hybrid representation - 4;;Hybrid representation - 5;;Hybrid representation - 6;;Contributions - 1;;Contributions - 2;;Contributions - 3;;System overview - 1;;System overview - 2;;System overview - 3;;Mesh segmentation;;Partitioning non-synthetic meshes - 1;;Partitioning non-synthetic meshes - 2;;Partitioning non-synthetic meshes - 3;;A multi-label MRF model - 1;;A multi-label MRF model - 2;;A multi-label MRF model - 3;;A multi-label MRF model - 4;;Interesting points - 1;;Interesting points - 2;;Interesting points - 3;;Hybrid sampling;;3D-objects and configuration space - 1;;3D-objects and configuration space - 2;;3D-objects and configuration space - 3;;3D-objects and configuration space - 4;;Energy formulation - 1;;Energy formulation - 2;;Energy formulation - 3;;Energy formulation - 4;;Energy formulation - 5;;Jump-Diffusion - 1;;Jump-Diffusion - 2;;Iterative refinement;;Primitive accumulation and mesh subdivision - 1;;Primitive accumulation and mesh subdivision - 2;;Experiments;;Facades and roofs - 1;;Facades and roofs - 2;;Facades and roofs - 3;;Rock sculture - 1;;Rock sculture - 2;;Comparison with mesh-based multi-view algorithms - 1;;Comparison with mesh-based multi-view algorithms - 2;;Comparison with mesh-based multi-view algorithms - 3;;Comparison with mesh-based multi-view algorithms - 4;;Comparison with mesh-based multi-view algorithms - 5;;Comparison with mesh-based multi-view algorithms - 6;;Other interesting points - 1;;Other interesting points - 2;;Conclusion;;Thank you !;;cvpr2010_lafarge_hmvr_01_Page_59'
13034,'lecture','en',12409,'2010-06-15','2010-07-19','Building Reconstruction using Manhattan-World Grammars','We present a passive computer vision method that\nexploits existing mapping and navigation databases in\norder to automatically create 3D building models. Our\nmethod defines a grammar for representing changes in\nbuilding geometry that approximately follow the\nManhattan-world assumption which states there is a\npredominance of three mutually orthogonal directions in\nthe scene. By using multiple calibrated aerial images, we\nextend previous Manhattan-world methods to robustly\nproduce a single, coherent, complete geometric model of a\nbuilding with partial textures. Our method uses an\noptimization to discover a 3D building geometry that\nproduces the same set of façade orientation changes\nobserved in the captured images. We have applied our\nmethod to several real-world buildings and have analyzed\nour approach using synthetic buildings.','Building Reconstruction using Manhattan-World Grammars;;Objective;;Applications;;Available Data - 1;;Available Data - 2;;Problem - 1;;Problem - 2;;Challenges ;;Challenges - 2;;Observation;;Our Approach - 1;;Our Approach - 2;;Our Approach - 3;;Our Approach - 4;;Our Approach - 5;;Our Approach - 6;;Our Approach - 7;;Our Approach - 8;;Contents - 1;;Contents - 2;;Previous Work - 1;;Previous Work - 2;;Previous Work - 3;;Contents;;Manhattan Building Grammar;;Building Representation - 1;;Building Representation - 2;;Rewriting System - 1;;Rewriting System - 2;;Rewriting System - 3;;Building Constraints;;Contents;;Building Reconstruction;;Signal Functions - 1;;Signal Functions - 2;;Signal Functions - 3;;Signal Functions - 4;;Signal Functions - 5;;Signal Functions - 6;;Signal Functions - 7;;Signal Functions - 8;;Signal Functions - 9;;Signal Functions - 10;;Signal Functions - 11;;Signal Functions - 12;;Signal Functions - 6;;Signal Functions - 7;;Signal Functions - 8;;Signal Functions - 9;;Signal Functions - 10;;Signal Functions - 11;;Signal Functions - 12;;Signal Functions - 13;;Signal Functions - 14;;Signal Functions - 15;;Signal Functions - 16;;Signal Functions - 17;;Signal Functions - 18;;Signal Functions - 19;;Signal Functions - 20 ;;Signal Functions - 21;;Signal Functions - 22;;Signal Functions - 23;;Refinement of floor contours - 1;;Refinement of floor contours - 2;;Refinement of floor contours - 3;;Refinement of floor contours - 4;;Refinement of floor contours - 5;;Refinement of floor contours - 6;;Contents;;Results - 1;;Results - 2;;Conclusions;;Future work and limitations;;Thank you!'
13035,'lecture','en',12409,'2010-06-15','2010-07-19','Estimating Camera Pose from a Single Urban Ground-View Omnidirectional Image and a 2D Building Outline Map','A framework is presented for estimating the pose of a\ncamera based on images extracted from a single omnidirectional\nimage of an urban scene, given a 2D map with\nbuilding outlines with no 3D geometric information nor appearance\ndata. The framework attempts to identify vertical\ncorner edges of buildings in the query image, which\nwe term VCLH, as well as the neighboring plane normals,\nthrough vanishing point analysis. A bottom-up process further\ngroups VCLH into elemental planes and subsequently\ninto 3D structural fragments modulo a similarity transformation.\nA geometric hashing lookup allows us to rapidly\nestablish multiple candidate correspondences between the\nstructural fragments and the 2D map building contours. A\nvoting-based camera pose estimation method is then employed\nto recover the correspondences admitting a camera\npose solution with high consensus. In a dataset that is even\nchallenging for humans, the system returned a top-30 ranking\nfor correct matches out of 3600 camera pose hypotheses\n(0.83% selectivity) for 50.9% of queries.','Estimating Camera Pose from a Single Urban Ground-View Omnidirectional Image and a 2D Building Outline Map;;Estimating Camera Pose from a Single Urban Ground-View Omnidirectional Image and a 2D Building Outline Map;;Urban Landmarks;;“Back-to-Basics” Map Reading!;;Related Work and Differences;;A Geometric Matching Paradigm;;2D Geometric Image Features;;2½D Geometric Image Features - 1;;2½D Geometric Image Features - 2;;2½D Geometric Image Features - 3;;Geometric Signatures –Uniqueness Analysis Under Ideal Conditions;;Overview of Localization Method;;Estimation of Quasi-Manhattan Vanishing Points;;Vertical Corner Line Hypothesis (VCLH);;Elemental Planes;;Structural Fragments;;More Examples;;Matching with Structural Fragments;;Matching Example with Structural Fragments;;Experiments - Dataset I;;Experiments –Dataset II;;Matching Results;;Dataset II Example Correct Matches;;Observations;;Concluding Remarks;;Credits;;cvpr2010_cham_ecps_01_Page_27;;cvpr2010_cham_ecps_01_Page_28;;cvpr2010_cham_ecps_01_Page_29'
13036,'demonstration video','en',12409,'2010-06-15','2010-07-09','Poster Spotlights',NULL,'Posture Invariant Surface Description and Feature Extraction;;Posture Invariant Feature Extraction;;Dense Non-rigid Surface Registration Using High-order Graph Matching - 1;;Dense Non-rigid Surface Registration Using High-order Graph Matching - 2;;Line Matching Leveraged by Point Correspondences - 1;;cvpr2010_spotlights2a_01_Page_06;;Detecting and Parsing Architecture at City Scale from Range Data;;Detecting and Parsing Architecture at City Scale;;Dynamic and Scalable Large Scale Image Reconstruction - 1;;Dynamic and Scalable Large Scale Image Reconstruction - 2;;Learning 3D Shape from a Single Facial Image via Non-linear Manifold Embedding and Alignment - 1;;Learning 3D Shape from a Single Facial Image via Non-linear Manifold Embedding and Alignment - 2;;Adaptive Pose Priors for Pictorial Structures;;Adaptive Pose Priors for PS;;A Game-Theoretic Approach to Fine Surface Registration without Initial Motion Estimation - 1;;A Game-Theoretic Approach to Fine Surface Registration without Initial Motion Estimation - 2;;Global and Local Isometry-Invariant Descriptor for 3D Shape Comparison and Partial Matching - 1;;Global and Local Isometry-Invariant Descriptor for 3D Shape Comparison and Partial Matching - 2;;Point-Based Non-Rigid Surface Registration with Accuracy Estimation - 1;;Point-Based Non-Rigid Surface Registration with Accuracy Estimation - 2;;3D Shape Correspondence by Isometry-Driven Greedy Optimization - 1;;3D Shape Correspondence by Isometry-Driven Greedy Optimization - 2;;On Growth and Formlets:Sparse Multi-Scale Coding of Planar Shape;;On Growth and Formlets;;Growing semantically meaningful models for visual SLAM - 1;;Growing semantically meaningful models for visual SLAM - 2;;Diffeomorphic Sulcal Shape Analysis for Cortical Surface Registration;;Sulcal Shape Analysis for Cortical Registration'
13037,'lecture','en',12409,'2010-06-15','2010-07-19','Monocular 3D Pose Estimation and Tracking by Detection','Automatic recovery of 3D human pose from monocular\nimage sequences is a challenging and important research\ntopic with numerous applications. Although current methods\nare able to recover 3D pose for a single person in controlled\nenvironments, they are severely challenged by realworld\nscenarios, such as crowded street scenes. To address\nthis problem, we propose a three-stage process building on\na number of recent advances. The first stage obtains an initial\nestimate of the 2D articulation and viewpoint of the person\nfrom single frames. The second stage allows early data\nassociation across frames based on tracking-by-detection.\nThese two stages successfully accumulate the available 2D\nimage evidence into robust estimates of 2D limb positions\nover short image sequences (= tracklets). The third and\nfinal stage uses those tracklet-based estimates as robust image\nobservations to reliably recover 3D pose. We demonstrate\nstate-of-the-art performance on the HumanEva II\nbenchmark, and also show the applicability of our approach\nto articulated 3D tracking in realistic street conditions.','Monocular 3D Pose Estimation and Tracking by Detection;;Motivation - 1;;Motivation - 2;;Towards Our Approach - 1;;Towards Our Approach - 2;;Towards Our Approach - 2;;Our Approach - 1;;Our Approach - 2;;Related Work;;Our Approach;;People Detection & 2D Pose Estimation;;Combining Pictorial Structures Models;;Results: Single-frame Detection - 1;;Results: Single-frame Detection - 2;;Results: Single-frame Detection - 3;;Results: Single-frame Viewpoint Estimation;;Our Approach;;2D Tracking;;Results: 2D Tracking;;Our Approach;;3D Pose Estimation;;3D Likelihood based on 2D tracklets;;3D Pose Inference;;3D Pose Estimation: Quantitative Results;;3D Pose Estimation: Qualitative Results;;Conclusions and Future Work;;See you at the Poster!'
13038,'lecture','en',12409,'2010-06-15','2010-07-19','Dynamical Binary Latent Variable Models for 3D Human Pose Tracking','We introduce a new class of probabilistic latent variable\nmodel called the Implicit Mixture of Conditional Restricted\nBoltzmann Machines (imCRBM) for use in human\npose tracking. Key properties of the imCRBM are as follows:\n(1) learning is linear in the number of training exemplars\nso it can be learned from large datasets; (2) it learns\ncoherent models of multiple activities; (3) it automatically\ndiscovers atomic “movemes”; and (4) it can infer transitions\nbetween activities, even when such transitions are not\npresent in the training set. We describe the model and how\nit is learned and we demonstrate its use in the context of\nBayesian filtering for multi-view and monocular pose tracking.\nThe model handles difficult scenarios including multiple\nactivities and transitions among activities. We report\nstate-of-the-art results on the HumanEva dataset.','Dynamical Binary Latent Variable Models for 3D Human Pose Tracking;;Prior Models of Human Pose and Motion;;Implicit Mixtures of CRBMs - 1;;Implicit Mixtures of CRBMs - 2;;Implicit Mixtures of CRBMs - 3;;Overview: Bayesian filtering with the imCRBM - 1;;Overview: Bayesian filtering with the imCRBM - 1;;Overview: Bayesian filtering with the imCRBM - 2;;Overview: Bayesian filtering with the imCRBM - 3;;Restricted Boltzmann Machines (RBM) - 1;;Restricted Boltzmann Machines (RBM) - 2;;Restricted Boltzmann Machines (RBM) - 3;;Conditional Restricted Boltzmann Machines (CRBM) - 1;;Conditional Restricted Boltzmann Machines (CRBM) - 2;;Conditional Restricted Boltzmann Machines (CRBM) - 3;;Conditional Restricted Boltzmann Machines (CRBM) - 4;;Implicit mixture of CRBMs (imCRBM) - 1;;Implicit mixture of CRBMs (imCRBM) - 2;;Implicit mixture of CRBMs (imCRBM) - 3;;Implicit mixture of CRBMs (imCRBM) - 4;;Advantages of the imCRBM;;Pose Tracking via Bayesian Filtering - 1;;Pose Tracking via Bayesian Filtering - 2;;Pose Tracking via Bayesian Filtering - 3;;Pose Tracking via Bayesian Filtering - 4;;Bayesian Filtering - 1;;Bayesian Filtering - 2;;Experiments;;Multi-view: HumanEva walking - 1;;Multi-view: HumanEva walking - 2;;Multi-view: HumanEva walking - 3;;Multi-view: Walking + Jogging with Transitions - 1;;Multi-view: Walking + Jogging with Transitions - 2;;Multi-view: Walking + Jogging with Transitions - 3;;Multi-view: Walking + Jogging with Transitions - 4;;Multi-view: Walking + Jogging with Transitions - 5;;Monocular tracking with transitions (imCRBM-2L);;Conclusions;;Acknowledgements'
13039,'lecture','en',12409,'2010-06-15','2010-07-19','Contour People: A Parameterized Model of 2D Articulated Human Shape','We define a new “contour person” model of the human\nbody that has the expressive power of a detailed 3D model\nand the computational benefits of a simple 2D part-based\nmodel. The contour person (CP) model is learned from a\n3D SCAPE model of the human body that captures natural\nshape and pose variations; the projected contours of this\nmodel, along with their segmentation into parts forms the\ntraining set. The CP model factors deformations of the body\ninto three components: shape variation, viewpoint change\nand part rotation. This latter model also incorporates a\nlearned non-rigid deformation model. The result is a 2D\narticulated model that is compact to represent, simple to\ncompute with and more expressive than previous models.\nWe demonstrate the value of such a model in 2D pose es-\ntimation and segmentation. Given an initial pose from a\nstandard pictorial-structures method, we refine the pose and\nshape using an objective function that segments the scene\ninto foreground and background regions. The result is a\nparametric, human-specific, image segmentation.','Contour People:A Parameterized Model of2D Articulated Human Shape;;2D generative models of humans;;Problem;;Possible solution: SCAPE;;Problem;;Goal: The best of both - 1;;Goal: The best of both - 2;;The Contour Person (CP) model;;Deformable template;;Deformation of a line segment - 1;;Deformation of a line segment - 2;;Deformation of a line segment - 3;;Deformation of a line segment - 4;;Deformation of T - 1;;Deformation of T - 2;;Deformation of T - 3;;Deformation of T - 3;;Deformation of T - 4;;Deformation of T - 5;;Deformation of T - 6;;Deformation of T - 7;;Factorization - 1;;Factorization - 2;;Factorization - 3;;Factorization - 4;;Factorization - 5;;Learning;;Shape training examples - 1;;Shape training examples - 2;;Shape training examples - 3;;Pose training examples - 1;;Pose training examples - 2;;Pose training examples - 3;;Camera training examples - 1;;Camera training examples - 2;;Camera training examples - 3;;Training set;;Principal Component Analysis - 1;;Principal Component Analysis - 2;;Principal Component Analysis - 3;;Eigen-shapes ;;Eigen-shapes - 2;;Eigen-shapes - 3;;Eigen-cameras - 1;;Eigen-cameras - 2;;Eigen-cameras - 3;;Pose:rigid+ non-rigiddeformations - 1;;Pose:rigid+ non-rigiddeformations - 2;;Pose:rigid+ non-rigiddeformations - 3;;Pose:rigid+ non-rigiddeformations - 4;;Synthesis;;Fitting CP to silhouettes;;Selected results;;Combine pose/shape estimation with segmentation;;Selected results;;Future work - 1;;Future work - 2;;Future work - 2;;Conclusions;;Acknowledgments'
13040,'lecture','en',12409,'2010-06-15','2010-07-19','Combining Discriminative and Generative Methods for 3D Deformable Surface and Articulated Pose Reconstruction','Historically non-rigid shape recovery and articulated\npose estimation have evolved as separate fields. Recent\nmethods for non-rigid shape recovery have focused on improving\nthe algorithmic formulation, but have only considered\nthe case of reconstruction from point-to-point correspondences.\nIn contrast, many techniques for pose estimation\nhave followed a discriminative approach, which allows\nfor the use of more general image cues. However, these\ntechniques typically require large training sets and suffer\nfrom the fact that standard discriminative methods do not\nenforce constraints between output dimensions. In this paper,\nwe combine ideas from both domains and propose a\nunified framework for articulated pose estimation and 3D\nsurface reconstruction. We address some of the issues of\ndiscriminative methods by explicitly constraining their prediction.\nFurthermore, our formulation allows for the combination\nof generative and discriminative methods into a\nsingle, common framework.','Combining Discriminative and Generative Methods for 3D Deformable Surface and Articulated Pose Reconstruction;;Non-Rigid Reconstruction;;Approaches for Deformable Shape Recovery;;Approaches for Articulated Pose Estimation;;Combining Generative and Discriminative;;Our Approach;;Discriminative Regression;;Discriminative Regression: Limitations;;Constrained Discriminative Regression - 1;;Constrained Discriminative Regression - 2;;Constrained Discriminative Regression - 3;;Constrained Discriminative Regression - 4;;Constrained Discriminative Regression - 5;;Constrained Discriminative Regression - 6;;Algorithm;;Better Use of the Predictor - 1;;Better Use of the Predictor - 2;;Poor Use od the Image;;Combining Generative and Discriminative;;Comparison with Previous Reconstructions;;Experimental Evaluation;;Reconstructing a Piece of Cardboard from 2D Locations - 1;;Reconstructing a Piece of Cardboard from 2D Locations - 2;;Comparison against State-of-the-art;;Non-Rigid Reconstruction from Pyramid HOG;;Recovering the Pose of a Hand;;Human Pose Estimation;;Conclusions - 1;;Conclusions - 2'
13042,'lecture','en',12409,'2010-06-16','2010-07-19','Visual Tracking Decomposition','We propose a novel tracking algorithm that can work robustly in a challenging scenario such that several kinds of\nappearance and motion changes of an object occur at the\nsame time. Our algorithm is based on a visual tracking decomposition scheme for the efficient design of observation\nand motion models as well as trackers. In our scheme, the\nobservation model is decomposed into multiple basic observation models that are constructed by sparse principal\ncomponent analysis (SPCA) of a set of feature templates.\nEach basic observation model covers a specific appearance\nof the object. The motion model is also represented by the\ncombination of multiple basic motion models, each of which\ncovers a different type of motion. Then the multiple basic trackers are designed by associating the basic observation models and the basic motion models, so that each specific tracker takes charge of a certain change in the object.\nAll basic trackers are then integrated into one compound\ntracker through an interactive Markov Chain Monte Carlo\n(IMCMC) framework in which the basic trackers communicate with one another interactively while run in parallel.\nBy exchanging information with others, each tracker further improves its performance, which results in increasing\nthe whole performance of tracking. Experimental results\nshow that our method tracks the object accurately and reliably in realistic videos where the appearance and motion\nare drastically changing over time.','Visual Tracking Decomposition;;Goal of Visual Tracking;;Real-World Scenarios;;Previous Works;;Bayesian Tracking Approach - 1;;Bayesian Tracking Approach - 2;;Compound Model;;Our Approach - 1;;Our Approach - 2;;Our Approach - 3;;Our Approach - 4;;Our Approach - 5;;Remaining Tasks - 1;;Remaining Tasks - 2;;Design of Basic Observation Models;;Object Model - 1;;Object Model - 2;;Object Model - 3;;Object Model - 4;;Basic Observation Model;;Design of Basic Motion Models;;Weights of Basic Models;;Experimental Results - 1;;Experimental Results - 2;;Abrupt Motions and Illumination Changes;;Illumination Changes and Pose Variations;;Occlusions and Pose Variations;;Background Clutters;;Quantitative Results;;Summary;;Thank you'
13043,'lecture','en',12409,'2010-06-16','2010-07-19','A Globally Optimal Data-Driven Approach for Image Distortion Estimation','Image alignment in the presence of non-rigid distortions\nis a challenging task. Typically, this involves estimating\nthe parameters of a dense deformation field that\nwarps a distorted image back to its undistorted template.\nGenerative approaches based on parameter optimization\nsuch as Lucas-Kanade can get trapped within local minima.\nOn the other hand, discriminative approaches like\nNearest-Neighbor require a large number of training samples\nthat grows exponentially with the desired accuracy. In\nthis work, we develop a novel data-driven iterative algorithm\nthat combines the best of both generative and discriminative\napproaches. For this, we introduce the notion of\na “pull-back” operation that enables us to predict the parameters\nof the test image using training samples that are\nnot in its neighborhood (not ε-close) in parameter space.\nWe prove that our algorithm converges to the global optimum\nusing a significantly lower number of training samples\nthat grows only logarithmically with the desired accuracy.\nWe analyze the behavior of our algorithm extensively using\nsynthetic data and demonstrate successful results on experiments\nwith complex deformations due to water and clothing.','A Globally Optimal Data-driven Approach for Image Distortion Estimation;;Distortions in the real world;;Problem statement - 1;;Problem statement - 2;;Distortion model;;Related work;;Spaceship returning to the Earth - 1;;Spaceship returning to the Earth - 2;;Spaceship returning to the Earth - 3;;Spaceship returning to the Earth - 4;;Spaceship returning to the Earth - 5;;Spaceship returning to the Earth - 6;;Similar operations for images - 1;;Similar operations for images - 2;;Similar operations for images - 3;;Similar operations for images - 4;;The three components of our algorithm;;NN in image vs. parameter space - 1;;NN in image vs. parameter space - 2;;The three components of our algorithm;;The pull-back operation H;;Non-invertible distortions;;The distribution of training samples;;Training sample distribution - 1;;Training sample distribution - 2;;Training sample distribution - 3;;Training sample distribution - 4;;Number of training samples;;Simulations;;Drift-free video tracking - 1;;Drift-free video tracking - 2;;Drift-free video tracking - 3;;Drift-free video tracking - 4;;Drift-free video tracking - 5;;Water distortions;;Bases for water distortion;;Correcting water distortions;;Video rectification/Surface reconstruction;;Video rectification;;Video tracking - 1;;Video tracking - 2;;Cloth deformation;;Cloth tracking;;Paper bending;;Summary;;Thank you!'
13044,'lecture','en',12409,'2010-06-16','2010-07-19','Tracking the Invisible: Learning Where the Object Might Be','Objects are usually embedded into context. Visual context\nhas been successfully used in object detection tasks,\nhowever, it is often ignored in object tracking. We propose a\nmethod to learn supporters which are, be it only temporally,\nuseful for determining the position of the object of interest.\nOur approach exploits the General Hough Transform\nstrategy. It couples the supporters with the target and naturally\ndistinguishes between strongly and weakly coupled\nmotions. By this, the position of an object can be estimated\neven when it is not seen directly (e.g., fully occluded or outside\nof the image region) or when it changes its appearance\nquickly and significantly. Experiments show substantial improvements\nin model-free tracking as well as in the tracking\nof “virtual” points, e.g., in medical applications.','Tracking the Invisible: Learning Where the Object Might be;;I’m Carl – Track me…;;Tracking Carl;;Goal: Estimate the Position of an Object - 1;;Goal: Estimate the Position of an Object - 2;;SUPPORTERS… - 1;;SUPPORTERS… - 2;;SUPPORTERS help Tracking of…;;Local Image Features as Supporters - 1;;Local Image Features as Supporters - 2;;Local Image Features as Supporters - 3;;Local Image Features as Supporters - 4;;Local Image Features as Supporters - 5;;Local Image Features as Supporters - 6;;Local Image Features as Supporters - 7;;Discovering the Supporters;;Model;;Implicit Shape Model;;Implicit Shape Model - Features;;Implicit Shape Model – Object Displacement;;Implicit Shape Model - 1;;Implicit Shape Model - 2;;Implicit Shape Model - 3;;„Model of Carl“ – Object Detection;;Model of Supporters;;Reliable Information & Motion Coupling;;Supporter;;Implementation / Approximations - 1;;Implementation / Approximations - 2;;Experimental Results: ETH-Cup Sequenze;;ETH-Cup: Humans;;ETH-Cup: Of the Web Tracker;;ETH-Cup: Our Result – Voting Space;;ETH-Cup: Improving Object Tracking;;ETH-Cup: Supportes;;ETH-Cup: Supporters;;Beyond the Image;;Changing Supporter;;Appearance Change;;Coupled Motion;;Changing Supporters;;Obviously, there are failure cases… …. and magician knows that.;;Conclusions;;Look for SUPPORTERS!'
13045,'lecture','en',12409,'2010-06-16','2010-07-19','Motion Detail Preserving Optical Flow Estimation','We discuss the cause of a severe optical flow estimation problem that fine motion structures cannot always be\ncorrectly reconstructed in the commonly employed multi-scale variational framework. Our major finding is that significant and abrupt displacement transition wrecks small-scale motion structures in the coarse-to-fine refinement. A\nnovel optical flow estimation method is proposed in this\npaper to address this issue, which reduces the reliance of\nthe flow estimates on their initial values propagated from\nthe coarser level and enables recovering many motion details in each scale. The contribution of this paper also includes adaption of the objective function and development\nof a new optimization procedure. The effectiveness of our\nmethod is borne out by experiments for both large- and\nsmall-displacement optical flow estimation.','Motion Detail Preserving Optical Flow Estimation;;Conventional Optical Flow;;Large Displacement Optical Flow;;Both Large and Small Motion Exist;;Our Work;;Outline;;The Multi-scale Problem - 1;;The Multi-scale Problem - 2;;The Multi-scale Problem - 3;;The Multi-scale Problem - 4;;The Multi-scale Problem - 5;;Extended Flow Initialization - 1 ;;Extended Flow Initialization - 2;;Extended Flow Initialization - 3;;Extended Flow Initialization - 4;;Extended Flow Initialization - 5;;Outline;;Data Constraints;;Problems - 1;;Problems - 2;;Our Proposal;;Comparisons;;Outline;;Energy Functions and Solver;;Mean Field Approximation - 1;;Mean Field Approximation - 2;;Mean Field Approximation - 3;;Algorithm Skeleton;;Results;;Middlebury Dataset;;Results from Different Steps - 1;;Results from Different Steps - 2;;Large Displacement - 1;;Large Displacement - 2;;Comparison;;More Results - 1;;More Results - 2;;More Results - 3;;More Results - 4;;Conclusion;;Thank you!;;cvpr2010_xu_mdpo_01_Page_42'
13046,'demonstration video','en',12409,'2010-06-16','2010-07-19','Poster Spotlights',NULL,'Modeling Pixel Process with Scale Invariant Local Patterns for Background Subtraction in Complex Scenes - 1;;Modeling Pixel Process with Scale Invariant Local Patterns for Background Subtraction in Complex Scenes - 2;;Real-Time Tracking of Multiple Occluding Objects using Level Sets - 1;;Real-Time Tracking of Multiple Occluding Objects using Level Sets - 2;;Visual Tracking via Weakly Supervised Learning from Multiple Imperfect Oracles - 1;;Visual Tracking via Weakly Supervised Learning from Multiple Imperfect Oracles - 2;;Warping Background SubtractionTeresa - 1;;Warping Background SubtractionTeresa - 2;;Free-Form Mesh Tracking: A Patch-Based Approach - 1;;Free-Form Mesh Tracking: A Patch-Based Approach - 2;;Trajectory Matching from Unsynchronized Videos - 1;;Trajectory Matching from Unsynchronized Videos - 2;;Rapid Selection of Reliable Templates for Visual Tracking - 1;;Rapid Selection of Reliable Templates for Visual Tracking - 2;;Generalized Simultaneous Registration and Segmentation - 1;;Generalized Simultaneous Registration and Segmentation - 2;;A Probabilistic Framework for Joint Segmentation and Tracking - 1;;A Probabilistic Framework for Joint Segmentation and Tracking - 2;;Probabilistic 3D Occupancy Flow with Latent Silhouette Cues - 1;;Probabilistic 3D Occupancy Flow with Latent Silhouette Cues - 2;;Online Multiple Instance Learning with No Regret - 1;;Online Multiple Instance Learning with No Regret - 2;;Dynamic Surface Matching by Geodesic Mapping for 3D Animation Transfer - 1;;Dynamic Surface Matching by Geodesic Mapping for 3D Animation Transfer - 2'
13047,'lecture','en',12409,'2010-06-16','2010-07-19','What\'s going on? Discovering Spatio-Temporal Dependencies in Dynamic Scenes','We present two novel methods to automatically learn\nspatio-temporal dependencies of moving agents in complex\ndynamic scenes. They allow to discover temporal rules,\nsuch as the right of way between different lanes or typical\ntraffic light sequences. To extract them, sequences of\nactivities need to be learned. While the first method extracts\nrules based on a learned topic model, the second\nmodel called DDP-HMM jointly learns co-occurring activities\nand their time dependencies. To this end we employ Dependent\nDirichlet Processes to learn an arbitrary number\nof infinite Hidden Markov Models. In contrast to previous\nwork, we build on state-of-the-art topic models that allow\nto automatically infer all parameters such as the optimal\nnumber of HMMs necessary to explain the rules governing\na scene. The models are trained offline by Gibbs Sampling\nusing unlabeled training data.','What’s going on?;;Dynamic Scene Analysis;;Applications;;Finding spatio-temporal rules, approach overview;;Finding local rules, two stage approach (1);;Finding global rules, joint approach (1);;Finding local rules, two stage approach;;Low level representation (1);;Low level representation (2);;Finding local rules, two stage approach[;;Model for Activities;;Hierarchical Dirichlet Processes (HDP);;Activities found by HDP, all activities;;Activities found by HDP, clips for activity 1;;Activities found by HDP, clips for activity 2;;Finding local rules, two stage approach (2);;Finding local rules, two stage approach (3);;Finding local rules, two stage approach (4);;Finding local rules, two stage approach (5);;Finding local rules, blocking rule;;Finding local rules, traffic light rule;;Finding global rules, joint approach (2);;Finding global rules, joint approach (3);;Finding global rules, joint approach (4);;Finding global rules, joint approach (5);;Finding global rules, joint approach (6);;Finding global rules, joint approach (7);;Finding global rules, joint approach (8);;Joint Model (DDP-HMM) Summary;;Joint model result, traffic light controlled scene (1);;Joint model result, traffic light controlled scene (2);;Joint model result, comparison;;Joint model result, larger traffic light controlled scene;;Joint model result, stochastic scene;;Conclusion;;Thank you for your attention'
13048,'lecture','en',12409,'2010-06-16','2010-07-19','Visual Event Recognition in Videos by Learning from Web Data','We propose a visual event recognition framework for\nconsumer domain videos by leveraging a large amount of\nloosely labeled web videos (e.g., from YouTube). First,\nwe propose a new aligned space-time pyramid matching\nmethod to measure the distances between two video clips,\nwhere each video clip is divided into space-time volumes\nover multiple levels. We calculate the pair-wise distances\nbetween any two volumes and further integrate the information\nfrom different volumes with Integer-flow Earth Mover’s\nDistance (EMD) to explicitly align the volumes. Second,\nwe propose a new cross-domain learning method in order\nto 1) fuse the information from multiple pyramid levels and\nfeatures (i.e., space-time feature and static SIFT feature)\nand 2) cope with the considerable variation in feature distributions\nbetween videos from two domains (i.e., web domain\nand consumer domain). For each pyramid level and\neach type of local features, we train a set of SVM classifiers\nbased on the combined training set from two domains\nusing multiple base kernels of different kernel types and\nparameters, which are fused with equal weights to obtain\nan average classifier. Finally, we propose a cross-domain\nlearning method, referred to as Adaptive Multiple Kernel\nLearning (A-MKL), to learn an adapted classifier based on\nmultiple base kernels and the prelearned average classifiers\nby minimizing both the structural risk functional and\nthe mismatch between data distributions from two domains.\nExtensive experiments demonstrate the effectiveness of our\nproposed framework that requires only a small number of\nlabeled consumer videos by leveraging web data.','Visual Event Recognition in Videos by Learning from Web Data;;Outline;;Overview, GOAL (1);;Overview, GOAL (2);;Overview, Flowchart of the system;;Similarity between Videos, Pyramid matching methods;;Similarity between Videos (1);;Similarity between Videos, Aligned Space-Time Pyramid Matching;;Similarity between Videos (2);;Similarity between Videos (3);;Cross-Domain Problem (1);;Cross-Domain Problem (2);;Cross-Domain Problem (3);;Cross-Domain Problem (4);;Cross-Domain Problem (5);;Cross-Domain Problem (6);;Experiments, Data set;;Experiments, Two types of features;;Experiments (1);;Experiments (2);;Experiments (3);;Experiments (4);;Conclusion;;References (1);;References (2);;Thank you'
13050,'lecture','en',12409,'2010-06-16','2010-07-19','Anomaly Detection in Crowded Scenes','A novel framework for anomaly detection in crowded\nscenes is presented. Three properties are identified as important\nfor the design of a localized video representation\nsuitable for anomaly detection in such scenes: 1) joint modeling\nof appearance and dynamics of the scene, and the\nabilities to detect 2) temporal, and 3) spatial abnormalities.\nThe model for normal crowd behavior is based on mixtures\nof dynamic textures and outliers under this model are\nlabeled as anomalies. Temporal anomalies are equated to\nevents of low-probability, while spatial anomalies are handled\nusing discriminant saliency. An experimental evaluation\nis conducted with a new dataset of crowded scenes,\ncomposed of 100 video sequences and five well defined abnormality\ncategories. The proposed representation is shown\nto outperform various state of the art anomaly detection\ntechniques.',' Anomaly Detection in Crowded Scenes;;Anomaly Detection;;Defining ;;Another type …;;Modeling the video;;Mixture of dynamic textures;;Temporal anomaly detection;;Spatial anomaly detection;;MDT for saliency;;Approximation…;;Computing the saliency;;Learning a mixture model;;Integrated Anomaly Map;;UCSD Anomaly Dataset;;Evaluation Procedure;;Experiments;;Results ;;Results …;;More examples : MDT;;ROC - Peds1, ROC – Peds2;;Anomaly Localization : Accuracy;;Conclusion;;Thank you!, visit our poster - F4, Questions;;Video results : bike;;Video results : another cart;;One more;;MDT, SF+ MPPCA;;FAQs'
13051,'demonstration video','en',12409,'2010-06-16','2010-07-19','Poster Spotlights',NULL,'Illumination Compensation Based Change Detection Using Order Consistency;;Problem & Motivation, Contributions, Sample;;Efficient Action Spotting Based on a Spacetime Oriented Structure Representation;;Goal, Challenges, Approach;;Cross-Dataset Action Detection;;Cross-Dataset Action Detection - Abstract;;Learning 3D Action Models from a few 2D videos;;Learning 3D Action Models from a few 2D videos - Abstract;;Exploiting Simple Hierarchies for Unsupervised Human Behavior Analysis;;Exploiting Simple Hierarchies for Unsupervised Human Behavior Analysis -Abstract;;Clustering Dynamic Textures with the Hierarchical EM Algorithm;;Clustering Dynamic Textures with the Hierarchical EM Algorithm -Abstract;;Recognizing Human Actions From Still Images With Latent Poses;;Recognizing Human Actions From Still Images With Latent Poses - Abstract;;Group Motion Segmentation Using a Spatio-Temporal Driving Force Model;;Group Motion Segmentation Using a Spatio-Temporal Driving Force Model - Abstract;;Learning a Hierarchy of Discriminative Space-Time Neighborhood Features;;Learning a Hierarchy of Discriminative Space-Time Neighborhood Features - Abstract;;Chaotic Invariants of Lagrangian Particle Trajectories ;;Chaotic Invariants of Lagrangian Particle Trajectories - Abstract;;A Hough Transform-Based Voting Framework for Action Recognition;;A Hough Transform-Based Voting Framework for Action Recognition - Abstarct;;Scene Understanding by Statistical Modeling of Motion Patterns;;Scene Understanding by Statistical Modeling of Motion Patterns - Abstract;;Spike Train Driven Dynamical Models for Human Actions;;Spike Train Driven Dynamical Models for Human Actions - Abstract'
13052,'lecture','en',12409,'2010-06-17','2010-07-19','Face Recognition Based on Image Sets','We introduce a novel method for face recognition from\nimage sets. In our setting each test and training example\nis a set of images of an individual’s face, not just a single\nimage, so recognition decisions need to be based on comparisons\nof image sets. Methods for this have two main\naspects: the models used to represent the individual image\nsets; and the similarity metric used to compare the models.\nHere, we represent images as points in a linear or\naffine feature space and characterize each image set by a\nconvex geometric region (the affine or convex hull) spanned\nby its feature points. Set dissimilarity is measured by geometric\ndistances (distances of closest approach) between\nconvex models. To reduce the influence of outliers we use\nrobust methods to discard input points that are far from the\nfitted model. The kernel trick allows the approach to be extended\nto implicit feature mappings, thus handling complex\nand nonlinear manifolds of face images. Experiments on\ntwo public face datasets show that our proposed methods\noutperform a number of existing state-of-the-art ones.','Face recognition based on image sets;;Outline;;Face recognition based on image sets (1);;Face recognition based on image sets (2);;Related methods (1);;Related methods (2);;Proposed method - Convex Sets;;Proposed method;;Reduced Affine Hull Modeling;;Convex Hull Modelling;;Extension to the nonlinear case - Kernel Trick;;Experiments (1);;Experiments (2);;Experiments (3);;Experiments (4);;Conclusion;;Thank you! Questions'
13053,'lecture','en',12409,'2010-06-17','2010-07-19','Unsupervised Discovery of Facial Events',NULL,'Unsupervised Discovery of Facial Events;;Motivation (1);;Motivation (2);;Motivation (3);;Motivation (4);;Motivation (5), Query sequence ;;Related work in facial expression analysis;;Mining facial expression across subjects;;Related work in time series;;Summarization with ACA;;Kernel k‐means and spectral clustering (1);;Kernel k‐means and spectral clustering (2);;Problem formulation for ACA;;Matrix formulation for ACA (1);;Matrix formulation for ACA (2);;Facial image features;;Experiments;;Facial event discovery across subjects (1);;Facial event discovery across subjects (2);;Facial event discovery across subjects (3);;Facial event discovery across subjects (4);;Facial event discovery across subjects (5);;Unsupervised facial event discovery;;Honey bee dance (1);;Honey bee dance (2);;Conclusions and future work;;Thanks, Questions?'
13054,'lecture','en',12409,'2010-06-17','2010-07-19','3D Morphable Model Construction for Robust Ear and Face Recognition','Recent work suggests that the human ear varies significantly\nbetween different subjects and can be used for identification.\nIn principle, therefore, using ears in addition to\nthe face within a recognition system could improve accuracy\nand robustness, particularly for non-frontal views. The\npaper describes work that investigates this hypothesis using\nan approach based on the construction of a 3D morphable\nmodel of the head and ear. One issue with creating a model\nthat includes the ear is that existing training datasets contain\nnoise and partial occlusion. Rather than exclude these\nregions manually, a classifier has been developed which automates\nthis process. When combined with a robust registration\nalgorithm the resulting system enables full head\nmorphable models to be constructed efficiently using less\nconstrained datasets. The algorithm has been evaluated using\nregistration consistency, model coverage and minimalism\nmetrics, which together demonstrate the accuracy of the\napproach. To make it easier to build on this work, the source\ncode has been made available online.','3D Morphable Model Construction for Robust Ear and Face Recognition;;Morphable Models;;Linear Shape and Colour Model;;Morphable Model Construction (1);;Morphable Model Construction (2);;Morphable Model Construction (3);;Existing problems: Ears;;Existing problems: Preprocessing;;Existing problems: Analysis;;Ear modelling (1);;Ear modelling (2);;Automated Preprocessing;;Automated Preprocessing: Results;;Model quality analysis (graph);;How general/redundant is the model? (graph);;Contributions;;Questions?'
13056,'lecture','en',12409,'2010-06-17','2010-07-19','Interest Seam Image','We propose interest seam image, an efficient visual synopsis\nfor video. To extract an interest seam image, a spatiotemporal\nenergy map is constructed for the target video\nshot. Then an optimal seam which encompasses the highest\nenergy is identified by an efficient dynamic programming\nalgorithm. The optimal seam is used to extract a seam of\npixels from each video frame to form one column of an image,\nbased on which an interest seam image is finally composited.\nThe interest seam image is efficient both in terms of\ncomputation and memory cost. Therefore it is able to power\na wide variety of web-scale video content analysis applications,\nsuch as near duplicate video clip search, video genre\nrecognition and classification, as well as video clustering,\netc.. The representation capacity of the proposed interest\nseam image is demonstrated in a large scale video retrieval\ntask. Its advantages are clearly exhibited when compared\nwith previous works, as reported in our experiments.','Interest Seam Image;;Problem to solve;;Specifications;;Questions to answer;;Interest seam image ;;Interest seam;;Naïve slice vs interest seam;;Key-frame v.s. interest seam image;;Video signature;;Inverted file indexing;;Temporal context;;Redefinition of similarity;;Sorted inverted list;;Scene verification with GIST (1);;Scene verification with GIST (2);;Dataset;;Experimental settings and criterion;;Retrieval accuracy on Qr;;Impact of scene verification;;Efficiency comparison;;Conclusion;;Please email'
13057,'lecture','en',12409,'2010-06-17','2010-07-19','Aggregating local descriptors into a compact image representation','We address the problem of image search on a very large\nscale, where three constraints have to be considered jointly:\nthe accuracy of the search, its efficiency, and the memory\nusage of the representation. We first propose a simple yet\nefficient way of aggregating local image descriptors into a\nvector of limited dimension, which can be viewed as a simplification\nof the Fisher kernel representation. We then show\nhow to jointly optimize the dimension reduction and the indexing\nalgorithm, so that it best preserves the quality of vector\ncomparison. The evaluation shows that our approach\nsignificantly outperforms the state of the art: the search accuracy\nis comparable to the bag-of-features approach for\nan image representation that fits in 20 bytes. Searching a\n10 million image dataset takes about 50ms.','Aggregating local descriptors into a compact representation;;Problem setup: Image indexing;;Related work on large scale image search;;Objective and proposed approach;;Aggregation of local descriptors;;VLAD : Vector of Locally Aggregated Descriptors;;VLADs for corresponding images;;VLAD performance and dimensionality reduction;;Indexing algorithm: searching with quantization ;;Product quantization for nearest neighbor search;;Product quantizer: asymmetric distance computation;;Optimizing the dimension reduction and quantization together;;Results on standard datasets;;Large scale experiments (10 million images);;Conclusion;;End'
13058,'lecture','en',12409,'2010-06-17','2010-07-19','Automatic Image Annotation Using Group Sparsity','Automatically assigning relevant text keywords to images\nis an important problem. Many algorithms have been proposed\nin the past decade and achieved good performance.\nEfforts have focused upon model representations of keywords,\nbut properties of features have not been well investigated.\nIn most cases, a group of features is preselected,\nyet important feature properties are not well used to select\nfeatures. In this paper, we introduce a regularization based\nfeature selection algorithm to leverage both the sparsity and\nclustering properties of features, and incorporate it into the\nimage annotation task. A novel approach is also proposed\nto iteratively obtain similar and dissimilar pairs from both\nthe keyword similarity and the relevance feedback. Thus\nkeyword similarity is modeled in the annotation framework.\nNumerous experiments are designed to compare the performance\nbetween features, feature combinations and regularization\nbased feature selection methods applied on the image\nannotation task, which gives insight into the properties\nof features in the image annotation task. The experimental\nresults demonstrate that the group sparsity based method is\nmore accurate and stable than others.','Automatic Image Annotation Using Group Sparsity;;Introductions (1);;Introductions (2);;Outline (1);;Regularization based Feature Selection (1);;Regularization based Feature Selection (2);;Regularization based Feature Selection (3);;Regularization based Feature Selection (4);;Regularization based Feature Selection (5);;Regularization based Feature Selection (6);;Outline (2);;Obtain Image Pairs (1);;Obtain Image Pairs (2);;Outline (3);;Experimental Settings (1);;Experimental Settings (2);;Evaluation of Regularization Methods;;Evaluation of Generality;;Some Annotation Results;;Conclusions and Future Work;;Thanks for listening, Questions'
13059,'lecture','en',12409,'2010-06-17','2010-07-19','Poster Spotlights',NULL,'Nonparametric Label-to-Region by Search;;Nonparametric Label-to-Region by Search - Abstract;;CRAM: Compact Representation of Actions in Movies, Mikel Rodriguez;;CRAM: Compact Representation of Actions in Movies, Mikel Rodriguez - Abstract;;Building and Using a Semantivisual Image Hierarchy;;Building and Using a Semantivisual Image Hierarchy - Abstract;;Weakly-Supervised Hashing in Kernel Space;;Weakly-Supervised Hashing in Kernel Space - Abstract;;Spatial-Bag-of-Features;;Spatial-Bag-of-Features - Abstrast;;Locality-constrained Linear Coding for Image Classification ;;Locality-constrained Linear Coding for Image Classification - Abstract;;Semantic Context Modeling with Maximal Margin Conditional Random Fields ;;Semantic Context Modeling with Maximal Margin Conditional Random Fields - Abstract;;Image Retrieval via Probabilistic Hypergraph Ranking;;Image Retrieval via Probabilistic Hypergraph Ranking - Abstract;;Large-scale image retrievalwith compressed Fisher vectors;;Large-scale image retrievalwith compressed Fisher vectors - Abstract;;Optimizing kd-trees for scalable visual descriptor indexing;;Optimizing kd-trees for scalable visual descriptor indexing - Abstract;;Content-Aware Ranking for Visual Search;;Content-Aware Ranking for Visual Search - Abstract;;Unsupervised Discovery of Co-occurrence in Sparse High Dimensional Data;;Unsupervised Discovery of Co-occurrence in Sparse High Dimensional Data - Abstract;;Semi-Supervised Hashing for Scalable Image Retrieval;;Semi-Supervised Hashing for Scalable Image Retrieval - Abstract;;Image Webs: Computing and Exploiting Connectivity in Image Collections;;Image Webs: Computing and Exploiting Connectivity in Image Collections - Abstract;;Tag-based Web Photo Retrieval Improved by Batch Mode Re-Tagging;;Tag-based Web Photo Retrieval Improved by Batch Mode Re-Tagging - Abstract;;Finding Meaning on YouTube: Tag Recommendation and Category Discovery;;Finding Meaning on YouTube: Tag Recommendation and Category Discovery - Abstract;;Discovering Scene Categories by Information Projection and Cluster Sampling;;Discovering Scene Categories by Information Projection and Cluster Sampling - Abstract;;Total Bregman Divergence and its Applications to Shape Retrieval;;Total Bregman Divergence and its Applications to Shape Retrieval - Abstract;;Scalable Face Image Retrieval with Quantization and Re-ranking;;Scalable Face Image Retrieval with Quantization and Re-ranking - Abstract;;Compact Projection: Simple and Efficient Near Neighbor Search ;;Compact Projection: Simple and Efficient Near Neighbor Search - Abstract;;SUN Database;;SUN Database - Abstract'
13060,'lecture','en',12409,'2010-06-15','2010-07-19','Polynomial Shape from Shading','We examine the shape from shading problem without\nboundary conditions as a polynomial system. This view allows,\nin generic cases, a complete solution for ideal polyhedral\nobjects. For the general case we propose a semidefinite\nprogramming relaxation procedure, and an exact line\nsearch iterative procedure with a new smoothness term that\nfavors folds at edges. We use this numerical technique to\ninspect shading ambiguities.','Polynomial Shape from Shading;;Shape from shading (SFS);;Standard Lambertian SFS;;Polynomial form;;Outline;;SFS of a polyhedron (1);;SFS of a polyhedron (2);;SFS on a grid;;Conjugate gradient with exact line search, Zo (1);;Conjugate gradient with exact line search, Zo (2);;Conjugate gradient with exact line search, Zo, Z1;;Conjugate gradient with exact line search, Zo, Z1, Z2;;Conjugate gradient with exact line search, Zo, Z1, Z2, Z3;;Result;;SDP relaxation (1);;SDP relaxation (2);;SDP relaxation (3);;SDP relaxation (4);;SDP relaxation (5);;SDP relaxation (6);;SDP relaxation (7);;Advantages of SDP relaxations;;Results (1);;Results (2);;Results (3);;Results (4);;SDP – room for improvements;;Shading ambiguities;;Visualizing SFS ambiguities;;Results (5);;What shape is this? (1);;What shape is this? (2);;References'
13061,'lecture','en',12409,'2010-06-15','2010-07-19','Analysis of Light Transport in Scattering Media','We propose a new method to analyze light transport in\nhomogeneous scattering media. The incident light undergoes\nmultiple bounces in translucent objects, and produces\na complex light field. Our method analyzes the light transport\nin two steps. First, single and multiple scattering\nare separated by projecting high-frequency stripe patterns.\nThen, multiple scattering is decomposed into each bounce\ncomponent based on the light transport equation. The light\nfield for each bounce is recursively estimated. Experimental\nresults show that light transport in scattering media can be\ndecomposed and visualized for each bounce.','Analysis of Light Transportin Scattering Media;;Scattering in translucent media;;Different scattering ;;Related work;;Our purpose;;Light field in scattering media;;Analysis of 3D light field;;Experimental environment;;Separation of single scattering;;Analysis of single scattering;;Analysis of multiple scattering;;Optimized rendering for bounce analysis;;Decomposition;;Visualization of the light field - entire light field;;Visualization of the light field - examples;;Slanted incident light - examples;;Conclusion;;Thank you !;;Summary of our approach'
13062,'lecture','en',12409,'2010-06-15','2010-07-19','A New Texture Descriptor Using Multifractal Analysis in Multi-orientation Wavelet Pyramid','Based on multifractal analysis in wavelet pyramids of\ntexture images, a new texture descriptor is proposed in this\npaper that implicitly combines information from both spatial\nand frequency domains. Beyond the traditional wavelet\ntransform, a multi-oriented wavelet leader pyramid is used\nin our approach that robustly encodes the multi-scale information\nof texture edgels. Moreover, the resulting texture\nmodel shows empirically a strong power law relationship\nfor nature textures, which can be characterized well by\nmultifractal analysis. Combined with a statistics on affine\ninvariant local patches, our proposed texture descriptor is\nrobust to scale and rotation changes, more general geometrical\ntransforms and illumination variations. In addition,\nthe proposed texture descriptor is computationally efficient\nsince it does not require many expensive processing steps,\ne.g., texton generation and cross-bin comparisons, which\nare often used by existing methods. As an application, the\nproposed descriptor is applied to texture classification and\nthe experimental results on several public texture datasets\nverified the accuracy and efficiency of our descriptor','A new texture descriptor using multi-fractal analysis on wavelet pyramid;;Introduction;;From wavelets coefficients to wavelet leaders;;High-pass wavelet coefficients vswavelet leaders;;Wavelet pyramid with multi-orientation;;Multi-fractal analysis;;Why using multi-fractal analysis;;Algorithm;;Illustration of MFS and its robustness to geometrical changes;;Experiments on texture classification using SVM classifier (1);;Experiments on texture classification using SVM classifier (2);;Classification results on UIUC dataset;;Detailed results on UIUC dataset;;Classification results on UMD dataset;;Detailed results on UMD dataset;;Thanks, Questions'
13063,'demonstration video','en',12409,'2010-06-15','2010-07-19','Poster Spotlights',NULL,'A Content-Aware Image Prior;;A Content-Aware Image Prior -Abstract;;Learning from Interpolated Images using Neural Networks ;;Learning from Interpolated Images using Neural Networks - Abstract;;A probabilistic image jigsaw puzzle solver;;A probabilistic image jigsaw puzzle solver - Abstract;;Dynamic Texture Recognition Based on Distributions;;Dynamic Texture Recognition - Abstract;;Finding Dots: Segmentation as Popping Out Regions from Boundaries;;Finding Dots - Abstract;;Estimating Optical Properties of Layered Surfaces Using the Spider Model;;Estimating Optical Properties - Abstract;;Optimal HDR reconstruction with digital linear cameras;;Optimal HDR reconstruction - Abstract;;Learning to Recognize Shadows from Monochromatic Natural Images;;Learning to Recognize Shadows - Abstract;;Context-Constrained Hallucination for Image Super-Resolution;;Context-Constrained Hallucination - Abstract;;Exploring Features in a Bayesian Framework for Material Recognition ;;Exploring Features in a Bayesian Framework - Abstract;;Estimation of Image Bias Field with Sparsity Constraints;;Estimation of Image Bias Field - Abstract;;Performance Evaluation of Color Correction Approaches for Automatic Multi-view Image ;;Color Correction Approaches - Abstract;;Surface color estimation based on inter- and intra-pixel relationships in outdoor scenes;;Surface color estimation - Abstract;;Estimating demosaicing algorithms using image noise variances;;Estimating demosaicing algorithms - Abstract;;Object-to-Object Color Transfer: Optimal Flows and SMSP Transformations;;Object-to-Object Color Transfer - Abstract;;The Phase Only Transform for unsupervised surface defect detection;;The Phase Only Transform - Abstract;;Direct Image Alignment of Projector-Camera Systems with Planar Surfaces;;Direct Image Alignment of Projector-Camera - Abstract;;Spatialized Epitome;;Spatialized Epitome - Abstract;;Global Optimization for Estimating a BRDF with Multiple Specular Lobes;; Estimating a BRDF with Multiple Specular Lobes - Abstract;;An Approach to Vectorial Total Variation based on Geometric Measure Theory;;Vectorial Total Variation - Abstract;;Robust Order-based Methods for Feature Description;;Robust Order-based Methods - Abstract'
13064,'lecture','en',12409,'2010-06-15','2010-07-19','A Theory of Plenoptic Multiplexing','Multiplexing is a common technique for encoding highdimensional\nimage data into a single, two-dimensional image.\nExamples of spatial multiplexing include Bayer patterns\nto capture color channels, and integral images to encode\nlight fields. In the Fourier domain, optical heterodyning\nhas been used to acquire light fields.\nIn this paper, we develop a general theory of multiplexing\nthe dimensions of the plenoptic function onto an image\nsensor. Our theory enables a principled comparison\nof plenoptic multiplexing schemes, including noise analysis,\nas well as the development of a generic reconstruction algorithm.\nThe framework also aides in the identification and\noptimization of novel multiplexed imaging applications.','A Theory of Plenoptic Multiplexing CVPR 2010;;Applicability of Theory;;Contributions;;How does a camera record light ? (1);;How does a camera record light ? (2);;How does a camera record light ? (3);;How does a camera record light ? (4);;How does a camera record light ? (5);;Plenoptic Multiplexing;;Image Formation Model;;Plenoptic Multiplexing - Examples;;Plenoptic Multiplexing (1);;Plenoptic Multiplexing (2);;Spatial Reconstruction;;Fourier Reconstruction;;Unified Plenoptic Reconstruction;;Plenoptic Sampling and Reconstruction;;Case Studies;;Imaging with Color Filter Arrays;;Light Field Acquisition (1);;Light Field Acquisition (2);;Light Field Acquisition (3);;Light Field Acquisition (4);;Noise Analysis (1);;Noise Analysis (2);;Noise Analysis – Light Fields;;Conclusions;;Thank You!, Questions?;;cvpr2010_ihrke_wetzstein_tpm_01_Page_29;;cvpr2010_ihrke_wetzstein_tpm_01_Page_30;;cvpr2010_ihrke_wetzstein_tpm_01_Page_31;;cvpr2010_ihrke_wetzstein_tpm_01_Page_32;;cvpr2010_ihrke_wetzstein_tpm_01_Page_33;;cvpr2010_ihrke_wetzstein_tpm_01_Page_34;;cvpr2010_ihrke_wetzstein_tpm_01_Page_35'
13065,'lecture','en',12409,'2010-06-15','2010-07-19','Non-uniform Deblurring for Shaken Images','Blur from camera shake is mostly due to the 3D rotation\nof the camera, resulting in a blur kernel that can be\nsignificantly non-uniform across the image. However, most\ncurrent deblurring methods model the observed image as\na convolution of a sharp image with a uniform blur kernel.\nWe propose a new parametrized geometric model of\nthe blurring process in terms of the rotational velocity of\nthe camera during exposure. We apply this model to two\ndifferent algorithms for camera shake removal: the first one\nuses a single blurry image (blind deblurring), while the second\none uses both a blurry image and a sharp but noisy image\nof the same scene. We show that our approach makes\nit possible to model and remove a wider class of blurs than\nprevious approaches, including uniform blur as a special\ncase, and demonstrate its effectiveness with experiments on\nreal images.','Non‐uniform Deblurring for Shaken Images;;What is camera shake?;;Blur due to camera shake;;What’s behind the blur?;;Outline (1);;Related work, Blur due to camera motion;;Camera shake: translation or rotation? (1);;Camera shake: translation or rotation? (2);;Geometric model (1);;Geometric model (2);;Geometric model (3);;Blur model – time‐agnostic (1);; Blur model – time‐agnostic (2);;Convolution;;Our blur model;;Blur model – parameterization;;Uniform blur;;Blur model – parameterization;;Blur model – discrete;;Blur model – comparison (1);;Blur model – comparison (2);;Outline (2);;ApplicaCon I: Blind deblurring (1);;ApplicaCon I: Blind deblurring (2);;Blind deblurring – example result (1);;Blind deblurring – example result (2);;Blind deblurring – example result (3);;Blind deblurring – example result (4);;Application II: Noisy/blurry image pairs;;Noisy/blurry image pairs;;Noisy/blurry image pairs – example (1);;Noisy/blurry image pairs – example (2);;Noisy/blurry image pairs – detail ;;Contributions;;Questions'
13066,'lecture','en',12409,'2010-06-15','2010-07-19','Axial Light Field for Curved Mirrors: Reflect Your Perspective, Widen Your View','Mirrors have been used to enable wide field-of-view\n(FOV) catadioptric imaging. The mapping between the incoming\nand reflected light rays depends non-linearly on the\nmirror shape and has been well-studied using caustics. We\nanalyze this mapping using two-plane light field parameterization,\nwhich provides valuable insight into the geometric\nstructure of reflected rays. Using this analysis, we study the\nproblem of generating a single-viewpoint virtual perspective\nimage for catadioptric systems, which is unachievable\nfor several common configurations.\nInstead of minimizing distortions appearing in a single\nimage, we propose to capture all the rays required to generate\na virtual perspective by capturing a light field. We\nconsider rotationally symmetric mirrors and show that a\ntraditional planar light field results in significant aliasing\nartifacts. We propose axial light field, captured by moving\nthe camera along the mirror rotation axis, for efficient\nsampling and to remove aliasing artifacts. This allows us\nto computationally generate wide FOV virtual perspectives\nusing a wider class of mirrors than before, without using\nscene priors or depth estimation. We analyze the relationship\nbetween the axial light field parameters and the\nFOV/resolution of the resulting virtual perspective. Real results\nusing a spherical mirror demonstrate generating 140◦\nFOV virtual perspective using multiple 30◦ FOV images.','Axial Light Field for Curved Mirrors: Reflect Your Perspective, Widen Your View;;Non-Single Viewpoint Image;;Single-Viewpoint Image ;;No Approximation, No Knowledge of Scene Geometry;;Single/Non-Single Viewpoint;;Single-Viewpoint Catadioptric Systems;;Generating Single-Viewpoint Image fromNon-Single Viewpoint Image;;Light Field;;Input Images (Axial Light Field);;Copy Circles;;Single-Viewpoint Image;;Key Idea;;Geometric Interpretation;;Light Fields for Symmetric Mirrors in 3D (1);;Light Fields for Symmetric Mirrors in 3D (2);;Light Fields for Symmetric Mirrors in 3D (3);;Light Fields for Symmetric Mirrors in 3D (4);;Light Fields for Symmetric Mirrors in 3D (5);;Planar LF vs. Axial LF;;Axial LF Sampling Parameters (1);;Axial LF Sampling Parameters (2);;Single-Viewpoint Image Generation;;Simulation Results for Different Mirror Shapes;;Changing Resolution Property;;Comparison, Same Number (25) of Input Images (FOV 32 x 24);;Comparison, Output Cube Maps (FOV 140);;Advantages;;Limitations;;Summary'
13067,'lecture','en',12409,'2010-06-15','2010-07-19','Rectifying rolling shutter video from hand-held devices','This paper presents a method for rectifying video sequences\nfrom rolling shutter (RS) cameras. In contrast to\nprevious RS rectification attempts we model distortions as\nbeing caused by the 3D motion of the camera. The camera\nmotion is parametrised as a continuous curve, with knots\nat the last row of each frame. Curve parameters are solved\nfor using non-linear least squares over inter-frame correspondences\nobtained from a KLT tracker. We have generated\nsynthetic RS sequences with associated ground-truth\nto allow controlled evaluation. Using these sequences, we\ndemonstrate that our algorithm improves over to two previously\npublished methods. The RS dataset is available on\nthe web to allow comparison with other methods.','Rectifying rolling shutter video from hand-held devices;;Cell-phone footage;;Rolling shutter sensors (1);;Rolling shutter sensors (2);;Existing solution - mechanical image stabilisation (1);;Existing solution - mechanical image stabilisation (2);;Existing solution - mechanical image stabilisation (3);;Existing solution - mechanical image stabilisation (4);;Existing solution - optical flow based compensation (1);;Existing solution - optical flow based compensation (2);;Existing solution - optical flow based compensation (3);;New solution: ego-motion estimation (1);;New solution: ego-motion estimation (2);;New solution: ego-motion estimation (3);;New solution: ego-motion estimation (4);;cvpr2010_forssen_rrsv_01_Page_16;;cvpr2010_forssen_rrsv_01_Page_17;;cvpr2010_forssen_rrsv_01_Page_18;;cvpr2010_forssen_rrsv_01_Page_19;;Ego-motion estimation (1);;Ego-motion estimation (2);;Ego-motion estimation (3);;Ego-motion estimation (4);;Ego-motion estimation (5);;Ego-motion estimation (6);;Ego-motion estimation (7);;Ego-motion estimation (8);;Ego-motion estimation (9);;Rectification;;Synthetic dataset (1);;Synthetic dataset (2);;Synthetic dataset (3);;Synthetic dataset (4);;Results;;Rolling shutter rectification (1);;Rolling shutter rectification (2);;Rolling shutter rectification (3);;Rolling shutter rectification (4);;Rolling shutter rectification (5);;Rolling shutter rectification (6);;Rolling shutter rectification (7);;Video example;;Final remarks'
13068,'demonstration video','en',12409,'2010-06-15','2010-07-19','Poster Spotlights',NULL,'Correcting Over-Exposure in Photographs;;Correcting Over-Exposure in Photographs - Abstract;;Denoising vs. Deblurring;;Denoising vs. Deblurring - Abstract;;Gradient-directed Composition of Multi-exposure Images;;Gradient-directed Composition - Abstract;;Warp Propagation for Video Resizing;;Warp Propagation for Video Resizing - Abstract;;Sensor Saturation in Fourier Multiplexed Imaging;;Sensor Saturation in Fourier Multiplexed Imaging - Abstract;;Noise-Optimal Capture for High Dynamic Range Photography;;Noise-Optimal Capture - Abstract;;Using Optical Defocus to Denoise;;Using Optical Defocus to Denoise - Abstract;;Discontinuous Seam-Carving for Video Retargeting;;Discontinuous Seam-Carving - Abstract;;Hybrid Shift Map for Video Retargeting;;Hybrid Shift Map for Video Retargeting - Abstract;;Geo-location estimation from two shadow trajectories;;Geo-location estimation - Abstract;;Estimating Satellite Attitude from Pushbroom Sensors;;Estimating Satellite Attitude from Pushbroom Sensors - Abstract;;Optimal Coded Sampling For Temporal Super-Resolution;;Optimal Coded Sampling - Abstract;;Efficient Filter Flow for Space-Variant Multiframe Blind Deconvolution;;Space-Variant Multiframe Blind Deconvolution - Abstract;;Regenerative Morphing;;Regenerative Morphing - Abstract'
13069,'lecture','en',12409,'2010-06-15','2010-07-19','RASL: Robust Alignment by Sparse and Low-rank Decomposition for Linearly Correlated Images','This paper studies the problem of simultaneously aligning a batch of linearly correlated images despite gross corruption (such as occlusion). Our method seeks an optimal set of image domain transformations such that the matrix of transformed images can be decomposed as the sum of a sparse matrix of errors and a low-rank matrix of recovered aligned images. We reduce this extremely challenging optimization problem to a sequence of convex programs that minimize the sum of 1 -norm and nuclear norm of the two component matrices, which can be efficiently solved by scalable convex optimization techniques with guaranteed fast convergence. We verify the efficacy of the proposed robust alignment algorithm with extensive experiments with both controlled and uncontrolled real data, demonstrating higher accuracy and efficiency than existing methods over a wide range of realistic misalignments and corruptions. ',NULL
13071,'lecture','en',12409,'2010-06-15','2010-07-19','On the design of robust classifiers for computer vision','The design of robust classifiers, which can contend with\nthe noisy and outlier ridden datasets typical of computer vision,\nis studied. It is argued that such robustness requires\nloss functions that penalize both large positive and negative\nmargins. The probability elicitation view of classifier design\nis adopted, and a set of necessary conditions for the design\nof such losses is identified. These conditions are used to derive\na novel robust Bayes-consistent loss, denoted Tangent\nloss, and an associated boosting algorithm, denoted TangentBoost.\nExperiments with data from the computer vision\nproblems of scene classification, object tracking, and multiple\ninstance learning show that TangentBoost consistently\noutperforms previous boosting algorithms.','cvpr2010_masnadi_shirazi_drc_01_Page_01;;cvpr2010_masnadi_shirazi_drc_01_Page_02;;cvpr2010_masnadi_shirazi_drc_01_Page_03;;cvpr2010_masnadi_shirazi_drc_01_Page_04;;cvpr2010_masnadi_shirazi_drc_01_Page_05;;cvpr2010_masnadi_shirazi_drc_01_Page_06;;cvpr2010_masnadi_shirazi_drc_01_Page_07;;cvpr2010_masnadi_shirazi_drc_01_Page_08;;cvpr2010_masnadi_shirazi_drc_01_Page_09;;cvpr2010_masnadi_shirazi_drc_01_Page_10;;cvpr2010_masnadi_shirazi_drc_01_Page_11;;cvpr2010_masnadi_shirazi_drc_01_Page_12;;cvpr2010_masnadi_shirazi_drc_01_Page_13;;cvpr2010_masnadi_shirazi_drc_01_Page_14'
13072,'lecture','en',12409,'2010-06-15','2010-07-19','Online-Batch Strongly Convex Multi Kernel Learning','Several object categorization algorithms use kernel\nmethods over multiple cues, as they offer a principled approach\nto combine multiple cues, and to obtain state-of-theart\nperformance. A general drawback of these strategies is\nthe high computational cost during training, that prevents\ntheir application to large-scale problems. They also do not\nprovide theoretical guarantees on their convergence rate.\nHere we present a Multiclass Multi Kernel Learning\n(MKL) algorithm that obtains state-of-the-art performance\nin a considerably lower training time. We generalize the\nstandardMKL formulation to introduce a parameter that allows\nus to decide the level of sparsity of the solution. Thanks\nto this new setting, we can directly solve the problem in the\nprimal formulation. We prove theoretically and experimentally\nthat 1) our algorithm has a faster convergence rate as\nthe number of kernels grow; 2) the training complexity is\nlinear in the number of training examples; 3) very few iterations\nare enough to reach good solutions. Experiments on\nthree standard benchmark databases support our claims.','Online-Batch Strongly Convex Multi Kernel Learning;;Outline (1);;Outline (2);;Problem definition;;Linear classification;;Multi Kernel Learning (1);;Multi Kernel Learning (2);;Sparsity vs “PhD Student Kernels”;;Why using the dual? (1);;Why using the dual? (2);;Use your favorite loss (1);;Use your favorite loss (2);;Outline (3);;(2; p) group norm for MKL;;A small ball is better than a big one (1);;A small ball is better than a big one (2);;A small ball is better than a big one (3);;A small ball is better than a big one (4);;Online-Batch Strongly Convex multi kernel learning;;Convergence rate for OBSCURE (1);;Convergence rate for OBSCURE (2);;A draft of the general algorithm;;The core of the algorithm;;Outline (4);;Baseline;;Caltech-101 Experiments: Performance;;Caltech-101 Experiments: Time;;Different settings of p;;More kernels = faster convergence;;Summary;;Questions'
13073,'demonstration video','en',12409,'2010-06-15','2010-07-19','Poster Spotlights',NULL,'Efficient Joint 2D and 3D Palmprint Matching with Alignment Refinement;;Efficient Joint 2D and 3D Palmprint Matching - Abstract;;Visual Recognition using Mappings that Replicate Margins;;Mappings that Replicate Margins;;An Eye for an Eye: A Single Camera Gaze-Replacement Method;;An Eye for an Eye - Abstract;;Ink-Bleed Reduction Using Functional Minimization;;Ink-Bleed Reduction - Abstract;;Action Classification on Product Manifolds;;Action Classification - Abstract;;Motion Field to Predict Play Evolution in Dynamic Sport Scenes;;Motion Field to Predict Play Evolution - Abstract;;SPEC Hashing: Similarity Preserving algorithm for Entropy Based Coding;;SPEC Hashing - Abstract;;Shape-based Similarity Retrieval of Doppler Images for Clinical Decision Support;;Shape-based Similarity Retrieval - Abstract;;Real-Time Vehicle Global Localisation with a Single Camera in Dense Urban Areas;;Real-Time Vehicle Global Localisation - Abstract;;Taxonomic Classification for Web-based Videos;;Taxonomic Classification - Abstract;;YouTubeCat: Learning to Categorize Wild Web Videos;;YouTubeCat - Abstract;;Covering Trees and Lower-bounds on Quadratic Assignment;;Covering Trees and Lower-bounds - Abstract;;Efficient Piecewise Learning for Conditional Random Fields;;Efficient Piecewise Learning for CRFs - Abstract'
13074,'lecture','en',12409,'2010-06-15','2010-07-19','Using Cloud Shadows to Infer Scene Structure and Camera Calibration','We explore the use of clouds as a form of structured lighting\nto capture the 3D structure of outdoor scenes observed\nover time from a static camera. We derive two cues that relate\n3D distances to changes in pixel intensity due to clouds\nshadows. The first cue is primarily spatial, works with low\nframe-rate time lapses, and supports estimating focal length\nand scene structure, up to a scale ambiguity. The second\ncue depends on cloud motion and has a more complex, but\nstill linear, ambiguity. We describe a method that uses the\nspatial cue to estimate a depth map and a method that combines\nboth cues. Results on time lapses of several outdoor\nscenes show that these cues enable estimating scene geometry\nand camera focal length.','Using Clouds Shadows to Infer Scene Structure and Camera Calibration;;Time lapse videos in the wild;;Example - Time lapse video;;Related work;;Outline: from clouds to depth maps;;Spatial cue (1);;Spatial cue (2);;Temporal correlation is related to distance;;What is the relationship between correlation and distance?;;Algorithm overview;;Detail in buildings;;Estimating thecorrelation to distance mapping;;Improving an existing depth map (1);;Improving an existing depth map (2);;Improving an existing depth map (3);;Improving an existing depth map (4);;Recap of the spatial cue;;Temporal delay cue;;Linear constraints on location;;Wind direction;;cvpr2010_jacobs_ucsi_01_Page_21;;cvpr2010_jacobs_ucsi_01_Page_22;;cvpr2010_jacobs_ucsi_01_Page_23;;cvpr2010_jacobs_ucsi_01_Page_24;;cvpr2010_jacobs_ucsi_01_Page_25;;cvpr2010_jacobs_ucsi_01_Page_26;;cvpr2010_jacobs_ucsi_01_Page_27;;cvpr2010_jacobs_ucsi_01_Page_28;;cvpr2010_jacobs_ucsi_01_Page_29'
13075,'lecture','en',12409,'2010-06-15','2010-07-19','Depth from Diffusion','An optical diffuser is an element that scatters light and is\ncommonly used to soften or shape illumination. In this paper,\nwe propose a novel depth estimation method that places\na diffuser in the scene prior to image capture. We call this\napproach depth-from-diffusion (DFDiff).\nWe show that DFDiff is analogous to conventional depthfrom-\ndefocus (DFD), where the scatter angle of the diffuser\ndetermines the effective aperture of the system. The main\nbenefit of DFDiff is that while DFD requires very large\napertures to improve depth sensitivity, DFDiff only requires\nan increase in the diffusion angle – a much less expensive\nproposition. We perform a detailed analysis of the image\nformation properties of a DFDiff system, and show a variety\nof examples demonstrating greater precision in depth\nestimation when using DFDiff.','Depth from Diffusion;;Optical Diffuser (1);;Optical Diffuser (2);;Diffusers as Accessories;;Diffusion Encodes Depth;;Geometry of Diffusion: A Pinhole Camera (1);;Geometry of Diffusion: A Pinhole Camera (2);;Geometry of Diffusion: A Pinhole Camera (3);;Diffusion Law;;Diffusion Object Size and Depth;;Diffuser as a proxy object;;Diffusion as Convolution: A Pinhole Camera;;Geometry of Diffusion: A Lens Camera (1);;Geometry of Diffusion: A Lens Camera (2);;Geometry of Diffusion: A Lens Camera (3);;Diffusion as Convolution: A Lens Camera;;Depth from Diffusion (DFDiff) Algorithm;;Depth from Diffusion vs. Depth from Defocus;;Depth from Diffusion (1);;Depth from Defocus (1);;Depth from Defocus (2);;Depth from Diffusion (2);;Depth from Defocus (3);;Depth from Defocus (4);;PSF Measurement: A Pinhole Camera (1);;PSF Measurement: A Pinhole Camera (2);;PSF Measurement: A Lens Camera;;Experiments (1);;Experiments (2);;Experiments (3);;Experiments (4);;Experiments (5);;Experiments (6);;Experiments (7);;Experiments (8);;Summary;;Questions'
13076,'lecture','en',12409,'2010-06-15','2010-07-09','Self-calibrating Photometric Stereo','We present a self-calibrating photometric stereo method.\nFrom a set of images taken from a fixed viewpoint under\ndifferent and unknown lighting conditions, our method automatically\ndetermines a radiometric response function and\nresolves the generalized bas-relief ambiguity for estimating\naccurate surface normals and albedos. We show that color\nand intensity profiles, which are obtained from registered\npixels across images, serve as effective cues for addressing\nthese two calibration problems. As a result, we develop\na complete auto-calibration method for photometric stereo.\nThe proposed method is useful in many practical scenarios\nwhere calibrations are difficult. Experimental results validate\nthe accuracy of the proposed method using various\nreal-world scenes.','Self-calibrating Photometric Stereo;;Collaborators;;Photometric Stereo (1);;Photometric Stereo (2);;Photometric Stereo (3);;Photometric Stereo (4);;Motivation (1);;Motivation (2);;Our Approach (1);;Color & Intensity Profiles;;Our Approach (2);;Radiometric Calibration (1);;Radiometric Calibration (2);;Radiometric Calibration (3);;Parameterize;;Color Profiles;;50 Profiles used;;Our Approach (3);;Shape/Light Ambiguity;;Resolving GBR Ambiguity;;Pixel Grouping Approach;;Pixel Grouping;;Result (1);;Result (2);;Result (3);;Result (4);;3D Reconstruction;;Summary;;Questions'
13077,'demonstration video','en',12409,'2010-06-15','2010-07-19','Poster Spotlights',NULL,'Geometric Properties of Multiple Reflections in Catadioptric Camera with Two Planar Mirrors;;Geometric Properties of Multiple Reflections - Abstract;;Recovering Thin Structures via Nonlocal-Means Regularization with Application to Depth from Defocus;;Recovering Thin Structures - Abstract;;Upsampling Range Data in Dynamic Environments;;Upsampling Range Data - Abstract;;Object Cut: Complex 3D Object Reconstruction Through Line Drawing Separation;;Complex 3D Object Reconstruction - Abstract;;Consensus Photometric Stereo;;Consensus Photometric Stereo - Abstract;;Model Evolution: An Incremental Approach to Non-Rigid Structure from Motion;; Approach to Non-Rigid Structure - Abstract;;Refinement of Digital Elevation Models from Shadowing Cues;;Refinement of Digital Elevation Models - Abstract;;Simultaneous Pose, Correspondence and Non-Rigid Shape;;Simultaneous Pose - Abstract;;Surface Extraction from Binary Volumes with Higher-Order Smoothness;;Surface Extraction - Abstract;;A Framework for Ultra High Resolution 3D Imaging;;Ultra High Resolution 3D Imaging - Abstract;;3D Reconstruction of Glossy Surfaces Using Stereo Cameras and Projector-Display;;3D Reconstruction of Glossy Surfaces - Abstract;;Simultaneous Point Matching and 3D Deformable Surface Reconstruction;;Simultaneous Point Matching - Abstract;;Shape and Refractive Index Recovery from Single-View Polarisation Images;;Shape and Refractive Index Recovery - Abstract;;High-Resolution Modeling of Moving and Deforming Objects Using Sparse Geometric and Dense Photometric Measurements;;High-Resolution Modeling - Abstract;;Specular Surface Reconstruction from Sparse Reflection Correspondences;;Specular Surface Reconstruction - Abstract;;Single Image Depth Estimation From Predicted Semantic Labels;;Single Image Depth Estimation - Abstract;;Robust Piecewise-Planar 3D Reconstruction and Completion from Large-Scale Unstructured Point Data;;Robust Piecewise-Planar 3D Reconstruction - Abstract'
13078,'lecture','en',12409,'2010-06-16','2010-07-19','Probabilistic Temporal Inference on Reconstructed 3D Scenes','Modern structure from motion techniques are capable\nof building city-scale 3D reconstructions from large image\ncollections, but have mostly ignored the problem of largescale\nstructural changes over time. We present a general\nframework for estimating temporal variables in structure\nfrom motion problems, including an unknown date for each\ncamera and an unknown time interval for each structural element.\nGiven a collection of images with mostly unknown or\nuncertain dates, we use this framework to automatically recover\nthe dates of all images by reasoning probabilistically\nabout the visibility and existence of objects in the scene. We\npresent results on a collection of over 100 historical images\nof a city taken over decades of time.','Probabilistic Temporal Inference on Reconstructed 3D Scenes;;The World Changes Over Time;;Temporal Inference Problem (1);;Temporal Inference Problem (2);;Overview (1);;Overview (2);;Overview (3);;Overview (4);;3D Reconstruction;;Grouping Points into Buildings;;3D Reconstruction: Points vs. Objects;;Reasoning About Time: From Constraint Satisfaction...;;…to Probabilistic Temporal Inference;;P(T) ‐ Image Date Prior;;Observation Probability Model;;Optimizing Temporal Parameters (1);;Optimizing Temporal Parameters (2);;Optimizing Temporal Parameters (3);;Optimizing Temporal Parameters (4);;Results: Full Temporal Optimization - Synthetic Scene;;Results: Full Temporal Optimization - Downtown Atlanta (102 Images);;Results: Full Temporal Optimization - Downtown Atlanta;;Results: Leave‐One‐Out Image Dating;;Results: Building Date Intervals;;Conclusions and Future Work;;Questions'
13079,'lecture','en',12409,'2010-06-16','2010-07-19','Piecewise Planar and Non-Planar Stereo for Urban Scene Reconstruction','Piecewise planar models for stereo have recently become\npopular for modeling indoor and urban outdoor\nscenes. The strong planarity assumption overcomes the\nchallenges presented by poorly textured surfaces, and results\nin low complexity 3D models for rendering, storage,\nand transmission. However, such a model performs poorly\nin the presence of non-planar objects, for example, bushes,\ntrees, and other clutter present in many scenes. We present\na stereo method capable of handling more general scenes\ncontaining both planar and non-planar regions. Our proposed\ntechnique segments an image into piecewise planar\nregions as well as regions labeled as non-planar. The nonplanar\nregions are modeled by the results of a standard\nmulti-view stereo algorithm. The segmentation is driven by\nmulti-view photoconsistency as well as the result of a colorand\ntexture-based classifier, learned from hand-labeled planar\nand non-planar image regions. Additionally our method\nlinks and fuses plane hypotheses across multiple overlapping\nviews, ensuring a consistent 3D reconstruction over\nan arbitrary number of images. Using our system, we have\nreconstructed thousands of frames of street-level video. Results\nshow our method successfully recovers piecewise planar\nsurfaces alongside general 3D surfaces in challenging\nscenes containing large buildings as well as residential\nhouses.',NULL
13080,'lecture','en',12409,'2010-06-16','2010-07-19','Disambiguating Visual Relations Using Loop Constraints','Repetitive and ambiguous visual structures in general\npose a severe problem in many computer vision applications.\nIdentification of incorrect geometric relations between\nimages solely based on low level features is not always\npossible, and a more global reasoning approach about\nthe consistency of the estimated relations is required. We\npropose to utilize the typically observed redundancy in the\nhypothesized relations for such reasoning, and focus on the\ngraph structure induced by those relations. Chaining the\n(reversible) transformations over cycles in this graph allows\nto build suitable statistics for identifying inconsistent\nloops in the graph. This data provides indirect evidence for\nconflicting visual relations. Inferring the set of likely false\npositive geometric relations from these non-local observations\nis formulated in a Bayesian framework. We demonstrate\nthe utility of the proposed method in several applications,\nmost prominently the computation of structure and\nmotion from images.','Disambiguating Visual Relations Using Loop Constraints;;The Problem in Structure and Motion (1);;The Problem in Structure and Motion (2);;Our Contribution in a Nutshell;;Options to Avoid Incorrect 3D Models;;Explicit Verification of Visual Relations;;Transformation Consistency along Loops (1);;Transformation Consistency along Loops (2);;Inference Using Loop Consistency (1);;Inference Using Loop Consistency (2);;How to Sample Loops?;;Bottom-Up SfM;;How to Model d(T)?;;Rejected Pairs;;Structure and Motion Results (1);;Structure and Motion Results (2);;Structure and Motion Results (3);;Structure and Motion Results (4);;Questions'
13081,'demonstration video','en',12409,'2010-06-16','2010-07-19','Poster Spotlights',NULL,'Towards Internet-scale Multi-view Stereo;;Towards Internet-scale Multi-view Stereo - Abstract;;Reconstruction of Display and Eyes from a Single Image;;Reconstruction of Display and Eyes - Abstract;;Outlier Removal using Duality;;Outlier Removal using Duality - Abstract;;A Constant-Space Belief Propagation Algorithm for Stereo Matching;;A Constant-Space Belief Propagation - Abstract;;Evaluation of Stereo Confidence Indoors and Outdoors;;Evaluation of Stereo Confidence - Abstract;;Pushing the Envelope of Modern Methods ;;Pushing the Envelope - Abstract;;Quasi-dense 3D Reconstruction using Tensor-based Multiview Stereo;;Quasi-dense 3D Reconstruction - Abstract;;Accurate 3D Face Reconstruction from Weakly Calibrated Wide Baseline Images with Profile Contours;;Accurate 3D Face Reconstruction - Abstract;;Live Dense Reconstruction with a Single Moving Camera;;Live Dense Reconstruction - Abstract;;Multi-View Scene Flow Estimation: A View Centered Variational Approach;;Multi-View Scene Flow Estimation - Abstract;;Egomotion using Assorted Features;;Egomotion using Assorted Features - Abstract;;Monocular SLAM with Locally Planar Landmarks ;;Monocular SLAM - Abstract;;Ray Markov Random Fields for Image-Based 3D Modeling;;Ray Markov Random Fields - Abstract;;3D Curve Sketch: Flexible Curve-Based Stereo Reconstruction and Calibration;;3D Curve Sketch - Abstract;;Scalable Active Matching;;Scalable Active Matching - Abstract;;Triangulation Made Easy;;Triangulation Made Easy - Abstract;;Simultaneous surveillance camera calibration and foot-head homology estimation from human detections;;Simultaneous surveillance camera calibration - Abstract;;Surface Stereo with Soft Segmentation;;Surface Stereo with Soft Segmentation - Abstract;;Admissible Linear Maps Models of Linear Cameras;;Admissible Maps of Linear Cameras - Abstract;;Exploiting Global Connectivity Constraints for Reconstruction of 3D Line Segment from Images;;Exploiting Global Connectivity Constraints - Abstract;;Improving the Efficiency of Hierarchical Structure-and-Motion;;Hierarchical Structure-and-Motion - Abstract;;Multiview Constraints in Frequency Space and Camera Calibration from Unsynchronized Images;;Multiview Constraints in Frequency Space - Abstract'
13082,'lecture','en',12409,'2010-06-17','2010-07-19','Non-Rigid Structure from Locally-Rigid Motion','We introduce locally-rigid motion, a general framework for\nsolving the M-point, N-view structure-from-motion problem\nfor unknown bodies deforming under orthography. The\nkey idea is to first solve many local 3-point, N-view rigid\nproblems independently, providing a “soup” of specific,\nplausibly rigid, 3D triangles. The main advantage here is\nthat the extraction of 3D triangles requires only very weak\nassumptions: (1) deformations can be locally approximated\nby near-rigid motion of three points (i.e., stretching not\ndominant) and (2) local motions involve some generic rotation\nin depth. Triangles from this soup are then grouped\ninto bodies, and their depth flips and instantaneous relative\ndepths are determined. Results on several sequences,\nboth our own and from related work, suggest these conditions\napply in diverse settings—including very challenging\nones (e.g., multiple deforming bodies). Our starting point\nis a novel linear solution to 3-point structure from motion,\na problem for which no general algorithms currently exist.','Non-Rigid Structure from Locally-Rigid Motion;;Complex Non-Rigid Deformation;;Non-Rigid Structure from Motion;;30 Years of Rigid Structure from Motion (1);;30 Years of Rigid Structure from Motion (2);;Locally-Rigid Motion;;Non-Rigid Structure from Locally-Rigid Motion (1);;Triangle Soups from 3-SFM;;30 Years of Structure from Motion (3);;Solving 3-SFM (1);;Solving 3-SFM (2);;The 3-SFM Algorithm (1);;The 3-SFM Algorithm (2);;The 3-SFM Algorithm (3);;The 3-SFM Algorithm (4);;Non-Rigid Structure from Locally-Rigid Motion (2);;Flexible Triangle Pairs => Deforming Bodies (1);;Flexible Triangle Pairs => Deforming Bodies (2);;Non-Rigid Structure from Locally-Rigid Motion (3);;Depth-Flip Assignment (1);;Depth-Flip Assignment (2);;Non-Rigid Structure from Locally-Rigid Motion (4);;Relative Depth Constraints;;Experimental Results: Real Videos;;Silk Scarf Sequence (1);;Silk Scarf Sequence (2);;Two Cloths Sequence (1);;Two Cloths Sequence (2);;Paper Sequence (1);;Paper Sequence (2);;Experimental Results: Datasets w/ Ground Truth (mocap);;Bend Sequence;;Rip Sequence;;Two-Papers Sequence;;Wind Sequence;;Jackie Sequence;;Remaining Issues;;Concluding Remarks (1);;Concluding Remarks (2)'
13083,'lecture','en',12409,'2010-06-17','2010-07-19','Bundled Depth-Map Merging for Multi-View Stereo',NULL,'Bundled Depth-Map Merging for Multi-View Stereo;;Outline;;Motivation;;Framework;;Stereo pair selection;;Stereo matching;;Track building and optimization;;Bundled track optimization (1);;Bundled optimization (2);;Implementation;;Results on Middlebury;;Results on Real Datasets;;More Results;;Results from video input;;Conclusions;;Questions'
13084,'lecture','en',12409,'2010-06-17','2010-07-19','Multi-View Structure Computation without Explicitly Estimating Motion',NULL,'Multi-view Structure Computation without explicitly estimating camera motion;;The 3D-Reconstruction Problem;;The standard approach for 3D-Reconstruction;;This approach has been quite successful in practice;;Motion-Estimation is almost always the first step in the processing pipeline;;Motion-Estimation... (2);;Motion-Estimation... (3);;Motion-Estimation... (4);;Motivations;;Our goal;;How do we describe the 3D shape of point clouds (1);;How do we describe the 3D shape of point clouds (2);;Coordinate Representation vs. Distance Representation;;Graph-Embedding Problem;;The Molecule Problem;;Our unique idea;;How to measure distance in 3D-space (1);;How to measure distance in 3D-space (2);;How to measure distance in 3D-space (3);;How to measure distance in 3D-space (4);;How to measure distance in 3D-space (5);;How to measure distance in 3D-space (6);;Basic Equation System;;Roadmap;;How to solve the system of basic equations efficiently (1);;How to solve the system of basic equations efficiently (2);;How to solve the system of basic equations efficiently (3);;How to solve the system of basic equations efficiently (4);;How to solve the system of basic equations efficiently (5);;How to solve the system of basic equations efficiently (6);;How to solve the system of basic equations efficiently (7);;How to solve the system of basic equations efficiently (8);;Strategies for solving it;;Matrix trace form;;Further relaxations;;The geometry intuition;;The final formulation: finding edges (1);;The final formulation: finding edges (2);;How to address the solution uniqueness question?;;Resort to graph rigidity theory;;Graph Rigidity Theory: some definitions;;Eg: Not globally-rigid graph (1);;Eg: Not globally-rigid graph (2);;Eg: Not globally-rigid graph (3);;Eg: Not globally-rigid graph (4);;Eg: Globally-rigid graph;;In our 3D reconstruction context;;How to tell when a given framework is globally-rigid?;;Algorithm Sketch;;Experimental validation;;Synthetic data ;;Reconstruction error v/s noise level;;Worst case time-complexity (running time);;Error v/s Number of points;;Error v/s Number of views;;Tests on real images (1): with sparse, non-complete graph;;Test on real image (2): with Delaunay mesh;;Conclusions (1);;Conclusions (2);;Conclusions (3);;Conclusions (4);;Conclusions (5);;Questions'
13085,'demonstration video','en',12409,'2010-06-17','2010-07-19','Poster Spotlights',NULL,'ABSORB: Atlas Building by Self-Organized Registration and Bundling;;ABSORB: Atlas Building - Abstract;;Stratified Learning of Local Anatomical Context for Lung Nodules in CT Images;;Stratified Learning of Local Anatomical Context - Abstract;;Delineating Trees in Noisy 2D Images and 3D Image-Stacks;;Delineating Trees in Noisy 2D Images - Abstract;;Sign Ambiguity Resolution for Phase Demodulation in Interferometry with Application to Prelens Tear Film Analysis;;Sign Ambiguity Resolution - Abstract;;Multiple Dynamic Models for Tracking the Left Ventricle of the Heart from Ultrasound Data using Particle Filters and Deep Learning Architectures;;Multiple Dynamic Models - Abstract;;Multi-linear Feature Extraction and Classification of Multi-Focal Images, With Applications in Nematode Taxonomy;;Multi-linear Feature Extraction - Abstract;;Compression of Surface Registrations using Beltrami Coefficients;;Compression of Surface Registrations - Abstract;;Natural Gradients for Deformable Registration;;Natural Gradients for Deformable Registration - Abstract;;Curious Snakes: A Minimum Latency Solution to the Cluttered Background Problem;;A Minimum Latency Solution - Abstract;;Anatomical Parts-Based Regression Using Non-Negative Matrix Factorization;;Anatomical Parts-Based Regression - Abstract;;Metric-Induced Optimal Embedding for Intrinsic 3D Shape Analysis;;Metric-Induced Optimal Embedding - Abstract;;Simultaneous Searching of Globally Optimal Interacting Surfaces with Shape Priors;;Simultaneous Searching - Abstract;;Group MRF for fMRI Activation Detection;;Group MRF for fMRI Activation Detection - Abstract;;Localizing non-overlapping surveillance cameras under the L-infinity norm;;Localizing non-overlapping surveillance cameras - Abstract;;Neuron Geometry Extraction by Perceptual Grouping in ssTEM Images ;;Neuron Geometry Extraction - Abstract;;An automatic unsupervised classification of MR images in Alzheimer’s disease;;MR images in Alzheimer’s disease - Abstract;;Masked FFT Registration;;Masked FFT Registration - Abstract;;Lymph Node Detection in 3-D Chest CT using a Spatial Prior Probability;;Lymph Node Detection - Abstract;;Image Atlas Construction via Intrinsic Averaging on the Manifold of Images;;Image Atlas Construction - Abstract;;Heterogeneous Conditional Random Field: Realizing Joint Detection and Segmentation of Cell Regions in Microscopic Images;;Heterogeneous Conditional Random Field - Abstract;;Model-Based Respiratory Motion Compensation for Image-Guided Cardiac Interventions;;Model-Based Respiratory Motion Compensation - Abstract'
13086,'lecture','en',12409,'2010-06-16','2010-07-19','A Generative Perspective on MRFs in Low-Level Vision','Markov random fields (MRFs) are popular and generic\nprobabilistic models of prior knowledge in low-level vision.\nYet their generative properties are rarely examined, while\napplication-specific models and non-probabilistic learning\nare gaining increased attention. In this paper we revisit\nthe generative aspects of MRFs, and analyze the quality of\ncommon image priors in a fully application-neutral setting.\nEnabled by a general class of MRFs with flexible potentials\nand an efficient Gibbs sampler, we find that common models\ndo not capture the statistics of natural images well. We\nshow how to remedy this by exploiting the efficient sampler\nfor learning better generative MRFs based on flexible potentials.\nWe perform image restoration with these models\nby computing the Bayesian minimum mean squared error\nestimate (MMSE) using sampling. This addresses a number\nof shortcomings that have limited generative MRFs so far,\nand leads to substantially improved performance over maximum\na-posteriori (MAP) estimation. We demonstrate that\ncombining our learned generative models with sampling based\nMMSE estimation yields excellent application results\nthat can compete with recent discriminative methods.','A Generative Perspective on MRFs in Low-Level Vision;;Low-Level Vision (1);;Low-Level Vision (2);;Low-Level Vision (3);;Common MRF Evaluation (1);;Common MRF Evaluation (2);;Common MRF Evaluation (3);;Common MRF Evaluation (4);;Desirable MRF Evaluation (1);;Desirable MRF Evaluation (2);;Agenda (1);;Agenda (2);;Agenda (3);;Agenda (4);;Flexible MRF Model (1);;Flexible MRF Model (2);;Flexible MRF Model (3);;Flexible MRF Model (4);;Flexible MRF Model (5);;Flexible MRF Model (6);;Sampling from the MRF (1);;Sampling from the MRF (2);;MRF Sampling – Example;;Generative Properties of Pairwise MRFs (1);;Generative Properties of Pairwise MRFs (2);;Generative Properties of Pairwise MRFs (3);;Generative Properties of Pairwise MRFs (4);;Generative Properties of Pairwise MRFs (5);;Generative Properties of High-order MRFs (1);;Generative Properties of High-order MRFs (2);;Generative Properties of High-order MRFs (3);;Learning Better Generative MRFs (1);;Learning Better Generative MRFs (2);;Learning Better Generative MRFs (3);;Learning Better Generative MRFs (4);;Generative Properties of Our Pairwise MRF (1);;Generative Properties of Our Pairwise MRF (2);;Generative Properties of Our Pairwise MRF (3);;Generative Properties of Our Pairwise MRF (4);;Our Learned FoE in Comparison (1);;Our Learned FoE in Comparison (3);;Generative Properties of our FoE;;Image Denoising (1);;Image Denoising (2);;Image Denoising (3);;Image Denoising (4);;Image Denoising (5);;Image Denoising (6);;Image Denoising – MAP (1);;Image Denoising – MAP (2);;Image Denoising – MMSE (1);;Image Denoising – MMSE (2);;Image Denoising – Results (1);;Image Denoising – Results (2);;Image Denoising – Results (3);;Advantages of the MMSE (1);;Advantages of the MMSE (2);;Advantages of the MMSE (3);;Advantages of the MMSE (4);;Advantages of the MMSE (5);;Advantages of the MMSE (6);;Summary;;Questions;;cvpr2010_schmidt_gpmrf_01_Page_64'
13087,'lecture','en',12409,'2010-06-16','2010-07-19','Manifold Blurring Mean Shift Algorithms for Manifold Denoising','We propose a new family of algorithms for denoising\ndata assumed to lie on a low-dimensional manifold. The\nalgorithms are based on the blurring mean-shift update,\nwhich moves each data point towards its neighbors, but constrain the motion to be orthogonal to the manifold. The\nresulting algorithms are nonparametric, simple to implement and very effective at removing noise while preserving\nthe curvature of the manifold and limiting shrinkage. They\ndeal well with extreme outliers and with variations of density along the manifold. We apply them as preprocessing for\ndimensionality reduction; and for nearest-neighbor classification of MNIST digits, with consistent improvements up\nto 36% over the original data.','Manifold Blurring Mean Shift Algorithms for Manifold Denoising;;Manifold denoising;;Denoising given the manifold;;Gaussian blurring mean shift (GBMS): clustering;;Gaussian blurring mean shift (GBMS): denoising (1);;Gaussian blurring mean shift (GBMS): denoising (2);;Gaussian blurring mean shift (GBMS): denoising (3);;Gaussian blurring mean shift (GBMS): denoising (4);;cvpr2010_carreira_perpinan_mbms_01_Page_09;;cvpr2010_carreira_perpinan_mbms_01_Page_10;;cvpr2010_carreira_perpinan_mbms_01_Page_11;;Gaussian blurring mean shift (GBMS): denoising (5);;Manifold blurring mean shift (MBMS);;Manifold blurring mean shift (MBMS): denoising (1);;Manifold blurring mean shift (MBMS): denoising (2);;Manifold blurring mean shift (MBMS): denoising (3);;Manifold blurring mean shift (MBMS): denoising (4);;Pseudocode: MBMS;;Particular cases of MBMS;;Pseudocode: LTP;;Complexity, convergence and stopping criterion;;Experiment: noisy spiral with outliers;;Preprocessing for spectral methods: 100D swissroll;;100D swissroll: robustness to parameter choice;;Other datasets;;Preprocessing for MNIST digit classification (1);;Preprocessing for MNIST digit classification (2);;Preprocessing for MNIST digit classification (3);;Preprocessing for MNIST: confusion matrix;;Preprocessing for MNIST digit classification (4);;Conclusions'
13088,'lecture','en',12409,'2010-06-16','2010-07-19','Increasing Depth Resolution of Electron Microscopy of Neural Circuits using Sparse Tomographic Reconstruction','Future progress in neuroscience hinges on reconstruction\nof neuronal circuits to the level of individual synapses.\nBecause of the specifics of neuronal architecture, imaging\nmust be done with very high resolution and throughput.\nWhile Electron Microscopy (EM) achieves the required resolution\nin the transverse directions, its depth resolution is\na severe limitation. Computed tomography (CT) may be\nused in conjunction with electron microscopy to improve\nthe depth resolution, but this severely limits the throughput\nsince several tens or hundreds of EM images need to be\nacquired. Here, we exploit recent advances in signal processing\nto obtain high depth resolution EM images computationally.\nFirst, we show that the brain tissue can be represented\nas sparse linear combination of local basis functions\nthat are thin membrane-like structures oriented in various\ndirections. We then develop reconstruction techniques\ninspired by compressive sensing that can reconstruct the\nbrain tissue from very few (typically 5) tomographic views\nof each section. This enables tracing of neuronal connections\nacross layers and, hence, high throughput reconstruction\nof neural circuits to the level of individual synapses.',NULL
13089,'demonstration video','en',12409,'2010-06-16','2010-07-19','Poster Spotlights',NULL,'SVM for Edge-Preserving Filtering;;SVM for Edge-Preserving Filtering - Abstract;;Personalization of Image Enhancement;;Personalization of Image Enhancement - Abstract;;Adaptive Linear Predictors for Real-Time Tracking;;Adaptive Linear Predictors - Abstract;;Transform Coding for Fast Approximate Nearest Neighbor Search in High Dimensions;;Nearest Neighbor Search in High Dimensions - Abstract;;Multilinear Pose and Body Shape Estimation of Dressed Subjects from Image Sets;;Pose and Shape from Image Sets - Abstract;;Linear View Synthesis Using a Dimensionality Gap Light Field Prior;;Linear View Synthesis - Abstract;;Multi-Target Tracking of Time-Varying Spatial Patterns;;Multi-Target Tracking - Abstract;;Abrupt Motion Tracking via Adaptive Stochastic Approximation Monte Carlo Samplin;;Abrupt Motion Tracking - Abstract;;Boosting for transfer learning with multiple sources;;Boosting for transfer learning - Abstract;;Energy Minimization for Linear Envelope MRFs;;Linear Envelope MRFs - Abstract;;Unified graph matching in Euclidean spaces;;Unified graph matching - Abstract;;On-line Semi-supervised Multiple-Instance Boosting;;Multiple-Instance Boosting - Abstract;;Robust RVM Regression Using Sparse Outlier Model;;Robust RVM Regression - Abstract;;Parametric Dimensionality Reduction by Unsupervised Regression;;Parametric Dimensionality Reduction - Abstract;;Moving Vistas: Exploiting Motion for Describing Scenes;;Moving Vistas - Abstract;;Part and Appearance Sharing: Recursive Compositional Models for Multi-View Multi-Object Detection;;Multi-View Multi-Object Detection - Abstract;;Randomized Hybrid Linear Modeling by Local Best-fit Flats;;Randomized Hybrid Linear Modeling - Abstract;;Improving State-of-the-Art OCR through High-Precision Document-Specific Modeling;;High-Precision Document-Specific Modeling - Abstract;;Discriminative Clustering for Image Co-segmentation;;Image Co-segmentation - Abstract'
13090,'lecture','en',12409,'2010-06-17','2010-07-19','Visual Classification with Multi-Task Joint Sparse Representation',NULL,'Visual Classification with Multi-Task Joint Sparse Representation;;Problem to Study;;Motivations;;Related Work;;Our Method;;Joint Sparse Representation;;Formulation;;Different Mixed-Norms (1);;Different Mixed-Norms (2);;Optimization;;Classification;;Algorithm 1;;Kernel-View Extensions;;Algorithm 2;;Column Generation;;Experiments;;Data Sets;;Results on Oxford flowers 17 (1);;Results on Oxford flowers 17 (2);;Results on Oxford flowers 102;;Results on Caltech 101;;Conclusions;;Thank you;;cvpr2010_yuan_vcmt_01_Page_24'
13091,'lecture','en',12409,'2010-06-17','2010-07-19','Classification and Clustering via Dictionary Learning with Structured Incoherence and Shared Features',NULL,'Classication and Clustering via Dictionary Learning with Structured Incoherence and Shared Features;;Applications of Sparse Models;;Sparse Models - 1;;Sparse Models - 2;;Sparse Models - 3;;Sparse Models - 4;;Learning a Sparse Model;;Sparse Models for Supervised Classication - 1;;Sparse Models for Supervised Classication - 2;;Classication Results;;Promoting Cross-Incoherence - 1;;Promoting Cross-Incoherence - 2;;Promoting Cross-Incoherence - 3;;Sparse Models for Clustering - 1;;Sparse Models for Clustering - 2;;Sparse Models for Clustering - 3;;Sparse Models for Clustering - 4;;Sparse Models for Clustering - 5;;Sparse Models for Clustering - 6;;Object Detection;;Texture Segmentation;;Extensions - 1;;Extensions - 2;;Extensions - 3;;Source Separation: Hierarchical models - 1;;Source Separation: Hierarchical models - 2;;Source Separation: Hierarchical models - 3;;Collaborative Source Separation - 1;;Collaborative Source Separation - 2;;Collaborative Source Separation Results - 1;;Collaborative Source Separation Results - 2;;Conclusions - 1;;Conclusions - 2'
13092,'lecture','en',12409,'2010-06-17','2010-07-19','The Automatic Design of Feature Spaces for Local Image Descriptors using an Ensemble of Non-linear Feature Extractors','The design of feature spaces for local image descriptors\nis an important research subject in computer vision due to\nits applicability in several problems, such as visual classification\nand image matching. In order to be useful, these descriptors\nhave to present a good trade off between discriminating\npower and robustness to typical image deformations.\nThe feature spaces of the most useful local descriptors have\nbeen manually designed based on the goal above, but this\ndesign often limits the use of these descriptors for some specific\nmatching and visual classification problems. Alternatively,\nthere has been a growing interest in producing feature\nspaces by an automatic combination of manually designed\nfeature spaces, or by an automatic selection of feature\nspaces and spatial pooling methods, or by the use of\ndistance metric learning methods. While most of these approaches\nare usually applied to specific matching or classification\nproblems, where test classes are the same as training\nclasses, a few works aim at the general feature transform\nproblem where the training classes are different from\nthe test classes. The hope in the latter works is the automatic\ndesign of a universal feature space for local descriptor\nmatching, which is the topic of our work. In this paper,\nwe propose a new incremental method for learning automatically\nfeature spaces for local descriptors. The method\nis based on an ensemble of non-linear feature extractors\ntrained in relatively small and random classification problems\nwith supervised distance metric learning techniques.\nResults on two widely used public databases show that our\ntechnique produces competitive results in the field.','The Automatic Design of Feature Spaces for Local Image Descriptors using an Ensemble of Non-linear Feature Extractors;;Set of Matching Problems (1);;Set of Matching Problems (2);;Set of Matching Problems (3);;Set of Matching Problems (4);;Set of Matching Problems (5);;The Universal Feature Transform;;(Linear) Distance Metric Learning;;(Non-Linear) Distance Metric Learning[;;Linear vs Non-linear DML;;Intuition (1);;Intuition (2);;Intuition (3);;Toy Example;;Experiments - Dataset of for training;;Experiments - Using cross validation;;Experiments - Matching database;;Conclusion;;cvpr2010_carneiro_adfs_01_Page_19;;cvpr2010_carneiro_adfs_01_Page_20'
13093,'lecture','en',12409,'2010-06-17','2010-07-19','Supervised Translation-Invariant Sparse Coding',NULL,'Supervised Translation-Invariant Sparse Coding;;Our Goal;;Translation-Invariant Sparse Coding Model (1);;Translation-Invariant Sparse Coding Model (2);;Translation-Invariant Sparse Coding Model (3);;Translation-Invariant Sparse Coding Model (4);;Translation-Invariant Sparse Coding Model (5);;Translation-invariant property by max pooling;;Sparse Coding for Image Classification;;Supervised Dictionary Training (1);;Supervised Dictionary Training (2);;Denote the cost function;;Find the gradient using chain rules (1);;Find the gradient using chain rules (2);;Find the gradient using chain rules (3);;Find the gradient using chain rules (4);;Solution: use implicit differentiation (1);;Solution: use implicit differentiation (2);;Solution: use implicit differentiation (3);;Initialization and Convergence;;Experiment Evaluation;;Experiment –Face Recognition (1);;Experiment –Face Recognition (1) Results;;Experiment –Face Recognition (2);;Experiment –Face Recognition (2) Results;;Experiment – Handwritten Digit Recognition;;Experiment – Gender Recognition;;Conclusion and Future Work;;Questions'
13094,'demonstration video','en',12409,'2010-06-17','2010-07-19','Poster Spotlights',NULL,'Comparative object similarity for improved recognition with few or no examples;;Comparative object similarity - Abstract;;Bayes Optimal Kernel Discriminant Analysis;;Bayes Optimal Kernel Discriminant Analysis - Abstract;;Efficient Additive Kernels via Explicit Feature Maps;;Efficient Additive Kernels - Abstract;;Data Driven Mean-Shift Belief Propagation for Non-Gaussian MRFs;;Data Driven Mean-Shift Belief Propagation - Abstract;;Local Features Are Not Lonely - Laplacian Sparse Coding for Image Classification;;Local Features Are Not Lonely - Abstract;;Factorization Towards a Classifier;;Factorization Towards a Classifier - Abstract;;Online Multi-Class LPBoost;;Online Multi-Class LPBoost - Abstract;;Sparse Representation using Nonnegative Curds and Whey;;Sparse Representation - Abstract;;Multi-Structure Model Selection via Kernel Optimisation;;Multi-Structure Model Selection - Abstract;;Data fusion through cross-modality metric learning using similarity-sensitive hashing;;Cross-modality metric learning;;Pareto Discriminant Analysis;;Pareto Discriminant Analysis (PARDA) - Asbtract;;Sufficient Dimension Reduction for Visual Sequence Classification;;Sufficient Dimension Reduction - Abstract;;Fast Sparse Representation with Prototypes;;Fast Sparse Representation - Abstract'
13095,'lecture','en',12409,'2010-06-16','2010-07-19','Parallel and Distributed Graph Cuts by Dual Decomposition','Graph cuts methods are at the core of many state-of-theart\nalgorithms in computer vision due to their efficiency\nin computing globally optimal solutions. In this paper, we\nsolve the maximum flow/minimum cut problem in parallel\nby splitting the graph into multiple parts and hence, further\nincrease the computational efficacy of graph cuts. Optimality\nof the solution is guaranteed by dual decomposition, or more\nspecifically, the solutions to the subproblems are constrained\nto be equal on the overlap with dual variables.\nWe demonstrate that our approach both allows (i) faster\nprocessing on multi-core computers and (ii) the capability\nto handle larger problems by splitting the graph across multiple\ncomputers on a distributed network. Even though our\napproach does not give a theoretical guarantee of speedup,\nan extensive empirical evaluation on several applications\nwith many different data sets consistently shows good\nperformance. An open source implementation of the dual\ndecomposition method is also made publicly available.','Parallel and Distributed Graph Cuts by Dual Decomposition;;Applications of Graph Cuts;;Graph Cuts;;Previous work (1);;Previous work (2);;Dual decomposition;;Decomposition of graphs;;Global solution;;Integer graphs;;Solution procedure;;Multiple splits;;Multiple splits (3D);;Results;;Convergence;;Regularization;;”Worst case” scenario;;Multiple computers (1);;Multiple computers (2);;Conclusions'
13096,'lecture','en',12409,'2010-06-16','2010-07-19','Object Separation In X-Ray Image Sets','In the segmentation of natural images, most algorithms\nrely on the concept of occlusion. In x-ray images, however,\nthis assumption is violated, since x-ray photons penetrate\nmost materials. In this paper, we introduce SATISφ, a\nmethod for separating objects in a set of x-ray images using\nthe property of additivity in log space, where the logattenuation\nat a pixel is the sum of the log-attenuations\nof all objects that the corresponding x-ray passes through.\nOur method leverages multiple projection views of the same\nscene from slightly different angles to produce an accurate\nestimate of attenuation properties of objects in the\nscene. These properties can be used to identify the material\ncomposition of these objects, and are therefore crucial\nfor applications like automatic threat detection. We evaluate\nSATISφ on a set of collected x-ray scans, showing that it\noutperforms a standard image segmentation approach and\nreduces the error of material estimation.','Object Separation in X-ray Image Sets;;Motivation;;X-Ray Image Object Detection;;Low-Level Vision: Segmentation;;Low-Level Vision: Multiple Views;;Full Example;;Problem Formulation;;SATISphi;;Data Model;;Assumptions;;SatisPhi MRF;;Goal: MAP Decomposition;;Joint Optimization;;Example Result;;Comparison to Baselines;;Quantitative Comparison;;Results –Water Bottles;;Results –Three Objects;;Summary;;Conclusion;;Questions'
13098,'lecture','en',12409,'2010-06-16','2010-07-19','Isoperimetric Cut on a Directed Graph',NULL,'Isoperimetric Cut on a Directed Graph;;Agenda;;Glossary;;General Procedure of Spectral Clustering;;Normalized Cut (1);;Normalized Cut (2);;Solution of NCut;;Graph Isoperimetric Ratio;;Problems of Spectral Clustering;;A Failed Case;;An Alternative Probabilistic View;;Kernel Density Estimation;;Bayes Error;;Nonparametric density modeling;;NCut = Minimal Bayes Error;;Local Density;;Directed Graph Construction;;Random Walks;;Random Walk Isoperimetric Ratio;;Isocut;;Hitting Time View;;Useful Facts;;Evaluation;;Experimental Results (1);;Experimental Results (2);;Experimental Results (3);;Future Work;;Thank you'
13099,'demonstration video','en',12409,'2010-06-16','2010-07-19','Poster Spotlights',NULL,'Lattice Cut;;Lattice Cut - Abstract;;A Diffusion Approach to Seeded Image Segmentation;;Seeded Image Segmentation - Abstract;;Discrete minimum ratio curves and surfaces;;Discrete minimum ratio curves and surfaces - Abstract;;Efficient Hierarchical Graph-Based Video-Segmentation;;Graph-Based Video-Segmentation - Abstract;;A Spatially Varying PSF-based Prior for Alpha Matting;;PSF-based Prior for Alpha Matting - Abstract;;Simultaneous Foreground, Background, and Alpha Estimation for Image Matting;;Estimation for Image Matting - Abstract;;Fast Matting Using Large Kernel Matting Laplacian Matrices;;Fast Matting Using Large Kernel Matting Laplacian Matrices - Abstract;;Fast Approximate Energy Minimization with Label Costs;;Fast Approximate Energy Minimization - Abstract;;Parallel Graph-cuts by Adaptive Bottom-up Merging;;Parallel Graph-cuts - Abstract;;cvpr2010_spotlights7_01_Page_19;;cvpr2010_spotlights7_01_Page_20;;Morphological Snakes;;Morphological Snakes - Abstract;;Co-Clustering of Image Segments using Convex Optimization Applied to EM Neuronal Reconstruction;;Co-Clustering of Image Segments - Abstract;;Multi-domain, Higher Order Level Set Scheme for 3D Image Segmentation on the GPU;;3D Image Segmentation on the GPU - Abstract;;A Study on Continuous Max-Flow and Min-Cut Approaches;;Max-Flow and Min-Cut Approaches - Abstract'
13100,'lecture','en',12409,'2010-06-17','2010-07-19','Tiered Scene Labeling with Dynamic Programming','Dynamic programming (DP) has been a useful tool for a\nvariety of computer vision problems. However its application\nis usually limited to problems with a one dimensional\nor low treewidth structure, whereas most domains in vision\nare at least 2D. In this paper we show how to apply DP\nfor pixel labeling of 2D scenes with simple “tiered” structure.\nWhile there are many variations possible, for the applications\nwe consider the following tiered structure is appropriate.\nAn image is first divided by horizontal curves\ninto the top, middle, and bottom regions, and the middle region\nis further subdivided vertically into subregions. Under\nthese constraints a globally optimal labeling can be found\nusing an efficient dynamic programming algorithm. We apply\nthis algorithm to two very different tasks. The first is\nthe problem of geometric class labeling where the goal is\nto assign each pixel a label such as “sky”, “ground”, and\n“surface above ground”. The second task involves incorporating\nsimple shape priors for segmentation of an image\ninto the “foreground” and “background” regions.','Tiered Scene Labeling ;;Global Optimum;;Pixel Labeling Problems;;Energy Function;;Restricting Label Layout;;Tiered Labeling;;Application: Geometric Labeling (Hoiem et.al.);;Application: Shape Prior for Binary Segmentation;;Dynamic Programming for 1D ;;Tiered Labeling -> DP: Overview;;Tiered labeling: State Space;;Tiered Labeling DP: Unary Terms;;Tiered Labeling DP: Pairwise Terms;;Tiered Labeling DP: Optimization;;Tiered Labeling DP: Speed Ups;;Geometric Labeling Results;;Shape Prior for Binary Segmentation;;Interactive Segmentation;;Shape Prior for Binary Segmentation;;Summary'
13101,'lecture','en',12409,'2010-06-17','2010-07-19','Segmentation of Building Facades Using Procedural Shape Priors','In this paper we propose a novel approach to the perceptual\ninterpretation of building facades that combines shape\ngrammars, supervised classification and random walks.\nProcedural modeling is used to model the geometric and\nthe photometric variation of buildings. This is fused with visual\nclassification techniques (randomized forests) that provide\na crude probabilistic interpretation of the observation\nspace in order to measure the appropriateness of a procedural\ngeneration with respect to the image. A random exploration\nof the grammar space is used to optimize the sequence\nof derivation rules towards a semantico-geometric\ninterpretation of the observations. Experiments conducted\non complex architecture facades with ground truth validate\nthe approach.','Segmentation of Building Facades using Procedural Shape Priors;;Introduction;;Problem (1);;Problem (2);;Problem (3);;Problem (4);;Problem (5);;Problem (6);;Problem (7);;Problem (8);;Problem (9);;Problem (10);;Problem (11);;Problem (12);;Related Work;;Shape grammar [Stiny 72] (1);;Shape grammar [Stiny 72] (2);;Split Grammars [Wonka 03];;Procedural Modeling of Facades (1);;Procedural Modeling of Facades (2);;Procedural Modeling of Facades (3);;Procedural Modeling of Facades (4);;Procedural Modeling of Facades (5);;Segmentation energy (1);;Segmentation energy (2);;Segmentation energy (3);;Segmentation energy (4);;Segmentation energy (5);;Segmentation energy (6);;Supervised Learning;;Optimization : grammar factorization (1);;Optimization : grammar factorization (2);;Optimization: algorithm (1);;Optimization: algorithm (2);;Optimization: algorithm (3);;Optimization: algorithm (4);;Quantitative Results;;Analysis;;Qualitative Results;;Conclusion;;Future Work;;Questions'
13102,'lecture','en',12409,'2010-06-17','2010-07-19','Layered Object Detection for Multi-Class Segmentation','We formulate a layered model for object detection and\nmulti-class segmentation. Our system uses the output of a\nbank of object detectors in order to define shape priors for\nsupport masks and then estimates appearance, depth ordering\nand labeling of pixels in the image. We train our system\non the PASCAL segmentation challenge dataset and show\ngood test results with state of the art performance in several\ncategories including segmenting humans.','Layered Object Detection for Multi-Class Image Segmentation;;Introduction (1);;Introduction (2);;Introduction (3);;Introduction (4);;Layered Representation;;Related work;;Issues;;Detector calibration;;Example (1);;Example (2);;Example (3);;Example (4);;Example (5);;Example (6);;Example (7);;Model;;Inference: coordinate descent (1);;Bottom-up segmentation;;Inference: coordinate descent (2);;Building P (1);;Shape priors (1);;Shape priors (2);;Shape priors (3);;Bicycle part-based priors;;Motorcycle part-based priors;;Horse part-based prior;;Bottle part-based priors;;Building P (2);;Building P (3);;Building P (4);;Building P (5);;Building P (6);;Building P (7);;Building P (8);;Building P (9);;Building P (10);;Building P (11);;Building P (12);;Building P (13);;The algorithm;;Results (1);;Results (2);;Results (3);;Results (4);;PASCAL 2009 Segmentation Challenge;;What aspects of the model are useful?;;Does ordering help?;;Conclusions;;Thank you'
13103,'demonstration video','en',12409,'2010-06-17','2010-07-19','Poster Spotlights',NULL,'Rectification of figure and photos in document images using bounding box interface;;Rectification of figure and photos - Abstract;;Geodesic Star Convexity for interactive image segmentation;;Geodesic Star Convexity - Abstract;;Figure-Ground Segmentation Improves Handled Object Recognition in Egocentric Video;;Figure-Ground Segmentation Helps Recognition - Abstract;;Learning Kernels for variants of Normalized Cuts: Convex Relaxations and applications;;Learning Kernels for variants of Normalized Cuts - Abstract;;Globally Optimal Pixel Labeling Algorithms for Tree Metrics;;Globally Optimal Pixel Labeling Algorithms - Abstract;;Geodesic Graph Cut for Interactive Image Segmentation;;Geodesic Graph Cut - Abstract;;iCoseg: Interactive Co-segmentation with Intelligent Scribble Guidance;;iCoseg: Interactive Co-segmentation - Abstract;;Variational Segmentation of Elongated Volumetric Structures;;Variational Segmentation - Abstract;;Collect-Cut: Segmentation with Top-Down Cues Discovered in Multi-Object Images;;Collect-Cut: Segmentation with Top-Down Cues - Abstract;;Authority-Shift Clustering: Hierarchical Clustering by Authority Seeking on Graphs;;Authority-Shift Clustering - Abstract;;Nonparametric Higher-Order Learning for Interactive Segmentation;;Nonparametric Higher-Order Learning - Abstract;;Efficiently Selecting Regions for Scene Understanding;;Efficiently Selecting Regions - Abstract;;A Shape-Driven MRF Model for the Segmentation of Organs in Medical Images;;A Shape-Driven MRF Model - Abstract;;Constrained Parametric Min-Cuts for Automatic Object Segmentation;;Constrained Parametric Min-Cuts - Abstract;;Towards weakly supervised semantic segmentation by means of multiple instance and multitask learning;;Towards weakly supervised semantic segmentation - Abstract;;Fast Global Optimization of Curvature;;Fast Global Optimization of Curvature - Abstract;;Label Propagation in Video Sequences;;Label Propagation in Video Sequences - Abstract;;Vessel Scale-Selection using MRF Optimization ;;Vessel Scale-Selection - Abstract;;Harmony Potentials for Joint Classification and Segmentation;;Joint Classification and Segmentation - Abstract'
13104,'lecture','en',12409,'2010-06-16','2010-07-19','Measuring Visual Saliency by Site Entropy Rate',NULL,'Measuring Visual Saliency by Site Entropy Rate;;Visual Attention & Visual Saliency;;Typical Applications;;Related Work;;Overview of our model;;The Proposed Framework (1);;The Proposed Framework (2);;The Proposed Framework (3);;The Proposed Framework (4);;The Proposed Framework (5);;Sparse Coding Bases;;Sub-band Graph Representation (1);;Sub-band Graph Representation (2);;Random Walk on The Graph;;Two Thoughts on Salience Measure;;Site Entropy Rate (1);;Site Entropy Rate (2);;Site Entropy Rate (3);;More Details about SER (1);;More Details about SER (2);;More Details about SER (3);;The Generalized Center-Surround Explanation;;The Saliency Map;;Experimental Results;;Experiments on Psychological Stimuli;;Experiments on Color Image Data Set;;Comparison Results;;Experiments on Gray Image Data Set;;Experiments on Videos (1);;Experiments on Videos (2);;Conclusions;;Acknowledgement;;Questions'
13105,'lecture','en',12409,'2010-06-16','2010-07-19','Context-Aware Saliency Detection','We propose a new type of saliency – context-aware saliency\n– which aims at detecting the image regions that represent\nthe scene. This definition differs from previous definitions\nwhose goal is to either identify fixation points or detect the\ndominant object. In accordance with our saliency definition,\nwe present a detection algorithm which is based on\nfour principles observed in the psychological literature. The\nbenefits of the proposed approach are evaluated in two applications\nwhere the context of the dominant objects is just\nas essential as the objects themselves. In image retargeting\nwe demonstrate that using our saliency prevents distortions\nin the important regions. In summarization we show that\nour saliency helps to produce compact, appealing, and informative\nsummaries.','Describe this picture (1);;Describe this picture (2);;Describe this picture (3);;Saliency = human attention;;Saliency = dominant object;;Saliency = segmentation;;Saliency = story telling;;Context-aware saliency;;Contributions (1);;Contributions (2);;Principles of saliency;;Principle 1;;Principle 2;;Principle 1 + 2;;Principle 3;;Principle 4;;Incorporating the 4 Principles (1);;Incorporating the 4 Principles (2);;The “how”;;Local-global saliency;;Computing uniqueness;;Appearance uniqueness (1);;Appearance uniqueness (2);;Positional information (1);;Positional information (2);;Positional information (3);;Single scale uniqueness (1);;Single scale uniqueness (2);;Single scale uniqueness (3);;Single scale saliency (1);;Single scale saliency (2);;Multiple scales;;Including immediate context;;Visual organization;;Final saliency;;High-level factors;;Algorithm summary;;Results;;Non-interesting background (1);;Non-interesting background (2);;Object + immediate surrounding (1);;Object + immediate surrounding (2);;Complex scenes (1);;Complex scenes (2);;Quantitative evaluation;;Compare with Liu et al.;;Applications;;Image retargeting (1);;Image retargeting (2);;Image retargeting (3);;Collage (1);;Collage (2);;Collage (3);;Collage (4);;Summary;;Questions'
13106,'lecture','en',12409,'2010-06-16','2010-07-19','Minimum length in the tangent bundle as a model for curve completion',NULL,'Minimum length in the tangent bundle as model for curve completion;;Phenomenology of Curve Completion;;The problem of Curve Completion;;The Axiomatic Approach to Curve Completion (1);;The Axiomatic Approach to Curve Completion (2);;Axiomatic Models to Curve Completion (1);;Axiomatic Models to Curve Completion (2);;The Axiomatic Approach to Curve Completion (3);;Relevant Perceptual Insights;;Relevant Neuro-Physiological Insights;;Abstraction of V1 as the Unit Tangent Bundle;;Our approach: Curve Completion in the Unit Tangent Bundle;;Curve Completion in the Unit Tangent Bundle;;Admissibility in the Unit Tangent Bundle;;Minimum Length Curve Completion (1);;Minimum Length Curve Completion (2);;Numerical Solution via Nonlinear Optimization;;Experimental Results (1);;Experimental Results (2);;Induced Perceptual Properties (1);;Induced Perceptual Properties (2);;Summary;;In the Pipeline;;Questions'
13112,'lecture','en',12410,'2010-06-25','2010-07-20','Welcome and Overview',NULL,NULL
13113,'invited talk','en',12410,'2010-06-25','2010-07-20','OpenCV',NULL,'Open Source Purpose and Models, Open Source Parts and Wholes ;;Outline - 1;;What is the Purpose of Open Source?;;The Arc of Computer Science;;What is the Purpose of Open Source?;;Implication;;Models - 1;;Models - 2;;Algorithms, not Code;;Outline - 2;;Willow Garage ... and Open Source;;What is Willow Garage?;;Business Plan - 1;;Business Plan - 2;;Business Plan - 3;;Outline - 3;;ROS;;What is ROS?;;ROS Concepts;;Architecture Overview;;Nodes;;ROS Messages;;master, roscore;;Packages & Stacks;;Repositories;;A Model for Open Source?;;Outline - 4;;OpenCV Overview;;Machine Learning Library (MLL);;OpenCV History;;OpenCV Tends Towards Real Time;;License;;Where is OpenCV Used?;;Useful OpenCV Links;;Outline - 5;;Canny Edge Detector;;Distance Transform;;Hough Transform;;Space Variant vision;;Scale Space;;Thresholds;;Histogram Equalization;;Contours;;Morphological Operations Examples;;Image textures;;Segmentation;;Recent Algorithms: GrabCut;;Motion Templates;;Segmentation, Motion Tracking and Gesture Recognition;;New Optical Flow Algorithms;;Tracking with CAMSHIFT;;Projections;;Stereo ... Depth from Triangulation;;Stereo;;Stereo Rectification;;Recognition;;Patch Matching;;Boosting;;Outline - 6;;New C++API: Usage Example;;Software Engineering;;New Directory Structure;;New OpenCV Conceptual Structure;;Modules/Stacks/Pipelines;;Organize OpenCV by Procesing Stacks;;Detector interface;;Descriptor interfaces;;Instantiate DescriptorExtractor;;Run Descriptor Matcher;;Compare and Contrast using Testbench output;;Features2D Use: Homography;;Features2D Use: Visual Odometry;;New Object Rec. Pipelines Coming;;Outline - 7;;First: The Sensors PR2 has;;Dense Stereo from Textured Light;;Willow Garage: Milestone 2;;Milestone 2: Door Handle Detection;;Detecting Outlets from Far Away;;Visual Servoing to Plug In: 2D Features + Geometry;;Milestone 2;;Binary Gradient Grid;;Binary Gradient Grid (BiGG);;Use of BiGG for Manipulation;;Low Level Processing: Separating Planes, Finding Normals;;Start with Radu Rusu\'s Point Feature Histohram (PFH);;Fast Point Feature Histograms (EPFH) - 1;;Fast Point Feature Histograms (EPFH) - 2;;Point Feature Histograms (EPFH) ;;Surface Classification;;FPFH Classification;;Moving Towards Object Class Recognition;;Global FPFHs (GFPFH);;Object Class Recognition Arhitecture;;GFPFH Classification;;Recognition;;FPFH Use in Manipulation - 1;;FPFH Use in Manipulation - 2;;Latest Work: ViewPoint Feature Histogram;;Latest Work 3D Pop Out from 2D;;Outline - 8;;Working on: Object Database;;Working on: Computer Vision challenges - 1;;Working on: Computer Vision challenges - 2;;Working on: Solved Problems in Vision Contest;;Questions?'
13114,'invited talk','en',12410,'2010-06-25','2010-07-20','Reproducible Research in Computational Science: Problems and Solutions For Data and Code Sharing ','Scientific computation is emerging as absolutely central to the scientific method, but the prevalence of very relaxed practices is leading to a credibility crisis. Reproducible computational research, in which all details of computations—code and data—are made conveniently available to others, is a necessary response to this crisis. Results from a 2009 survey of the Machine Learning community (NIPS participants) designed to elucidate factors that affect data and code sharing will be presented. Intellectual property concerns create a significant barrier to sharing, and I will also present work on the “Reproducible Research Standard” giving open licensing options designed to create an intellectual property framework for scientists consonant with longstanding scientific norms and facilitating reproducible research.\n','Reproducible Research in Computational Science;;Outline;;Scientific Research is Sharing;;Examples fo Pervasiveness of Computational Methods;;Examples of the Changing Nature of Scientific Discovery - 1;;Examples of the Changing Nature of Scientific Discovery - 2;;Examples of the Changing Nature of Scientific Discovery - 3;;Examples of the Changing Nature of Scientific Discovery - 4;;Examples of the Changing Nature of Scientific Discovery - 5;;Evidence of a problem ...;;Climategate;;Clinical trials based on flawed genomic studies - 1;;Clinical trials based on flawed genomic studies - 2;;A Credibility Crisis on Computational Science ...;;Controling Error is Central to Scientific Progress;;The Third Branch of the Scientific Method;;Toward a Resolution of the Credibility Crisis;;Question: How do we share computational work?;;Surveying the Machine Learning Community;;Top Reasons Not to Share;;Survey of Machine Learning Community;;Top Reasons to Share;;Findings;;Legal Barriers to Reproducibility;;Response Outside the Sciences - 1;;Response Outside the Sciences - 2;;Response from Within the Sciences ;;Copyleft Not Appropriate for Scientific Code;;Releasing Data?;;Benefits and Dificulties of the RRS;;Conclusions;;References'
13115,'lecture','en',12410,'2010-06-25','2010-07-20','Universal Java Matrix Package','The Universal Java Matrix Package (UJMP) is an open source Java library which provides sparse and dense matrix classes, as well as a large number of calculations for linear algebra like matrix multiplication or matrix inverse. Operations such as mean, correlation, standard deviation, replacement of missing values or the calculation of mutual information are supported also.\n\nThe Universal Java Matrix Package provides various visualization methods, import and export filters for a large number of file formats, and the possibility to link to tables in JDBC databases. Multi-dimensional matrices as well as generic matrices with a specified object type are supported and very large matrices with up to 2^63 rows and columns can be handled even when they do not fit into memory.\n\nA central concept of UJMP is the separation of interfaces, abstract classes and their implementations, which makes it very easy to exchange the underlying data storage. Thus, a matrix in our framework can be an array of values in main memory, a file on disk or a table in an SQL database. In fact, the actual storage implementation becomes secondary and UJMP can even integrate other matrix libraries such as JAMA or Colt, making UJMP’s visualization and import and export filters available to these libraries.\n\nOn the other hand, UJMP can also decide to redirect calculations to other matrix libraries, depending on matrix size and computer hardware. UJMP uses multiple threads for calculations, which results in much better performance compared to JAMA or Colt on modern hardware.\n\nUJMP also includes interfaces to Matlab, Octave and R, which makes it easy to perform calculations not available in Java.\n\nWhile some parts of UJMP are pretty stable by now, a lot of development is still going on in other parts. Developers are welcome to contribute!','The Universal Java Matrix Package (UJMP);;Introduction;;Comparison of Matrix Libraries for Java;;Concepts for a Next-Generation Matrix Library;;Integration of Other Matrix Libraries;;Calculation Methods;;Matrix Annotation;;Automatic Entry Type Conversation;;Demo;;Summary and Discussion'
13116,'lecture','en',12410,'2010-06-25','2010-07-20','Shogun','The SHOGUN machine learning toolbox\'s focus is on large scale kernel methods and especially on Support Vector Machines (SVM). It comes with a generic interface for kernel machines and features 15 different SVM implementations that all access features in a unified way via a general kernel framework or in case of linear SVMs so called \"DotFeatures\", i.e., features providing a minimalistic set of operations (like the dot product).','The SHOGUN Machine Learning Toolbox;;Outline;;SHOGUN Machine Learning Toolbox - Overview - 1;;SHOGUN Machine Learning Toolbox - Overview - 2;;Feature Representations;;Interfaces;;The Eierlegendewollmilchsau Interface;;Unique Features of SHOGUN - 1;;Unique Features of SHOGUN - 2;;Application;;Demo;;Summary'
13117,'lecture','en',12410,'2010-06-25','2010-07-20','The next steps after UCI - mldata.org','Recently, mloss.org has enabled machine learning researchers to register their software and allow other researchers to easily find, download, and reuse software matching their interests. Currently, more than 200 projects are listed. Furthermore, the Journal of Machine Learning Research now accepts papers to its special Open Source Software track, in which papers describing peer-reviewed software can be published, as a further incentive for researchers to publish their software under an open source license. Since its inception, in October 2007, seven papers have been published in this track with more papers currently under review. So far, the initiative has been highly successful, but has focused mostly on the ”method” side of the problem to make machine learning research more reproducible. Hence we see the need to initiate a companion project to mloss.org which focuses on the free exchange and benchmarking of datasets. Additionally, this new repository will emphasise the precise specification of machine learning tasks: detailed definitions of datasets to be used (possibly including feature extraction or other preprocessing steps) together with the desired operation to be performed and the relevant performance metric. Finally, a solution to such a task would provide details of how to apply a general software package (such as on mloss.org) to this particular problem instance, as well as the obtained numerical performance measures. This project will thus focus on providing a platform for publishing, exchanging, collecting, and discussing such data sets, tasks, and solutions for challenging machine learning problems.','Pascal Machine Learning Data Repository;;Overview;;mldata Structure;;Current Status;;Screenshot - 1;;Screenshot - 2;;Next steps'
13118,'debate','en',12410,'2010-06-25','2010-07-20','Exchanging Software and Data',NULL,NULL
13119,'lecture','en',12410,'2010-06-25','2010-07-20','Libra','The Libra machine learning toolkit includes implementations of a variety of algorithms for learning and inference with Bayesian networks and arithmetic circuits:\n\nLearning algorithms -- Structure learning for BNs and ACs; Chow-Liu algorithm; AC weight learning\n\nInference algorithms - Mean field, belief propagation, Gibbs sampling, AC variable elimination, AC exact inference\n\nLibra\'s strength is exploiting context-specific independence (such as decision tree CPDs) to allow exact inference in models with high treewidth.','The Libra Toolkit;;Libra in a Nutshell - 1;;Libra in a Nutshell - 2;;Outline - 1;;Probabillistic Graphical Models - 1;;Probabillistic Graphical Models - 2;;Local Structure: Decision Trees;;Local Structure: Features;;Arithmetic Circuits;;Outline - 2;;Structure Learning;;Exact Inference;;Approximate Inference;;What\'s Missing?;;Outline - 3;;Implementation - 1;;Implementation - 2;;Why OCaml?;;OCaml Example;;Demo;;Lessons Learned;;Conclusions;;Exact Inference'
13120,'lecture','en',12410,'2010-06-25','2010-07-20','FastInf','The FastInf C++ library is designed to perform memory and time efficient approximate inference in large-scale discrete undirected graphical models. The focus of the library is propagation based approximate inference methods, ranging from the basic loopy belief propagation algorithm to propagation based on convex free energies. Various message scheduling schemes that improve on the standard synchronous or asynchronous approaches are included. Also implemented are a clique tree based exact inference, Gibbs sampling, and the mean field algorithm. In addition to inference, FastInf provides parameter estimation capabilities as well as representation and learning of shared parameters. It offers a rich interface that facilitates extension of the basic classes to other inference and learning methods.','Fastinf: An Efficient Approximate Inference Library;;Probabilistic Graphical Models 101;;Factor Graphs - 1;;Factor Graphs - 2;;Factor Graphs - 3;;Factor Graphs - 4;;Example - HMM - 1;;Example - HMM - 2;;Example - HMM - 3;;Queries;;Approximate Inference;;(Our) Motivation;;Relational Probabilistic Graphical Models;;HMM revisited;;Library Design;;FastInf Features;;Comparison;;Applications;;External Libraries;;Demo;;Acknowledgments'
13121,'lecture','en',12410,'2010-06-25','2010-07-20','PyBrain','PyBrain is a versatile machine learning library for Python. Its goal is to provide flexible, easy-to-use yet still powerful algorithms for machine learning tasks, including a variety of predefined environments and benchmarks to test and compare algorithms. Implemented algorithms include Long Short-Term Memory (LSTM), policy gradient methods, (multidimensional) recurrent neural networks and evolution strategies like CMA-ES, NES or FEM.',NULL
13122,'lecture','en',12410,'2010-06-25','2010-07-20','Jstacs','Sequence analysis is one of the major subjects of bioinformatics. Several existing libraries combine the representation of biological sequences with exact and approximate pattern matching as well as alignment algorithms. We present Jstacs, an open source Java library, which focuses on the statistical analysis of biological sequences instead. Jstacs comprises an efficient representation of sequence data and provides implementations of many statistical models with generative and discriminative approaches for parameter learning. Using Jstacs, classifiers can be assessed and compared on test datasets or by cross-validation experiments evaluating several performance measures. Due to its strictly object-oriented design Jstacs is easy to use and readily extensible.','Problems - 1;;Problems - 2;;Jstacs - 1;;Jstacs - 2;;Jstacs - 3;;Jstacs - 4;;Jstacs - 5;;Jstacs - 6'
13123,'lecture','en',12410,'2010-06-25','2010-07-20','JBlas','jblas is a fast linear algebra library for Java. jblas is based on BLAS and LAPACK, the de-facto industry standard for matrix computations, and uses state-of-the-art implementations like ATLAS for all its computational routines, making jBLAS very fast.\n\njblas can is essentially a light-wight wrapper around the BLAS and LAPACK routines. These packages have originated in the Fortran community which explains their archaic API. On the other hand modern implementations are hard to beat performance wise. jblas aims to make this functionality available to Java programmers such that they do not have to worry about writing JNI interfaces and calling conventions of Fortran code.\n\njblas is the only actively developed matrix library which is based on native implementations (The other such project is netlib-java which is apparently not maintained anymore). Therefore, jblas is much faster than other projects, in particular for large complex tasks like matrix-matrix multiplication, solving linear equations, or eigenproblems.','jblas;;Overview;;Benchmarks;;Structure;;Background on Native Calls in Java - 1;;Background on Native Calls in Java - 2;;Matrix creation;;Element access - 1;;Element access - 2;;Simple Arithmetic;;Machine Learning;;Computing a sinc data set;;Gaussian kernel;;Kernel Ridge Regression - 1;;Kernel Ridge Regression - 2;;Computing the mean-squared error;;Conjugate Gradients - 1;;Conjugate Gradients - 2;;Outlook'
13124,'lecture','en',12410,'2010-06-25','2010-07-12','Scikitlearn','Scikits.learn is a Python module integrating classique machine learning algorithmes in the tightly-nit world of scientific Python packages\n\nIt aims to provide simple and efficient solutions to learning problems that are accessible to everybody and reusable in various contexts: machine-learning as a versatile tool for science and engineering.','Scikit Learn;;Project vision and goals;;API and design - 1;;API and design - 2;;Main features and algorithms;;To wrap up ...'
13125,'lecture','en',12410,'2010-06-25','2010-07-20','Mulan Mulan','Mulan is an open-source Java library for learning from multi-label datasets. Multi-label datasets consist of training examples of a target function that has multiple binary target variables. This means that each item of a multi-label dataset can be a member of multiple categories or annotated by many labels (classes). This is actually the nature of many real world problems such as semantic annotation of images and video, web page categorization, direct marketing, functional genomics and music categorization into genres and emotions. An introduction on mining multi-label data is provided in (Tsoumakas et al., 2010).\n\nCurrently, the library includes a variety of state-of-the-art algorithms for performing the following major multi-label learning tasks:\n\nClassification. This task is concerned with outputting a bipartition of the labels into relevant and irrelevant ones for a given input instance.\nRanking. This task is concerned with outputting an ordering of the labels, according to their relevance for a given data item\nClassification and ranking. A combination of the two tasks mentioned-above.\nIn addition, the library offers the following features:\n\nFeature selection. Simple baseline methods are currently supported.\nEvaluation. Classes that calculate a large variety of evaluation measures through hold-out evaluation and cross-validation.\nAs already mentioned, Mulan is a library. As such, it offers only programmatic API to the library users. There is no graphical user interface (GUI) available. The possibility to use the library via command line, is also currently not supported. The Getting Started page in the Documentation section is the ideal place to start exploring Mulan.','Mulan: A Java Library for Multi-Label Learning;;What is Multi-Label Learning;;Applications;;Mulan at a Glance;;Data Format;;Hierarchies of Labels;;Transformation Based ML-Learners;;Algorithm Adaptation ML-Learners;;Multi-Label Meta Learners;;An Example;;Sample output;;Thanks for your attention'
13126,'lecture','en',12410,'2010-06-25','2010-07-20','OpenKernel','The OpenKernel library is an open-source software library for designing, combining, learning and using kernels for machine learning applications\n\nThe library supports the design and use of kernels defined over dense and sparse real vectors, as well as over sequences or distributions of sequences.\n\nFor dense and sparse features, the library provides implementation of the classical kernels: linear, polynomial, Gaussian and sigmoid.\n\nFor sequences and distributions of sequences, the library implements the rational kernel framework of Cortes et al. (JMLR, 2004). The library supplies the following sequence kernels:\n\nn -gram kernels,\ngappy n-gram kernels,\nmismatch kernels (Leslie et al., 2004),\nand gives the utilities for creating arbitrary rational kernels simply by providing the weighted finite-state transducers they are based on.\n\nKernels can be combined by taking their sum or their product, and can be composed with a polynomial, a Gaussian or a sigmoid. They support on-demand evaluation and caching. In addition to its own binary format, the library uses the ASCII format of LIBSVM/LIBLINEAR/SVMlight for representing features (and precomputed kernels for LIBSVM).\n\nFinally, the OpenKernel library also includes several options for using training data to automatically combine multiple kernels. This is particularly useful when the single best kernel for the task is not known. The algorithms implemented include\n\nL1-regularized linear combinations (Lanckriet et al. JMLR 2004);\nL2-regularized linear combinations (Cortes et al. UAI 2009);\nL2-regularized quadratic combinations (Cortes et al. NIPS 2009),\nas well as kernel correlation, or alignment (Cortes et al. ICML 2010), based combinations. Specialized efficient versions of these algorithms are also made available for weighting features and sparseness and can be used to further improve efficiency. The output kernels can be easily used in conjunction with LIBSVM, SVMlight and included kernel ridge regression implementations. Full reference documentation, tutorials and examples (with formatted datasets) are included.\n\nThe library is an open-source project distributed under the Apache license (2.0). This work has been partially supported by Google Inc. The library uses the OpenFst library for representing and manipulating weighted finite-state transducers.','OpenKernel Library;;Library overview;;Rational Kernels;;Learning Kernel Tools;;Future plans'
13127,'lecture','en',12410,'2010-06-25','2010-07-20','MultiBoost','AdaBoost [Freund-Schapire, 1997] is one of the best off-the-shelf supervised classification methods developed in the last fifteen years. Despite (or perhaps due to?) its simplicity and versatility, it is suprisingly under-represented in the family of open softwares. The goal of this submission is to fill this gap.\n\nOur implementation is based on the AdaBoost.MH algorithm [Schapire-Singer, 1999]. It is an intrinsically multi-class classification method (unlike SVM for example), and it was easy to extend to multi-label or multi-task classification (when one item can belong to several classes). The program package can be divided into four modules that can be changed more-or-less independently depending on the application.\n\nThe strong learner. It tells you how to boost. The main boosting engine is AdaBoost.MH, but we have also implemented FilterBoost for a research project. Other possible strong learners could be LogitBoost and ADTrees.\n\nThe base (or weak) learner. It tells you what features to boost. Right now we have two basic (feature-wise) base learners: decision stumps for real-valued features and indicators for nominal features. We have two meta base learners: trees and products. They can use any base learner and construct a generic complex base learner using a \"classic\" tree-structure (decision trees), or using the product of simple base learners (self advertisement: boosting products of stumps is the best reported no-domain-knowledge algorithm on MNIST after Hinton and Salakhutdinov\'s deep belief nets). We have also implemented Haar filters [Viola-Jones, 2004] for image classification, a meta base learner that uses stumps over a high dimensional feature space computed \"on the fly\". It is a nice example of a domain dependent base learner that works hand-in-hand with its appropriate data structure.\n\nThe data representation. The basic data structure is a matrix of observations with a vector of labels. We also have multi-label classification when the label data is also a full matrix. In addition, we have sparse data representation for both the observation matrix and the label matrix. In general, base learners are implemented to work with their own data representation (for example, sparse stumps work on sparse observation matrices, or Haar filters work on a integral image data representation.\n\nData parser. We can read in data in arff and svmlight formats.\n\nThe base learner/data structure combinations cover a large spectrum of possible applications, but the main advantage of the package is that it is easy (for the advanced user) to adapt MultiBoost to a specific (non-standard) application by implementing the base learner and data structure interfaces that work together.\n\nThe source code is available from the website multiboost.org. It can be compiled on Mac OS X, Linux, and Microsoft Windows. The interface is command line execution with switches.','multiboost.org - 1;;Position slide;;A \"simple\" base learner for nominal features;;Cost sensitive multi-label/multi-class - 1;;Cost sensitive multi-label/multi-class - 2;;multiboost.org - 2;;multiboost.org - 3;;Benchmark and challenge results'
13128,'lecture','en',12410,'2010-06-25','2010-07-20','Gidoc','Transcription of handwritten text in (old) documents is an important, time-consuming task for digital libraries. It might be carried out by first processing all document images off-line, and then manually supervising system transcriptions to edit incorrect parts. However, current techniques for automatic page layout analysis, text line detection and handwriting recognition are still far from perfect, and thus post-editing system output is not clearly better than simply ignoring it.\n\nA more effective approach to transcribe old text documents is to follow an interactive- predictive paradigm in which both, the system is guided by the user, and the user is assisted by the system to complete the transcription task as efficiently as possible. Following this approach, a system prototype called GIDOC (Gimp-based Interactive transcription of old text DOCuments) has been developed to provide user-friendly, integrated support for interactive-predictive layout analysis, line detection and handwriting transcription.\n\nGIDOC is designed to work with (large) collections of homogeneous documents, that is, of similar structure and writing styles. They are annotated sequentially, by (par- tially) supervising hypotheses drawn from statistical models that are constantly updated with an increasing number of available annotated documents. And this is done at different annotation levels. For instance, at the level of page layout analysis, GIDOC uses a novel text block detection method in which conventional, memoryless techniques are improved with a “history” model of text block positions. Similarly, at the level of text line image transcription, GIDOC includes a handwriting recognizer which is steadily improved with a growing number of (partially) supervised transcriptions.',NULL
13129,'lecture','en',12410,'2010-06-25','2010-07-20','Dependency Modelling Toolbox','Investigation of dependencies between multiple data sources allows the discovery of regularities and interactions that are not seen in individual data sets. The increasing availability of co-occurring measurement data in computational biology, social sciences, and in other domains emphasizes the need for practical implementations of general-purpose dependency modeling algorithms.\n\nThe project collects various dependency modeling approaches into a unified toolbox. The techniques for the discovery and analysis of statistical dependencies are based on well-established models such as probabilistic canonical correlation analysis and multi-task learning whose applicability has been demonstrated in previous case studies.','Probabilistic Tools for Dependency Modeling ;;Summary;;Models for Dependency - 1;;Models for Dependency - 2;;Cancer gene discovery with dependency detection;;References;;For more information'
13130,'debate','en',12410,'2010-06-25','2010-07-20','Reproducible research',NULL,NULL
13131,'introduction','en',12410,'2010-06-25','2010-07-20','Introduction and overview of the SIMBAD project',NULL,'Learning in Non-(geo)metric Spaces - Workshop;;The SIMBAD FP7 Project;;Pattern Recognition and Hume\'s Similarity principle;;The Classical \"Feature-based\" Approach and its Limitations;;Beyond features?;;Objectives of SIMBAD;;The structure of SIMBAD;;For more information;;Journal Special Issue;;The SIMBAD Workshop Series;;Workshop Schedule - 1;;Workshop Schedule - 2'
13132,'lecture','en',12410,'2010-06-25','2010-07-20','Clustering without any subjective similarity information','Consider the task of clustering university web pages based on the graph of links between these pages. Can clusters of \"functionally similar\" pages be detected from just this link structure? Note that this is a clustering task in which one starts without any prior knowledge of any similarity or distance measure between the domain elements. All the information in the input comes as objective, observed, binary relations among the objects. These relations are not similarity links. For example, the cluster of professors pages have very internal links, whereas the cluster of service pages have lots of internal links. What we are looking for are clusters whose members share similar link patterns with respect to the other clusters. \nWe propose a formal model for such clustering tasks. Our model is based on an objective function that measures the homogeneity of between-clusters links. I shall discuss the computational complexity of finding a clustering with minimal objective cost and describe some hardness results as well as efficient approximation algorithms. \nThe talk is (partly) based on work with Sharon Wulff. ','Clustering without any subjective similarity measure - Regularity Clustering;;A different clustering task;;Differences from common clustering tasks;;The clustering goal;;Epistasis Networks;;Formal task definition;;The Monochromatic Objective Function;;Interpretations;;The variance objective function;;Relationship to Szemeredi\'s Regularity Lemma;;Correlation Clustering;;Connection to Regularity Clustering;;Extensions to Co-Clustering;;The Netflix Challenge;;Bi-clustering expression micro-arrays;;The Computational Complexity of Regularity Clusterings;;Approximation Algorithms outline;;Conclusions;;Future research direction'
13133,'lecture','en',12410,'2010-06-25','2010-07-20','Learning with similarity functions','Kernel functions have become an extremely popular tool in machine learning, with many applications and an attractive theory. This theory views a kernel as performing an implicit mapping of data points into a possibly very high dimensional space, and describes a kernel function as being good for a given learning problem if data is separable by a large margin in that implicit space. In this talk I will describe an alternative, more general, theory of learning with similarity functions (i.e., sufficient conditions for a similarity function to allow one to learn well) that does not require reference to implicit spaces, and does not require the function to be positive semi-definite (or even symmetric). \nIn particular, I will describe a notion of a good similarity function for a given learning problem that (a) is fairly natural and intuitive (it does not require an implicit space and allows for functions that are not positive semi-definite), (b) is a sufficient condition for learning well, and (c) strictly generalizes the notion of a large-margin kernel function in that any such kernel is also a good similarity function, though not necessarily vice-versa. ','Learning with General Similarity Functions;;2-Minute Version;;Kernel Methods;;Example;;Generalize Well if Good Margin;;Kernel Methods;;Limitations of the Current Theory;;Better Theoretical Framework;;More General Similarity Functions;;A First Attempt - 1;;A First Attempt - 2;;A First Attempt - 3;;A First Attempt - 4;;A First Attempt - 5;;A First Attempt - 6;;Broader Definition - 1;;Broader Definition - 2;;Kernels versus Similarity Functions - 1;;Kernels versus Similarity Functions - 2;;Kernels versus Similarity Functions - 3;;Learning with Multiple Similarity Functions;;Conclusions - 1;;Conclusions - 2;;Picture;;Similarity Functions for Classification'
13134,'lecture','en',12410,'2010-06-25','2010-07-20','From collaborative filtering to multitask learning','Recent work on collaborative filtering has led to a large number of both scalable and theoretically well founded algorithms. In this paper, we show that collaborative filtering and multitask learning are innately closely connected. In particular, the \'learning the kernel\' paradigm in multitask learning turns out to be identical to a Ky-Fan norm minimization. This allows us to “import” collaborative filtering techniques into multitask learning and vice versa; in particular, we solve a multitask learning problem where the tasks also have features. We show the feasibility of our approach on two large real-world multitask learning applications. \nJoint work with Markus Weimer, Wei Chu, Deepayan Chakrabarti. ','Learning the Kernel?;;Outline - 1;;Outline - 2;;Outline - 3;;Outline - 4;;Three problems - one solution;;Learning the Kernel - 1;;Learning the Kernel - 2;;Learning the Kernel - 3;;Learning the Kernel - 4;;Learning the Kernel - 5;;Learning the Kernel - 6;;Learning the Kernel - 7;;Multitask Learning - 1;;Multitask Learning - 2;;Multitask Learning - 3;;Multitask Learning - 4;;Multitask Learning - 5;;From CF to MTL - 1;;From CF to MTL - 2;;From CF to MTL - 3;;Factorization - 1;;Factorization - 2;;Factorization - 3;;Factorization - 4;;Factorization - 5;;Factorization - 6;;Factorization - 7;;Factorization - 8;;Applications;;Tensor Factorization - 1;;Tensor Factorization - 2;;Tensor Factorization - 3;;Tensor Factorization - 4;;Optimization;;User profiles;;Datasets;;Click model;;Page classification;;Effect of dimensionality;;Summary - 1;;Summary - 2;;Summary - 3;;Summary - 4'
13135,'lecture','en',12410,'2010-06-25','2010-07-20','On probabilistic hypergraph matching','We consider the problem of finding a matching between two sets of features, given complex relations among them, going beyond pairwise. We derive the hyper-graph matching problem in a probabilistic setting represented by a convex optimization. First, we formalize a soft matching criterion that emerges from a probabilistic interpretation of the problem input and output, as opposed to previous methods that treat soft matching as a mere relaxation of the hard matching problem. Second, the model induces an algebraic relation between the hyper-edge weight matrix and the desired vertex-to-vertex probabilistic matching. Third, the model explains some of the graph matching normalization proposed in the past on a heuristic basis such as doubly stochastic normalizations of the edge weights. A key benefit of the model is that the global optimum of the matching criteria can be found via an iterative successive projection algorithm. The algorithm reduces to the well known Sinkhorn row/column matrix normalization procedure in the special case when the two graphs have the same number of vertices and a complete matching is desired. Another benefit of our model is the straightforward scalability from graphs to hyper-graphs. \nThe work was done with Ron Zass (and made its debut in CVPR 2008) ','Probabiistic Graph and Hypergraph Matching;;Example: Object Matching;;Hypergraph Matching in Computer Vision - 1;;Hypergraph Matching in Computer Vision - 2;;Related Work Hypergraph matching;;Related Work Inexact Graph Matching;;From Soft to Hard;;Hypergraph Matching;;Probabilistic Hypergraph Matching;;Kronecker Product;;S ↔ X connection;;S ↔ X connection for graphs;;Globally Optimal Soft Hypergraph Matching - 1;;Cour, Srinivasan & Shi 2006;;Globally Optimal Soft Hypergraph Matching - 2;;Globally Optimal Soft Hypergraph Matching - 3;;Globally Optimal Soft Hypergraph Matching - 4;;Globally Optimal Soft Hypergraph Matching - 5;;Successive Projections;;Globally Optimal Soft Hypergraph Matching - 6;;Sampling;;Runtime;;Experiments on Graphs - 1;;Experiments on Graphs - 2;;Limitations on Graphs ;;feature Matching in Computer Vision;;Global Affine Transformation;;Non-rigid Matching - 1;;Non-rigid Matching - 2;;Summary'
13136,'lecture','en',12410,'2010-06-25','2010-07-20','A metric notion of dimension and its applications to learning','Let us define the dimension of a metric space as the minimum k>0 such that every ball in the metric space can be covered by 2^k balls of half the radius. This definition has several attractive features besides being applicable to every metric space. For instance, it coincides with the standard notion of dimension in Euclidean spaces, but captures also nonlinear structures such as manifolds. \nMetric spaces of low dimension (under the above definition) occur naturally in many contexts. I will discuss recent theoretical results regarding such metric spaces, including questions such as embeddability, dimension reduction, Nearest Neighbor Search, and large-margin classification, the common thread being that low dimension implies algorithmic efficiency. ','A Metric Notion of Dimension and Its Applications to Learning;;Finite metric spaces;;Intrinsic Dimension;;A Metric Notion of Dimension;;Example: Earthmover metric;;Applications of Doubling Metrics;;Near Neighbor Search (NNS);;NNS in Doubling Metrics;;Nets;;Navigating nets;;The JL Lemma;;A Stronger Version of JL?;;Embedding for a Single Scale;;Snowflake Embedding;;Distance-Based Classification;;Efficient Classification of Metric Data;;The Bigger Picture'
13137,'lecture','en',12410,'2010-06-25','2010-07-20','A note of caution regarding distances on graphs','Non-geometric data is often represented in form of a graph where edges represent similarity or local relationships between instances. One elegant way to exploit the global structure of the graph is implemented by the commute distance (also known as resistance distance). Supposedly it has the property that vertices from the same cluster are \"close\" to each other whereas vertices from different clusters are \"far\" from each other. We study the behavior of the commute distance as the size of the underlying graph increases. We prove that the commute distance converges to an expression that does not take into account the structure of the graph and that is completely meaningless as a distance function on the graph. Consequently, the use of the raw commute distance for machine learning purposes is strongly discouraged for large graphs and in high dimensions. We suspect that a similar behavior holds for several other distances on graphs. ','A Note of Caution Regarding Distances on Graphs;;Graph in machine learning;;Global distance function between vertices;;Commute distance: two definitions;;The resistance distance is very appealing - 1;;The resistance distance is very appealing - 2;;Question;;Answer;;Convergence Theorem;;First intuition;;Second intuition;;Simulations - 1;;Simulations - 2;;Summary and outlook - 1;;Summary and outlook - 2'
13138,'panel','en',12410,'2010-06-25','2010-07-20','Is non-(geo)metricity an issue for machine learning?',NULL,NULL
13139,'lecture','en',12410,'2010-06-25','2010-07-20','Scalable algorithms for learning on graphs','Networked data are found in a variety of domains: Web, social networks, biological networks, and many others. In learning tasks, networked data are often represented as a weighted graph whose edge weights reflect the similarity between incident nodes. In this talk, we consider the problem of classifying the nodes of an arbitrary given graph in the game-theoretic mistake bound model. We characterize the optimal predictive performance in terms of the cutsize of the graph\'s random spanning tree, and describe a randomized prediction algorithm achieving the optimal performance while running in expected time sublinear in the graph size (on most graphs). These results are then extended to the active learning model, where training labels are obtained by querying nodes selected by the algorithm. We describe a fast query placement strategy that, in the special case of trees, achieves the optimal number of mistakes when classifying the non-queried nodes. \nJoint work with: Claudio Gentile, Fabio Vitale and Giovanni Zappella. ',NULL
13166,'opening','en',13108,'2010-07-05','2010-08-04','Welcome',NULL,NULL
13167,'lecture','en',13108,'2010-07-05','2010-08-05','Introduction to Machine Learning','How can we represent data on a computer and use it to learn to perform\nuseful tasks? This lecture reviews some simple classification and\nregression rules, discusses under- and over-fitting and emphasises the\nutility of defining objective functions for learning. There is also a\nshort overview of Bayesian learning, and some practical tips for\npre-processing and visualizing data. The lecture ends with a brief\nmention of unsupervised learning and related topics.','Introduction to Machine Learning;;Face detection;;What do we do? (1);;What do we do? (2);;Response surface optimization;;Speech recognition ;;Recommender systems;;Roadmap;;Oranges and Lemons;;A two-dimensional space;;Stars and Galaxies;;Linear classier;;The weight vector (1);;The weight vector (2);;Learning the weights (1);;Learning the weights (2);;Implementing the bias;;Output of the perceptron;;The perceptron;;K-Nearest neighbours classier;;The odd-ball orange;;Decision boundaries;;LANDSAT application;;Parametric vs. non-parametric;;Linear classier revisited;;Nonlinear basis functions;;Batch supervised learning;;Linear regression;;Linear regression (with features);;Neighbour-based regression;;Simplest kernel smoothing (1);;Simplest kernel smoothing (2);;Least squares classier (1);;Least squares classier (2);;Roadmap;;Algorithm\'s Objective/Cost;;Loss functions;;Choosing loss functions;;Squared error;;Comparing loss functions;;Logistic regression (1);;Logistic regression (2);;Over fitting;;Generalization;;Validation set;;Learning curves;;Using validation sets;;Early stopping;;Regularization (1);;Regularization (2);;Different regularizers;;Regularization constants;;Learning theory;;The Bayesian view;;Bayesian procedure;;Bayesian connections;;Bayesian logistic regression;;Bayesian logistic regression;;Bayesian computations;;Bayesian models;;Supervised learning;;Pre-processing;;Rescaling and centering;;Log-transform +ve inputs;;Encoding attributes;;Basis functions features;;Feature engineering;;The SIFT story;;Creating extra data;;PCA | Principal Components;;PCA applied to DNA data (1);;PCA applied to DNA data (2);;Visualization;;Things to try;;Tours, linked plots, more;;Unsupervised Learning;;I see clusters;;K-means demo (1);;K-means demo (2);;K-means demo (3);;K-means demo (4);;K-means demo (5);;K-means demo (6);;K-means demo (7);;K-means demo (8);;K-means demo (9);;K-means demo (10);;K-means demo (11);;Mixtures of Gaussians;;Dimensionality reduction;;Density estimation;;\"Missing data\";;Underfitting;;More underfitting;;Building richer models;;Summary;;What I haven\'t covered;;A rant about least squares'
13168,'lecture','en',13108,'2010-07-06','2010-08-05','Probability and Mathematical Needs','This lectures covers basics in linear algebra and probabilities as well as a\nbrief introduction to optimization.\nIn linear algebra, the lecture starts with the definition of vectors spaces,\ndimension, basis, span of vectors and so forth. Norms and dot products as well\nas Hilbert spaces are introduced. Then the problem of solving linear system is\ntackled, introducing matrices, eigenvalues... and some common factorization\n(SVD, LU, Choleski, QR).\nIn probabilities, we start from the definition of discrete and continuous random\nvariables, give common examples, introduce the concepts of independence and\nconditional probabilities. We tackle estimation through Bayes framework, give\nthe basic definitions in information theory (entropy, Kullback-Leibler\ndivergence) and introduce error bounds (Hoeffding bounds).\nOptimization is briefly introduced defining extrema and convex functions. An\nexample of constrained minimization is demonstrated.','Probabilities and mathematical needs;;Outline;;Vector spaces (1);;Vector spaces (2);;Vector spaces (3);;Definition (Vector space);;Vector subspaces, family of vectors, dimension;;Bases;;Orthogonality, dot product, norm (1);;Orthogonality, dot product, norm (2);;Orthonormal bases;;Hyperplanes (1);;Hyperplanes (2);;Matrices (1);;Matrices (2);;Matrices (3);;Matrices (4);;Square matrices (m=d);;Inverting a matrix (1);;Inverting a matrix (2);;Inverting a matrix (3);;Inverting a matrix (4);;Matrix determinant;;Eigenvalues, eigenvectors;;Singular value decomposition (1);;Singular value decomposition (2);;Singular value decomposition (3);;Singular value decomposition (4);;Singular value decomposition (5);;Singular value decomposition (6);;Other decompositions;;Framework (1);;Framework (2);;bootcamp2010_anthoine_pmn_01_Page_34;;Random variables;;Discrete random variables - Examples;;Discrete random variables (1);;Discrete random variables ;;bootcamp2010_anthoine_pmn_01_Page_39;;Discrete random variables (2);;Bernoulli variables;;Discrete random vectors;;Discrete random vectors - Example;;Continuous random variables (1);;Continuous random variables (2);;Continuous random variables (3);;Joint probabilities (1);;Joint probabilities (2);;Joint probabilities (3);;Independence (1);;Independence (2);;Conditional probabilities (1);;Conditional probabilities (2);;Conditional probabilities (3);;Conditional probabilities (4);;Bayes rule, maximum likelihood, maximum a posteriori;;Information theory;;Approximations and confidence intervals (1);;Approximations and confidence intervals (2);;Approximations and confidence intervals (3);;Approximations and confidence intervals (4);;Approximations and confidence intervals (5);;Approximations and confidence intervals (6);;Approximations and confidence intervals (7);;Approximations and confidence intervals (8);;Minimizing a function (1);;Minimizing a function (2);;Convex functions (1);;Convex functions (2);;A convex and constrained problem in classification'
13169,'lecture','en',13108,'2010-07-07','2010-08-05','Graphical Models','We will discuss probabilistic graphical models associated to directed and\nundirected graphs. We will introduce exact inference algorithms, such as the\nsum-product algorithm, and apply it to hidden Markov models. We will also\ndiscuss elements of learning in graphical models including maximum likelihood,\nmaximum a posteriori and the expectation-maximisation algorithm.','An Introduction to Probabilistic Graphical Models;;Reference material;;Statistical machine learning: A mariage between statistics and computer science;;Graphical models: A marriage between probability theory and graph theory;;Graphical models are applied in ...;;Organising document collections (Blei et al., JMLR 2003);;Bioinformatics (Husmeier et al.);;Image denoising (McAuley et al., ICML 2006);;Printer infrastructure management;;Overview (1);;Basics;;Conditional independence (CI);;CI examples;;Probabilistic graphical model;;Overview (2);;Bayesian networks (directed graphical models);;Factorisation in directed graphical models (1);;Factorisation in directed graphical models (2);;D-separation;;Head-to-tail nodes: independence;;Head-to-tail nodes: conditional independence;;Tail-to-tail nodes: independence;;Tail-to-tail nodes: conditional independence;;Head-to-head nodes: independence;;Head-to-head nodes: conditional independence;;Blocked paths;;D-separation, CI and factorisation;;Markov blanket in Bayesian networks;;Overview (3);;Markov random elds (undirected graphical models);;Graph separation;;Cliques;;Factorisation in undirected graphical models;;Separation, CI and factorisation;;MRFs versus Bayesian networks;;Mapping a Bayesian networks into a MRF;;Overview (4);;Exact inference in graphical models;;Graphical interpretation of Bayes\' rule;;Belief propagation in a (Markov) chain (1);;Belief propagation in a (Markov) chain (2);;Belief propagation in a tree;;Factor graph;;Converting a DAG into a factor graph;;Converting an undirected graph into a factor graph;;Sum-product algorithm (1);;Sum-product algorithm (2);;Sum-product algorithm (3);;Incorporating data;;Hidden Markov model (HMM);;Sum-product in action (HMM factor graphs);;Sum-product in action (HMM forward recursion);;Sum-product in action (HMM backward recursion);;HMM with 3 states and Gaussian noise;;Applications of HMMs;;Max-product algorithm;;Max-sum algorithm;;Max-sum algorithm with backtracking;;Junction-tree algorithm;;Overview (5);;Learning in graphical models;;Maximum likelihood (ML);;ML in Bayesian networks;;Maximum likelihood in MRFs;;Maximum a posteriori (MAP);;Expectation-maximisation (EM);;EM (lower bound);;EM (principle);;EM (algorithm) ;;Mixture of Bernoulli distributions;;Mixture of Bernoullis (application);;Mixture of Bernoullis (EM updates);;Mixture of Gaussians (Old Faithful geyser data);;Want to know more about our research?'
13170,'lecture','en',13108,'2010-07-08','2010-08-05','Introduction to Kernel Methods','In this talk, we are going to see the basics of kernels methods. After a brief\npresentation of a very simple kernel classifier, we\'ll give the definition of a\npostive definite kernel and explain Support vector machine learning. Then, a few\nkernels for structured data, namely sequences and graphs, will be described. The\nrepresenter theorem is presented, which explains the rationale for the usual\nkernel expansion encountered when working with kernel methods. Finally, a few\nelements from statistical learning theory are given.','Introduction to kernel methods;;Outline;;Warming up;;Focus: binary classification (1);;Focus: binary classification (2);;Quick reminders: vector space and inner product (1);;Quick reminders: vector space and inner product (2);;Quick reminders: vector space and inner product (3);;A simple linear classifier (1);;A simple linear classifier (2);;A simple linear classifier (3);;A simple linear classifier (4);;The kernel trick;;Lineairly classifying in feature space;;Mercer Kernels;;Kernel trick recipe;;Back to the simple kernelized classifier;;Common kernels (1);;Common kernels (2);;Back to the simple kernelized classifier (2);;Back to the simple kernelized classifier (3);;(Kernel) Gram matrices (1);;(Kernel) Gram matrices (2);;Partial conclusion (1);;Support Vector Machines;;Support Vector Classification [Boser et al., 1992, Cortes and Vapnik, 1995;;Hard margin linear SVM;;Hard margin linear SVM and convex optimization (1);;Hard margin linear SVM and convex optimization (2);;Hard margin linear SVM and convex optimization (3);;Introducing Lagrange multipliers;;Switching the min and the max;;A dual quadratic program;;On the dual formulation and support vectors (1);;On the dual formulation and support vectors (2);;Soft margin linear SVM (1);;Soft margin linear SVM (2);;Soft margin linear SVM (3);;Nonlinear SVM: tricking SVMs with kernels;;Partial conclusion (2);;Examples of kernels for structures;;Prediction on structured data;;A rough scale on classification problems difficulty;;Classifying sequences;;Classifying graphs;;Working with structured data made easier by kernel methods;;Combining Gram matrices to classify proteins (1);;Combining Gram matrices to classify proteins (2);;Building sequence kernels;;Spectrum kernel [Leslie et al., 2002];;Spectrum kernel (2);;Spectrum kernel (3);;Spectrum kernel (4);;Spectrum kernel (5);;Mismatch String Kernel [Leslie et al., 2003];;Fisher kernels [Jaakkola and Haussler, 1998];;Reminders on graphs (1);;Reminders on graphs (2);;Reminders on graphs (3);;Reminders on graphs (4);;Reminders on graphs (5);;Naive/stupid kernels;;Convolution kernels;;Walk/path based graph kernels;;Kernels based on powers of adjacency matrices [Gaertner et al., 2003];;Kernels based on powers of adjacency matrices (2);;Kernels based on powers of adjacency matrices (3);;Graph-structured spaces and kernels (1);;Graph-structured spaces and kernels (2);;Partial conclusion (3);;The Representer Theorem;;Question of interest;;Main result;;Building the reproducing kernel Hibert space;;Proof of the representer theorem;;Partial conclusion (4);;bootcamp2010_ralaivola_ikm_01_Page_077;;bootcamp2010_ralaivola_ikm_01_Page_078;;bootcamp2010_ralaivola_ikm_01_Page_079;;bootcamp2010_ralaivola_ikm_01_Page_080;;bootcamp2010_ralaivola_ikm_01_Page_081;;bootcamp2010_ralaivola_ikm_01_Page_082;;bootcamp2010_ralaivola_ikm_01_Page_083;;bootcamp2010_ralaivola_ikm_01_Page_084;;bootcamp2010_ralaivola_ikm_01_Page_085;;bootcamp2010_ralaivola_ikm_01_Page_086;;bootcamp2010_ralaivola_ikm_01_Page_087;;bootcamp2010_ralaivola_ikm_01_Page_088;;bootcamp2010_ralaivola_ikm_01_Page_089;;bootcamp2010_ralaivola_ikm_01_Page_090;;bootcamp2010_ralaivola_ikm_01_Page_091;;bootcamp2010_ralaivola_ikm_01_Page_092;;bootcamp2010_ralaivola_ikm_01_Page_093;;bootcamp2010_ralaivola_ikm_01_Page_094;;bootcamp2010_ralaivola_ikm_01_Page_095;;bootcamp2010_ralaivola_ikm_01_Page_096;;bootcamp2010_ralaivola_ikm_01_Page_097;;bootcamp2010_ralaivola_ikm_01_Page_098;;bootcamp2010_ralaivola_ikm_01_Page_099;;bootcamp2010_ralaivola_ikm_01_Page_100;;bootcamp2010_ralaivola_ikm_01_Page_101;;bootcamp2010_ralaivola_ikm_01_Page_102;;bootcamp2010_ralaivola_ikm_01_Page_103;;bootcamp2010_ralaivola_ikm_01_Page_104;;bootcamp2010_ralaivola_ikm_01_Page_105;;bootcamp2010_ralaivola_ikm_01_Page_106;;Conclusion;;Conclusion and open questions;;Thank you;;bootcamp2010_ralaivola_ikm_01_Page_110;;bootcamp2010_ralaivola_ikm_01_Page_111;;bootcamp2010_ralaivola_ikm_01_Page_112;;bootcamp2010_ralaivola_ikm_01_Page_113;;bootcamp2010_ralaivola_ikm_01_Page_114'
13171,'lecture','en',13108,'2010-07-08','2010-08-05','Machine Learning for Natural Languages Processing','Probabilistic Context Free Grammars (PCFG) is a powerful formalism\nthat has been used for several applications in Computational Linguistics. One\nimportant problem of these models is the probabilistic estimation of the\nprobabilistic part of the models. This probabilistic estimation is based on\ntabular algorithms similar to the CKY algorithm. We review these estimation\nalgorithms and their properties. The use of these models for Language Modeling\nand Machine Translation is also introduced. Finally, an interactive-predictive\nframework for parsing is explained, that can be used for developing both on-line\nlearning techniques and active learning techniques.','Probabilistic Estimation of Probabilistic Syntactic Models;;Index - 1;;Index - 2;;Introduction - 1;;Introduction - 2;;Introduction - 3;;Introduction - 4;;Introduction - 5;;Introduction - 6;;Syntactic Models and Parsing - 1;;Syntactic Models and Parsing - 2;;Syntactic Models and Parsing - 3;;Syntactic Models and Parsing - 4;;Syntactic Models for Language Modeling - 1;;Syntactic Models for Language Modeling - 2;;Syntactic Models for Language Modeling - 3;;Syntactic Models for Machine Translation - 1;;Syntactic Models for Machine Translation - 2;;Index - 3;;Notation and Definitions - 1;;Notation and Definitions - 2;;Notation and Definitions - 3;;Notation and Definitions - 4;;Notation and Definitions - 5;;Notation and Definitions - 6;;Notation and Definitions - 7;;Notation and Definitions - 8;;Notation and Definitions - 9;;Notation and Definitions - 10;;Notation and Definitions - 11;;Basic Probabilistic Properties of Syntatic Models;;CKY - Based Parsing Algorithms - 1;;CKY - Based Parsing Algorithms - 2;;CKY - Based Parsing Algorithms - 3;;CKY - Based Parsing Algorithms - 4;;CKY - Based Parsing Algorithms - 5;;Index - 4;;Introduction - 7;;Introduction - 8;;Introduction - 9;;Inside - Outside Algorithm - 1;;Inside - Outside Algorithm - 2;;Viterbi Algorithm - 1;;Viterbi Algorithm - 2;;Viterbi Algorithm - 3;;Probabilistic Properties of the Estimated PCFG - 1;;Probabilistic Properties of the Estimated PCFG - 2;;Probabilistic Properties of the Estimated PCFG - 3;;Probabilistic Properties of the Estimated PCFG - 4;;Use of PCFG for LM - 1;;Use of PCFG for LM - 2;;Use of PCFG for LM - 3;;Use of PCFG for LM - 4;;Use of PCFG for LM - 5;;Use of PCFG for LM - 6;;Use of PCFG for LM - 7;;Use of PCFG for LM - 8;;Use of PCFG for LM - 9;;Index - 5;;Introduction - 10;;Introduction - 11;;Introduction - 12;;Introduction - 13;;Introduction - 14;;Parsing with SITG - 1;;Parsing with SITG - 2;;Parsing with SITG - 3;;Parsing with SITG - 4;;Use of SITG for MT - 1;;Use of SITG for MT - 2;;Use of SITG for MT - 3;;Index - 6;;On-line Learning of Syntatic Models - 1;;On-line Learning of Syntatic Models - 2;;On-line Learning of Syntatic Models - 3;;On-line Learning of Syntatic Models - 4;;On-line Learning of Syntatic Models - 5;;On-line Learning of Syntatic Models - 6;;On-line Learning of Syntatic Models - 7;;Active Learning of Syntatic Models - 1;;Active Learning of Syntatic Models - 2;;Active Learning of Syntatic Models - 3;;Active Learning of Syntatic Models - 4;;Active Learning of Syntatic Models - 5;;IPP: A Framework for Active Learning - 1;;IPP: A Framework for Active Learning - 2;;IPP: A Framework for Active Learning - 3;;IPP: A Framework for Active Learning - 4;;IPP: A Framework for Active Learning - 5;;IPP: A Framework for Active Learning - 6;;IPP: A Framework for Active Learning - 7;;References - 1;;References - 2;;References - 3;;References - 4;;References - 5;;Appendices;;Appendix A - 1;;Appendix A - 2;;Appendix B - 1;;Appendix B - 2;;Appendix C'
13172,'lecture','en',13108,'2010-07-09','2010-08-05','Speech Processing','The lecture presents various aspects of automatic speech processing\n(SP), from spoken contents extraction to high level categorization of\nspeech signals. We show how machine learning provides solutions to the\nmain issues that the speech processing systems have to deal with.\nSpeech is one of the main way that humans communicate together. It is a\ncomplex process that involves, in a highly integrated way, perception\nabilities and cognitive processes. In spite of the efforts produced by\nthe scientific community for simulating these abilities, knowledge-based\napproaches failed in modeling of speech.\nNowadays, most of the SP methods relies on statistical modeling of\nspeech. The lecture presents this theorical framework in which the major\nissues in speech processing are formulated. Then, the main tasks of SP\nare overviewed, especially speaker identification and speech recognition\nand understanding.','Speech Processing - 1;;Speech Processing - 2;;Speech Processing - 3;;What is Speech? - 1;;What is Speech? - 2;;Speech Processing: the engineer point of view - 1;;Speech Processing: the engineer point of view - 2;;What is Speech? - 3;;Speech processing and A.I.;;History of Speech processing;;Statistical Speech modeling - 1;;Statistical Speech modeling - 2;;Statistical Speech modeling - 3;;Statistical Speech modeling - 4;;Statistical Speech modeling - 5;;Statistical Speech modeling - 6;;Statistical Speech modeling - 7;;Statistical Speech modeling - 8;;Statistical Speech modeling - 9;;Statistical Speech modeling - 10;;Statistical Speech modeling - 11;;Statistical Speech modeling - 12;;Statistical Speech modeling - 13;;Statistical Speech modeling - 14;;Statistical Speech modeling - 15;;Statistical Speech modeling - 16;;Statistical Speech modeling - 17;;Statistical Speech modeling - 18;;Statistical Speech modeling - 19;;Statistical Speech modeling - 20;;Statistical Speech modeling - 21;;Speech Processing systems;;ASR: some applications - 1;;ASR: some applications - 2;;ASR: some applications - 3;;ASR: some applications - 4;;ASR: some applications - 5;;ASR: some applications - 6;;Fundamentals of statistical ASR - 1;;Fundamentals of statistical ASR - 2;;Fundamentals of statistical ASR - 3;;Fundamentals of statistical ASR - 4;;Fundamentals of statistical ASR - 5;;Fundamentals of statistical ASR - 6;;Fundamentals of statistical ASR - 7;;Fundamentals of statistical ASR - 8;;Fundamentals of statistical ASR - 9;;Fundamentals of statistical ASR - 10;;Fundamentals of statistical ASR - 11;;Where we are in LVCSR?;;What about the cost?;;ASR: conclusion;;Speech Analytics - 1;;Speech Analytics - 2;;Speaker Recognition - 1;;Speaker Recognition - 2;;GMM based speaker identification;;Performance of state-of-the art speaker identification systems;;Statistical speech processing: conclusions'
13174,'lecture','en',13108,'2010-07-13','2010-08-05',' Online Learning','This talk aim at presenting a first approaching to the Online Learning\nmethodology. It starts presenting the linear Perceptron algorithm and several\nderivations. The kernel Perceptron algorithm is also motivated. The Passive-\nAggressive (PA) Online Learning algorithm is then presented for binary\nclassification, regression and multi-class problems as well. Linear and kernel\nversion of PA are presented and discussed playing an especial attention to the\nupdate rules derivation. An important issue is to be able to control the model\ncomplexity, to this end different budgeted online algorithms are proposed, first\nfor the conventional Perceptron and derivations and second, for the PA\nalgorithm. Finally some examples of online learning applications are presented\nin order to motivate the audience to the application of these techniques in\ndifferent real scenarios.','Online Learning;;Index;;Introduction - 1;;Introduction - 2;;Introduction - 3;;Introduction - Notation;;Linear Models - 1;;Linear Models - 2;;Linear Models - 3;;Linear Models - 4;;Linear Models - 5;;Linear Models - 6;;Linear Models - 7;;Online Learning: Perceptron - 1;;Online Learning: Perceptron - 2;;Online Learning: Perceptron - 3;;Online Learning: Perceptron - 4;;Online Learning: Perceptron - 5;;Online Learning: Perceptron - General Model;;Online Learning: Perceptron - MIRA - 1;;Online Learning: Perceptron - The shifting Perceptron - 1;;Online Learning: Perceptron - The shifting Perceptron - 2;;Online Learning: Perceptron - Extension to Multiclass;;Online Learning: Perceptron - Multiclass algorithms - 1;;Online Learning: Perceptron - Multiclass algorithms - 2;;Online Learning: Perceptron - MIRA - 2;;Online Learning: Kernel Perceptron - 1;;Online Learning: Kernel Perceptron - 2;;Online Learning: Kernel Perceptron - 3;;Passive - Agressive Online Learning - 1;;Passive - Agressive Online Learning - 2;;Passive - Agressive Online Learning - 3;;Passive - Agressive Online Learning - 4;;Passive - Agressive Online Learning - 5;;Passive - Agressive Online Learning - 6;;Passive - Agressive Online Learning - 7;;Passive - Agressive Online Learning - 8;;Passive - Agressive Online Learning - 9;;Passive - Agressive Online Learning - 10;;Passive - Agressive Online Learning - 11;;Passive - Agressive Online Learning - 12;;Passive - Agressive Online Learning - 13;;PA with kernels - 1;;PA with kernels - 2;;PA with kernels - 3;;PA with kernels - 4;;Passive - Agressive Online Learning - 14;;PA for Regression - 1;;PA for Regression - 2;;PA for Regression - 3;;PA for multiclass problems - 1;;PA for multiclass problems - 2;;PA for multiclass problems - 3;;PA for multiclass problems - 4;;Online Learning on a Budget ;;Online Classification on a Budget ;;Online Classification on a Budget : Budget Perceptron - 1;;Online Classification on a Budget : Budget Perceptron - 2;;Online Classification on a Budget : Budget Perceptron - 3;;Online Classification on a Budget : Forgetron - 1;;Online Classification on a Budget : Forgetron - 2;;Online Classification on a Budget : Forgetron - 3;;Online Classification on a Budget : LBP;;Online Classification on a Budget : Stoptron;;Online Classification on a Budget : Randomized Budget Perceptron;;Online PA on a Budget - 1;;Online PA on a Budget - 2;;Online PA on a Budget - 3;;Online PA on a Budget - 4;;Online PA on a Budget - 5;;Online Learning Applications;;Online Learning for Video Tagging;;Introduction - 4;;Video Tagging - 1;;Video Tagging - 2;;Video Tagging - 3;;Video Tagging - 4;;Linear Approaches;;Online Learning: PAMIR - 1;;Online Learning: PAMIR - 2;;Online Learning: PAMIR - 3;;Stochastic Gradient Descent: MROC - 1;;Stochastic Gradient Descent: MROC - 2;;Stochastic Gradient Descent: MROC - 3;;Experiments;;Results - 1;;Results per concept;;Results - 2;;Conclusions;;Online Learning for Relevance Feedback on Image Retrieval;;Introduction - 5;;Datasets;;Results - 3;;Results - 4;;References'
13175,'lecture','en',13108,'2010-07-12','2010-07-16',' Grammatical Inference','Grammatical inference is about learning automata and grammars given\ninformation about the language.\nDuring this tutorial we will introduce the problem and its applications,\nstudy the various paradigms and\nrelated learnability results and discuss some of the most important\nalgorithms in the field.','Grammatical inference;;Acknowledgements;;Outline;;Gramatical inference;;The functions/goals;;The data: examples of strings - 1;;The data: examples of strings - 2;;The data: examples of strings - 3;;The data: examples of strings - 4;;The data: examples of strings - 5;;The data: examples of strings - 6;;The data: examples of strings - 7;;The data: examples of strings - 8;;The data: examples of strings - 9;;The data: examples of strings - 10;;And also;;An introductory example;;The problem;;Hypothesis;;Example: (the prisoner\'s dilemma) - 1;;Example: (the prisoner\'s dilemma) - 2;;Example: (the prisoner\'s dilemma) - 3;;The general problem;;Suppose we know the oponent\'s strategy;;Graph - 1;;Graph - 2;;Question;;Data;;First move;;Second move;;Third move;;Fourth move;;Fifth move;;Sixth move - 1;;Sixth move - 2;;Seventh move;;Eight move;;Ninth move - 1;;Ninth move - 2;;Ninth move - 3;;Ninth move - 4;;Ninth move - 5;;Ninth move - 6;;Ninth move - 7;;Result;;How do we get hold of the learning data?;;An open problem;;Tit for Tat;;What does learning mean?;;Motivating question - 1;;Motivating question - 2;;Motivating question - 3;;What usually is called \"having learnt\";;What we would like to say;;Why should we bother and those in statistical machine learning not?;;Some convergence criteria;;(if not) What would we like to say?;;Suppose we cannot say anything of teh sort?;;Non probabilistic setting?;;Example - 1;;Identification in the limit;;The general idea;;A presentation is;;Some types of presentations - 1;;Some types of presentations - 2;;Presentation;;Learning function;;Convergence to a hypothesis;;Identification in the limit;;Consistency;;Conservatism;;What about efficiency?;;More precise definition of convergence;;Resource bounded identification in the limit;;Probabilistic settings;;Learning a language from sampling;;PAC - learning - 1;;PAC - learning - 2;;PAC - learning - 3;;French radio;;Results - 1;;Alternatively;;No error;;Results - 2;;With error;;Results - 3;;Conclusion - 1;;Learning from an informant ;;Motivation;;Ideas;;Alternative;;Obviously many possible candidates ;;Two types of final states;;What is determinism about?;;The prefix tree acceptor;;From the sample to the PTA - 1;;From the sample to the PTA - 2;;Red, Blue and White states;;Merge and fold - 1;;Merge and fold - 2;;Merge and fold - 3;;Merge and fold - 4;;Merge and fold - 5;;Merge and fold - 6;;Merge and fold - 7;;Merge and fold - 8;;Merge and fold - 9;;Merge and fold - 10;;Merge and fold - 11;;Merge and fold - 12;;Merge and fold - 13;;Merge and fold - 14;;Merge and fold - 15;;Merge and fold - 16;;Merge and fold - 17;;Merge and fold - 18;;Merge and fold - 19;;Merge and fold - 20;;Merge and fold - 21;;Merge and fold - 22;;Merge and fold - 23;;Merge and fold - 24;;Merge and fold - 25;;Merge and fold - 26;;A characteristic sample;;About characteristic samples;;Exercises;;Open problems;;Conclusion - 2;;Learning from text;;GI as a search problem;;Teh theory;;Limit point;;L is a limit point;;Theorem;;Mincons slasses;;Existence of an accumulation point ( Kapur 91);;L is an accumulation point;;Theorem (for Mincons classes);;Infinite Elasticity -1;;Infinite Elasticity -2;;Finite Elasticity ;;Theorem (Wright);;Tell tale sets;;Theorem (Angluin);;Proposition (Kapur 91);;Learning by observing;;Definition - 1;;Definition - 2;;An example;;Window language;;The hierarchy of k-TSS languages;;A language that is not k-testable;;K-TSS inference;;Example - 2;;Building the corresponding automaton;;Running the algorithm;;Properties - 1;;Properties - 2;;Properties - 3;;Extensions;;Learning actively;;About learning with queries;;The Oracle;;Some queries;;Membership queries ;;Equivalence (weak) queries;;Equivalence (strong) queries;;Subset queries;;Correct learning;;The Minimal Adequate Teacher;;General idea of L*;;An observation table - 1;;An observation table - 2;;Meaning - 1;;Meaning - 2;;Equivalent prefixes;;Building a DFA from a table - 1;;Building a DFA from a table - 2;;Some rules;;An incomplete table;;Good idea;;A table is;;And a table that is not closed;;What do we do when we have a table that is not closed?;;An inconsistent table;;A table is consistent if;;What do we do when we have an inconsistent table?;;What do we do when we have a closed and inconsistent table?;;What do we do if we get a counter-example?;;Run of the algorithm;;An equivalence query is made! - 1;;An equivalence query is made! - 2;;An equivalence query is made! - 3;;Polynomial;;Conclusion - 3;;Conclusion - 4;;Extensions (PFA, transducers, tree automata);;Main results for learning PFA;;Main results for learning transducers;;10 Conclusions;;Open problems;;Some addresses to start working'
